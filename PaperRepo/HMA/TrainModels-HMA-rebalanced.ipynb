{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9318ec3e",
   "metadata": {},
   "source": [
    "# Train the Models for some/all your datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af03e3",
   "metadata": {},
   "source": [
    "### First just run the cell below, it should hopefully complete without error (expect some Warnings from TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed1e1813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using TensorFlow v2.3.0\n",
      "Using TensorFlow v2.3.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "#load some packages in\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as python_random\n",
    "from numba import njit\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from stemutils.io import Path\n",
    "import hyperspy.api as hs\n",
    "import concurrent.futures\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import lru_cache\n",
    "from stemseg.processing_funcs import *\n",
    "\n",
    "#set some variables\n",
    "print('Using TensorFlow v%s' % tf.__version__)\n",
    "plt.style.use('default')\n",
    "\n",
    "\n",
    "#define some functions\n",
    "\n",
    "###################################################\n",
    "########### Data Preprocessing ####################\n",
    "###################################################\n",
    "\n",
    "def batch_resize(d, bs=512):\n",
    "    if len(d.shape) == 4:\n",
    "        flat_d = flatten_nav(d)\n",
    "    else:\n",
    "        flat_d = d\n",
    "    n_batches = int(np.ceil(flat_d.shape[0]//bs))\n",
    "    batches = [flat_d[i*bs:(i+1)*bs] for i in range(n_batches+1)]\n",
    "    if len(batches[-1])==0:\n",
    "        batches.pop(-1)\n",
    "    print(len(batches[-1]))\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=4) as exe:\n",
    "        res = [exe.submit(resize, batch, (batch.shape[0],128,128)) for batch in batches]\n",
    "    r_batches = [f.result() for f in res]\n",
    "    return np.concatenate(r_batches, axis = 0).reshape((d.shape[0],128,128))\n",
    "\n",
    "def data_manip(d, bs = 512):\n",
    "    if type(d) != np.ndarray:\n",
    "        print('dask to numpy')\n",
    "        d = d.compute()\n",
    "        print('dask to numpy done')\n",
    "    print('started data manipulations')\n",
    "    #d = resize(d,(d.shape[0],128,128))\n",
    "    print('resized')\n",
    "    d = d.astype('float32')\n",
    "    for i in range(d.shape[0]):\n",
    "        d_max = np.max(d[i])\n",
    "        d[i] = d[i]/d_max\n",
    "    d = batch_resize(d, bs)\n",
    "    scaler = np.log(1001)\n",
    "    return np.log((d*1000)+1)/scaler \n",
    "\n",
    "\n",
    "def data_manip_lowq(d, central_box = 128):\n",
    "    pxc, pyc = d.shape[1]//2, d.shape[2]//2 \n",
    "    pxl, pxu = pxc - central_box//2, pxc + central_box//2 \n",
    "    pyl, pyu = pyc - central_box//2, pyc + central_box//2 \n",
    "    \n",
    "    d = d[:, pxl:pxu, pyl:pyu]\n",
    "    if type(d) != np.ndarray:\n",
    "        print('dask to numpy')\n",
    "        d = d.compute()\n",
    "        print('dask to numpy done')\n",
    "    print('started data manipulations')\n",
    "    #d = resize(d,(d.shape[0],128,128))\n",
    "    print('resized')\n",
    "    d = d.astype('float32')\n",
    "    for i in range(d.shape[0]):\n",
    "        d_max = np.max(d[i])\n",
    "        d[i] = d[i]/d_max\n",
    "    \n",
    "    scaler = np.log(1001)\n",
    "    return np.log((d*1000)+1)/scaler \n",
    "\n",
    "\n",
    "###################################################\n",
    "###################################################\n",
    "###################################################\n",
    "\n",
    "def flatten_nav(sig):\n",
    "    shape = [sig.shape[0]*sig.shape[1]]\n",
    "    for i in sig.shape[2:]:\n",
    "        shape.append(i)\n",
    "    return sig.reshape(shape)\n",
    "\n",
    "\n",
    "class My_Custom_Generator(keras.utils.Sequence) :\n",
    "    def __init__(self, image_filenames,  batch_size) :\n",
    "        self.image_filenames = image_filenames\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n",
    "    \n",
    "    \n",
    "    @lru_cache(None)\n",
    "    def __getitem__(self, idx) :\n",
    "        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        out_img = np.asarray([np.load(file_name)[:,:,None] for file_name in batch_x])\n",
    "        return out_img, out_img\n",
    "        #return batch_x, batch_y\n",
    "        \n",
    "        \n",
    "class Array_Generator(keras.utils.Sequence) :\n",
    "    def __init__(self, images,  batch_size, target = 'same') :\n",
    "        self.images = images\n",
    "        self.batch_size = batch_size\n",
    "        if target == 'same':\n",
    "            self.target = images\n",
    "        else:\n",
    "            self.target = target\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.images) / float(self.batch_size))).astype(np.int)\n",
    "    \n",
    "    \n",
    "    @lru_cache(None)\n",
    "    def __getitem__(self, idx) :\n",
    "        out_img = self.images[idx * self.batch_size : (idx+1) * self.batch_size, :,:,None]\n",
    "        out_targ = self.target[idx * self.batch_size : (idx+1) * self.batch_size, :,:,None]\n",
    "        return out_img, out_targ\n",
    "        #return batch_x, batch_y\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        epsilon = tf.keras.backend.random_normal(shape=tf.shape(z_mean))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "def create_vae_model(hparams):\n",
    "    \n",
    "    n_img = 128\n",
    "    latent_dim = hparams['LAT']\n",
    "    beta = hparams['B']\n",
    "\n",
    "    image_input = keras.Input(shape=(n_img, n_img,1), name = 'enc_input')\n",
    "    x = layers.Conv2D(hparams['KN1'],5, strides = 2, activation='relu',padding='same', input_shape=image_input.shape, name = 'enc_conv1')(image_input)\n",
    "    x = layers.Conv2D(hparams['KN2'],5, strides = 2, activation='relu',padding='same', name = 'enc_conv2')(x)\n",
    "    x = layers.Conv2D(hparams['KN3'],5, strides = 2, activation='relu',padding='same', name = 'enc_conv3')(x)\n",
    "    x = layers.Conv2D(hparams['KN4'],5, strides = 2, activation='relu',padding='same', name = 'enc_conv4')(x)\n",
    "    x = layers.Conv2D(hparams['KN5'],5, strides = 2, activation='relu',padding='same', name = 'enc_conv5')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(hparams['D1'], activation='relu', name = 'enc_d1')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d2_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d3_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d4_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d5_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d6_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d7_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d8_t')(x)\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean_t\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var_t\")(x)\n",
    "    z_output = Sampling()([z_mean, z_log_var])\n",
    "    encoder_VAE = keras.Model(image_input, [z_mean, z_log_var, z_output])\n",
    "\n",
    "    z_input = keras.Input(shape=(latent_dim,), name = 'dec_input_t')\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d1_t')(z_input)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d2')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d3')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d4')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d5')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d6')(x)\n",
    "    x = layers.Dense(hparams['D1'], activation=\"relu\", name = 'dec_d7')(x)\n",
    "    x = layers.Dense(4*4*hparams['KN5'], activation=\"relu\", name = 'dec_d8')(x)\n",
    "    x = layers.Reshape((4, 4,hparams['KN5']))(x)\n",
    "    x = layers.Conv2DTranspose(hparams['KN4'],5, strides = 2, activation='relu',padding='same', name = 'dec_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(hparams['KN3'],5, strides = 2, activation='relu',padding='same', name = 'dec_conv2')(x)\n",
    "    x = layers.Conv2DTranspose(hparams['KN2'],5, strides = 2, activation='relu',padding='same', name = 'dec_conv3')(x)\n",
    "    x = layers.Conv2DTranspose(hparams['KN1'],5, strides = 2, activation='relu',padding='same', name = 'dec_conv4')(x)\n",
    "    image_output = layers.Conv2DTranspose(1,5, strides = 2, activation='sigmoid',padding='same', name = 'dec_conv5')(x)\n",
    "    #image_output = layers.Conv2DTranspose(16,3, strides = 2, activation='sigmoid',padding='same')\n",
    "    #image_output = layers.Reshape((n_img, n_img,1))(x)\n",
    "    decoder_VAE = keras.Model(z_input, image_output)\n",
    "\n",
    "    # VAE class\n",
    "    class VAE(keras.Model):\n",
    "        # constructor\n",
    "        def __init__(self, encoder, decoder, **kwargs):\n",
    "            super(VAE, self).__init__(**kwargs)\n",
    "            self.encoder = encoder\n",
    "            self.decoder = decoder\n",
    "\n",
    "        # customise train_step() to implement the loss \n",
    "        def train_step(self, x):\n",
    "            if isinstance(x, tuple):\n",
    "                x = x[0]\n",
    "            with tf.GradientTape() as tape:\n",
    "                # encoding\n",
    "                z_mean, z_log_var, z = self.encoder(x)\n",
    "                # decoding\n",
    "                x_prime = self.decoder(z)\n",
    "                # reconstruction error by binary crossentropy loss\n",
    "                reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(x, x_prime)) * n_img * n_img\n",
    "                # KL divergence\n",
    "                kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "                # loss = reconstruction error + KL divergence\n",
    "                loss = reconstruction_loss + beta* kl_loss\n",
    "            # apply gradient\n",
    "            grads = tape.gradient(loss, self.trainable_weights)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "            # return loss for metrics log\n",
    "            return {\"loss\": loss}\n",
    "\n",
    "\n",
    "        def call(self, x):\n",
    "            if isinstance(x, tuple):\n",
    "                x = x[0]\n",
    "            # encoding\n",
    "            z_mean, z_log_var, z = self.encoder(x)\n",
    "            # decoding\n",
    "            x_prime = self.decoder(z)\n",
    "            return x_prime\n",
    "    # build the VAE\n",
    "    vae_model = VAE(encoder_VAE, decoder_VAE)\n",
    "\n",
    "    # compile the VAE\n",
    "    vae_model.compile(optimizer=keras.optimizers.Adam(learning_rate=hparams['LR']),loss=custom_loss)\n",
    "    vae_model.build((1,128,128,1))\n",
    "    \n",
    "    return vae_model\n",
    "\n",
    "\n",
    "\n",
    "def custom_loss(x,y):\n",
    "    n_img = 128\n",
    "    return tf.reduce_mean(keras.losses.binary_crossentropy(x, y)) * n_img * n_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d8cb2",
   "metadata": {},
   "source": [
    "### Now check that you can find the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "632ca150",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 17:07:27.274270: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 17:07:27.299328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-03-25 17:07:27.299360: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-25 17:07:27.391253: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-25 17:07:27.433357: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-25 17:07:27.442292: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-25 17:07:27.540773: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-25 17:07:27.552519: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-25 17:07:27.729550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-25 17:07:27.731351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc9b277",
   "metadata": {},
   "source": [
    "# Training a Single Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f176f5",
   "metadata": {},
   "source": [
    "### Either enter the path directly to the dp variable or use the index from the list above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bffe1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Either\n",
    "dp = Path('/dls/science/groups/imaging/ePSIC_students/Al_alloy_4DSTEM_EM19064-2/20180727_112544-9cmCL-4Mx.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67044adc",
   "metadata": {},
   "source": [
    "### Create a directory to save our intermediate model checkpoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89b8aabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel\n"
     ]
    }
   ],
   "source": [
    "mp = Path('/dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel')\n",
    "if not mp.exists():\n",
    "    mp.mkdir()\n",
    "print(mp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05f914f",
   "metadata": {},
   "source": [
    "### Load in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53835384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:hdf5plugin:blosc filter already loaded, skip it.\n",
      "WARNING:hdf5plugin:bshuf filter already loaded, skip it.\n",
      "WARNING:hdf5plugin:lz4 filter already loaded, skip it.\n",
      "WARNING:hdf5plugin:zfp filter already loaded, skip it.\n",
      "WARNING:hdf5plugin:fcidecomp filter already loaded, skip it.\n"
     ]
    }
   ],
   "source": [
    "sample = ProcessedSample(dp, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd976a9c",
   "metadata": {},
   "source": [
    "### Create a dictionary to hold some useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5f57da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be3e2406",
   "metadata": {},
   "outputs": [],
   "source": [
    "nds = flatten_nav(sample.raw_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6202317b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261121, 256, 256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a32f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = hs.load(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7184fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flat_dps = flatten_nav(ds.data)\n",
    "flat_dps = nds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "581467ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261121, 256, 256)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_dps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9e81191",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_map = np.load('/dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FitMap6.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "733ed38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"426\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f78bc848190>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(best_map, cmap='turbo', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8f289e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_bm = flatten_nav(best_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f4962b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20105"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(flat_bm ==2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70b7d4ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "resample_ds = []\n",
    "nl_resample_ds = []\n",
    "for uind in np.unique(flat_bm):\n",
    "    if uind == 1:\n",
    "        nsamples = 100\n",
    "    else:\n",
    "        nsamples = 8000\n",
    "    \n",
    "    print(uind)\n",
    "    pdf = np.where(flat_bm ==uind, 1, 0)\n",
    "    npdf = pdf/pdf.sum()\n",
    "    for i in range(20):\n",
    "        sdps = hs.signals.Signal2D(flat_dps[np.random.choice(np.arange(flat_dps.shape[0]), nsamples, False, npdf)])\n",
    "        pn_dps = sdps.copy()\n",
    "        nl_resample_ds.append(sdps.data)\n",
    "        #pn_dps.add_poissonian_noise()\n",
    "        #resample_ds.append(pn_dps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "004ea257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resample_ds = np.concatenate([x.data for x in resample_ds],axis = 0)\n",
    "nl_resample_ds = np.concatenate([x for x in nl_resample_ds],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb2f38e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322000, 256, 256)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl_resample_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4948cbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Item assignment with <class 'int'> not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_267963/3117871755.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnl_resample_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.shuffle\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.shuffle\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/dls_sw/apps/python/anaconda/4.6.14/64/envs/epsic3.7/lib/python3.7/site-packages/dask/array/core.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1469\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m             raise NotImplementedError(\n\u001b[0;32m-> 1471\u001b[0;31m                 \u001b[0;34m\"Item assignment with %s not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m             )\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Item assignment with <class 'int'> not supported"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(nl_resample_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d7b3659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322000, 256, 256)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl_resample_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a309f76f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20ab03c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask to numpy\n",
      "dask to numpy done\n",
      "started data manipulations\n",
      "resized\n"
     ]
    }
   ],
   "source": [
    "input_data = data_manip_lowq(nl_resample_ds)\n",
    "np.random.shuffle(input_data)\n",
    "#input_targets = data_manip_lowq(nlds)\n",
    "#val_data = data_manip_lowq(nl_resample_ds[::10])\n",
    "#np.random.shuffle(val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ab6791f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"399\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7871679450>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_patt = np.random.randint(0, len(input_data))\n",
    "plt.figure(figsize = (4,4))\n",
    "plt.imshow(input_data[rand_patt])\n",
    "#plt.figure(figsize = (4,4))\n",
    "#plt.imshow(input_targets[rand_patt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e3db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b9de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac1672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a40856e2",
   "metadata": {},
   "source": [
    "##### Otherwise just skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f3e252b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(322000, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "244c845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8192\n",
    "\n",
    "train_gen = Array_Generator(input_data, batch_size)#, target = input_targets)\n",
    "#valid_gen = Array_Generator(val_data, batch_size)\n",
    "\n",
    "batch_shape = train_gen[0][0].shape\n",
    "input_shape = (batch_shape[1],batch_shape[2],batch_shape[3])\n",
    "out_dims = int(train_gen[0][1].shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f66918e",
   "metadata": {},
   "source": [
    "### Check the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aff70b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"399\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7872f5eb10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_patt = np.random.randint(0, len(input_data))\n",
    "plt.figure(figsize = (4,4))\n",
    "plt.imshow(input_data[rand_patt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6a2909",
   "metadata": {},
   "source": [
    "### Set the checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b62fcf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpoint_filepath = str(mp)+'/chk-{epoch:02d}-{loss:.5e}.hdf5'\n",
    "chkpoint_model = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = chkpoint_filepath,\n",
    "    monitor=\"loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"min\",\n",
    "    save_freq=\"epoch\",\n",
    "    options=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2430e279",
   "metadata": {},
   "source": [
    "### Redefine the model parameters if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88ace2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rebin_factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ceb00f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 17:16:37.009751: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-25 17:16:37.083873: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2400000000 Hz\n",
      "2022-03-25 17:16:37.087174: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5558b9c04690 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-03-25 17:16:37.087198: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-03-25 17:16:37.212272: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5558bbb0f060 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-03-25 17:16:37.212304: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2022-03-25 17:16:37.236090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-03-25 17:16:37.236176: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-25 17:16:37.236293: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-25 17:16:37.236315: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-25 17:16:37.236332: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-25 17:16:37.236348: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-25 17:16:37.236363: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-25 17:16:37.236380: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-25 17:16:37.238147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2022-03-25 17:16:37.240412: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-25 17:16:45.184374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-25 17:16:45.184413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2022-03-25 17:16:45.184420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2022-03-25 17:16:45.232567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30132 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "sample_name = 'full'\n",
    "hparams= {'KN1':32,'KN2':64,'KN3':128, 'KN4':128, 'KN5':256,'D1':128,'D2':512,'LAT':2,'LR':0.0001, 'B':1}\n",
    "\n",
    "vae_model = create_vae_model(hparams)\n",
    "info[sample_name] = {'rebin': rebin_factor, 'hparams':hparams}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05ca6a1",
   "metadata": {},
   "source": [
    "### Will be helpful to start with a trained model so set one here (otherwise will just take longer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "33c0aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model ='/dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-34-8.73786e+03.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "468f2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model.load_weights(old_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e0450d",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "682c34e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of google.protobuf.any_pb2 failed: Traceback (most recent call last):\n",
      "  File \"/home/dto55534/.local/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/dto55534/.local/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/dls_sw/apps/python/anaconda/4.6.14/64/envs/epsic3.7/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/dls_sw/apps/python/anaconda/4.6.14/64/envs/epsic3.7/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/dls_sw/apps/python/anaconda/4.6.14/64/envs/epsic3.7/lib/python3.7/site-packages/google/protobuf/any_pb2.py\", line 71, in <module>\n",
      "    '__module__' : 'google.protobuf.any_pb2'\n",
      "TypeError: A Message class can only inherit from Message\n",
      "]\n",
      "[autoreload of google.protobuf.wrappers_pb2 failed: Traceback (most recent call last):\n",
      "  File \"/home/dto55534/.local/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/dto55534/.local/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/dls_sw/apps/python/anaconda/4.6.14/64/envs/epsic3.7/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/dls_sw/apps/python/anaconda/4.6.14/64/envs/epsic3.7/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/dls_sw/apps/python/anaconda/4.6.14/64/envs/epsic3.7/lib/python3.7/site-packages/google/protobuf/wrappers_pb2.py\", line 328, in <module>\n",
      "    '__module__' : 'google.protobuf.wrappers_pb2'\n",
      "TypeError: A Message class can only inherit from Message\n",
      "]\n",
      "[autoreload of google.protobuf.struct_pb2 failed: Traceback (most recent call last):\n",
      "  File \"/home/dto55534/.local/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/dto55534/.local/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/dls_sw/apps/python/anaconda/4.6.14/64/envs/epsic3.7/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/dls_sw/apps/python/anaconda/4.6.14/64/envs/epsic3.7/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/dls_sw/apps/python/anaconda/4.6.14/64/envs/epsic3.7/lib/python3.7/site-packages/google/protobuf/struct_pb2.py\", line 259, in <module>\n",
      "    '__module__' : 'google.protobuf.struct_pb2'\n",
      "TypeError: A Message class can only inherit from Message\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      " 2/40 [>.............................] - ETA: 1:05 - loss: 8693.5688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.8582s vs `on_train_batch_end` time: 1.2908s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.8582s vs `on_train_batch_end` time: 1.2908s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 8693.1181\n",
      "Epoch 00001: loss did not improve from 8688.63867\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.1411\n",
      "Epoch 2/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0844\n",
      "Epoch 00002: loss did not improve from 8688.63867\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0867\n",
      "Epoch 3/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.3556\n",
      "Epoch 00003: loss did not improve from 8688.63867\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.3592\n",
      "Epoch 4/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.2146\n",
      "Epoch 00004: loss did not improve from 8688.63867\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.3150\n",
      "Epoch 5/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0912\n",
      "Epoch 00005: loss did not improve from 8688.63867\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0743\n",
      "Epoch 6/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.1439\n",
      "Epoch 00006: loss did not improve from 8688.63867\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.2108\n",
      "Epoch 7/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.3925\n",
      "Epoch 00007: loss did not improve from 8688.63867\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.3026\n",
      "Epoch 8/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0736\n",
      "Epoch 00008: loss did not improve from 8688.63867\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.1381\n",
      "Epoch 9/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.2261\n",
      "Epoch 00009: loss did not improve from 8688.63867\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.2210\n",
      "Epoch 10/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9282\n",
      "Epoch 00010: loss did not improve from 8688.63867\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9576\n",
      "Epoch 11/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.4113\n",
      "Epoch 00011: loss did not improve from 8688.63867\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.3712\n",
      "Epoch 12/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.1091\n",
      "Epoch 00012: loss did not improve from 8688.63867\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.1287\n",
      "Epoch 13/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.1011\n",
      "Epoch 00013: loss did not improve from 8688.63867\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.1170\n",
      "Epoch 14/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.1680\n",
      "Epoch 00014: loss did not improve from 8688.63867\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.2462\n",
      "Epoch 15/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.1516\n",
      "Epoch 00015: loss did not improve from 8688.63867\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0468\n",
      "Epoch 16/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.2015\n",
      "Epoch 00016: loss did not improve from 8688.63867\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.1630\n",
      "Epoch 17/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.2308\n",
      "Epoch 00017: loss improved from 8688.63867 to 8687.92383, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-17-8.68792e+03.hdf5\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.1013\n",
      "Epoch 18/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.1625\n",
      "Epoch 00018: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.1420\n",
      "Epoch 19/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9797\n",
      "Epoch 00019: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8802\n",
      "Epoch 20/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.2342\n",
      "Epoch 00020: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.2549\n",
      "Epoch 21/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.3937\n",
      "Epoch 00021: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.3736\n",
      "Epoch 22/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0833\n",
      "Epoch 00022: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.1304\n",
      "Epoch 23/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0276\n",
      "Epoch 00023: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9828\n",
      "Epoch 24/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0601\n",
      "Epoch 00024: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9653\n",
      "Epoch 25/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.2599\n",
      "Epoch 00025: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.3030\n",
      "Epoch 26/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9041\n",
      "Epoch 00026: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9525\n",
      "Epoch 27/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.1920\n",
      "Epoch 00027: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.3060\n",
      "Epoch 28/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0095\n",
      "Epoch 00028: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9819\n",
      "Epoch 29/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.2573\n",
      "Epoch 00029: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.2733\n",
      "Epoch 30/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9366\n",
      "Epoch 00030: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9079\n",
      "Epoch 31/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0977\n",
      "Epoch 00031: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0162\n",
      "Epoch 32/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0081\n",
      "Epoch 00032: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9403\n",
      "Epoch 33/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8538\n",
      "Epoch 00033: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8983\n",
      "Epoch 34/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.3869\n",
      "Epoch 00034: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.3960\n",
      "Epoch 35/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9156\n",
      "Epoch 00035: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0184\n",
      "Epoch 36/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.2915\n",
      "Epoch 00036: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.3019\n",
      "Epoch 37/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0640\n",
      "Epoch 00037: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0745\n",
      "Epoch 38/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9467\n",
      "Epoch 00038: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0080\n",
      "Epoch 39/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0092\n",
      "Epoch 00039: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0044\n",
      "Epoch 40/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9759\n",
      "Epoch 00040: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0888\n",
      "Epoch 00041: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0448\n",
      "Epoch 42/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9655\n",
      "Epoch 00042: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9456\n",
      "Epoch 43/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.2201\n",
      "Epoch 00043: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.1893\n",
      "Epoch 44/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9535\n",
      "Epoch 00044: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8692.8946\n",
      "Epoch 45/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9241\n",
      "Epoch 00045: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8745\n",
      "Epoch 46/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.1769\n",
      "Epoch 00046: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.1269\n",
      "Epoch 47/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9573\n",
      "Epoch 00047: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9811\n",
      "Epoch 48/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0817\n",
      "Epoch 00048: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0756\n",
      "Epoch 49/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0389\n",
      "Epoch 00049: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9484\n",
      "Epoch 50/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9564\n",
      "Epoch 00050: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0572\n",
      "Epoch 51/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.1294\n",
      "Epoch 00051: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.2047\n",
      "Epoch 52/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8330\n",
      "Epoch 00052: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8470\n",
      "Epoch 53/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9950\n",
      "Epoch 00053: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0306\n",
      "Epoch 54/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.1738\n",
      "Epoch 00054: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.1293\n",
      "Epoch 55/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9801\n",
      "Epoch 00055: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9978\n",
      "Epoch 56/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.2615\n",
      "Epoch 00056: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.2260\n",
      "Epoch 57/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7343\n",
      "Epoch 00057: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.7379\n",
      "Epoch 58/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0862\n",
      "Epoch 00058: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0875\n",
      "Epoch 59/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6906\n",
      "Epoch 00059: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.7055\n",
      "Epoch 60/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0441\n",
      "Epoch 00060: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9944\n",
      "Epoch 61/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0180\n",
      "Epoch 00061: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.1204\n",
      "Epoch 62/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8878\n",
      "Epoch 00062: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9391\n",
      "Epoch 63/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9154\n",
      "Epoch 00063: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8272\n",
      "Epoch 64/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8329\n",
      "Epoch 00064: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8587\n",
      "Epoch 65/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8864\n",
      "Epoch 00065: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8391\n",
      "Epoch 66/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.1529\n",
      "Epoch 00066: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.1344\n",
      "Epoch 67/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8122\n",
      "Epoch 00067: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9030\n",
      "Epoch 68/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.1410\n",
      "Epoch 00068: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.1431\n",
      "Epoch 69/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7277\n",
      "Epoch 00069: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.7520\n",
      "Epoch 70/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9590\n",
      "Epoch 00070: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8692.9668\n",
      "Epoch 71/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8102\n",
      "Epoch 00071: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8050\n",
      "Epoch 72/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8648\n",
      "Epoch 00072: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8928\n",
      "Epoch 73/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.1165\n",
      "Epoch 00073: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.1630\n",
      "Epoch 74/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8837\n",
      "Epoch 00074: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8479\n",
      "Epoch 75/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9033\n",
      "Epoch 00075: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0559\n",
      "Epoch 76/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7423\n",
      "Epoch 00076: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.7471\n",
      "Epoch 77/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8034\n",
      "Epoch 00077: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8641\n",
      "Epoch 78/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0795\n",
      "Epoch 00078: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0431\n",
      "Epoch 79/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7949\n",
      "Epoch 00079: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.7611\n",
      "Epoch 80/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.4049\n",
      "Epoch 00080: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.4323\n",
      "Epoch 81/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 8692.8347\n",
      "Epoch 00081: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8014\n",
      "Epoch 82/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8279\n",
      "Epoch 00082: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.7667\n",
      "Epoch 83/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9386\n",
      "Epoch 00083: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9020\n",
      "Epoch 84/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7420\n",
      "Epoch 00084: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8013\n",
      "Epoch 85/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8274\n",
      "Epoch 00085: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8642\n",
      "Epoch 86/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8318\n",
      "Epoch 00086: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8437\n",
      "Epoch 87/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5846\n",
      "Epoch 00087: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5398\n",
      "Epoch 88/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8961\n",
      "Epoch 00088: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9218\n",
      "Epoch 89/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9980\n",
      "Epoch 00089: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9890\n",
      "Epoch 90/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8098\n",
      "Epoch 00090: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8363\n",
      "Epoch 91/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9036\n",
      "Epoch 00091: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9872\n",
      "Epoch 92/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9732\n",
      "Epoch 00092: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9487\n",
      "Epoch 93/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8991\n",
      "Epoch 00093: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9592\n",
      "Epoch 94/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7405\n",
      "Epoch 00094: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8463\n",
      "Epoch 95/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7069\n",
      "Epoch 00095: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6839\n",
      "Epoch 96/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9871\n",
      "Epoch 00096: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0041\n",
      "Epoch 97/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5588\n",
      "Epoch 00097: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5332\n",
      "Epoch 98/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9161\n",
      "Epoch 00098: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9028\n",
      "Epoch 99/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6973\n",
      "Epoch 00099: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6841\n",
      "Epoch 100/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8498\n",
      "Epoch 00100: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8652\n",
      "Epoch 101/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5543\n",
      "Epoch 00101: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5193\n",
      "Epoch 102/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7244\n",
      "Epoch 00102: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6436\n",
      "Epoch 103/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.0787\n",
      "Epoch 00103: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9980\n",
      "Epoch 104/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7955\n",
      "Epoch 00104: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8849\n",
      "Epoch 105/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4712\n",
      "Epoch 00105: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5806\n",
      "Epoch 106/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7229\n",
      "Epoch 00106: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.7306\n",
      "Epoch 107/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7968\n",
      "Epoch 00107: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8227\n",
      "Epoch 108/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9022\n",
      "Epoch 00108: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0432\n",
      "Epoch 109/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7302\n",
      "Epoch 00109: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6805\n",
      "Epoch 110/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8945\n",
      "Epoch 00110: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9906\n",
      "Epoch 111/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7531\n",
      "Epoch 00111: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.7821\n",
      "Epoch 112/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6075\n",
      "Epoch 00112: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5791\n",
      "Epoch 113/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7253\n",
      "Epoch 00113: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8692.7926\n",
      "Epoch 114/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8244\n",
      "Epoch 00114: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8692.8175\n",
      "Epoch 115/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5686\n",
      "Epoch 00115: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5633\n",
      "Epoch 116/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8297\n",
      "Epoch 00116: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8851\n",
      "Epoch 117/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.8872\n",
      "Epoch 00117: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8923\n",
      "Epoch 118/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7300\n",
      "Epoch 00118: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6970\n",
      "Epoch 119/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5331\n",
      "Epoch 00119: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6221\n",
      "Epoch 120/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7533\n",
      "Epoch 00120: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8256\n",
      "Epoch 121/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 8692.9690\n",
      "Epoch 00121: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.9738\n",
      "Epoch 122/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4694\n",
      "Epoch 00122: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4013\n",
      "Epoch 123/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6511\n",
      "Epoch 00123: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.7308\n",
      "Epoch 124/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6162\n",
      "Epoch 00124: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6339\n",
      "Epoch 125/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7803\n",
      "Epoch 00125: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8692.8089\n",
      "Epoch 126/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7803\n",
      "Epoch 00126: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8802\n",
      "Epoch 127/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6821\n",
      "Epoch 00127: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.7010\n",
      "Epoch 128/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5010\n",
      "Epoch 00128: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4711\n",
      "Epoch 129/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6720\n",
      "Epoch 00129: loss did not improve from 8687.92383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.7829\n",
      "Epoch 130/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6703\n",
      "Epoch 00130: loss improved from 8687.92383 to 8687.21875, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-130-8.68722e+03.hdf5\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5373\n",
      "Epoch 131/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6495\n",
      "Epoch 00131: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.7183\n",
      "Epoch 132/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5650\n",
      "Epoch 00132: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4844\n",
      "Epoch 133/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7853\n",
      "Epoch 00133: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.7291\n",
      "Epoch 134/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6546\n",
      "Epoch 00134: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6184\n",
      "Epoch 135/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5613\n",
      "Epoch 00135: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6154\n",
      "Epoch 136/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6537\n",
      "Epoch 00136: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6594\n",
      "Epoch 137/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6250\n",
      "Epoch 00137: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6212\n",
      "Epoch 138/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6032\n",
      "Epoch 00138: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6533\n",
      "Epoch 139/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6414\n",
      "Epoch 00139: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6568\n",
      "Epoch 140/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6008\n",
      "Epoch 00140: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5603\n",
      "Epoch 141/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6359\n",
      "Epoch 00141: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6010\n",
      "Epoch 142/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5595\n",
      "Epoch 00142: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4906\n",
      "Epoch 143/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5327\n",
      "Epoch 00143: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5388\n",
      "Epoch 144/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6739\n",
      "Epoch 00144: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5905\n",
      "Epoch 145/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6367\n",
      "Epoch 00145: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5902\n",
      "Epoch 146/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6077\n",
      "Epoch 00146: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5620\n",
      "Epoch 147/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4812\n",
      "Epoch 00147: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4622\n",
      "Epoch 148/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5855\n",
      "Epoch 00148: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5917\n",
      "Epoch 149/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7765\n",
      "Epoch 00149: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.8110\n",
      "Epoch 150/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4350\n",
      "Epoch 00150: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4528\n",
      "Epoch 151/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7328\n",
      "Epoch 00151: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.7169\n",
      "Epoch 152/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4903\n",
      "Epoch 00152: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5245\n",
      "Epoch 153/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.7231\n",
      "Epoch 00153: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.7208\n",
      "Epoch 154/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4986\n",
      "Epoch 00154: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5057\n",
      "Epoch 155/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5807\n",
      "Epoch 00155: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5443\n",
      "Epoch 156/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4704\n",
      "Epoch 00156: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4261\n",
      "Epoch 157/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4827\n",
      "Epoch 00157: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5183\n",
      "Epoch 158/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5977\n",
      "Epoch 00158: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6603\n",
      "Epoch 159/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4622\n",
      "Epoch 00159: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5134\n",
      "Epoch 160/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6132\n",
      "Epoch 00160: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5417\n",
      "Epoch 00161: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5625\n",
      "Epoch 162/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6286\n",
      "Epoch 00162: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6473\n",
      "Epoch 163/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5315\n",
      "Epoch 00163: loss did not improve from 8687.21875\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4763\n",
      "Epoch 164/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4073\n",
      "Epoch 00164: loss improved from 8687.21875 to 8687.09570, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-164-8.68710e+03.hdf5\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2778\n",
      "Epoch 165/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6996\n",
      "Epoch 00165: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.7103\n",
      "Epoch 166/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.3983\n",
      "Epoch 00166: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4342\n",
      "Epoch 167/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4442\n",
      "Epoch 00167: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5120\n",
      "Epoch 168/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6076\n",
      "Epoch 00168: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5716\n",
      "Epoch 169/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5054\n",
      "Epoch 00169: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5603\n",
      "Epoch 170/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6392\n",
      "Epoch 00170: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6406\n",
      "Epoch 171/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4225\n",
      "Epoch 00171: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4363\n",
      "Epoch 172/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.3963\n",
      "Epoch 00172: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4712\n",
      "Epoch 173/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4795\n",
      "Epoch 00173: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4658\n",
      "Epoch 174/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5510\n",
      "Epoch 00174: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5062\n",
      "Epoch 175/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6505\n",
      "Epoch 00175: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6283\n",
      "Epoch 176/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.3567\n",
      "Epoch 00176: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3210\n",
      "Epoch 177/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2976\n",
      "Epoch 00177: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8692.3547\n",
      "Epoch 178/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4208\n",
      "Epoch 00178: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5020\n",
      "Epoch 179/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4751\n",
      "Epoch 00179: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4994\n",
      "Epoch 180/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5352\n",
      "Epoch 00180: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5961\n",
      "Epoch 181/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4612\n",
      "Epoch 00181: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4091\n",
      "Epoch 182/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6186\n",
      "Epoch 00182: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6502\n",
      "Epoch 183/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2220\n",
      "Epoch 00183: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2426\n",
      "Epoch 184/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2458\n",
      "Epoch 00184: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3339\n",
      "Epoch 185/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4882\n",
      "Epoch 00185: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3715\n",
      "Epoch 186/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5708\n",
      "Epoch 00186: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.6457\n",
      "Epoch 187/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.3882\n",
      "Epoch 00187: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3024\n",
      "Epoch 188/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.3679\n",
      "Epoch 00188: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3612\n",
      "Epoch 189/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5376\n",
      "Epoch 00189: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5370\n",
      "Epoch 190/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2685\n",
      "Epoch 00190: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2729\n",
      "Epoch 191/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2128\n",
      "Epoch 00191: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1422\n",
      "Epoch 192/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5523\n",
      "Epoch 00192: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5237\n",
      "Epoch 193/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4927\n",
      "Epoch 00193: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3961\n",
      "Epoch 194/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4345\n",
      "Epoch 00194: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3612\n",
      "Epoch 195/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4352\n",
      "Epoch 00195: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4750\n",
      "Epoch 196/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5246\n",
      "Epoch 00196: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5248\n",
      "Epoch 197/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1251\n",
      "Epoch 00197: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1509\n",
      "Epoch 198/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4021\n",
      "Epoch 00198: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3823\n",
      "Epoch 199/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2871\n",
      "Epoch 00199: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2953\n",
      "Epoch 200/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4117\n",
      "Epoch 00200: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2939\n",
      "Epoch 00201: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2973\n",
      "Epoch 202/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5221\n",
      "Epoch 00202: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5905\n",
      "Epoch 203/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.3907\n",
      "Epoch 00203: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4319\n",
      "Epoch 204/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.3257\n",
      "Epoch 00204: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2198\n",
      "Epoch 205/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2893\n",
      "Epoch 00205: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8692.3148\n",
      "Epoch 206/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.3529\n",
      "Epoch 00206: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3911\n",
      "Epoch 207/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4307\n",
      "Epoch 00207: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4126\n",
      "Epoch 208/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1962\n",
      "Epoch 00208: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1302\n",
      "Epoch 209/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5049\n",
      "Epoch 00209: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4806\n",
      "Epoch 210/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4415\n",
      "Epoch 00210: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8692.4570\n",
      "Epoch 211/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2730\n",
      "Epoch 00211: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8692.2347\n",
      "Epoch 212/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2401\n",
      "Epoch 00212: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1798\n",
      "Epoch 213/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2523\n",
      "Epoch 00213: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2060\n",
      "Epoch 214/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.9262\n",
      "Epoch 00214: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.0141\n",
      "Epoch 215/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8693.1983\n",
      "Epoch 00215: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8693.1336\n",
      "Epoch 216/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1937\n",
      "Epoch 00216: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2735\n",
      "Epoch 217/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2669\n",
      "Epoch 00217: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3673\n",
      "Epoch 218/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1819\n",
      "Epoch 00218: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1877\n",
      "Epoch 219/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.6128\n",
      "Epoch 00219: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5974\n",
      "Epoch 220/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9885\n",
      "Epoch 00220: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0231\n",
      "Epoch 221/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.3726\n",
      "Epoch 00221: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3124\n",
      "Epoch 222/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9874\n",
      "Epoch 00222: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9460\n",
      "Epoch 223/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4858\n",
      "Epoch 00223: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3854\n",
      "Epoch 224/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1388\n",
      "Epoch 00224: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2015\n",
      "Epoch 225/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2524\n",
      "Epoch 00225: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2842\n",
      "Epoch 226/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4173\n",
      "Epoch 00226: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4140\n",
      "Epoch 227/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0259\n",
      "Epoch 00227: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0577\n",
      "Epoch 228/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4703\n",
      "Epoch 00228: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5073\n",
      "Epoch 229/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2083\n",
      "Epoch 00229: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1907\n",
      "Epoch 230/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4558\n",
      "Epoch 00230: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4784\n",
      "Epoch 231/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0426\n",
      "Epoch 00231: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0363\n",
      "Epoch 232/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.3134\n",
      "Epoch 00232: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2956\n",
      "Epoch 233/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1067\n",
      "Epoch 00233: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1390\n",
      "Epoch 234/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2531\n",
      "Epoch 00234: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3532\n",
      "Epoch 235/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2961\n",
      "Epoch 00235: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3656\n",
      "Epoch 236/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1992\n",
      "Epoch 00236: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3015\n",
      "Epoch 237/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2515\n",
      "Epoch 00237: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1816\n",
      "Epoch 238/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.3161\n",
      "Epoch 00238: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3215\n",
      "Epoch 239/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0792\n",
      "Epoch 00239: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1229\n",
      "Epoch 240/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.3242\n",
      "Epoch 00240: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2793\n",
      "Epoch 241/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 8692.0930\n",
      "Epoch 00241: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0933\n",
      "Epoch 242/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1592\n",
      "Epoch 00242: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1973\n",
      "Epoch 243/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2772\n",
      "Epoch 00243: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1741\n",
      "Epoch 244/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0395\n",
      "Epoch 00244: loss did not improve from 8687.09570\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0190\n",
      "Epoch 245/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1324\n",
      "Epoch 00245: loss improved from 8687.09570 to 8686.76367, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-245-8.68676e+03.hdf5\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0015\n",
      "Epoch 246/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2556\n",
      "Epoch 00246: loss did not improve from 8686.76367\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2661\n",
      "Epoch 247/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1074\n",
      "Epoch 00247: loss did not improve from 8686.76367\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0993\n",
      "Epoch 248/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2943\n",
      "Epoch 00248: loss did not improve from 8686.76367\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2636\n",
      "Epoch 249/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1856\n",
      "Epoch 00249: loss did not improve from 8686.76367\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1981\n",
      "Epoch 250/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.3036\n",
      "Epoch 00250: loss did not improve from 8686.76367\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2523\n",
      "Epoch 251/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0727\n",
      "Epoch 00251: loss did not improve from 8686.76367\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0794\n",
      "Epoch 252/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2194\n",
      "Epoch 00252: loss did not improve from 8686.76367\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2164\n",
      "Epoch 253/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1745\n",
      "Epoch 00253: loss improved from 8686.76367 to 8686.52441, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-253-8.68652e+03.hdf5\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0367\n",
      "Epoch 254/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4507\n",
      "Epoch 00254: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4265\n",
      "Epoch 255/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8815\n",
      "Epoch 00255: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9615\n",
      "Epoch 256/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0536\n",
      "Epoch 00256: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0642\n",
      "Epoch 257/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1590\n",
      "Epoch 00257: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1468\n",
      "Epoch 258/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1713\n",
      "Epoch 00258: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0959\n",
      "Epoch 259/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0074\n",
      "Epoch 00259: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0181\n",
      "Epoch 260/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2224\n",
      "Epoch 00260: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2082\n",
      "Epoch 261/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9953\n",
      "Epoch 00261: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0750\n",
      "Epoch 262/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4068\n",
      "Epoch 00262: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3962\n",
      "Epoch 263/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1031\n",
      "Epoch 00263: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1534\n",
      "Epoch 264/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9172\n",
      "Epoch 00264: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9730\n",
      "Epoch 265/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2154\n",
      "Epoch 00265: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1718\n",
      "Epoch 266/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0252\n",
      "Epoch 00266: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0279\n",
      "Epoch 267/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1279\n",
      "Epoch 00267: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0275\n",
      "Epoch 268/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2175\n",
      "Epoch 00268: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1914\n",
      "Epoch 269/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0665\n",
      "Epoch 00269: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0758\n",
      "Epoch 270/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0222\n",
      "Epoch 00270: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0491\n",
      "Epoch 271/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0724\n",
      "Epoch 00271: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1823\n",
      "Epoch 272/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9654\n",
      "Epoch 00272: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9537\n",
      "Epoch 273/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9587\n",
      "Epoch 00273: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9194\n",
      "Epoch 274/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1874\n",
      "Epoch 00274: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1569\n",
      "Epoch 275/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1028\n",
      "Epoch 00275: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1728\n",
      "Epoch 276/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8968\n",
      "Epoch 00276: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9110\n",
      "Epoch 277/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4272\n",
      "Epoch 00277: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.3147\n",
      "Epoch 278/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8319\n",
      "Epoch 00278: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8853\n",
      "Epoch 279/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0330\n",
      "Epoch 00279: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9971\n",
      "Epoch 00280: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9457\n",
      "Epoch 281/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.5149\n",
      "Epoch 00281: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4065\n",
      "Epoch 282/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9229\n",
      "Epoch 00282: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8525\n",
      "Epoch 283/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0211\n",
      "Epoch 00283: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0507\n",
      "Epoch 284/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8662\n",
      "Epoch 00284: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8073\n",
      "Epoch 285/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0747\n",
      "Epoch 00285: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8692.1140\n",
      "Epoch 286/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9842\n",
      "Epoch 00286: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0116\n",
      "Epoch 287/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1077\n",
      "Epoch 00287: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8692.0615\n",
      "Epoch 288/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9115\n",
      "Epoch 00288: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9076\n",
      "Epoch 289/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0323\n",
      "Epoch 00289: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1039\n",
      "Epoch 290/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2160\n",
      "Epoch 00290: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1579\n",
      "Epoch 291/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8703\n",
      "Epoch 00291: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9151\n",
      "Epoch 292/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9331\n",
      "Epoch 00292: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0095\n",
      "Epoch 293/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1888\n",
      "Epoch 00293: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2135\n",
      "Epoch 294/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.2032\n",
      "Epoch 00294: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1186\n",
      "Epoch 295/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9545\n",
      "Epoch 00295: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8747\n",
      "Epoch 296/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0150\n",
      "Epoch 00296: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0927\n",
      "Epoch 297/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8947\n",
      "Epoch 00297: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0096\n",
      "Epoch 298/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7906\n",
      "Epoch 00298: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8903\n",
      "Epoch 299/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9012\n",
      "Epoch 00299: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8691.9327\n",
      "Epoch 300/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.3823\n",
      "Epoch 00300: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.4939\n",
      "Epoch 301/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8393\n",
      "Epoch 00301: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8691.8476\n",
      "Epoch 302/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7792\n",
      "Epoch 00302: loss did not improve from 8686.52441\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8595\n",
      "Epoch 303/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9883\n",
      "Epoch 00303: loss improved from 8686.52441 to 8686.48535, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-303-8.68649e+03.hdf5\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8540\n",
      "Epoch 304/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1767\n",
      "Epoch 00304: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.2081\n",
      "Epoch 305/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7608\n",
      "Epoch 00305: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7591\n",
      "Epoch 306/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0679\n",
      "Epoch 00306: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0163\n",
      "Epoch 307/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7925\n",
      "Epoch 00307: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8197\n",
      "Epoch 308/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9667\n",
      "Epoch 00308: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8348\n",
      "Epoch 309/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9437\n",
      "Epoch 00309: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9518\n",
      "Epoch 310/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0445\n",
      "Epoch 00310: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9341\n",
      "Epoch 311/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7491\n",
      "Epoch 00311: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8275\n",
      "Epoch 312/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9914\n",
      "Epoch 00312: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9839\n",
      "Epoch 313/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9475\n",
      "Epoch 00313: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0044\n",
      "Epoch 314/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8819\n",
      "Epoch 00314: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9380\n",
      "Epoch 315/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8529\n",
      "Epoch 00315: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8259\n",
      "Epoch 316/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7759\n",
      "Epoch 00316: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7783\n",
      "Epoch 317/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8538\n",
      "Epoch 00317: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8828\n",
      "Epoch 318/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9005\n",
      "Epoch 00318: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0026\n",
      "Epoch 319/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8781\n",
      "Epoch 00319: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.0653\n",
      "Epoch 00320: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0160\n",
      "Epoch 321/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9174\n",
      "Epoch 00321: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8755\n",
      "Epoch 322/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8426\n",
      "Epoch 00322: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8530\n",
      "Epoch 323/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7654\n",
      "Epoch 00323: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7724\n",
      "Epoch 324/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1342\n",
      "Epoch 00324: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1568\n",
      "Epoch 325/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7974\n",
      "Epoch 00325: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8285\n",
      "Epoch 326/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8328\n",
      "Epoch 00326: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8103\n",
      "Epoch 327/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9721\n",
      "Epoch 00327: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9745\n",
      "Epoch 328/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1180\n",
      "Epoch 00328: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1923\n",
      "Epoch 329/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6437\n",
      "Epoch 00329: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5557\n",
      "Epoch 330/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7708\n",
      "Epoch 00330: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7823\n",
      "Epoch 331/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9122\n",
      "Epoch 00331: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9272\n",
      "Epoch 332/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7908\n",
      "Epoch 00332: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8235\n",
      "Epoch 333/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9286\n",
      "Epoch 00333: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8691.8244\n",
      "Epoch 334/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7636\n",
      "Epoch 00334: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8658\n",
      "Epoch 335/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7524\n",
      "Epoch 00335: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7970\n",
      "Epoch 336/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7504\n",
      "Epoch 00336: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7908\n",
      "Epoch 337/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9767\n",
      "Epoch 00337: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9390\n",
      "Epoch 338/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7106\n",
      "Epoch 00338: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6913\n",
      "Epoch 339/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9816\n",
      "Epoch 00339: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.0149\n",
      "Epoch 340/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7052\n",
      "Epoch 00340: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7366\n",
      "Epoch 341/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8534\n",
      "Epoch 00341: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9513\n",
      "Epoch 342/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9731\n",
      "Epoch 00342: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9223\n",
      "Epoch 343/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8200\n",
      "Epoch 00343: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8933\n",
      "Epoch 344/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6006\n",
      "Epoch 00344: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6053\n",
      "Epoch 345/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9222\n",
      "Epoch 00345: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9096\n",
      "Epoch 346/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5457\n",
      "Epoch 00346: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5939\n",
      "Epoch 347/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5898\n",
      "Epoch 00347: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5119\n",
      "Epoch 348/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.1515\n",
      "Epoch 00348: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.1775\n",
      "Epoch 349/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8645\n",
      "Epoch 00349: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9441\n",
      "Epoch 350/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6114\n",
      "Epoch 00350: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5912\n",
      "Epoch 351/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7740\n",
      "Epoch 00351: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8466\n",
      "Epoch 352/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8833\n",
      "Epoch 00352: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7712\n",
      "Epoch 353/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5382\n",
      "Epoch 00353: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5869\n",
      "Epoch 354/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9022\n",
      "Epoch 00354: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9249\n",
      "Epoch 355/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7936\n",
      "Epoch 00355: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8170\n",
      "Epoch 356/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6524\n",
      "Epoch 00356: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6562\n",
      "Epoch 357/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7620\n",
      "Epoch 00357: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8007\n",
      "Epoch 358/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5244\n",
      "Epoch 00358: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4494\n",
      "Epoch 359/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.9347\n",
      "Epoch 00359: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9708\n",
      "Epoch 360/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 8691.7579\n",
      "Epoch 00360: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8118\n",
      "Epoch 361/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6979\n",
      "Epoch 00361: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7110\n",
      "Epoch 362/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6775\n",
      "Epoch 00362: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6343\n",
      "Epoch 363/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8149\n",
      "Epoch 00363: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8303\n",
      "Epoch 364/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6939\n",
      "Epoch 00364: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6283\n",
      "Epoch 365/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7513\n",
      "Epoch 00365: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7721\n",
      "Epoch 366/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7325\n",
      "Epoch 00366: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7814\n",
      "Epoch 367/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6567\n",
      "Epoch 00367: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7015\n",
      "Epoch 368/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7424\n",
      "Epoch 00368: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6587\n",
      "Epoch 369/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6149\n",
      "Epoch 00369: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5879\n",
      "Epoch 370/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5137\n",
      "Epoch 00370: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4270\n",
      "Epoch 371/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8250\n",
      "Epoch 00371: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8674\n",
      "Epoch 372/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6182\n",
      "Epoch 00372: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6141\n",
      "Epoch 373/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7796\n",
      "Epoch 00373: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7699\n",
      "Epoch 374/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8407\n",
      "Epoch 00374: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7622\n",
      "Epoch 375/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5734\n",
      "Epoch 00375: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6338\n",
      "Epoch 376/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6999\n",
      "Epoch 00376: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7295\n",
      "Epoch 377/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5806\n",
      "Epoch 00377: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4775\n",
      "Epoch 378/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7036\n",
      "Epoch 00378: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6274\n",
      "Epoch 379/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8293\n",
      "Epoch 00379: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7876\n",
      "Epoch 380/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4784\n",
      "Epoch 00380: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4644\n",
      "Epoch 381/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5224\n",
      "Epoch 00381: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5034\n",
      "Epoch 382/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6399\n",
      "Epoch 00382: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8691.7087\n",
      "Epoch 383/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6095\n",
      "Epoch 00383: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6460\n",
      "Epoch 384/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6860\n",
      "Epoch 00384: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6884\n",
      "Epoch 385/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7498\n",
      "Epoch 00385: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6976\n",
      "Epoch 386/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7428\n",
      "Epoch 00386: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8083\n",
      "Epoch 387/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4989\n",
      "Epoch 00387: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4608\n",
      "Epoch 388/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4123\n",
      "Epoch 00388: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3782\n",
      "Epoch 389/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8643\n",
      "Epoch 00389: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8673\n",
      "Epoch 390/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6407\n",
      "Epoch 00390: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5545\n",
      "Epoch 391/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5253\n",
      "Epoch 00391: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5055\n",
      "Epoch 392/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5646\n",
      "Epoch 00392: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6669\n",
      "Epoch 393/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8587\n",
      "Epoch 00393: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8032\n",
      "Epoch 394/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4453\n",
      "Epoch 00394: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3810\n",
      "Epoch 395/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5381\n",
      "Epoch 00395: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6376\n",
      "Epoch 396/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5060\n",
      "Epoch 00396: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5028\n",
      "Epoch 397/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7092\n",
      "Epoch 00397: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7600\n",
      "Epoch 398/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5278\n",
      "Epoch 00398: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4845\n",
      "Epoch 399/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5506\n",
      "Epoch 00399: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5043\n",
      "Epoch 400/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 8691.4066\n",
      "Epoch 00400: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3683\n",
      "Epoch 401/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8692.4317\n",
      "Epoch 00401: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8692.5415\n",
      "Epoch 402/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6189\n",
      "Epoch 00402: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5218\n",
      "Epoch 403/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3777\n",
      "Epoch 00403: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3997\n",
      "Epoch 404/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7084\n",
      "Epoch 00404: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7390\n",
      "Epoch 405/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6415\n",
      "Epoch 00405: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6708\n",
      "Epoch 406/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3090\n",
      "Epoch 00406: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3322\n",
      "Epoch 407/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6212\n",
      "Epoch 00407: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6845\n",
      "Epoch 408/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5835\n",
      "Epoch 00408: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6073\n",
      "Epoch 409/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3526\n",
      "Epoch 00409: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3764\n",
      "Epoch 410/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6391\n",
      "Epoch 00410: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7409\n",
      "Epoch 411/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5903\n",
      "Epoch 00411: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5379\n",
      "Epoch 412/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6133\n",
      "Epoch 00412: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7076\n",
      "Epoch 413/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4583\n",
      "Epoch 00413: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4765\n",
      "Epoch 414/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5075\n",
      "Epoch 00414: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6091\n",
      "Epoch 415/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5322\n",
      "Epoch 00415: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5729\n",
      "Epoch 416/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3055\n",
      "Epoch 00416: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4189\n",
      "Epoch 417/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7573\n",
      "Epoch 00417: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8121\n",
      "Epoch 418/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4483\n",
      "Epoch 00418: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4842\n",
      "Epoch 419/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2943\n",
      "Epoch 00419: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8691.3782\n",
      "Epoch 420/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5089\n",
      "Epoch 00420: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5268\n",
      "Epoch 421/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.8128\n",
      "Epoch 00421: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.9077\n",
      "Epoch 422/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2399\n",
      "Epoch 00422: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3376\n",
      "Epoch 423/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3716\n",
      "Epoch 00423: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4278\n",
      "Epoch 424/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5692\n",
      "Epoch 00424: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6716\n",
      "Epoch 425/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3711\n",
      "Epoch 00425: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3738\n",
      "Epoch 426/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5473\n",
      "Epoch 00426: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5760\n",
      "Epoch 427/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6081\n",
      "Epoch 00427: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5516\n",
      "Epoch 428/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5526\n",
      "Epoch 00428: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5806\n",
      "Epoch 429/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3256\n",
      "Epoch 00429: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3364\n",
      "Epoch 430/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.7622\n",
      "Epoch 00430: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.7180\n",
      "Epoch 431/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1571\n",
      "Epoch 00431: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1181\n",
      "Epoch 432/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4931\n",
      "Epoch 00432: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4761\n",
      "Epoch 433/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3272\n",
      "Epoch 00433: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2369\n",
      "Epoch 434/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4243\n",
      "Epoch 00434: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4724\n",
      "Epoch 435/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4880\n",
      "Epoch 00435: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4625\n",
      "Epoch 436/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3510\n",
      "Epoch 00436: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3753\n",
      "Epoch 437/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5369\n",
      "Epoch 00437: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4773\n",
      "Epoch 438/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3788\n",
      "Epoch 00438: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4238\n",
      "Epoch 439/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4005\n",
      "Epoch 00439: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4242\n",
      "Epoch 440/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 8691.2273\n",
      "Epoch 00440: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1760\n",
      "Epoch 441/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6959\n",
      "Epoch 00441: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.8212\n",
      "Epoch 442/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2497\n",
      "Epoch 00442: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2875\n",
      "Epoch 443/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4662\n",
      "Epoch 00443: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3962\n",
      "Epoch 444/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5496\n",
      "Epoch 00444: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6146\n",
      "Epoch 445/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2718\n",
      "Epoch 00445: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2576\n",
      "Epoch 446/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5362\n",
      "Epoch 00446: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5438\n",
      "Epoch 447/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3907\n",
      "Epoch 00447: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3305\n",
      "Epoch 448/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3145\n",
      "Epoch 00448: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3066\n",
      "Epoch 449/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2988\n",
      "Epoch 00449: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3033\n",
      "Epoch 450/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.5578\n",
      "Epoch 00450: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5059\n",
      "Epoch 451/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3770\n",
      "Epoch 00451: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3982\n",
      "Epoch 452/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3176\n",
      "Epoch 00452: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3192\n",
      "Epoch 453/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4393\n",
      "Epoch 00453: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5162\n",
      "Epoch 454/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4815\n",
      "Epoch 00454: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4218\n",
      "Epoch 455/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1754\n",
      "Epoch 00455: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1850\n",
      "Epoch 456/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4887\n",
      "Epoch 00456: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5694\n",
      "Epoch 457/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2723\n",
      "Epoch 00457: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1852\n",
      "Epoch 458/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3571\n",
      "Epoch 00458: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8691.3553\n",
      "Epoch 459/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2648\n",
      "Epoch 00459: loss did not improve from 8686.48535\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2531\n",
      "Epoch 460/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3917\n",
      "Epoch 00460: loss improved from 8686.48535 to 8685.42383, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-460-8.68542e+03.hdf5\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2462\n",
      "Epoch 461/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3653\n",
      "Epoch 00461: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3738\n",
      "Epoch 462/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3948\n",
      "Epoch 00462: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5227\n",
      "Epoch 463/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3120\n",
      "Epoch 00463: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2568\n",
      "Epoch 464/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2389\n",
      "Epoch 00464: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2718\n",
      "Epoch 465/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4937\n",
      "Epoch 00465: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4585\n",
      "Epoch 466/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0394\n",
      "Epoch 00466: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0213\n",
      "Epoch 467/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4286\n",
      "Epoch 00467: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4433\n",
      "Epoch 468/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3751\n",
      "Epoch 00468: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3921\n",
      "Epoch 469/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4155\n",
      "Epoch 00469: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3923\n",
      "Epoch 470/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2490\n",
      "Epoch 00470: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2147\n",
      "Epoch 471/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3233\n",
      "Epoch 00471: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2804\n",
      "Epoch 472/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1301\n",
      "Epoch 00472: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0893\n",
      "Epoch 473/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4699\n",
      "Epoch 00473: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3968\n",
      "Epoch 474/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3342\n",
      "Epoch 00474: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3371\n",
      "Epoch 475/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2215\n",
      "Epoch 00475: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2312\n",
      "Epoch 476/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0289\n",
      "Epoch 00476: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0535\n",
      "Epoch 477/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6889\n",
      "Epoch 00477: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6985\n",
      "Epoch 478/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1191\n",
      "Epoch 00478: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1227\n",
      "Epoch 479/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3942\n",
      "Epoch 00479: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2793\n",
      "Epoch 00480: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2993\n",
      "Epoch 481/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1364\n",
      "Epoch 00481: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1749\n",
      "Epoch 482/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2637\n",
      "Epoch 00482: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2636\n",
      "Epoch 483/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3377\n",
      "Epoch 00483: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3952\n",
      "Epoch 484/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3021\n",
      "Epoch 00484: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3991\n",
      "Epoch 485/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1182\n",
      "Epoch 00485: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1503\n",
      "Epoch 486/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4062\n",
      "Epoch 00486: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4691\n",
      "Epoch 487/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1305\n",
      "Epoch 00487: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1116\n",
      "Epoch 488/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3621\n",
      "Epoch 00488: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3205\n",
      "Epoch 489/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2253\n",
      "Epoch 00489: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1776\n",
      "Epoch 490/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1041\n",
      "Epoch 00490: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1044\n",
      "Epoch 491/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4569\n",
      "Epoch 00491: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4892\n",
      "Epoch 492/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0525\n",
      "Epoch 00492: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1515\n",
      "Epoch 493/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2141\n",
      "Epoch 00493: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2213\n",
      "Epoch 494/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2039\n",
      "Epoch 00494: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1942\n",
      "Epoch 495/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1164\n",
      "Epoch 00495: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1077\n",
      "Epoch 496/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2778\n",
      "Epoch 00496: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3140\n",
      "Epoch 497/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2397\n",
      "Epoch 00497: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2368\n",
      "Epoch 498/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3369\n",
      "Epoch 00498: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.4505\n",
      "Epoch 499/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1556\n",
      "Epoch 00499: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1822\n",
      "Epoch 500/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9060\n",
      "Epoch 00500: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8229\n",
      "Epoch 501/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3288\n",
      "Epoch 00501: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1855\n",
      "Epoch 502/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1764\n",
      "Epoch 00502: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1363\n",
      "Epoch 503/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2538\n",
      "Epoch 00503: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2081\n",
      "Epoch 504/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1331\n",
      "Epoch 00504: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1797\n",
      "Epoch 505/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2801\n",
      "Epoch 00505: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2872\n",
      "Epoch 506/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0275\n",
      "Epoch 00506: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0085\n",
      "Epoch 507/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3594\n",
      "Epoch 00507: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3438\n",
      "Epoch 508/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9523\n",
      "Epoch 00508: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0027\n",
      "Epoch 509/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1765\n",
      "Epoch 00509: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1836\n",
      "Epoch 510/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1234\n",
      "Epoch 00510: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0294\n",
      "Epoch 511/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.4068\n",
      "Epoch 00511: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5053\n",
      "Epoch 512/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2155\n",
      "Epoch 00512: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2060\n",
      "Epoch 513/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1474\n",
      "Epoch 00513: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0402\n",
      "Epoch 514/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9178\n",
      "Epoch 00514: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8229\n",
      "Epoch 515/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1448\n",
      "Epoch 00515: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0972\n",
      "Epoch 516/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9766\n",
      "Epoch 00516: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.9798\n",
      "Epoch 517/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2287\n",
      "Epoch 00517: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2470\n",
      "Epoch 518/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1897\n",
      "Epoch 00518: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2093\n",
      "Epoch 519/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8973\n",
      "Epoch 00519: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8628\n",
      "Epoch 520/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 8691.4788\n",
      "Epoch 00520: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.5313\n",
      "Epoch 521/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0490\n",
      "Epoch 00521: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0605\n",
      "Epoch 522/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1130\n",
      "Epoch 00522: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0509\n",
      "Epoch 523/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9139\n",
      "Epoch 00523: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8589\n",
      "Epoch 524/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.6434\n",
      "Epoch 00524: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.6490\n",
      "Epoch 525/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8281\n",
      "Epoch 00525: loss did not improve from 8685.42383\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8593\n",
      "Epoch 526/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2228\n",
      "Epoch 00526: loss improved from 8685.42383 to 8685.32227, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-526-8.68532e+03.hdf5\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0789\n",
      "Epoch 527/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9912\n",
      "Epoch 00527: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.9967\n",
      "Epoch 528/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9931\n",
      "Epoch 00528: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.9779\n",
      "Epoch 529/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0904\n",
      "Epoch 00529: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1480\n",
      "Epoch 530/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1587\n",
      "Epoch 00530: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0221\n",
      "Epoch 531/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9662\n",
      "Epoch 00531: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.9453\n",
      "Epoch 532/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0619\n",
      "Epoch 00532: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1677\n",
      "Epoch 533/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0231\n",
      "Epoch 00533: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0699\n",
      "Epoch 534/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1996\n",
      "Epoch 00534: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2814\n",
      "Epoch 535/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0131\n",
      "Epoch 00535: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0095\n",
      "Epoch 536/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9243\n",
      "Epoch 00536: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8677\n",
      "Epoch 537/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1627\n",
      "Epoch 00537: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1793\n",
      "Epoch 538/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0481\n",
      "Epoch 00538: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.9710\n",
      "Epoch 539/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0257\n",
      "Epoch 00539: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1150\n",
      "Epoch 540/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0200\n",
      "Epoch 00540: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0065\n",
      "Epoch 541/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9610\n",
      "Epoch 00541: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0296\n",
      "Epoch 542/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2286\n",
      "Epoch 00542: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2708\n",
      "Epoch 543/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0438\n",
      "Epoch 00543: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.9925\n",
      "Epoch 544/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0765\n",
      "Epoch 00544: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0323\n",
      "Epoch 545/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1877\n",
      "Epoch 00545: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1937\n",
      "Epoch 546/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9213\n",
      "Epoch 00546: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0004\n",
      "Epoch 547/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8495\n",
      "Epoch 00547: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.9096\n",
      "Epoch 548/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2473\n",
      "Epoch 00548: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8691.1592\n",
      "Epoch 549/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9376\n",
      "Epoch 00549: loss did not improve from 8685.32227\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8691.0249\n",
      "Epoch 550/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8059\n",
      "Epoch 00550: loss improved from 8685.32227 to 8685.04004, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-550-8.68504e+03.hdf5\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6652\n",
      "Epoch 551/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1565\n",
      "Epoch 00551: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2429\n",
      "Epoch 552/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7446\n",
      "Epoch 00552: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7464\n",
      "Epoch 553/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.2084\n",
      "Epoch 00553: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8691.1560\n",
      "Epoch 554/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0056\n",
      "Epoch 00554: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0637\n",
      "Epoch 555/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0234\n",
      "Epoch 00555: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0796\n",
      "Epoch 556/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9118\n",
      "Epoch 00556: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8329\n",
      "Epoch 557/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9800\n",
      "Epoch 00557: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.9567\n",
      "Epoch 558/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1099\n",
      "Epoch 00558: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 559/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9142\n",
      "Epoch 00559: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.9287\n",
      "Epoch 560/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8509\n",
      "Epoch 00560: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8690.8481\n",
      "Epoch 561/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9137\n",
      "Epoch 00561: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8115\n",
      "Epoch 562/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1415\n",
      "Epoch 00562: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2534\n",
      "Epoch 563/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9358\n",
      "Epoch 00563: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8970\n",
      "Epoch 564/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6480\n",
      "Epoch 00564: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5580\n",
      "Epoch 565/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3464\n",
      "Epoch 00565: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.3588\n",
      "Epoch 566/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9777\n",
      "Epoch 00566: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0203\n",
      "Epoch 567/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0187\n",
      "Epoch 00567: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0904\n",
      "Epoch 568/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9785\n",
      "Epoch 00568: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1080\n",
      "Epoch 569/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8920\n",
      "Epoch 00569: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.9985\n",
      "Epoch 570/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9422\n",
      "Epoch 00570: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.9499\n",
      "Epoch 571/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8229\n",
      "Epoch 00571: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7885\n",
      "Epoch 572/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9623\n",
      "Epoch 00572: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.9783\n",
      "Epoch 573/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9898\n",
      "Epoch 00573: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8905\n",
      "Epoch 574/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9238\n",
      "Epoch 00574: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8767\n",
      "Epoch 575/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9660\n",
      "Epoch 00575: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.9700\n",
      "Epoch 576/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7627\n",
      "Epoch 00576: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8190\n",
      "Epoch 577/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7418\n",
      "Epoch 00577: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6376\n",
      "Epoch 578/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3159\n",
      "Epoch 00578: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2575\n",
      "Epoch 579/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8557\n",
      "Epoch 00579: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8140\n",
      "Epoch 580/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7080\n",
      "Epoch 00580: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7527\n",
      "Epoch 581/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1705\n",
      "Epoch 00581: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1730\n",
      "Epoch 582/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6401\n",
      "Epoch 00582: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6502\n",
      "Epoch 583/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0514\n",
      "Epoch 00583: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0957\n",
      "Epoch 584/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8346\n",
      "Epoch 00584: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8002\n",
      "Epoch 585/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7095\n",
      "Epoch 00585: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7403\n",
      "Epoch 586/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0750\n",
      "Epoch 00586: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.9935\n",
      "Epoch 587/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6673\n",
      "Epoch 00587: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6611\n",
      "Epoch 588/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8765\n",
      "Epoch 00588: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7717\n",
      "Epoch 589/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9891\n",
      "Epoch 00589: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0081\n",
      "Epoch 590/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9062\n",
      "Epoch 00590: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.9644\n",
      "Epoch 591/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9177\n",
      "Epoch 00591: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8677\n",
      "Epoch 592/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7791\n",
      "Epoch 00592: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8885\n",
      "Epoch 593/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6649\n",
      "Epoch 00593: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6783\n",
      "Epoch 594/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9608\n",
      "Epoch 00594: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0324\n",
      "Epoch 595/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8034\n",
      "Epoch 00595: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8626\n",
      "Epoch 596/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0061\n",
      "Epoch 00596: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0629\n",
      "Epoch 597/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7779\n",
      "Epoch 00597: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8871\n",
      "Epoch 598/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8722\n",
      "Epoch 00598: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8308\n",
      "Epoch 599/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 8690.7950\n",
      "Epoch 00599: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8363\n",
      "Epoch 600/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7676\n",
      "Epoch 00600: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7331\n",
      "Epoch 601/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9006\n",
      "Epoch 00601: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8761\n",
      "Epoch 602/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6614\n",
      "Epoch 00602: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6068\n",
      "Epoch 603/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8109\n",
      "Epoch 00603: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.9268\n",
      "Epoch 604/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8261\n",
      "Epoch 00604: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8620\n",
      "Epoch 605/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7253\n",
      "Epoch 00605: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7926\n",
      "Epoch 606/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8424\n",
      "Epoch 00606: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8049\n",
      "Epoch 607/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8517\n",
      "Epoch 00607: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8676\n",
      "Epoch 608/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8195\n",
      "Epoch 00608: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8913\n",
      "Epoch 609/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7960\n",
      "Epoch 00609: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8532\n",
      "Epoch 610/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8600\n",
      "Epoch 00610: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8909\n",
      "Epoch 611/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7726\n",
      "Epoch 00611: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7138\n",
      "Epoch 612/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5450\n",
      "Epoch 00612: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4779\n",
      "Epoch 613/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.1130\n",
      "Epoch 00613: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1210\n",
      "Epoch 614/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5372\n",
      "Epoch 00614: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4638\n",
      "Epoch 615/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8487\n",
      "Epoch 00615: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8738\n",
      "Epoch 616/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6928\n",
      "Epoch 00616: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6507\n",
      "Epoch 617/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6660\n",
      "Epoch 00617: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6623\n",
      "Epoch 618/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7177\n",
      "Epoch 00618: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7214\n",
      "Epoch 619/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0476\n",
      "Epoch 00619: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0633\n",
      "Epoch 620/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6348\n",
      "Epoch 00620: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5082\n",
      "Epoch 621/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9137\n",
      "Epoch 00621: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8605\n",
      "Epoch 622/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5554\n",
      "Epoch 00622: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5100\n",
      "Epoch 623/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9646\n",
      "Epoch 00623: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.0119\n",
      "Epoch 624/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4988\n",
      "Epoch 00624: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6095\n",
      "Epoch 625/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8990\n",
      "Epoch 00625: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.9014\n",
      "Epoch 626/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4617\n",
      "Epoch 00626: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4400\n",
      "Epoch 627/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.0808\n",
      "Epoch 00627: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.1172\n",
      "Epoch 628/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8288\n",
      "Epoch 00628: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8103\n",
      "Epoch 629/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5870\n",
      "Epoch 00629: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6707\n",
      "Epoch 630/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8288\n",
      "Epoch 00630: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7786\n",
      "Epoch 631/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6201\n",
      "Epoch 00631: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5965\n",
      "Epoch 632/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7037\n",
      "Epoch 00632: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6566\n",
      "Epoch 633/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6055\n",
      "Epoch 00633: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5834\n",
      "Epoch 634/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9163\n",
      "Epoch 00634: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8014\n",
      "Epoch 635/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7599\n",
      "Epoch 00635: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7702\n",
      "Epoch 636/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6418\n",
      "Epoch 00636: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6589\n",
      "Epoch 637/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7332\n",
      "Epoch 00637: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8159\n",
      "Epoch 638/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.9112\n",
      "Epoch 00638: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.9936\n",
      "Epoch 639/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 8690.5383\n",
      "Epoch 00639: loss did not improve from 8685.04004\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4812\n",
      "Epoch 640/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8009\n",
      "Epoch 00640: loss improved from 8685.04004 to 8684.55859, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-640-8.68456e+03.hdf5\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6486\n",
      "Epoch 641/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4696\n",
      "Epoch 00641: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4207\n",
      "Epoch 642/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5922\n",
      "Epoch 00642: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6995\n",
      "Epoch 643/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6851\n",
      "Epoch 00643: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6880\n",
      "Epoch 644/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6529\n",
      "Epoch 00644: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6674\n",
      "Epoch 645/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7759\n",
      "Epoch 00645: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8133\n",
      "Epoch 646/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6463\n",
      "Epoch 00646: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5401\n",
      "Epoch 647/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6226\n",
      "Epoch 00647: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7341\n",
      "Epoch 648/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7449\n",
      "Epoch 00648: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6099\n",
      "Epoch 649/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8004\n",
      "Epoch 00649: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7296\n",
      "Epoch 650/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4617\n",
      "Epoch 00650: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6059\n",
      "Epoch 651/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5487\n",
      "Epoch 00651: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5589\n",
      "Epoch 652/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7489\n",
      "Epoch 00652: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7146\n",
      "Epoch 653/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6817\n",
      "Epoch 00653: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6198\n",
      "Epoch 654/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4394\n",
      "Epoch 00654: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5634\n",
      "Epoch 655/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7613\n",
      "Epoch 00655: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7150\n",
      "Epoch 656/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5983\n",
      "Epoch 00656: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5326\n",
      "Epoch 657/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6811\n",
      "Epoch 00657: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6506\n",
      "Epoch 658/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6513\n",
      "Epoch 00658: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6831\n",
      "Epoch 659/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6298\n",
      "Epoch 00659: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6162\n",
      "Epoch 660/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3100\n",
      "Epoch 00660: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1831\n",
      "Epoch 661/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8691.3658\n",
      "Epoch 00661: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8691.2724\n",
      "Epoch 662/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1415\n",
      "Epoch 00662: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1244\n",
      "Epoch 663/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6911\n",
      "Epoch 00663: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7150\n",
      "Epoch 664/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5512\n",
      "Epoch 00664: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5950\n",
      "Epoch 665/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5465\n",
      "Epoch 00665: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5052\n",
      "Epoch 666/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7333\n",
      "Epoch 00666: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7316\n",
      "Epoch 667/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6083\n",
      "Epoch 00667: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5227\n",
      "Epoch 668/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3980\n",
      "Epoch 00668: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3447\n",
      "Epoch 669/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6584\n",
      "Epoch 00669: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6909\n",
      "Epoch 670/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3918\n",
      "Epoch 00670: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4268\n",
      "Epoch 671/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5082\n",
      "Epoch 00671: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4650\n",
      "Epoch 672/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7057\n",
      "Epoch 00672: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7701\n",
      "Epoch 673/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7394\n",
      "Epoch 00673: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8208\n",
      "Epoch 674/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2222\n",
      "Epoch 00674: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2525\n",
      "Epoch 675/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7579\n",
      "Epoch 00675: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7518\n",
      "Epoch 676/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4080\n",
      "Epoch 00676: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3639\n",
      "Epoch 677/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5345\n",
      "Epoch 00677: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5732\n",
      "Epoch 678/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5558\n",
      "Epoch 00678: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 679/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5359\n",
      "Epoch 00679: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4891\n",
      "Epoch 680/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8174\n",
      "Epoch 00680: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7717\n",
      "Epoch 681/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5042\n",
      "Epoch 00681: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4124\n",
      "Epoch 682/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5617\n",
      "Epoch 00682: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5136\n",
      "Epoch 683/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4536\n",
      "Epoch 00683: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4212\n",
      "Epoch 684/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4813\n",
      "Epoch 00684: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5125\n",
      "Epoch 685/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4809\n",
      "Epoch 00685: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4371\n",
      "Epoch 686/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6125\n",
      "Epoch 00686: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6356\n",
      "Epoch 687/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5926\n",
      "Epoch 00687: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5537\n",
      "Epoch 688/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3841\n",
      "Epoch 00688: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3251\n",
      "Epoch 689/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2745\n",
      "Epoch 00689: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3215\n",
      "Epoch 690/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6372\n",
      "Epoch 00690: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5880\n",
      "Epoch 691/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3662\n",
      "Epoch 00691: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3831\n",
      "Epoch 692/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5165\n",
      "Epoch 00692: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5957\n",
      "Epoch 693/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5913\n",
      "Epoch 00693: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5897\n",
      "Epoch 694/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5428\n",
      "Epoch 00694: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8690.5737\n",
      "Epoch 695/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3830\n",
      "Epoch 00695: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3646\n",
      "Epoch 696/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4008\n",
      "Epoch 00696: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4445\n",
      "Epoch 697/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5929\n",
      "Epoch 00697: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6681\n",
      "Epoch 698/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8652\n",
      "Epoch 00698: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8836\n",
      "Epoch 699/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3450\n",
      "Epoch 00699: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3333\n",
      "Epoch 700/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5118\n",
      "Epoch 00700: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4439\n",
      "Epoch 701/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2300\n",
      "Epoch 00701: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2375\n",
      "Epoch 702/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4172\n",
      "Epoch 00702: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2795\n",
      "Epoch 703/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.7563\n",
      "Epoch 00703: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8690.7875\n",
      "Epoch 704/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1718\n",
      "Epoch 00704: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2059\n",
      "Epoch 705/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4953\n",
      "Epoch 00705: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6016\n",
      "Epoch 706/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4900\n",
      "Epoch 00706: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4425\n",
      "Epoch 707/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4023\n",
      "Epoch 00707: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4217\n",
      "Epoch 708/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3959\n",
      "Epoch 00708: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2978\n",
      "Epoch 709/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5627\n",
      "Epoch 00709: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5627\n",
      "Epoch 710/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3651\n",
      "Epoch 00710: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3548\n",
      "Epoch 711/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4983\n",
      "Epoch 00711: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4451\n",
      "Epoch 712/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4057\n",
      "Epoch 00712: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4537\n",
      "Epoch 713/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2918\n",
      "Epoch 00713: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3000\n",
      "Epoch 714/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6370\n",
      "Epoch 00714: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.6512\n",
      "Epoch 715/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2737\n",
      "Epoch 00715: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3631\n",
      "Epoch 716/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4596\n",
      "Epoch 00716: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3870\n",
      "Epoch 717/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2196\n",
      "Epoch 00717: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1714\n",
      "Epoch 718/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.6698\n",
      "Epoch 00718: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.7152\n",
      "Epoch 719/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 8690.2973\n",
      "Epoch 00719: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2888\n",
      "Epoch 720/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4422\n",
      "Epoch 00720: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3974\n",
      "Epoch 721/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1485\n",
      "Epoch 00721: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2304\n",
      "Epoch 722/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.8817\n",
      "Epoch 00722: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.8851\n",
      "Epoch 723/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2509\n",
      "Epoch 00723: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2764\n",
      "Epoch 724/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1912\n",
      "Epoch 00724: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2147\n",
      "Epoch 725/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5154\n",
      "Epoch 00725: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4646\n",
      "Epoch 726/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3555\n",
      "Epoch 00726: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8690.3775\n",
      "Epoch 727/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4607\n",
      "Epoch 00727: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4101\n",
      "Epoch 728/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1516\n",
      "Epoch 00728: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1133\n",
      "Epoch 729/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4406\n",
      "Epoch 00729: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3850\n",
      "Epoch 730/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4132\n",
      "Epoch 00730: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5382\n",
      "Epoch 731/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3210\n",
      "Epoch 00731: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3896\n",
      "Epoch 732/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2316\n",
      "Epoch 00732: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1587\n",
      "Epoch 733/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1900\n",
      "Epoch 00733: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1370\n",
      "Epoch 734/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5487\n",
      "Epoch 00734: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4534\n",
      "Epoch 735/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1091\n",
      "Epoch 00735: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1272\n",
      "Epoch 736/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4877\n",
      "Epoch 00736: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5919\n",
      "Epoch 737/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3656\n",
      "Epoch 00737: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4139\n",
      "Epoch 738/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4875\n",
      "Epoch 00738: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5892\n",
      "Epoch 739/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1540\n",
      "Epoch 00739: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2755\n",
      "Epoch 740/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4849\n",
      "Epoch 00740: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4496\n",
      "Epoch 741/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2896\n",
      "Epoch 00741: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2690\n",
      "Epoch 742/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2104\n",
      "Epoch 00742: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2643\n",
      "Epoch 743/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3225\n",
      "Epoch 00743: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2869\n",
      "Epoch 744/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5653\n",
      "Epoch 00744: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5743\n",
      "Epoch 745/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2270\n",
      "Epoch 00745: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2083\n",
      "Epoch 746/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3031\n",
      "Epoch 00746: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2243\n",
      "Epoch 747/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2628\n",
      "Epoch 00747: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8690.2185\n",
      "Epoch 748/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1949\n",
      "Epoch 00748: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2076\n",
      "Epoch 749/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4259\n",
      "Epoch 00749: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3189\n",
      "Epoch 750/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3932\n",
      "Epoch 00750: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3988\n",
      "Epoch 751/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1648\n",
      "Epoch 00751: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1263\n",
      "Epoch 752/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0768\n",
      "Epoch 00752: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1037\n",
      "Epoch 753/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5311\n",
      "Epoch 00753: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5894\n",
      "Epoch 754/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2740\n",
      "Epoch 00754: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2246\n",
      "Epoch 755/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2984\n",
      "Epoch 00755: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2710\n",
      "Epoch 756/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1976\n",
      "Epoch 00756: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2068\n",
      "Epoch 757/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2273\n",
      "Epoch 00757: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3090\n",
      "Epoch 758/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4885\n",
      "Epoch 00758: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5543\n",
      "Epoch 759/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 8690.0193\n",
      "Epoch 00759: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0843\n",
      "Epoch 760/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2570\n",
      "Epoch 00760: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2888\n",
      "Epoch 761/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0914\n",
      "Epoch 00761: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8690.0272\n",
      "Epoch 762/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3848\n",
      "Epoch 00762: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3284\n",
      "Epoch 763/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4291\n",
      "Epoch 00763: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3561\n",
      "Epoch 764/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4023\n",
      "Epoch 00764: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4194\n",
      "Epoch 765/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0276\n",
      "Epoch 00765: loss did not improve from 8684.55859\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0713\n",
      "Epoch 766/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2283\n",
      "Epoch 00766: loss improved from 8684.55859 to 8683.95117, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-766-8.68395e+03.hdf5\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0752\n",
      "Epoch 767/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4150\n",
      "Epoch 00767: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3657\n",
      "Epoch 768/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2204\n",
      "Epoch 00768: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2392\n",
      "Epoch 769/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0903\n",
      "Epoch 00769: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0086\n",
      "Epoch 770/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4956\n",
      "Epoch 00770: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3949\n",
      "Epoch 771/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9865\n",
      "Epoch 00771: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0088\n",
      "Epoch 772/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3329\n",
      "Epoch 00772: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3363\n",
      "Epoch 773/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1775\n",
      "Epoch 00773: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1695\n",
      "Epoch 774/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1843\n",
      "Epoch 00774: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1836\n",
      "Epoch 775/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0574\n",
      "Epoch 00775: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1250\n",
      "Epoch 776/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1333\n",
      "Epoch 00776: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1212\n",
      "Epoch 777/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3522\n",
      "Epoch 00777: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2992\n",
      "Epoch 778/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2013\n",
      "Epoch 00778: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0619\n",
      "Epoch 779/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2685\n",
      "Epoch 00779: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2890\n",
      "Epoch 780/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1588\n",
      "Epoch 00780: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2718\n",
      "Epoch 781/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1339\n",
      "Epoch 00781: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2329\n",
      "Epoch 782/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0374\n",
      "Epoch 00782: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0457\n",
      "Epoch 783/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2535\n",
      "Epoch 00783: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3297\n",
      "Epoch 784/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4409\n",
      "Epoch 00784: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5089\n",
      "Epoch 785/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9014\n",
      "Epoch 00785: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9340\n",
      "Epoch 786/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2310\n",
      "Epoch 00786: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1406\n",
      "Epoch 787/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0964\n",
      "Epoch 00787: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0988\n",
      "Epoch 788/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1207\n",
      "Epoch 00788: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1168\n",
      "Epoch 789/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0754\n",
      "Epoch 00789: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0070\n",
      "Epoch 790/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2202\n",
      "Epoch 00790: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2353\n",
      "Epoch 791/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1365\n",
      "Epoch 00791: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1561\n",
      "Epoch 792/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1219\n",
      "Epoch 00792: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0539\n",
      "Epoch 793/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2131\n",
      "Epoch 00793: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2892\n",
      "Epoch 794/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0446\n",
      "Epoch 00794: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0514\n",
      "Epoch 795/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2284\n",
      "Epoch 00795: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1935\n",
      "Epoch 796/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0959\n",
      "Epoch 00796: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1614\n",
      "Epoch 797/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2591\n",
      "Epoch 00797: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3244\n",
      "Epoch 798/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1980\n",
      "Epoch 00798: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0097\n",
      "Epoch 00799: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0482\n",
      "Epoch 800/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1555\n",
      "Epoch 00800: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1790\n",
      "Epoch 801/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1318\n",
      "Epoch 00801: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0700\n",
      "Epoch 802/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9868\n",
      "Epoch 00802: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9183\n",
      "Epoch 803/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1347\n",
      "Epoch 00803: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0304\n",
      "Epoch 804/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0882\n",
      "Epoch 00804: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0776\n",
      "Epoch 805/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3612\n",
      "Epoch 00805: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4320\n",
      "Epoch 806/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9865\n",
      "Epoch 00806: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0859\n",
      "Epoch 807/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1072\n",
      "Epoch 00807: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0828\n",
      "Epoch 808/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9751\n",
      "Epoch 00808: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9757\n",
      "Epoch 809/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1157\n",
      "Epoch 00809: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0548\n",
      "Epoch 810/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0700\n",
      "Epoch 00810: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9208\n",
      "Epoch 811/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3294\n",
      "Epoch 00811: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2437\n",
      "Epoch 812/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9824\n",
      "Epoch 00812: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9747\n",
      "Epoch 813/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0082\n",
      "Epoch 00813: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9160\n",
      "Epoch 814/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1634\n",
      "Epoch 00814: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1766\n",
      "Epoch 815/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0239\n",
      "Epoch 00815: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0509\n",
      "Epoch 816/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9338\n",
      "Epoch 00816: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9389\n",
      "Epoch 817/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1048\n",
      "Epoch 00817: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0452\n",
      "Epoch 818/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0729\n",
      "Epoch 00818: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1541\n",
      "Epoch 819/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9699\n",
      "Epoch 00819: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8896\n",
      "Epoch 820/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.5530\n",
      "Epoch 00820: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.5094\n",
      "Epoch 821/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7534\n",
      "Epoch 00821: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7425\n",
      "Epoch 822/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0474\n",
      "Epoch 00822: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0587\n",
      "Epoch 823/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9223\n",
      "Epoch 00823: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9234\n",
      "Epoch 824/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9731\n",
      "Epoch 00824: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9617\n",
      "Epoch 825/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1579\n",
      "Epoch 00825: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2019\n",
      "Epoch 826/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9204\n",
      "Epoch 00826: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8350\n",
      "Epoch 827/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1457\n",
      "Epoch 00827: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1096\n",
      "Epoch 828/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1781\n",
      "Epoch 00828: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2016\n",
      "Epoch 829/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8564\n",
      "Epoch 00829: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7574\n",
      "Epoch 830/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2219\n",
      "Epoch 00830: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2354\n",
      "Epoch 831/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8805\n",
      "Epoch 00831: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8077\n",
      "Epoch 832/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0588\n",
      "Epoch 00832: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0703\n",
      "Epoch 833/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7861\n",
      "Epoch 00833: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8285\n",
      "Epoch 834/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1126\n",
      "Epoch 00834: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1137\n",
      "Epoch 835/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7963\n",
      "Epoch 00835: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8389\n",
      "Epoch 836/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0707\n",
      "Epoch 00836: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0743\n",
      "Epoch 837/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9547\n",
      "Epoch 00837: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9705\n",
      "Epoch 838/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1581\n",
      "Epoch 00838: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1117\n",
      "Epoch 839/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 8689.7368\n",
      "Epoch 00839: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.6753\n",
      "Epoch 840/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0441\n",
      "Epoch 00840: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0078\n",
      "Epoch 841/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9340\n",
      "Epoch 00841: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9040\n",
      "Epoch 842/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3152\n",
      "Epoch 00842: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.2570\n",
      "Epoch 843/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.6431\n",
      "Epoch 00843: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.6657\n",
      "Epoch 844/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.2692\n",
      "Epoch 00844: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8690.1883\n",
      "Epoch 845/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8266\n",
      "Epoch 00845: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8689.8512\n",
      "Epoch 846/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9145\n",
      "Epoch 00846: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8896\n",
      "Epoch 847/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7719\n",
      "Epoch 00847: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7503\n",
      "Epoch 848/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1506\n",
      "Epoch 00848: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1705\n",
      "Epoch 849/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0398\n",
      "Epoch 00849: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9996\n",
      "Epoch 850/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.3239\n",
      "Epoch 00850: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.4266\n",
      "Epoch 851/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0598\n",
      "Epoch 00851: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0812\n",
      "Epoch 852/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8159\n",
      "Epoch 00852: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7834\n",
      "Epoch 853/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7359\n",
      "Epoch 00853: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7570\n",
      "Epoch 854/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.4269\n",
      "Epoch 00854: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.3865\n",
      "Epoch 855/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9027\n",
      "Epoch 00855: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9803\n",
      "Epoch 856/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.5772\n",
      "Epoch 00856: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.5996\n",
      "Epoch 857/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1311\n",
      "Epoch 00857: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8690.0243\n",
      "Epoch 858/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7489\n",
      "Epoch 00858: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7734\n",
      "Epoch 859/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8030\n",
      "Epoch 00859: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8714\n",
      "Epoch 860/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0678\n",
      "Epoch 00860: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9545\n",
      "Epoch 861/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.1496\n",
      "Epoch 00861: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.1150\n",
      "Epoch 862/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7701\n",
      "Epoch 00862: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7997\n",
      "Epoch 863/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9323\n",
      "Epoch 00863: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8251\n",
      "Epoch 864/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7560\n",
      "Epoch 00864: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7193\n",
      "Epoch 865/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0598\n",
      "Epoch 00865: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0751\n",
      "Epoch 866/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7390\n",
      "Epoch 00866: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7458\n",
      "Epoch 867/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0462\n",
      "Epoch 00867: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9778\n",
      "Epoch 868/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7771\n",
      "Epoch 00868: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8135\n",
      "Epoch 869/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9465\n",
      "Epoch 00869: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9761\n",
      "Epoch 870/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7407\n",
      "Epoch 00870: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8010\n",
      "Epoch 871/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0469\n",
      "Epoch 00871: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0434\n",
      "Epoch 872/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7531\n",
      "Epoch 00872: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7664\n",
      "Epoch 873/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9569\n",
      "Epoch 00873: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9727\n",
      "Epoch 874/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.6697\n",
      "Epoch 00874: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.6684\n",
      "Epoch 875/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9679\n",
      "Epoch 00875: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0031\n",
      "Epoch 876/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7600\n",
      "Epoch 00876: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7372\n",
      "Epoch 877/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8620\n",
      "Epoch 00877: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8084\n",
      "Epoch 878/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8310\n",
      "Epoch 00878: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8644\n",
      "Epoch 879/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 8690.0140\n",
      "Epoch 00879: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9835\n",
      "Epoch 880/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8901\n",
      "Epoch 00880: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9238\n",
      "Epoch 881/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.6966\n",
      "Epoch 00881: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.6516\n",
      "Epoch 882/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8648\n",
      "Epoch 00882: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8301\n",
      "Epoch 883/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.6170\n",
      "Epoch 00883: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.5787\n",
      "Epoch 884/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0105\n",
      "Epoch 00884: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9022\n",
      "Epoch 885/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9169\n",
      "Epoch 00885: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8507\n",
      "Epoch 886/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7864\n",
      "Epoch 00886: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8536\n",
      "Epoch 887/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9265\n",
      "Epoch 00887: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8690.0840\n",
      "Epoch 888/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7778\n",
      "Epoch 00888: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8831\n",
      "Epoch 889/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7459\n",
      "Epoch 00889: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8750\n",
      "Epoch 890/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7909\n",
      "Epoch 00890: loss did not improve from 8683.95117\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8985\n",
      "Epoch 891/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7817\n",
      "Epoch 00891: loss improved from 8683.95117 to 8683.73926, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-891-8.68374e+03.hdf5\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.6343\n",
      "Epoch 892/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9352\n",
      "Epoch 00892: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9781\n",
      "Epoch 893/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8423\n",
      "Epoch 00893: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8080\n",
      "Epoch 894/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.6316\n",
      "Epoch 00894: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7058\n",
      "Epoch 895/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8069\n",
      "Epoch 00895: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8725\n",
      "Epoch 896/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7896\n",
      "Epoch 00896: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7309\n",
      "Epoch 897/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7783\n",
      "Epoch 00897: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7791\n",
      "Epoch 898/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8128\n",
      "Epoch 00898: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8213\n",
      "Epoch 899/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7145\n",
      "Epoch 00899: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8038\n",
      "Epoch 900/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8690.0060\n",
      "Epoch 00900: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9054\n",
      "Epoch 901/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.5237\n",
      "Epoch 00901: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.4438\n",
      "Epoch 902/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9665\n",
      "Epoch 00902: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9710\n",
      "Epoch 903/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8390\n",
      "Epoch 00903: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9042\n",
      "Epoch 904/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7538\n",
      "Epoch 00904: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7095\n",
      "Epoch 905/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.5707\n",
      "Epoch 00905: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.4855\n",
      "Epoch 906/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8782\n",
      "Epoch 00906: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9211\n",
      "Epoch 907/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8100\n",
      "Epoch 00907: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8151\n",
      "Epoch 908/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.6275\n",
      "Epoch 00908: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7242\n",
      "Epoch 909/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8405\n",
      "Epoch 00909: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7731\n",
      "Epoch 910/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.5665\n",
      "Epoch 00910: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.5400\n",
      "Epoch 911/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7971\n",
      "Epoch 00911: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7886\n",
      "Epoch 912/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.9081\n",
      "Epoch 00912: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9315\n",
      "Epoch 913/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7796\n",
      "Epoch 00913: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7775\n",
      "Epoch 914/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.6171\n",
      "Epoch 00914: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7005\n",
      "Epoch 915/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.5769\n",
      "Epoch 00915: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.6649\n",
      "Epoch 916/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8596\n",
      "Epoch 00916: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7982\n",
      "Epoch 917/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7917\n",
      "Epoch 00917: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 85s 2s/step - loss: 8689.7496\n",
      "Epoch 918/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.6212\n",
      "Epoch 00918: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.6692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 919/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.5568\n",
      "Epoch 00919: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.5138\n",
      "Epoch 920/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8317\n",
      "Epoch 00920: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8147\n",
      "Epoch 921/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7682\n",
      "Epoch 00921: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7102\n",
      "Epoch 922/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8665\n",
      "Epoch 00922: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8687\n",
      "Epoch 923/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.6066\n",
      "Epoch 00923: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.5708\n",
      "Epoch 924/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.6614\n",
      "Epoch 00924: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7078\n",
      "Epoch 925/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.6435\n",
      "Epoch 00925: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7261\n",
      "Epoch 926/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8043\n",
      "Epoch 00926: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8043\n",
      "Epoch 927/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7358\n",
      "Epoch 00927: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7550\n",
      "Epoch 928/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.6954\n",
      "Epoch 00928: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.6620\n",
      "Epoch 929/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.5681\n",
      "Epoch 00929: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.4790\n",
      "Epoch 930/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.6712\n",
      "Epoch 00930: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7204\n",
      "Epoch 931/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7318\n",
      "Epoch 00931: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7335\n",
      "Epoch 932/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.5579\n",
      "Epoch 00932: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.5545\n",
      "Epoch 933/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8510\n",
      "Epoch 00933: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.8090\n",
      "Epoch 934/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.5273\n",
      "Epoch 00934: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.5691\n",
      "Epoch 935/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.8275\n",
      "Epoch 00935: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.9405\n",
      "Epoch 936/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.7695\n",
      "Epoch 00936: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.7026\n",
      "Epoch 937/10000\n",
      "40/40 [==============================] - ETA: 0s - loss: 8689.4935\n",
      "Epoch 00937: loss did not improve from 8683.73926\n",
      "40/40 [==============================] - 84s 2s/step - loss: 8689.4816\n",
      "Epoch 938/10000\n",
      "23/40 [================>.............] - ETA: 36s - loss: 8690.0084"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_267963/1177796222.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchkpoint_model\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = vae_model.fit(train_gen, epochs=10000, callbacks= [chkpoint_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "814a1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model.save_weights('/dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/ntest.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 - EPSIC [DLS Conda]",
   "language": "python",
   "name": "conda-env-DLS_Conda-epsic3.7-kernel.json"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
