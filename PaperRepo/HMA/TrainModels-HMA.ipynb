{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9318ec3e",
   "metadata": {},
   "source": [
    "# Train the Models for some/all your datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af03e3",
   "metadata": {},
   "source": [
    "### First just run the cell below, it should hopefully complete without error (expect some Warnings from TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed1e1813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 15:12:18.837532: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/dls_sw/apps/python/anaconda/4.6.14/64/envs/epsic3.7/lib/python3.7/site-packages/pyUSID/viz/__init__.py:18: FutureWarning: Please use sidpy.viz.plot_utils instead of pyUSID.viz.plot_utils. pyUSID.plot_utils will be removed in a future release of pyUSID\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow v2.3.0\n",
      "Using TensorFlow v2.3.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "#load some packages in\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as python_random\n",
    "from numba import njit\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from stemutils.io import Path\n",
    "import hyperspy.api as hs\n",
    "import concurrent.futures\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import lru_cache\n",
    "from stemseg.processing_funcs import *\n",
    "\n",
    "#set some variables\n",
    "print('Using TensorFlow v%s' % tf.__version__)\n",
    "plt.style.use('default')\n",
    "\n",
    "\n",
    "#define some functions\n",
    "\n",
    "###################################################\n",
    "########### Data Preprocessing ####################\n",
    "###################################################\n",
    "\n",
    "def batch_resize(d, bs=512):\n",
    "    if len(d.shape) == 4:\n",
    "        flat_d = flatten_nav(d)\n",
    "    else:\n",
    "        flat_d = d\n",
    "    n_batches = int(np.ceil(flat_d.shape[0]//bs))\n",
    "    batches = [flat_d[i*bs:(i+1)*bs] for i in range(n_batches+1)]\n",
    "    if len(batches[-1])==0:\n",
    "        batches.pop(-1)\n",
    "    print(len(batches[-1]))\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=4) as exe:\n",
    "        res = [exe.submit(resize, batch, (batch.shape[0],128,128)) for batch in batches]\n",
    "    r_batches = [f.result() for f in res]\n",
    "    return np.concatenate(r_batches, axis = 0).reshape((d.shape[0],128,128))\n",
    "\n",
    "def data_manip(d, bs = 512):\n",
    "    if type(d) != np.ndarray:\n",
    "        print('dask to numpy')\n",
    "        d = d.compute()\n",
    "        print('dask to numpy done')\n",
    "    print('started data manipulations')\n",
    "    #d = resize(d,(d.shape[0],128,128))\n",
    "    print('resized')\n",
    "    d = d.astype('float32')\n",
    "    for i in range(d.shape[0]):\n",
    "        d_max = np.max(d[i])\n",
    "        d[i] = d[i]/d_max\n",
    "    d = batch_resize(d, bs)\n",
    "    scaler = np.log(1001)\n",
    "    return np.log((d*1000)+1)/scaler \n",
    "\n",
    "\n",
    "def data_manip_lowq(d, central_box = 128):\n",
    "    pxc, pyc = d.shape[1]//2, d.shape[2]//2 \n",
    "    pxl, pxu = pxc - central_box//2, pxc + central_box//2 \n",
    "    pyl, pyu = pyc - central_box//2, pyc + central_box//2 \n",
    "    \n",
    "    d = d[:, pxl:pxu, pyl:pyu]\n",
    "    if type(d) != np.ndarray:\n",
    "        print('dask to numpy')\n",
    "        d = d.compute()\n",
    "        print('dask to numpy done')\n",
    "    print('started data manipulations')\n",
    "    #d = resize(d,(d.shape[0],128,128))\n",
    "    print('resized')\n",
    "    d = d.astype('float32')\n",
    "    for i in range(d.shape[0]):\n",
    "        d_max = np.max(d[i])\n",
    "        d[i] = d[i]/d_max\n",
    "    \n",
    "    scaler = np.log(1001)\n",
    "    return np.log((d*1000)+1)/scaler \n",
    "\n",
    "\n",
    "###################################################\n",
    "###################################################\n",
    "###################################################\n",
    "\n",
    "def flatten_nav(sig):\n",
    "    shape = [sig.shape[0]*sig.shape[1]]\n",
    "    for i in sig.shape[2:]:\n",
    "        shape.append(i)\n",
    "    return sig.reshape(shape)\n",
    "\n",
    "\n",
    "class My_Custom_Generator(keras.utils.Sequence) :\n",
    "    def __init__(self, image_filenames,  batch_size) :\n",
    "        self.image_filenames = image_filenames\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n",
    "    \n",
    "    \n",
    "    @lru_cache(None)\n",
    "    def __getitem__(self, idx) :\n",
    "        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        out_img = np.asarray([np.load(file_name)[:,:,None] for file_name in batch_x])\n",
    "        return out_img, out_img\n",
    "        #return batch_x, batch_y\n",
    "        \n",
    "        \n",
    "class Array_Generator(keras.utils.Sequence) :\n",
    "    def __init__(self, images,  batch_size, target = 'same') :\n",
    "        self.images = images\n",
    "        self.batch_size = batch_size\n",
    "        if target == 'same':\n",
    "            self.target = images\n",
    "        else:\n",
    "            self.target = target\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.images) / float(self.batch_size))).astype(np.int)\n",
    "    \n",
    "    \n",
    "    @lru_cache(None)\n",
    "    def __getitem__(self, idx) :\n",
    "        out_img = self.images[idx * self.batch_size : (idx+1) * self.batch_size, :,:,None]\n",
    "        out_targ = self.target[idx * self.batch_size : (idx+1) * self.batch_size, :,:,None]\n",
    "        return out_img, out_targ\n",
    "        #return batch_x, batch_y\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        epsilon = tf.keras.backend.random_normal(shape=tf.shape(z_mean))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "def create_vae_model(hparams):\n",
    "    \n",
    "    n_img = 128\n",
    "    latent_dim = hparams['LAT']\n",
    "    beta = hparams['B']\n",
    "\n",
    "    image_input = keras.Input(shape=(n_img, n_img,1), name = 'enc_input')\n",
    "    x = layers.Conv2D(hparams['KN1'],5, strides = 2, activation='relu',padding='same', input_shape=image_input.shape, name = 'enc_conv1')(image_input)\n",
    "    x = layers.Conv2D(hparams['KN2'],5, strides = 2, activation='relu',padding='same', name = 'enc_conv2')(x)\n",
    "    x = layers.Conv2D(hparams['KN3'],5, strides = 2, activation='relu',padding='same', name = 'enc_conv3')(x)\n",
    "    x = layers.Conv2D(hparams['KN4'],5, strides = 2, activation='relu',padding='same', name = 'enc_conv4')(x)\n",
    "    x = layers.Conv2D(hparams['KN5'],5, strides = 2, activation='relu',padding='same', name = 'enc_conv5')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(hparams['D1'], activation='relu', name = 'enc_d1')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d2_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d3_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d4_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d5_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d6_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d7_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d8_t')(x)\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean_t\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var_t\")(x)\n",
    "    z_output = Sampling()([z_mean, z_log_var])\n",
    "    encoder_VAE = keras.Model(image_input, [z_mean, z_log_var, z_output])\n",
    "\n",
    "    z_input = keras.Input(shape=(latent_dim,), name = 'dec_input_t')\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d1_t')(z_input)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d2')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d3')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d4')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d5')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d6')(x)\n",
    "    x = layers.Dense(hparams['D1'], activation=\"relu\", name = 'dec_d7')(x)\n",
    "    x = layers.Dense(4*4*hparams['KN5'], activation=\"relu\", name = 'dec_d8')(x)\n",
    "    x = layers.Reshape((4, 4,hparams['KN5']))(x)\n",
    "    x = layers.Conv2DTranspose(hparams['KN4'],5, strides = 2, activation='relu',padding='same', name = 'dec_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(hparams['KN3'],5, strides = 2, activation='relu',padding='same', name = 'dec_conv2')(x)\n",
    "    x = layers.Conv2DTranspose(hparams['KN2'],5, strides = 2, activation='relu',padding='same', name = 'dec_conv3')(x)\n",
    "    x = layers.Conv2DTranspose(hparams['KN1'],5, strides = 2, activation='relu',padding='same', name = 'dec_conv4')(x)\n",
    "    image_output = layers.Conv2DTranspose(1,5, strides = 2, activation='sigmoid',padding='same', name = 'dec_conv5')(x)\n",
    "    #image_output = layers.Conv2DTranspose(16,3, strides = 2, activation='sigmoid',padding='same')\n",
    "    #image_output = layers.Reshape((n_img, n_img,1))(x)\n",
    "    decoder_VAE = keras.Model(z_input, image_output)\n",
    "\n",
    "    # VAE class\n",
    "    class VAE(keras.Model):\n",
    "        # constructor\n",
    "        def __init__(self, encoder, decoder, **kwargs):\n",
    "            super(VAE, self).__init__(**kwargs)\n",
    "            self.encoder = encoder\n",
    "            self.decoder = decoder\n",
    "\n",
    "        # customise train_step() to implement the loss \n",
    "        def train_step(self, x):\n",
    "            if isinstance(x, tuple):\n",
    "                x = x[0]\n",
    "            with tf.GradientTape() as tape:\n",
    "                # encoding\n",
    "                z_mean, z_log_var, z = self.encoder(x)\n",
    "                # decoding\n",
    "                x_prime = self.decoder(z)\n",
    "                # reconstruction error by binary crossentropy loss\n",
    "                reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(x, x_prime)) * n_img * n_img\n",
    "                # KL divergence\n",
    "                kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "                # loss = reconstruction error + KL divergence\n",
    "                loss = reconstruction_loss + beta* kl_loss\n",
    "            # apply gradient\n",
    "            grads = tape.gradient(loss, self.trainable_weights)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "            # return loss for metrics log\n",
    "            return {\"loss\": loss}\n",
    "\n",
    "\n",
    "        def call(self, x):\n",
    "            if isinstance(x, tuple):\n",
    "                x = x[0]\n",
    "            # encoding\n",
    "            z_mean, z_log_var, z = self.encoder(x)\n",
    "            # decoding\n",
    "            x_prime = self.decoder(z)\n",
    "            return x_prime\n",
    "    # build the VAE\n",
    "    vae_model = VAE(encoder_VAE, decoder_VAE)\n",
    "\n",
    "    # compile the VAE\n",
    "    vae_model.compile(optimizer=keras.optimizers.Adam(learning_rate=hparams['LR']),loss=custom_loss)\n",
    "    vae_model.build((1,128,128,1))\n",
    "    \n",
    "    return vae_model\n",
    "\n",
    "\n",
    "\n",
    "def custom_loss(x,y):\n",
    "    n_img = 128\n",
    "    return tf.reduce_mean(keras.losses.binary_crossentropy(x, y)) * n_img * n_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d8cb2",
   "metadata": {},
   "source": [
    "### Now check that you can find the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "632ca150",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 15:12:45.452895: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2022-03-21 15:12:45.453990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-03-21 15:12:45.454015: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-21 15:12:45.485348: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-21 15:12:45.497305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-21 15:12:45.507387: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-21 15:12:45.523734: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolv"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "er.so.10\n",
      "2022-03-21 15:12:45.530080: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-21 15:12:45.557817: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-21 15:12:45.559595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc9b277",
   "metadata": {},
   "source": [
    "# Training a Single Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f176f5",
   "metadata": {},
   "source": [
    "### Either enter the path directly to the dp variable or use the index from the list above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bffe1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Either\n",
    "dp = Path('/dls/science/groups/imaging/ePSIC_students/Al_alloy_4DSTEM_EM19064-2/20180727_112544-9cmCL-4Mx.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67044adc",
   "metadata": {},
   "source": [
    "### Create a directory to save our intermediate model checkpoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b8aabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel\n"
     ]
    }
   ],
   "source": [
    "mp = Path('/dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel')\n",
    "if not mp.exists():\n",
    "    mp.mkdir()\n",
    "print(mp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05f914f",
   "metadata": {},
   "source": [
    "### Load in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53835384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:hdf5plugin:blosc filter already loaded, skip it.\n",
      "WARNING:hdf5plugin:bshuf filter already loaded, skip it.\n",
      "WARNING:hdf5plugin:lz4 filter already loaded, skip it.\n",
      "WARNING:hdf5plugin:zfp filter already loaded, skip it.\n",
      "WARNING:hdf5plugin:fcidecomp filter already loaded, skip it.\n"
     ]
    }
   ],
   "source": [
    "sample = ProcessedSample(dp, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd976a9c",
   "metadata": {},
   "source": [
    "### Create a dictionary to hold some useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5f57da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be3e2406",
   "metadata": {},
   "outputs": [],
   "source": [
    "nds = flatten_nav(sample.raw_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6202317b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261121, 256, 256)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2a32f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = hs.load(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95cb4b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n"
     ]
    }
   ],
   "source": [
    "from skimage.measure import shannon_entropy\n",
    "\n",
    "entropy = np.zeros((sample.raw_data.data.shape[0:2]))\n",
    "\n",
    "for i in range(ds.data.shape[0]):\n",
    "    print(i)\n",
    "    for j in range(ds.data.shape[1]):\n",
    "        entropy[i,j] = shannon_entropy(ds.data[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "080a6ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_patterns = flatten_nav(ds.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "afad0cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "entr = flatten_nav(entropy**20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1918a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_pdf = entr/ entr.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "72a24fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"426\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([1.8153e+04, 2.7689e+04, 3.6358e+04, 3.6621e+04, 4.0861e+04,\n",
       "        3.9430e+04, 2.7905e+04, 1.5369e+04, 7.5060e+03, 3.6770e+03,\n",
       "        1.8000e+03, 9.9100e+02, 6.3800e+02, 3.9200e+02, 3.0600e+02,\n",
       "        2.3800e+02, 1.8800e+02, 1.5400e+02, 1.5600e+02, 1.4500e+02,\n",
       "        1.1300e+02, 1.0100e+02, 1.1800e+02, 1.0700e+02, 8.0000e+01,\n",
       "        9.3000e+01, 8.9000e+01, 9.1000e+01, 7.3000e+01, 7.5000e+01,\n",
       "        8.6000e+01, 8.6000e+01, 6.4000e+01, 6.1000e+01, 5.6000e+01,\n",
       "        8.0000e+01, 6.8000e+01, 5.6000e+01, 5.2000e+01, 5.8000e+01,\n",
       "        4.6000e+01, 6.4000e+01, 4.6000e+01, 4.9000e+01, 5.4000e+01,\n",
       "        4.2000e+01, 5.4000e+01, 3.6000e+01, 4.2000e+01, 3.6000e+01,\n",
       "        3.4000e+01, 4.4000e+01, 3.0000e+01, 2.3000e+01, 3.2000e+01,\n",
       "        2.3000e+01, 2.2000e+01, 1.6000e+01, 1.9000e+01, 1.5000e+01,\n",
       "        1.5000e+01, 1.4000e+01, 2.3000e+01, 1.3000e+01, 1.8000e+01,\n",
       "        1.6000e+01, 1.2000e+01, 6.0000e+00, 6.0000e+00, 1.2000e+01,\n",
       "        1.0000e+01, 2.0000e+00, 1.0000e+01, 8.0000e+00, 5.0000e+00,\n",
       "        4.0000e+00, 3.0000e+00, 4.0000e+00, 5.0000e+00, 5.0000e+00,\n",
       "        2.0000e+00, 2.0000e+00, 2.0000e+00, 1.0000e+00, 2.0000e+00,\n",
       "        3.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00, 2.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00]),\n",
       " array([1.65690494e-07, 9.46855359e-07, 1.72802022e-06, 2.50918509e-06,\n",
       "        3.29034995e-06, 4.07151482e-06, 4.85267968e-06, 5.63384455e-06,\n",
       "        6.41500942e-06, 7.19617428e-06, 7.97733915e-06, 8.75850401e-06,\n",
       "        9.53966888e-06, 1.03208337e-05, 1.11019986e-05, 1.18831635e-05,\n",
       "        1.26643283e-05, 1.34454932e-05, 1.42266581e-05, 1.50078229e-05,\n",
       "        1.57889878e-05, 1.65701527e-05, 1.73513175e-05, 1.81324824e-05,\n",
       "        1.89136473e-05, 1.96948121e-05, 2.04759770e-05, 2.12571419e-05,\n",
       "        2.20383067e-05, 2.28194716e-05, 2.36006364e-05, 2.43818013e-05,\n",
       "        2.51629662e-05, 2.59441310e-05, 2.67252959e-05, 2.75064608e-05,\n",
       "        2.82876256e-05, 2.90687905e-05, 2.98499554e-05, 3.06311202e-05,\n",
       "        3.14122851e-05, 3.21934500e-05, 3.29746148e-05, 3.37557797e-05,\n",
       "        3.45369446e-05, 3.53181094e-05, 3.60992743e-05, 3.68804392e-05,\n",
       "        3.76616040e-05, 3.84427689e-05, 3.92239337e-05, 4.00050986e-05,\n",
       "        4.07862635e-05, 4.15674283e-05, 4.23485932e-05, 4.31297581e-05,\n",
       "        4.39109229e-05, 4.46920878e-05, 4.54732527e-05, 4.62544175e-05,\n",
       "        4.70355824e-05, 4.78167473e-05, 4.85979121e-05, 4.93790770e-05,\n",
       "        5.01602419e-05, 5.09414067e-05, 5.17225716e-05, 5.25037365e-05,\n",
       "        5.32849013e-05, 5.40660662e-05, 5.48472311e-05, 5.56283959e-05,\n",
       "        5.64095608e-05, 5.71907256e-05, 5.79718905e-05, 5.87530554e-05,\n",
       "        5.95342202e-05, 6.03153851e-05, 6.10965500e-05, 6.18777148e-05,\n",
       "        6.26588797e-05, 6.34400446e-05, 6.42212094e-05, 6.50023743e-05,\n",
       "        6.57835392e-05, 6.65647040e-05, 6.73458689e-05, 6.81270338e-05,\n",
       "        6.89081986e-05, 6.96893635e-05, 7.04705284e-05, 7.12516932e-05,\n",
       "        7.20328581e-05, 7.28140229e-05, 7.35951878e-05, 7.43763527e-05,\n",
       "        7.51575175e-05, 7.59386824e-05, 7.67198473e-05, 7.75010121e-05,\n",
       "        7.82821770e-05]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(sl_pdf,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2aeb7390",
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_loc = np.zeros(data_patterns.shape[0])\n",
    "for choice in np.random.choice(np.arange(data_patterns.shape[0]), 10000, True, sl_pdf):\n",
    "    choice_loc[choice] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "088238c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"771\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0d0acd8fd0>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(choice_loc.reshape(ds.data.shape[0:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "024ab496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_locs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5007f4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:hyperspy.signal:Changing data type from int64 to the original uint8\n",
      "WARNING:hyperspy.signal:Changing data type from int64 to the original uint8\n",
      "WARNING:hyperspy.signal:Changing data type from int64 to the original uint8\n",
      "WARNING:hyperspy.signal:Changing data type from int64 to the original uint8\n",
      "WARNING:hyperspy.signal:Changing data type from int64 to the original uint8\n",
      "WARNING:hyperspy.signal:Changing data type from int64 to the original uint8\n",
      "WARNING:hyperspy.signal:Changing data type from int64 to the original uint8\n",
      "WARNING:hyperspy.signal:Changing data type from int64 to the original uint8\n",
      "WARNING:hyperspy.signal:Changing data type from int64 to the original uint8\n",
      "WARNING:hyperspy.signal:Changing data type from int64 to the original uint8\n"
     ]
    }
   ],
   "source": [
    "mdps = []\n",
    "nldps = []\n",
    "for i in range(10):\n",
    "    sdps = hs.signals.Signal2D(data_patterns[np.random.choice(np.arange(data_patterns.shape[0]), 5000, True, sl_pdf)])\n",
    "    nldps.append(sdps.data)\n",
    "    dpc = sdps.copy()\n",
    "    dpc.add_poissonian_noise()\n",
    "    mdps.append(dpc.data)\n",
    "nds = flatten_nav(np.asarray(mdps))\n",
    "nlds = flatten_nav(np.asarray(nldps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca1918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507149ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d86087e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987755cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b3659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "20ab03c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started data manipulations\n",
      "resized\n",
      "started data manipulations\n",
      "resized\n"
     ]
    }
   ],
   "source": [
    "input_data = data_manip_lowq(nds)\n",
    "#np.random.shuffle(input_data)\n",
    "#input_targets = data_manip_lowq(nlds)\n",
    "val_data = data_manip_lowq(nds[::10])\n",
    "np.random.shuffle(val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8ab6791f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"399\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0d02eed7d0>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_patt = np.random.randint(0, len(input_data))\n",
    "plt.figure(figsize = (4,4))\n",
    "plt.imshow(input_data[rand_patt])\n",
    "#plt.figure(figsize = (4,4))\n",
    "#plt.imshow(input_targets[rand_patt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e3db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b9de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac1672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a40856e2",
   "metadata": {},
   "source": [
    "##### Otherwise just skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4f3e252b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "244c845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2048\n",
    "\n",
    "train_gen = Array_Generator(input_data, batch_size)#, target = input_targets)\n",
    "valid_gen = Array_Generator(val_data, batch_size)\n",
    "\n",
    "batch_shape = train_gen[0][0].shape\n",
    "input_shape = (batch_shape[1],batch_shape[2],batch_shape[3])\n",
    "out_dims = int(train_gen[0][1].shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f66918e",
   "metadata": {},
   "source": [
    "### Check the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "aff70b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"399\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAQoAAAEKCAYAAADqyxvJAAAgAElEQVR4nOy9eXQU15k2bmDAYAgExniAD3pXd6vV2vd96+5q1phFSEgCgQBhJAHad6m19d5VYIyNMcbgFS+JlyReYzsZz8RZJpuTOI49mUyS+U5+Z07OnPw5c85M8vz+eOveqla3NmPni8d9z7knDuquqq6696l3ed7nvQ2JkRiJkRjzjNv+X19AYiRGYvz1jwRQJEZiJMa8IwEUiZEYiTHvSABFYiRGYsw7EkCRGImRGPOOBFAkRmIkxrwjARSJkRiJMe9IAEViJEZizDsSQJEYiZEY844EUCRGYiTGvCMBFImRGIkx70gARWIkRmLMOxJAkRiJkRjzjgRQJEZiJMa8IwEUiZEYiTHvSABFYiRGYsw7EkCRGImRGPOOBFAkRmIkxrwjARSJkRiJMe9IAEViJEZizDsSQJEYiZEY844EUCRGYiTGvCMBFImRGIkx70gARWIkRmLMOxJAkRiJkRjzjgRQJEZiJMa8IwEUiZEYiTHvSABFYiRGYsw7PlWgePzxx1FQUICCggK8+eabn+apEiMxEuNTHJ8aUPzxj39Eamoq/vM//xN/+MMfYLfb8T//8z+f1ukSIzES41McnxpQvPbaa2htbeX/f/v27fjwww9n/fzK2+7A+ts2/sXmhr/ZjNXbTLhDS3PD7Vvn/87tW3GHxoQvrjNg/dK/w+qtyvfv0JqwZosJ65fcFf2d1VrcoTVh/RotNizfgjs0yudXGk1YmWTEyiQjVumVf193pzH+NSzdhNVbTVilp++t0snnvO2uuJ//wt8Zsfr/mLB+yd/hi+sNUddK16Tj92Hd3xqx/ra7sEpvwu1WA02zEasMJmxYthlfXG/g57xDZ4q65pUmI1Ya5ft4h+bTeV53aGPu09qNdJ++sCn6mlZvM2HD32yO/v7KbbjdYsRKmwErbXrcbjbStBqwymCKuTczn83qrSasX7oJ69fqlee92YT1t23Eur81xnx/wyrlPqzboPydPbv1X9At+Ld/cZ1yzi9sMvHfvGz9+k9r+8aMTw0onnzySQwPD/P/X19fj3fffTfqMzdu3EBlZSUqKytxx21fgGPJgb/YdK1qROnOIIrvDqFkTwjChpPzfset64R5QkJWs4gydwApPRKsQ8pMPy3Cubwu6jtCyhCsQxKK7w6hotoPs0eC2UOfN3lFGIIidPdGkDSpHKdkTyj+Na8+AnsHfd8YEJHTJKKi2g/H0proc97ZAkfhJDJOiUhrk+BcUY+Kan/UtVqHJLgyRiFsOImUHgmlO4NwLKuF2SNBcyUEzZUQ9FIE5gkJVRVeZB0XoXkoCH1EhCFE16yP0PVr7w9DHxFhHZIgWPrhWn0EzrwJOAon4cybgHNlwy0/L/fmNuQcEWHrpd9fWBOGM8cDx5IDyD4qwjJC98Q8LiGlR4Kw4SSEjafgKJxEZaUPRfvD0FwOQXM9AO1jPqS3ikg9K0F3gX6jdUhC0pSItHZ6VrmNEeQ00T229UmwjEioKvOi4GCY37+s4yIcS2vgyhxD8d2hqClsalWeW+oI//fCmjA9N4cfjsJJOAon4dZ0zPnbBXMf/35VmReOJQeQVx/BSoPp09q+MeMvZlHs2LFjToti/W0b/6JA8bEWq6EbeikC3b0R6M5HYB2WkDyozLmAwjpEi013IQKTT+T/ZvYoi5Udp2T37ECRek75nJDUG/9z6SP8+GqgSB5UQCJ5UAUU3RJKdxBQJA9K9PvujSBpSrlOfUSE8ekpaB/1Q3M1CN29EQKU6wFoHglAd2+EA4V7cxts/fQ9W58E4a7Tn9gzyGkSYfSLUcCefVSMeg4p3QQUroxRWIckDmy6eyPQPEgg6NZ1xj6b8xEU1EZizpnVLEIv0fNWAy0Dio/zO/LqI/x5VDj8i/5+8d4Q7tD+LwCKP/7xj0hLS8N//dd/4T/+4z/mjVF8EkDhNvYgq1mE29gT/++aDmQ1ixAs/R/v+JoOWEYlGIMiDGERrswxuA3dytx2LuY7bDGafCL0ERG6CxHopQgMYRGWUQkZp0QItkEISb38OMLGU7QY5LcIP97SGrg1HfxzrlWNCwYKYcNJCOY+pJ2hBe42dMO1pgmOZbW0ae5sgWNZLdJbRcXqUW0Mk1eE9oEwjH4RJh9tPM0NP0zPTkJzOQRDSIwBiqQpsjgy7iELjN+T9ceRc0SkN2qcZ+Na04TcwxFUl0zH/Lai/WFYRiRknhRRWemj725pj34Ouk44ltXCUTgJQ1iE7jzdc/O4BPOEhKRJiYBsWIIhLHILz+yRULorGHPOgtoILGPRIOsonIR769lZ10rpriCymsWYWS7QfRA2tcKVOQZb/8cDCmHjKWxYue3T2r4x41PNejz66KM86/HGG2/M+dkNt29dkPk/582zDxNCV/tp42k6IKw/rvzd0g/rkARnlmfBx3StaYJb0wHnygYId51G1nERqeck2LukWa9XWNcM97ZzcC6vg9vQjcwTtBgNQXrzJU0RYJimyTVw6zpp087cFPvCyK+LQDD3wa3vIpDQdNCmnus+mPuQeVJE5kkR+XURxcpZVouC2kj0ZlhWC/e2c3RsfRdSz0qwjMpv2THaVElTIixjEpIHVJtlQIL2gTCSnpuA5koIJq+IzBMigc7GU8hqpvuUPEDHy2wRIVgHIJj74MzxwOyRkNcQoeek60R18ZTy7GRwzT8UoXu/ol55k94d4tdQtC889/MrnIQ+InIXyTpE15I0KUF7Xxja+8PQXgpz4MhsEVFdPEXgs7mNuw8VDj+/n6lnCSjc+i44V9Rz4BaSehWw13SgsCbMv6OeUYB512nY+j4mUNzZgg23b/00t2/U+KvhUdyhNc3qmy8WKNgb3zokcQT/uEDhzB1H8oCkWClLa5Q5y3cqHH7YelUm99Ia5NdFkHpWgmv1EZTsDtEb+WoQ2kthJA9K3N+OmktrIFj6oRcphsFM63k3yFzXOePfmOvBjm0IK/dOdyECzfUA9DenkXpWgmNZLbKaacE7l9ch84TI/27rlaLPJZ/HtfoIzOMStJfC0DwcpA16MQL9zWloHg5CL0VgGZG4Gc7+V3eeXDRbvxTlwy8GKFyZYzFxGX1EhOYRumbdk15oHgnA5BORdkZSLLRltchsEcnqmfF7qounOFC4dZ2w9ZO1qDtP7qjRLyJ5QIJg7ot+BnGex60ARfHd/0tcj8WOO7QmZNwjonRXMGaWuQOzmtnxgEJ3PgLt/WFYh+MDRe7hCMqd/ph4QlygyJuAdUia1Z2JN0t20xs2q1lEXkMEeQ3kj5rHKVBWuiOI0h1BWMboTVZdMh0V/HIbulG6K4j8uggyT4hImhKR2xhBZaUPKT0SivYvACjmuk+bWvm9LdoXjrIU9BFyiapLpmEZk6B7wgvt4z6YJ8gst3dQsDCvIQKTV4TuSS8MN6ehF+l3znS/nCsbYOsla0pzOcRjBJqrQW5VGf1iVDyExQuMfvq3goNh7oYI5j5Ul0zTPTP3zfvsjH46vslLx0qapJiF5koI2gfCMARlqyt3nNwVGSgyTpH1ULorSK4MezZb2lFdPEVWo66TnquHXDPN5RD0ohyrmefaHEsooF5dNBV1/LmAv6rMy5+bvVP63xHMXOy4Q2uKQX8WDEs7I5FPt6px1ulYcgCCbRAp3bTINA+GYB2maL5rVSO9nZN66e05ICH1nDQv+LhWNXKTWEgZmj96v7QGrlWNKDgYhu7eCLQXoycLgJbuCsK19hgy7qGo+sxzVpV5eRDOEBSR0iPBkT8B1+ojSG8Vb93ysg1S/EGOQaT0UAAwpYc2tL1LgmPJAaSek6B/ygvNtQAF84Yk2HqVN77m4SD0N6dhuDkNzQ0/dPdG6DrXNMG1qhHO5XVwrqhHWjuBpO68HAB9iEAiaVI+Z1jkMQ5bH01jgMDDMkLXmXVcXNRvdK1qRGWlj+67nKFJ6ZF4kJW7I8MSnHl0bx1LDsC5vI4/m+QBui/OvAm+ztjLxbWqEYJ1gK65n65ZezECY1BESvfCXyzqY863tjJbRB6sNY9LWGlMAAWfFdV+CJtakdlCPm+8md5KUXDn8joI649Tukz2s229EtLaCWjY3/MPReYFCtfqI8hsoYduHaKYRO7hyJwuh7DxFN8U2osRaB/3Qf+Ul0/NDT8sI3RNzH9XAwVboOyc1mEJGffIv03204V1zXxRf9zpyhyDXqIAX9KkBPeWdgjrj0O4swXprSLflFnNIrQXIzB7JO4euFJHeAzBEBTJpXgkQJv/3ghPUaaek1BdPMWBglkKllF5jlAaWNh4CpZRiQNFdck0v5aCg2F+3JRuacEZBufKBh4X0lwLQHt/GGYPuYKlO4P83iZNStBLZLnY+iQ4VzagumiKP5usZhHC+uMovjvE11q5EIBjaQ3S2uQAtUQxH2H9cQh3nYaw8RTFxZh1Mhdg39mCtDaJpzwXAhSZJ2g9CHe2YMPyLX+x/flXCRQ5R0QU1oRRWBOGYB2Aa1UjUs/R4kqalPhbJmlS/v9jdLMZiucfikRbJf20GdhNry6aQsnuUFSQLN5iK9kT4tdRWBPmi8S97Rxc6SNR3xeSelFV5kXygKRkBR4JQHMtAM2DIUorXg/QtauuTQ0Uwrpm2LvmT8EJd7bAmeWJmu7NbQsGCre+C5kn6W1t9lAEnx2nZA/xPRxLKO2ouxCBIUQbqfBAmDbDnS0oPBBGSrdsxj8chCFEsQuzh4CyoDYCwT4cBRTWIQnZx5Rn68oYhXN5HWy9EncNnFkeuq+Fk0hvpXiCvVNCXn2EX6MrfSTmLexafQSuzDFuedr6FBfD1ishvy4Cx7JaVDgUPol5glLB2kthGEKUhamo9vPrq6zy8fXE1lrWcRHOHA+SB5S0a+7hSMw1CeY+CLbBuYFCjlHkH4rQvZjLYl1ag3IhwJ+NY8kBrL9t419sf/7VAUXyoAS3oTvGPEs9Rw9Kdy+luSyjFGzT3RuB7gIFxPIPRRYEFLc6S3cEOamH/Vtuo3JOBhS6eyM82q69SGb3zFz8fECReSIWKJw5nhjLq6piAW+lGVNNHmKZDHWMIfuoCO19YSWYOfM+7ArCMiJB81CQ/z33cCSKTzITKAT7cPRvWV6HjHuU+IQzywPhzhYYWUzj4SAE6wDchm4e6LR3SXCtPRYNftvOIXmAXhiu1UcosyQ/A1fmGP9cPKDQPBTkz6Zse2x6NOu4ciwWN1FzYJKmyF0T1jXz7+Q0icg4Jc5pWTCgYGtUHadayPzcAkVuY4Ty6CqXoLpoCtlHRYWHcG8EZduDqC6ZJrMxQG9GZ94Ez2urgaLgYBiCpX9O62Gh4JB7mN4eaWekGKBwbzsHwdIPwdKP/Do5Zz8u8fx7yZ4QnDkeCNYBFO8NIXlAimXlLauFkNSLwhp6wxlCIuydsSa3sK6Zn4vPeVKm8aZ7SzucWR6+WJkFw36nZVQGuBt+GP307+7NbRDuOo3cRsriWIckHmxlQGHrJavQlTnGgYJxJEr2hFC0P0yxgMwxzraMAor1x3ngMWlK5Ca3dYjiO0JSb9QGLN0RRNZx+ntVmReuNU0whGW3aZziSzOBwhhQ1hNzb1zpI3HJYQW1tJ4c+RPIP0QWlmVUAYr8QxF+TYKlH7mHyVViQOHMm+D3VG0RMKAorAlT2ngBa9S9pZ0f6wt/Z/yL7c+/GqBYs8UUN01UuitIxJiQyFmRroxRuLe087dL5slopl7priDST4tIPy3GJe0sZrpWNcK9pR2ZJ5U3ib2TNpSwrpn+vrmNNpBMlKounuLnZ1NN8nLmTRDRahbGYkW1H3qRAqDJgwv3zRc7hfXHIZj7YOul+5h+WuTBPhY30F4KQ3M9AEOIiFOMc5E8KMHeIfHfV3x3CO7NbchqVu5TZaWPA0VOk8j/nnpOYYtaRunNzkhPlZU+uI09yDwhwt4RHdROPy3ClTEa8zuyjyrnLNsehNvQDUNY5AFYR+EkfzYMKPQiWaJ6kTJkhpBI7oKKd8Nm0f4w7B2U2i53UtCWkdJ0FyIo2hcma2BpDQT7MN3HPoqdubeeRdE+xXLLr1OYn8KGk8g8qXA3FgTuxh5+rM9lenT9krvibojSXUF+Y5jrwRaLc3kdmbgzzbtltcrfbnGTOXPHYeuXoujPVRVefk5X+ghFvfvpDcLOyc4f9zqW1sxpklYXUaZFczkE88SnBxSFB5TUaOmuIJwr6pHZIvINwCjahpvTtLlld4IBRVWZV/mNOZ6Y+6QGiuRBukfGIB2fxYB091LQV/NQkLs/aWfItWDZH2bpzPY81UDBzjPTpWLPRg0ULIDKgFEfofjJYoEiaZJAU1jXzJ89u6aZ90QNFGytLub5JoBiFgq3YOlHZZUPlVU+lAsB/ub6NDZOXKCQeRRR8QB5g1SVebmbw1J9C0p1zTOrKrww+URorgVg8s5dTyBsOImi/WGU7KYg5GIyIuoYReYJYg3aOyhYbPKKMAZF6EUyzTNblFiK29gDQ5h4BizwxyyJov1h/rzc+i7iUfTLpr789taLEZTuDCLzJLmUmkcCFCOQN1J1yTSxWjUd/FhqQppzRT0qK31wpY7Q/8/yoGR3KGpDzpwsbuI29qCyyoeS3SGU7gyisspHMZJhCaZpMZoyz+5xypByTcYeFN8dQrmTgp6MC8JiFO5t51AuBJB2hsCjotqP7GNkqZXuCPJr/rhT2HASlVU+ZJ4UE0Dxqc2lNeQHLgLB1UCRPEgmcHXJNAVYzyoL0RCUYyW3GAtxLCHXwxAWoX3UD0NQpFz7ino+1daIW98FvUiL1dYrLSpWMTOYGXcOUwqRsRSdy+vgSh0hluUDYR5QNgaVWo+o+7eyAWaPpKRRGSgMK8fX3heG7nwEtj4pKvAYdy6rhbDhJOxd0cQzFsxMHqD0s3omD5Ib4FrTFHUf2WRgb+uTUO6chyUpryHninoIKUOUYp6ilLaw8RSceRP8vJknRF6lvNhnE3ctMut0CZH67tAkgOJTmW5DN3EqZkTeFwoU6afFKOKXGigsI8TX+CQsCtfqI3BvPQvLCJGR0tqlqKmOzLu3nuUb7lMBCvm3Mbp0QW0Etn4JmkcCvKBKcyUE3YVIfKBYUY/Uc/S21t4X5qDAgqCGEKUb3VvaaaPNQ2ord/qReo7iJ+qMEQOKMneAuAyqmX2UyFMz7yObjNfi3np2XovMmeXh32PWF6siTjtDzFt+bks/0ltlotetAsXSGuTVR1BwkJ6Da03T55NHsWG1ds5qvKgNr++CYB9WZsrQvG9ywdzH/dPSnZRyWxApxtyH/EMU2S7dEeTWiHNFPYr3hvjf7J3xy8xvZRYcDCOzRUT+oQj5+QNSTFWle+tZHmew9cuZlNkowUtrIJj7KGefN4HUs7KGwwQt+rz6CGlsDFOA0TJCx8xtjPBKzzJ3AJktlFEweclk11wOwTRN1znzGbIYRdKkxN0OY0Dk6UmjX5xXj0E9C2vCSJqiSlZbn8yaTB9BVek01cHsD0OwDUY9B3XqOr2VaPXqTEvmCXI5ongQSb3K+lIFygXrAN2nbmJI5tVHotK/zMpxG7pRVealWMYExUAqK8mFEuzDMendhQBFZouI7GMKOH5u06Px/MN4M/fwDJ5Er8Sj2nHnstqoXL11aGEU7sXM3MbIJw4U6lmyOxSTq58JFLMGzNimXV6H9NPEnGRl4vqnvNBeJLBji9Hskbgehb1TiqlsZcFMtWuSeTI+xZoBBYtFqLU4GLgthuOS06RwOzTXAzywqD7mXByXimqq8UlvVa7DlT4jbiDXevCUbe54zKbNOi5yMlzJ7lAMUOQ0UcUt5/rM4NWoU7YJoFjEmMuimPn2ri6a4mifXxdZNFAsxqJY6HTru5SKwRmbil33zLfWQqZw12nk11FB2Mw3pRookiYpo2Adnh0omEVRvJfqLZjoTNIUpSLzD0XgzJtAhcNPBWx7Q8QuVN2nMncAmSco0GkI0v+yQC63vHaRCI4zy4PcRgIcY5ACl4xazy2KIJ2buTbVJdP8OPmHIlRmv/EUhE2tFEuQYxr6m9OULbkSIm6F2sKccZ+iLFCWxjT3Kf+mBt/8CaS1RWdOYoBiCQV0GRPYvfUsPxYjrKktCkNQ5MSsjHvEOS0K97Zz0b//UISfn5Wxf66BYq4YBWNmsgen9oOryry8HmIuoMhtjHDfcjExiludahWltDPSomXhWIVidfEULfA7W7gP7Fxex2MUjJBm71AUsoR1zfyzzPcWNpxEdck0BUvvD0P7QJhIYbKfLdiH4czywDIi19mw78tWRUEtmd16kTgIhjCdU+3z5zRRLKd4bwiWMbI4TD6KtajJXSavLKknRWDvkjiZyDpM9yqlm67LlToCV8YokgeV+grtJSq8M4TFeanSi5mlO4PQi3Q97Pd83EyFsKkV6a2U8TB7yIqNUi9bVqs8T1k4yG3s4XETFvdgVPKoPfF5jVF8XKBwLKtdUKaBVTIuNuvx1wQUrtVH+CKy9VKFIs96eInk497cxt+mBbUR/tnKKh9pSJwkH921qhF59ZGojcwi/9ZhqvQ0e5RzMbEbliKMcvvuOh2VRXBvO4eUbkWgR3cvgbRzRT3yGiLRQHGBrsHskThJyjRNwF+6M8gDn+o3fEp3dDXxJ/k8Kyt9UcI0t7penCvq4VzZQHNFfXQcZOMp2DslTngT7jrNsypMv0RY1xzX8k1kPWbZ5FUVXuTVx4+s/7VNt7EHlZU+VFb6UFHtR7kQQLkQiCJqLRYo8upJQ0MdhMurJyqv9gEKErIKSfZdFnQr2x5EhcOPimo/7J0Sp1sXHCTNDpOX3AKTV+SCv5oHQ7wgzOQlJS72m4r3UvAy6ziJ+86M9bjWHuPZCeabp7fK6dUsD78fmS10XuswBftMPpGnel1rmlBZ5SN3ZYTexmVu+l5llQ/OlQ1wbz3Lr8mZNxF77za3kcs2i1vq3tKOkj0krsz0SaoqvEgelKUA5kvVznLMykrfvGptrvQRlO4I8irVcqc/KhbkyhxDVYV3VlfVlTqCL24w/MX2518/UKhYjExj8GMBxbLaW4tJsO8vgEnHsivJA7SZo76r/v4CGKRuXSdpNPTHTkOIAnuaRwJct9K99Sw/D3O3XKsaUe5UiqFyD8tAURuJcQN0F8is11yTK18fpjoIpjZl61dEgkt3BBVmbJz7ywhJeimCjHtig52Vlb6YVKzRT1kY15omVBdPcUsihpkpa2IyPkbGPSJZa6r7yMR1hZSh+OzdvAn+m80TEtcCYb+T3Se+Bmf5nerpzB2nc84lXCM/G2Ypqes/5lx3M/6WiFHMWExZzSJca4/xuotFk5qW1VIwce/HF3wp2h9Gxj0UjIoX3JoJFLZ+Wewmx8O/x2ZV6TRdU10EaWfI1J/tmM7ldVRLsqU9Ztr65DJpWV5Od57MVXaepElKf7IIv16MQHM5RNoOSw4g8wSZ+poHQ9DeH+YbxjIm8aI2VtiWVx/h53XkT5BUnVwant6q/Da3votfe+mOIM8qxKtriQcUFQ4/BQRlGT331rPIuIfcqox7RLjSR+Ba1UiaI2MSNDf80DxEEnuWkegqWgYUaWdUgC3fU5Yi1d0rMys7yS10rWniv5PxHsqFQPQzPCXOHnifBygESz9/NpYxWS91lsCmsK4ZWcfpnJktYgwjOQEUqlldNEX1+nHEZ+eazuV1lAu39EOwDSLtjBStgbjIqa5QLL47BCGpd1az0JnjIeHY9cd5jIL54dYhmTAlp+BYqpK5JUJS7+zlxnKwiy0YFoMwBIm4ZAxSlWXOEZpMMdw6JEvAhUmfwTJCVllau5IpsfURl4JpYjKCGSMrsdS1W9OBqjIvDEECGb1Icn0sq8QqdRn/xDJCIBhvY7Hq0ZwjtBGsQ+ReuI09FLjdcBKCdSAqlekonIRrTRPsnXKhoCwIpHkoCEOYZO3YsxGSeqk6tZ/iAEy3w7miHvYOcnW094d5GliwD0cBmmv1EQiWfn6M7KN0rbmHI1HPSNjUyqt4y7YH5wQKt6GbPxumBeLKHCMwtQ4oWZMt7XCljiCvIaKccwbYJoDiE5jCxlNR/rx16NaAwrFEYf/Fy9XPeh0qNShWzTgbUDA9ivkaAEVRl9WEqxnsP3XgkM2ZxVCpZ2P5JCxY6cifgGvtMdi7FKBQV4ca/QROwsZTcGZ5OFAwuX6TT4zRCpn1Psl6pmqOS3XJdMz1q4HCGBAVWviDCpdh5rNJPStxF6N4LwkWWcaIADaT26FmvQrmPv7v9o5YPgmbah4FD7jPo5mZ1xDhClwsHmQZjY4fxXs2CaCYARTCnS3EsvuYgUvnyga4Msei/PBbBgp9F98cSZPzcDdmAEXRfhKIdeZ46K0xAyjS2on/YOunXhyFB8Ixx2dAkdZOfy88EOY6F84sDzEu46huMT+fUZyri6fgzPJQ6wH1Ylxag3KnHzlHRB4XYNfEgEKw9HOlqaxmskaEDSc5UDA3hFlRrAPaQoEiaYqCpxmniPpslGto1EDhXF4HV/oIqoumUFFNQVrGesxtjCB5QOJ8G8cSCvyV7gjCPE73tqCW3DTtJepTUrQvzH9TRbWf1t2Gk3CtPQZnloeKuvroe4UHqAgu+5jI1brSW6nOht1XZ5Ynyp1wZYzy58VmVek0Kqr9JJl4XzgBFAsdG/5mc9RNYey/WfUkltZAWNc8b7qR+cH2Tonz5D82UOg6yYQPijAGxIUBhbkPqeeimXjOlQ2kT6liSTI5fnuHrAV6VopRtHataozS8WTugXBnC78PrrXHOGfCtfoI3IZuCoYy7VDVNZfsCSHzhMhTd8KGk1xUlmlE2jvougprwjGputJdstJXUi+qKrxcqtA8rvod8mSEKtfqI+SSzZiu1BFSMZtSdEdYIFTdfEfdNCjerKj283OqLTOmZ2rrpZiQ5sEQtPeFFStF3thVFSRnyBoROZYQt4Id09ZLwVwmzmvvkN22OKxZxpMo2hfmOqFsMmXz2UEAACAASURBVPKX2UN1MKywrPBAOObZJIBCNVZvM1H/ywUChbCpFfZOiQKD8wBF8oCSF78VoHAsrYFrTROK7w5Rq7yFNCxaVksAqNpg1SXTSOmRuIQ/Awp7J23kufgBTOKdbZzkQTK1q0um4VxRj4xTIl9sBQfDvD9q2fZgzDGdK+o5OFcXTfFrymoWSYNyVSOEu07D3kXR+ZRuKaqOhEvhXSUpOd35aBVu9WT3vrAmzOsk1DOvIQLX6iPIr6M3q+68XBMyHOt6zHW/ncvrYs7Jn92qRh5D0EuRKOXvjFMinCvqUVXh5W5cXn0k6j6x7+vOE4glD5A7Urx3Fnq9rhNGv5yZktswsv4fzhwPX098rj7Cr1n9bP5XAMXPf/5zFBcXo6SkBMXFxfj+978PAAiFQigsLERxcTHee++9eY+z7m+NXJDGlT6Ckj0hCs61kE5CVek0Kit99N8VXpS5A0gekHhbuVnf6JZ+lO4IxqL9Lcx4mpmznv/OFt6HgvWOEMx9vHbD3kWbpGhfmHL5C5FD03WidFcQtj7FtM8+KqJ0J10Xp3DnTyj9UXZQf5SqMm8UM9W5sgGOwsko+cC0dolfc1XpNEp3BpHTJMbomao1MzVXg9BcDiGnSc7qzJLuzT9EhWcle0LIaha5tcLcBGeWB0X7KcDImgezGEHprmBUVsW9uY2rds93z1yrj6C6aAq5h0k1LPuoIq+nJsMJ5j5+z+IpT1VW+mD0k9Vj6ydRIVf6CMqFQMzbX7izBfmHCFAYuOhF0t2Mp9S12PmZAop///d/xx//+EcAwPvvv4/CwkJ8+OGHKC0txZ/+9Cd88MEHKCkpmfc46hhFVjMtEsYP0J2PcLOWieuyt+l8QBF3LqCD1lyzbHuQN8Kd7zyCfZgXUKmZmc7ldcg4FdvXI+41xenA5VhWC3sHRf4ZtZn1DYnXaLd4rypgdlhJFbJu5moLRS0Aw4vC8ie4Zcauo2R3iBeFaR+gwKD2EqUpnSsb4nJOWCUsE59JHqDy7qgOWuuPR7lXyYNSVDEUvw/5E0rgcLZnJ98v95Z2pXFyPzFYWcOo5EFZImAhrNnCSeqoFpQl/hdQu1PmDpAVEyGXlVHlF7PmPvNAoR6/+tWvUFJSggcffBChUIj/u81mw3/913/N+d05geICNXDRixEOFGnt9Hb7OJZCudOP3MaIsjCW1qBof3jBPAth/XEekJztM6xSM/solVGntRP70LWqEc4cDzJP0kKbCyiK9in9Kxl/ILeRKjUzT4hw5E9QulTTgexjcuPkjNG4sZPivSHeCMfkozgE72beo3TQcuRP8A2oBgp1D1b35jZKFQ9LvPGy9iIFB03TVH2aNEm/lwm6xAOK0l2U0rQOK0G8mUDB2i2q05GuVY1c5JgFUAtrwrEixJZ+fv8y7lH6vhpCxDRNa6PvV1b6iB+ygE3L7oPb2EPP8YQYW30ab71oOqioS35e6mc7nzv1vwoo/vu//xuCIOC1116D1+vF1atX+d+Kiorw+9//PuY7N27cQGVlJSorK3HHbV/gN6BkTwgZ99CCM/koaMRy4bZeSfHDPybTsqKagEIw91FTWWMPNb5p/vhZEffmtqiO2oKlH0mTBGiOJQeQcQ9F8wXrAEr2KOm0zJNyZ3FVlFxY1wy3sSeq4pXVetg7lEa75UKAp+HKnX7SbZzFymEWBfO/bb2k5uTMIRVu0zRZJJWVPjgKJ5HVTNyCeGXmwqZWZB8jLoC6hJrJ2Rv9otIU6AIRtVhgNfsYiesK5j7kNirfs3co7QBYN/OsZsoszOSVsPQouzcZ91Dmgm/0pdT1vaJaYaOyyYCCCc6YPTLJS9NBFuD64wuOZzF6fcmeEG8pEI9YJtzZoqwL+beUbScpQB4otg4QiLBO9apO825Dd9xr+swBxZ/+9CfU1dXhgQceAIAYiyIlJWVRFgWfsnnL4wG3aKrNRHl1c17rkHRLQJHbGOHHYsfTi5EooGA8iplzZpPi6qKpGP1HNVBw/oCsqcnN3znuTfHeEPQRkW8Ipm+gFyNcL5JlGlhXrqJ94bhAwWZeQyQGKDQPBTm3QfeEF9rHfPQ2Vblg7Dfzc84AivnmTKAQknqj/76qkVsbc00WSDZPKK5HVYV3wRoZDChYzMI6HL8vbJk7wNeF2i0UNrUSSHtF7l6zz3Frr1sRDJ6ZBftMAcWf//xnHDt2DH6/n//bL3/5S5SXl+PPf/4zPvroIxQXF897nNkIV259F5y544vOWLjWNKF0VxAFtVQ4NVOGzLmiHs7ccRTU0gYvcwc+Vvm5W9OB4rtDPE4Q9faaVMBHDRS5h2XFqMJJ3uJOTeF2b27jf2eLLKuZeo5WF08h54jSHMfkm1ssx7X2GEp2h5DeSu5cfh3pYhTfrcQXrMMy+FyhBsLGgIjivUT1Nk2TpRUvu8SAgn1PcyXECV3aB8L0bw+GkHFK5EIwJXtC/LflHBFJIu/+MEw+UpnKPxRBQW1k1ngBC3ba+uR7mz9B5fQbTtKb3dLPtTDYeWabrEesIUT3pmh/GJknRCVuws6ZO87vmbpQTN2kmAWV4wLF9iBs/VTBy3hB1UVTKDhIKui8ilal1ZHTJKKglmjy5onY5kyfOaD42te+httvvx3l5eUoLy/H3r17AQCBQABFRUUoLi7Gj3/843mP80kyM50rG+ghDij6BULKEHEM1jRFb6z8Cdg7ZiwMmfPvWtM0b4CL1RMYZRp1SrfEsxn2LonLv2ecohhCSrdSBORa1QhX6kgMUEQB0bZzVIrM0pNyRaTRrywuVkLvWtMU66erulFZh6So6zOP0yJN6Za7cV8jS0D7QJgzL3XnCQxYHxNhXTO3MPIaKDaheVixIkxemTouuyDGAN1/RiV35nj4vS3bTh3dNVdCvPu8IUgumntLu8INUTWiLr47xH9H8d0hfiwhqRfJA9K8SuTsPgnrj6OqzMtTlvqISvJ/BlAU7Ve0RdXcDAYUrEzc3jVDb0JOf5bspraG7m3n4Fp7DMK6Zk5qY9W7LIuiXju2XrJKWUxJDRTOlQ1Yv2zTrW7fBY+/Gh7FJwkURfvD/CbrLtBkzXPtndHSZ84V9RQfUG2wsu1B7p+ruR1zAQUTW2GMPj7lBZ5/iMxrLiC7rBY5TQp5atZCs2W1cK09hqJ9YSJkdRF5SVh/nGoh5GBuRbWfCFUzYhQz29axeIhr7TGF7LT2GIr3hvimZ0DByr/ZRjL5aKaeI9eEWRTai1RspnkkwIuzhLtO0/E3tZKWiKpzOru3hqAI3RNeUtp6SOEn6C5QrKPwAMUdcg9HkNcQ4UCR0i27BoWT/FisFaOtl4KUs6VMqyq8sHfJ9O0rIS75p+ZrLBYoKit9/J6qXyzuzW1IPauI9di7JP7yYgQspgWSPEj6Iuq14952LopVqwaK0p1BrN72edSj+IIezrwJOHPHFy88OmNWF08hr54egDGgTNO00gg37qZfewzO3HFktoiKKSkzCgXbYFzXxK3rRNG+MPEghAAFoLadozfnjNaIZduDUfGECoeff3dmv1V+TWua6JpOEnsvaUqMS4dm5m1VhZfuozwrqv3UoyNAm7zC4YejcBKVlT5UF01RPn9ZLVwZo8hqps9FNcYZkaX2HyTXQnsfdQZ35FO3M6Ms86a9RBtPHyE6M/+dy2pR5g4gp0nkcQHTNFlXuntlgJEtCt77Q+7TmjxARDHrMIGcM2+C629WlXlRWenj9089i/eGSC5Rjl0Iln5SqZLvuXVYzqjJmptMYJgFRov3kosnWAfoZZI3EfWM2b0t2x5E0iSVBlSVTse4x6wTetE+om3beonWbgyQlgdbo+aJ+L1HXauPoGQ3MTSTBynoWl00hTJ3ACW7Q1i78XPYUnCuJsUfZ8YrCmNzNqBgjXCNAYWTwIAi+yiRvxaSaalw+Im5OUvLwMVMdcCMBf6yjscGXRnjMCZgxwqP5OAnKx1nbNCZtR6silMNFJqrQWgf88H49BQ0l0NRZjqLc7BrM4/L2hAz4iaMs2AIUptC/c1paC9GOL+Aic4aVX/XPeHlLg2zcrQPhKF70gvLmPJsYsBVbqXAAoe5h0k4x7minmuFaK6EeM9RJsfHmxTLdTjxUtdqVizrFMYs1rl4Nc6VDdHNmlOGyNrrVay92aqGq0qV4rikKQpkl20PfrZiFJ/UuENrQl5DhMyvW1THLnf6OQoX1oS5ECqbLFaR1xDhWpSMeWgIidwsVfezyD5Kb8rsY/Oz6j4NoGBlyWZPfEJV4QEqcHLmeFCyJ0SqVxItYtOzk9A8GKLUYFBpzhsDFMtqqRBL7thdtp06W1lG6L5oLoeopPsa9fRgU3eBOoBprhID1JU+gpwmMQqQnTke0umUg5xGP0nyCUm9tGlsgxCSemEdkqB7wgvLV8ahfdzHC7dMXjqX5uEgDDenoXkkQBqhXdEvluqiKWQdJ+uJ1U+Ypun7Wc1kUQm2QdLhuOEngd5rAW4NsbR7xin6bvZRkVsWjiWyDmlSL9JPizy9WrSf0ptqcCzdGUT2UZHPnCMkqsvX4OojpDVi6EbRvvCcQFEu0P1mmST9U1RX84VNn0PXY80WqvVwbz37iXQeTz9NG79oX5iOqdYqlHUObL0S1y9IHqQ3G2PPJU1SwRVrnMx6SVrGZmeDMrFbXgsyC1C41h6LuaZZgUJukMx8cOsQUb7d287xYi63oRtZzbSRnDkeUtmWyWqaB0NIem6CmgyfEnmAUnM5xNmFaqCw9SodxF2pI3CtPoKcJpE3O9I8HOQbWHtJbugji+doHgxxzQdbf/R9YhaF7l4SyjF7qABq5n2wd0rQPelF8gseSq/eF+Yul+7eCAEEszZkDYqq0mlqnrztHAoPhBUrR46tmD1Kb9iKaj/chm4OFJrr5IJorhGrNKtZhFvXidRzEs9COHPHObvTrevkArjWIYnuk+rF4Vp7jP7eRirjSVMiZxILKUNxmwBVVPvnBIoyd4DEjG9OI+m5CRifnoI+8rltKXgXHIWTFHBT8fk/1lxaw3PULCqtVgcq2q8052XViuoKxeriqRjZOqaopLsQmTXAKWxq5erJcwFFVZmXhHAX2s9iWW0USSt5kIJbQlIv3Pou/lZnEfyo9n2yL86YqOmtZFUkv+AhS+NySIkJya5HVvMMF0umjDuX18E8LnGZf+bOaC+qWgpaB+ICBfsdaW2KNoTJK8Y8m8wTZNFZn/eQqyMHSNnv01wJ0TnvC/NzsvuRPCBzWGSgiOqhIT9P5npoH/XzxshcTlC2UthLg8VqnLnjpBXSSZufWWq2/lgKd1WZl0DoCllfhpvTVBA2B71+PqBgrofmwRC0j/o/70CxkTQQh6gcPF7VqHvbOSrwmmUDure0o3QHmb/Fe0NRHbTUm7LwgKo5bwsVU1VW+lBV5kVVmTcq4u3WdaJ0R5DeqDIxiVkZ8c7P3iBzAQVTiSpzB/j1lu4IUnOaWawp1unMPC6L4IgRMmU1HVy9ivnb2vvCFEuQ6I3K5O9KdwRRVeFFTpMI/c1pmJ6dhPZxH3KOELOxdCdle1hdhStjFBUOuia3vgulO4m3obkiZzge81HsIkDgo70vjNRz9OY2+cTo1ofys7EOK2xOFu0v2h8m6vgSIq4ZgyKMz0zC+PQUWRX3hxVCFwOKi0rHMesQlYBXVdDzq3D4eWDU6Bej5PZZMFP7qB/aR/3Kpr5OZr3m4SAB7cNBAiw1UHQpyuK5jfTCYM+u3OmntLymg+7TNN0n1nuEC/jIBXvOvAnluTv81M92lrQuWy+skI6B4ErD5xwobL3kG0aVRK9s4DUIrO4hZjPZBqlUekApv2bpOPVbSw0UTIZ+tunM8vDjsBmvqtCxhNSmTD5yW5IHJKqNmM2NWlaLrGZRSV32yWm9O1viuiTO5XUQ7jpNG/UyLWxH4STc+i5lAcslzOzty1rZ6SVVGftdp+HMm4DmWgDGZyaR9NwEvZ39copwWG6uu6aJl6kLd51GVRn5xawjueaaDBSP+2AelwuenpmE9jEfN+MLD4R5uToTtjGEqB2h9mJEOecQPW/XqkYU1JJ1p3vCC/3NaQp6PkD9Sg1BOcYxw6Kw9cngJq8X1+oj3FXRXiQBG9eaJrjWHkPpriA1TX7cR8d+1E+xikf9BE5sPj0FzcNBrmcqrGtGSo9CdRcs/Tx+xFKf6roje5fERYpZvEgNFExRnseCVjXSvZLvV5RFJ0sVuFY1QrAN8qDv7Umfw6wHA4rkQbnhi1ohaFUjMk8ofjoTRpm5oZzL6yBsOMkLhoRNrRSPWH886sYvCihkQRf1nJWEtawWwsZTyD9E5cQp3bNH5h1LKDDmyhyDdUjifnbGPSKlWWd8ttzph71LJic96of+5jQso3KznY2nqNmOLIrCNglL+VlGiAgkrD9OfSOyPJSCvErdwpgwr16iaQirYgJXQpxirH3cB92TRMvW3hfmaUXNgyHonvAi4+tDsL04huQXPLC/NArNlRAHKPbstBcjXOGbtRmwjJLVxzgHlhGJF5mxRj/JA/Q8U8+S66N70svf+K6M0ej1IgMFBzQ5jqK5FkDScxPIe60fBa/3ofD1PpR+owfZrwwi4+tDKHuzm0/dk15orgahlyJUmr/hJL8PCwEK65CcLZJBmKl0xQOKlB6yiMwe+u2pZ2e0HMynPrHs/jBB5Nutn1O5fsHch4KD4RiT3bminswuWdyWFfXMFgysKvOidFdw1r8XHiAKsLpd28edwoaTtFBVM/uoyCXcMu4RSSItx0MPfyZz0jpA9OF9YVQXT1HdQZvS0NaZ5UF18RTST1OQVfMgUbc1N/w8GFldMo2s42TJJE0qqdT00yIKDoZRcDCMCoefX1/JbtL6YKxL5sszXoT2YkShYMtT+5iPxzW0j/k4g9I0TdF44zOTyHutH9mvDCLr5SFkvzJIwCKnDk1euj4GULonvLSJ7w8TTdmjpBxZe0RWvq69SGnXcqcf5gkJhpvTMH95ApqHgzBPyPR7VWbCubKB194w89/4zCSyXxlE1dud2PuP92D735/Bznfa+X8L3zqLL/3DaXzpH05j9zttSHlplKyKq0GisFd4kXWcYirGgEjZmo2nUFhD97d4byjKyk0ekHjAWK2rkXmCgp+lO4P82RQcDCO/joCdKZurA6QsRmH0kzvFnsntls+rRTHPplSbr3MBxXyz8ED4E2tSzJmZs0zzhKrwKE6nMFfqCPWllMuy1XRoJumuuxDtm88sxJptqkEwXiWlepbuJP5A8qDEg6HaB8K8z6ftxTEUv9ELy1fGobke4AtXezEC/VOUpSh+oxdVb3ei6u1OBSjulSneKs6C9v4wkl/w8DSn9r4wDxwygGB0bqZxobkcgvHpKaS8NIrsVwaR/cogDDeneZPieByX6uIpSgPLVsTOd9px5HvH0PGjgzjxT4dx6geN6PjRQfT85AB6fnIAp3/QgFM/aETz95tQ++5JCN86C9uLY1RT46WWEaxgb76Au71TiuabzJgzmxQzWQL293hAobkegPHpKQKwh4JY+bl1PRYBFMYg5abjcRoqqonxOBuQuLeeJdbeJ1CJqgYKy4ginc8mo46X7gjyc7rSR5DbSAGx9FaRpww1DwdhfGaSJOivBVDmDqCi2k8du+Q3uO48UcGdWR6kno1u28cDfpdD/K1v7yDth5Ld9HZTC9WWuQO8zDztjMS7xNs7iHmZ2ULntL80ioLX+1D1dieyXib3QvekF0nPTcD24hjyXutH1dudqH33JBxvd6DszW443u6gjXxBZsgGRR7ANPlEWuw3/JyzwhoYaR4O8tiB9nEfdVu/n6wK5uKYvzwB85cnoH2MLJZyIRCXpMdEfw1hEbYXx7DznXY0fLcZbT88FAUUIz/9EsZ+ugdtPzzEQeLQd07A8XYHdE94KV5WOMnbBhiDYpTKdnXRFH+eTLC4oposOME2CME6wGe5QCCbeZIYoGqmrtvYo3xWrqnJr4vw85q8MnP1UeKyJCwK9UZce4xiDZtaUVXm5RvSOkSCJSxazkxOYVMrcppELo5yq0CwUKCwjMiMR9WmZU11kiYpIs8EXCqqKXvB3ATt/WFoH/PB9OwkvcFu+Ll569Z3ce0E6zBlN1gzGOaKWUZlNikDigdDPJagFyktWrKHCEWp54gfkn6amvsy4ZqUbrqf1mFZhDepFzlNBBTZrwyi4q0uOL95DoWv9yH31QHkvjqAwtf7UPZmN3a+047ad0+i7YeHsPudNgjfOov93z6F5Bc8xJmYoN+qFyMKM/RJL+9CxupLLKMkq5f03AQsXxmH8ZlJ6J7wcvIUk9fXPUmBTs01Smeq385MVMi9uY2vG9O0COvzHmz/+zM49J0TOP2DBjR/v4kDxcTPdsH38+0486M6nPinw2j4bjMHCu1jPtKLSBmi2hQ5tevIn+DHL90ZJBGcYTndHhFnrUQWLP38/ucejpDG55omSo3KfXTZcQVzXxS72DxOIMWCr7cnf05jFPFubOmOIG/xxtKdQsqQ0vBVLaGWMkSfY9Jmf0GgYK3tOUhcJEZk8gse4gQEqWOXc2UDCg/Qgk96jt6MhpvTsHxlHLYXx2B7cQwp3VJUc1zninpeNcl4A+x3ZtxD2YL8Q9FWhfZihAvnMOoyK3ZStzFkQFG6iyLvpmkR2kf9lA153AfNDT+3Jna+0w7nN8/B8XYHn8K3zqL/J/sQeF/AQ78swdTPdmLwvb0YfG8vDn3nBEq/0cN99RhauVyUxbMLK+qR2aJqkyinFQXbIJy54wQOclcwzTWq07AORetRFBwMwxAW+T2y9ZPJnvbVETje7sCh75zAmR/V4cj3jqH5+03o+ckBhN934cIvqrllMfWznah5twVVb3cScMvl8/z5yqlOdvzq4ike7GQp21n7eiytUe6/7CpVVvp442XB0h/VNlLtrmgeCcBwcxrGp6dg/vIE7rDr/mL7868fKHbF1jCoe30wfkGFw4+8BjJt8+ojCmlqNjdmZQM1k7UNfiJAwYOIF+RCp2sB6J/y0pvzhp9vloKDYb54k1/wwPbiGIxPT8Fwc5rMbPnNmldPvT2ZxaRuMmMZIzO04GCY+lo4/Eg/LReM1ZH5a/JS8Rj7e/ZRMX7h0apGsnZkHQdjQOQxCWbiV7zVBeFbZ7H7nTYeg2CBwEPfOYELv6jGkx/l4tV/ScaTH+XioV+W4MIvqnHinw6j4q0uni7VR0TkNka4cLIxSG6I5qEgjAFq1Gvrl7j0oTFIwdLCA2Fqxvy4j+IdMo9D8yBZSfl1Eb4GUnooiMjKs61D1HaQAUXNuy04/YMGtP3wEDp+dBCD7+1F+H0X7v+gHBd+UY2LH1Ti/g/KceZHdah5twVZLw+RmyRnh1iBHGNbWockzqlg9HiTl7QkyrYHkVcfQV59BPmHIihzBxQB6cwxfs3preSm5jZS1zXGDmZFjEzpTXONrCnj01MwPTuJVXb9X2x//vUDxQ5Sm7b1qSwK+zC3FpjPx26oPjJ/b1CWxrR3UOzgloBCTm+yDczScMwHZzLtmht+AoL7wpy1l/bVEaR9dQTGp6fI77wSgmVUCeIlTVITHsfSmihmpnmCXBDBPgz3lnbOHWGdwgT7MFGzU0diRGXVQMF0LNg9ca0+QgtddoHSvzaM3FcHsP3vz2D3O23Y/U4bKt7qQsVbXah5twXN329Cx48O4tl/zsJbvzbjp7/9P/jOb7R469dmPPZRPs78qA4Vb3XRBpcDtJWVPri3nlXelqzHxqWwYpnJLEb1y4EVQ3HKtWqyDWUdklOH8r+zvh3aRxWg2P/tU9ySGHxvL0Z++iUOFNc/LMBjH+XjyY9y4fv5drT98BCK3+hF+teGqfZEJrJprgWoNF39AhtWGJu6CxRgNY8rVaqsIC+vIQLninrepNg6JPEaFu19Ye5eaS8q7QSYEpjmoSBnexpuTmOlLQEUykZc00TaBjLph/nkaWco66EGipwmah47XzajbDv1EXVvO7fonqYzZ3XRFPHwZeFf3RNemJ6d5BRkxvbTXA9A+6ifBwHTvjqCqrc7UfZmN9U1yEVajEylvzlN6lIyUOTVy+Iqw3LD4K1nua6FcNdpFO8NcaBwrmyAcNdpFB4Iw95B4GmajrUo8uojsHdJ3Kowe+jtOxMoHG93YOc77dj/7VPckuj40UEE3hdw/cMCvPVrM374m23413/bhA9+txk//M02PPvPWWj74SEUvt7Hy9P5lEvStZeIR5E0Kfv2olJ2rg66stgAL4qSiVickHUpzF0blqXRs8IxkbIyDCi+9A+n0fDdZlS81YWd77Rj5Kdfgu/n2yH+woGLH1Tiwi+qEX7fhZGffglHv3cU9pdGkfLSKAcK1tlLTRHnL4pRZTIrU/+UijgmB1/TW0Wu3amOb7EqXO19YQp+y/VIpmmyVFkXNe0lKsBLxChmcxdyx4lrH6HctCt9BOVOcjnyGiKorJpbut+1pglCyhCyj4pzpkfdW9qpgCdlaNau1dz1SRmiZr9yUNL4zCTMX6ZgnOZagEhNspnMSqStz3uQ91o/9/dzXx2gaL8U4YE63ZNeimucJqDIryMmY/bR+LJ0ZduDikWx4SScOR6ktSlZEaaS5Cic5E18mNp5VRlxBHT3Rngtgf2lUaR/bRhZLw+h4q0ubP/7MzwbcOKfDsP38+249mERXvhVGr7zGy1+/tst+L//tgkf/W4Tfvibbbj+YQFO/aARxW/0UlzhgTCvVdBcD3BFbN2FCO+UZQiKnHzFN9CEzAZl9StyII8dR/NQEMkDFKDNayDQ0T5GxDDNIxTHMNychv2lUZS92Q3nN89xy2j3O20YfG8vD2aG33ch8L6AqZ/tRMePDmL3O20UWJZjApqrQd75nbkHjPfC1iCbDOAYTdzskbiivHWISGjpreRu5DWQXGPSlMjjSkLKEI8fmSekqHuT1k7B5zs0n1cK93xv75JpRT9ADw8b9wAAIABJREFUpBu+mL4e8RrhxvucOnA4F7NSPVPPklZC8gsemL88Af3NaU6gYY1wLWPEkzB/eYJzDliGoOzNbmS/MojiN3opgCbzB1iTGdYwaLb2BGqgcBROxnAq1Hqe6v6W7JrUgUXdk15kvzKItK+OIOWlURS+3gfhW2fR8N1m9P9kH8Lvu/DVf7HjjV9b8M6/GvDB7zbjX/9tE/6//7sZH/1uE77zGy2mfrYTR753DFVvd1K1qaxnoX3MB32EArAle0L8+ngBVpaHCx+rxXc5UFxWvsMDh6pgZn5dRGF/yr/JcHM6in+R++oAd50Yh6L/J/sw8bNdGPvpHgy+txcN321G+teo4lVzOQTjMxSYZoVqSZOKHkU8Jq11WOJZndJdQdKjUAn+zsajiGpbMKPninUour/J51KPYjFAYfIppbtqoHDrOlFQG4Fb1wnX2mMoPBBGQW2E2J4bTt4SUFQ4/HSs2gjPupTsCaGgNoL8OnILtI/6ydW4HOLMTAYU7G1o+co40r46grzX+rH7nTbUvNuCI987htJv9MD+0mjUYtReItZifl0Eae2z9LdUWUGuzDEU7Q/zCs2C2gixGT1kDicPEIuTcQ4KDlLglCtYPUQcBuMzk9DfnEbyCx5kvTwEx9sd2P1OG2rfPcmDf499lI8XfpWGt35txq9+twm/+t0m/Py3W/DWr824+c/Z6PpxDRq+2wzhW2dh+co4veFlvoTufISnYplFwZiZmScobcg6oWseIrdNc8PP76HmEYpLsJ4a7DkU1BLVmwGFZYwsKE57fjjIRXwyvk6/68Q/Hcah75xA7bsnORFr/7dPofiNXspIBUVlqrQ3zOPk/lYXTaF0ZxBF+8JR6yn9tMiFcdPaiAVs66OYkyt9hHcj4wH3pTVc8p8Bf1q7xAvujAEqka8umuK/de1dn0MexYblW8hsnqUoyrGEmHbMjEseoAdVWeXj32NFY6wxTpRW5JZ2uA3dSDtD38s6PnsDWAYUlhGKBwibWqPaz5ULAbi3tMPepTSd1VwJcVqyyavoNxj9lPdmb6Ssl4eQ++oA8l7rx/5vn0LDd5tx5HvHUPB6H6zPe7gvy95GhpDI/d7kAer9yX5v1Nx4Cu5t50hHQe6q5kof4c2Q086Qqes29vDvFO2jGIZ5nMx7zbUATM9SUZTmISJ/ZXx9iJvr+799Cv0/2Qffz7fj8i/LcPOfs/HqvyTjo99RbOL7v9Hg5j9n4+IHlTj9gwbObrS/NMpjCczPZylclsa1jCn8GMuIxDUzNNdV2aNrAWJ7PuFF0iRZRu6tZ5FxSiGSMVKa5qrcze3OFpIIGJV4fEF7fxj6p7ywvzSKL/3DaVS81YWyN7tx9HtH8aV/OI2yN7thf2kUhpvTXA8jeVCptTBPEGjnH4ooLSXkvqws5lVYE+ZrTW0V5DaSInzOEVGpR5LdRVbKz56ZPqLQ8s3jxNZ05nhIEmFY+nyWmd+hMcHWSzd1NnqsM8vDo+Hpp6nCsVwI8IY26kpMNVGFl5kvrSGxF1nwZTbLhUvZy0FKQ0iM0quw9cvFORFVxaZq4bPO35Yxme8vb37tYz5kfH0Ipd/owc532rH7nTZs//szKP1GD2wvjimb6aIiK2f2qDbNlRDX15g5Wfk5C3aqKxDZb3ataUJmi8i/48zy0L/LbgBX1L4cUgqzHvMh6+UhFL/RC+c3z6H5+03o+nENwu+7cPmXZXjso3x8819N+Oa/mvDqvyRz4lLNuy0QvnUWxW/0crEVA6vWZEQrWZCXuwnnZdBQAwXLGjwc5FqaLIugeYQCxNpLxJ1QM2RZk2OmD2L2KKI7+qe8SJqit7T2UT9ZUw+GkPXyENV4yNWj+qcozmEMiLy5Em+ArFpDLHVt6yVlcMcSuR2EfN9ZSwbrkJKdYv072LNglb2CpZ//Peqca5pg65Xvy8OUTv58AsUcmpnO5XW8DwJLD1qHSRE582Qsnz7/EOWw2SwXAosS7HWlkjlrnpA45ZgV65TuCJJ1IafDLKMSNwUZk7F0ZxDOFfWw9cnNaWX5MuMzkyh8vQ/Fb/Tyjef85jlUvNVFQCGnT5niNTuuyUcRcsYNSD1HpcnMarEOSdxUt4xQsKt0V5DckTVNpHuwK4iSPaGonp6FNWHScKjwonRHEPl1ES5XpztPGZHMkyLnfFS81YW9/3gPGr7bzKnPLKj50C9LIP7CgaPfO4rd77TB8XYHsl8ZpKDuDb9ClJIBT3M1yKtgNTdos5p8FKwt2idTtuVmQozkpLkc4hWv+qe8nHykuRqEMShSI+btQZTsDvEMgslL1oZljNKwmht+Hj9KmhK5BJ4hRGXyasuFpawZCLnWNMG97Ry/Z5VVPqUBtLzW4pUUCLbBqPUYb5YLAc7Q5P8uN+Rm52IBc71ItUMJoGBAIasSudYeg71DlS4LiTxfzTYwVzeSeRYLBQU+Z3Qhc61pQupZRTmJB9tW1KN0R5D0NcNyD1C2IDa1wtZPasmuVY2cBKV5hEx6+0ujqHq7E3mv9cP24hiviXC83cHrJ7QXCQxs/WTKunWdnIVpHSbgyTxB4rXZxxSQVPf5YM2cHfkTcGs6uEam7nx0kxn1jCoKeyAMw81paqhzZwvFWW74YwKwR753DKd/0ID+n+xD149r0Pz9JpS92Y2sl4eQ8fUhcmHkQjYunitTzZmsW/ILHm4V8GDmXac5n0BzLcAp4Ny6uOFH8gseonnLHBSTVykKc61p4oI0XJdjTHkbM6BglHvzuOI+smCp5qqqkO08ZSSE9cdRXTzF15tllL7PBHn5WmLqaDPnfGtwxmdnBjM1lynjwvhEn0ugWGk0weQVOVC4N7chs4V0HtNbFRYfMy0tYzJDUZbkd6WO8Cq7RQPF0hoU1oSjuzwtraF+olvPkh8s9wHNuEfkpCG3viuqJJ4Bhb2T3sSCdQBl2+mtqH/Ky7Md2a8MwvbiGM8qWL4yHuWr5x+ifp3OFfWkLrWlnQKP8mLWXqLOWmryFhORYQ2DWcWjeULiVZxq94lZIQwAS3cG4VhaQ0E4uXuXdYi6cQmWfgoyvjqAire6UPqNHlifp3hL6Td6sPcf70Htuyd5UNb6vIdKoiNUXcre3vqISOzEzDFYxsh10z5AjY1N0/T36pJpCOuPE6jIqlms9JxRmC1fGUfG14eQ9tURWJ/3QPu4LxooVjWSyIxP5ArbzH3UnSdCltlDwGsZozoc97ZzcBt7qB+qHGA1een7xXdTb9GsZrLmWAvI6qIp6M7TZ1O6KdAspAzxzmjqmXVcnLXXCM96tIq8t65gHYgBCtZpzr31LDJPilhp/AwCxR/+8Ad88YtfxPXr1wEAoVAIhYWFKC4uxnvvvTfv91dvMyG9lSpC3Vva4dZ0RPWqtHdR9FjdNMfskcuSI1QcxkqpBfswCd0ae6I6abvWHoMrdUSJLqua2pbsCc0pYlO6M4jMForOF+0LQzD30bQN0ltwXTMHChbHqC6eQmFNmKsnWZ/38LSj9Xm5BuSZSfI5/Yp1wJrMuDUd/Dx59REuna+5SjJtrPLS+MwkVWo+6aUYxwN0Tu0DsgDuYz4kTZKKlK2PNoh5XO7mFYwGiswW2lCGkEIhri6ZRtoZCdmvDKL0Gz0oeL0PpmcnecpRzbMofL0P5i9PKEHFK5QBMoRJmatkDwnw2vrlAidZkZuBVnUxqVHl1ZPwDwvmmieoYMwg08uZSA6LexjCVOHp3tLO5fqZZcXAgrUp0Nygz7PsWemuIAT7MARzH5cDzGoma9HeKfcBlaXwUs9RHw/35jYIln4en2Jy/c7ccc7SZcCc1k48C1YRyteOag25Msd4R3nrUHSnebYuUrop/sTW42eyAVB7ezt2796N69ev48MPP0RpaSn+9Kc/4YMPPkBJScm835+ZHlUDRUp3dOen3MMRbvapi3R4jto+zPt6qHPcrnRF++Hj6FG4jT3U2UlFGTb5yLVg1YTqQh69SJWcxqenkPXyEApe7+OBMq4r8HBsLUvJnhAcS2t4dag6SMco4fz80ySUy5iIzMowPj1FVaTyRinaH+ZvLXVfjyjXY0ZfD2OA3uj6p7wc5JgaFGNusgBg7qsD2P1OG7JeHuKaFUnPTSDr5SHKpLDfrGIzai8R70T7mE/Rp1RJ/FeXKP0szB6JM19Z8ZzuCa/iJsjU5oLaSFyg4JW1DwdhfHqK3zO2fhgvR63zGRVnkIFC3SlsLqAwhESuR1FV4Y2Kf8183qz3qJpPMhMomLSi+po+czyK999/H0ePHoXH48H169djupnbbLZFdzN3rWkihafccbgyx7jAa9F+Ep2xdxKHggV61HL2OU1UEJU8IAPF0hqUCwFkH6V0k8lHAa65elTGBQpZ5p0BBVMc0j4QJgUrFVCwLlfZx0h7wfbiGFJeGqVFzVSj5Ig7XzTDdMyUbhKcrS6eQrnTTyxGWfXJGBCR1kY6jrZeMt9ZFsEYELmJz4hNLL2W1i6raBVNoWif3Jw3LPLirOQBeotWlXk5Ld7skXh8wvTsJHeZrM9TMVvSc1T5yijraV8dUfpkPBLgDE9mOWkfo4CcZYziINrHfTzbw7p2qVmnwqZWOPMmuCq25kqIJAC/Ms6zTJorIe7W5b46QBolMlCYvIoQsOZqkErV7wtz5qYxSMpVyQOKWT8bUDiX18GVOYbKKh+K9pObmnNE5FbATKBgAsvOvAkuiltYE+ZtH9RTHxGVtooyczP7GPFnkgdk6y9A1jY7t9vY89kDirvvvhu//e1vOVB4vV5cvXqV/72oqAi///3vY75348YNVFZWorKyEnfc9oUFZSPsHZQ2yj6q+KTOFfXIOq64JCndEv9cuRCAsOEk+X/99G+maXrAi6nzcK0+AsE+DH2EFrq9S1LqO+6lalW3vgtpZ+gcae3UZ7S6hKpCk56bIBk5FYeAlVHbOyTuEvCmtLJ2qGAfVrqXyWpO+Yci/A2nOy+XtHvFKLBhfA71gkweJJFhV+aYUlfAuAWybqYrc4wXujExYbYZ0746wnkW1uc9lD5UFSnpn/LyhsSah4jhafnKuNIa4IafV4Tqn6KaGKY7wcRqiu8ORXfcWlpDJKpLYSoAk7/DKN+aq0GYnp3ktTPprVTvk9IjuzZyxaXmhp8LDWuuE3DY+imukNamAAU7v7Cumb9IXKsaeYPmyiofrMPRa4xVDrs1HbzpdfIAxRocy2pRUBtr9aqtRO1FYo+qS+fZ87J3KipnljE6rr1Dgitz7LMFFK+++ir6+voAYFaLIiUlZdEWxWxR4SilYvVGXtUIZw4pYDlzPPxzlVVU6588KCs9y6pB9s7FuR559REyA4cpqyFsPBVFMWbq1WyBuVYfId5GjofcAbnmgzf0lSsQs44ritdso6tNUrbZ9ZJMS344yDtkWYfkIN/DQW6y6iMiD2iqtRpZv0/3tnOk5DwsMxjlQCtbpNpLYb5pqkum4d7SzoOK2kthXpSluUEFbixFqX3UzxWvWccv3h5QBgUmf8cbE8uBWQYoBa/3cfl/DuIMKORMTNpXR1Dweh9X57aMSFzbI/uVQZL3l60Vfr+vBsnqukD/zXgULPZl9Iv8N7O3t61f4j1eGX3e3kWbVi9FSAlefs5F+8L8BVW8lzqsZx8T5wUKDlxXg7wIUP38U88RYaxkT4gDBVsvzuV1ny2gmJ6eRnl5OQRBgNFohN1ux7e+9S2Ul5fjz3/+Mz766CMUFxfPe5xPopu5e+tZlOwJRRVyVVb6kDwo9wqRZfaduePUbHYRmptqk7GqzAvninquk5B7mDgH9g55c6l8SbeuE7mHSSMi8ySZj2xxG4MU5S53+okGvD8cFePIPEHaGqzEnLkszJ/Oq6dzax4Mcd+fZYZyDxMYMtUlJoTr3noW7s1txBMZpwAh7/GpahmoF+maS3YTj0B7f5gHEw03p7ngruHmNMVC5A7kRfvCKHMHOAeFxTk4f0LuN8KySLp7I7yiNv1rwxwASndRr5Xq4inF9ZDdGVZPo3kkQFbFNcqGpH9tmOpsnlKAiJdnX5N/n/zfZg+xJkv2hJBfR4VZxXeHkHpW4kV07NmwzuuMb2HyiVH1Ja6MURTtp7qZ9FYR1UVTxOCU2w1yoAtRpzbW+czkU7UfeNwHY1D5m2VUaffoSh1B7uEIivaFo1yzzxRQqAezKAAgEAigqKgIxcXF+PGPfzzvdz8WUCxA87Ky0qd05ZrBlZjz+zP+NhMoYiyOhghn21VU+5VzxZmFNWGlA5ZskVRVeHk3Ktb5imdmltYg97CsdXCeNmTyIKko8biJys3IryNqcV6DEvRl3AxeZr60BhmnVGpSMkdBL1sITMCV8QhYgJTFG3jZ95NeXqfB35SyqTzT9WEzrZ1EhovvJjao7gkvByBOX78QXcjGgpksHcwzRqxb2aPErWD8Cu19Yc6aZcLErIqX8U3yGiIxz6Zkdyg2AKrq+qW9P6xwfVTfE9Y1k8IVK3eXM09caoB1V1OLDDMmrGwpqtcDE2OOa/XK5/zMAsWtjMUChXBnC7KPUa/NOT+3/jjchm7kH6I3ZNZxylG71jTxdvWOpTUo2hfm9NuqCi9yGyNRwc75gELY1Aq3vgtufRcqHH5+rnjT3iXx6kOjn/zsCocfjmW1cGs66DiGbt5zNOu4yKPfrswxrqVZeCCMtHZZEYpxBUbIBGYxG8sYWQ3aS9SHg/E/so5TIJaxRrm4jFwcxoDCGBThyhxD/iFymZi+Aut5YfLSW5ZRrll3MsaKtA4rlpAhrPQBzTwh8mtjcQtWbm4dknixF8u+sHgQo3CzehTzBLmCVRVeOoaPuCPO3HEIln6aKUPUCkEWk2FpS9b6kaVfWRyI9eNgfUs1D4Y4gLLsjK1f4s+GWYuWEcXFY65UxVtdyPj6EJKemyC+y6Uwbzad0iNnN1KG4MoYjcrSlO4Kwr3tXMwLy731LLKa6ZxrNn8G06O3OhYLFKy/ZcmeEHXkUjchvus0ZzWy5j+FNeEooGClzAW1EaVYrI3qTPIPyYIuKtp3yZ4QN5eL7w7R21zfxc/j1nVyl4f1t2QxB7YwrMNExMo6Tjl6VmCkuRyK1dJYWoPkQQpWmj3kr+YejkQFYHOayEQ1hOU2hv2xb2+2GTWXiars3nYOQsoQ/bucReCFaCwjIxeHaR6iFoLCumZUVlIWhdGq1UChfSDM/521/2OkMOuwpNRlXAojpZtIa2xTMOUn9TWz1LUrYxSZJ+TgJ9OkkOnfLP5gGZN43xSeTu+RogKiwqZWInnJ+hYMlHjnMfk3MzFfDhSiIiakfdTP40CZJ0ReK2IdUooMGTjrI5SyLv1GTzSV/QrR1NlnC2ojfN06l9ch45TItTIrK33Ra0uerJteWruUAIrFAAVfGCpiVX6d4gZwHoXaxJQtDZYlYXRsJsrKglwz60Pcmg4kD5DvzXpPsPMwoVvn8roooODK3BfInORBTnlhsM/FyPctraEYgsybYGle9WdympTvV1b64FrVGKV5wAJmLEfPgMKVOab0CmGSclfIDbA+7+E8Cc21AAcKtkCj3ABVzIC5Adr7w9ydYTUSrJGP5pEAdUTTdSol+XMAhWPJATiW1SLzpEKFZ2XqvCMaywaoyHkzgSKvgT6vu0CmPnNzeK3IlRBvjKx9zBejgaF9gECPdVpzLKuN4rhUF0/xtcXSo5qHg1wpjMVNzONKxWmMGzxjjRYcDEetLfW0DlGFdML1UE1X+ghKdodQsjsUtZlcq4/AUThJD+n/Z+/Ng6Oq0/3hUV69OHL14jv4A4Rek+7OvpE9nb37NLIoSwwQIBBIAiSQlexbJ+m9TwvIJoggiCjuuIELKo77htswbqOOy9Ste8s7U1N36nqnxuf94/k+zzmnExZn5jc1vpiqU+OQpNPLOc95ns/zWXKHNbNc9lJlxTSeqYhj1uAY4NDiVnJFy/JHoKxgFIVU4m8XzEPPg7juCNOTiyQ/I96Met8YxFbYPgqJLSo/CrEjz1sYQor5pRXgTO3nvzcmyfrSCgYnC11+sM9BoZBjYhW4DC1QMC/Iz8XsQwZhVhViHfkLtNyM2BGZV8IpG5AzQXJt/SEvqyd1twYh5ugwdhPiOeu3hyBjtcyrWOtAhF2k1BeC2ocjxiM8FATvQw1kptXhndQUxMJs9qOYi94H6rTyFyjvOwX0mtXZozsVgNQUUrZD1DHkVmD6VnIDFjZTQBWufMiLitZ7MKRZtyvIzt5Epc9bFIJZ1bJSKEQAEH02YwqFqnspyx/BbuUgjnPxnfh6Su2jmkSzc47M1k5+T9Tnc3ID/j3XtIaLtFBcOnVc6bfahTu34sLcpnIXh3im1xQKsV7NXqKYt8Z34gWe0BbRuAs5J1Xj1kB1wdHvxA7jCSlNqR83Kay4zMcsSLNPxj3+fpz/bb3CGl90FuM9f8p6IEGac1I15C9QHK6caWjpT6E6BIKZAjJ6Iojvk5CMDmu/4ptB3AbjXR4lQvC2AOMVrCMRIJtuN3YfZEkf9+AgMzOJI0EgnK0X+QG0HqVRxbA1zBhKQpuwAyALAPpslobZ44PWiZK1k1e6lBjGa1ZKGgspJDjqMkxBWekYBA+DgEPLfW5FtLZdAT5jPFhIpdjNUJY/wl1MjFdbKDJXhPl1OLLQKV0dNGztF93gzWFcmYp/13igXFqhrPuvXMlBytLVNZpRuixvhP9WVpVIQ59YBZMnTP2HXZ//NIXiyhkx47Li/ppC4bxyJbiMrRDfoS0ULnM7E67IqDZ/QZDJNGrwMrpQUAIYFR9qQ89XKEh4pDZdjd+Mqy91wrqmUGQOQWJzhJ2ViJBFhcJx2RJO1yYTFnKuTmyNsB9G8sYIBw/rd6i4HAe9Gs8F/TYkSRFuoT/kxZmaisRtKAknPYnhMErmEx7u1ySH0YaEVpLEj7A9MMjfLy308Ptd6PIrpkLiszGFZNazkIKT2m3dHvSTMJE0XWwSCDS19QjaPHEmBH2eftZ4ZJRxDeJW6LehMpQLE90MRoQ+RWyEDFvCGncx56Rqfh2Oy5eB88qVkFovMwmLCq21T3x24t/zF6go4L+oQ+eyZiRWEfuWCHx8Ply+bMw5mr00DFeYLkKM4uf6GN46aC6a9EGmrZbnDisf1BXLMcA3b4Q1+86kPvwAYjdDabEH4jujCsW0BshbhNyHjNWYF1Ek+cGROYQouaotpEKR3IBtKF3wuYsxS4N+p7TYw88ve2lYWY9OqIRCl59xhIxVSCunhDDLUARRbXpupjZ+TEpbT12HylnKJaVCIU2p51lYvwNJUHTCm32ocHRkDkF8Z0QxexEFgkBHWoEaDnvAFJRZ90EtOG0V9NvCipntAZ/irXH3CAcYUcfASlZxMVvuQxk5h/lsDfPdt/wSNCYmWnnh7ADzKujnY7yY+BbfiReu/qCXfSh0ewJc+Iwy0td5ayHwFkpMo0JhOOwBax9+hqnrEDg0bMV1M1HdyRHc7BMJ7ge93C2pCwWFEjkyh5hqT1sPs1+MOYKeT+Mar64vwTwaoo9bByJML6dxKqsqzI/vyBxiEiH9/YxV8sWZPXq2QnG2g/IqyLCFbNAvBKNQH2rhUXqNPKZQkGdmxiqZg3Dt1ytdTs5NSpfDfhRlPs3FQOs+aeoGXCUKNaPayStvUUjTlVAQLgmP1FJmtfCIeRC7FYcqyrMwidafQDviAdCd1nz3CHYPKsagMSxrjGzJ/p60GGQ4Q7+ruy2gafNpJUgqWev96JxucSOYqC4UNA7SNokLhcAKiOeQVitwD/E6jMKijgBSzaEy3x3v+8S2JKwqmjPBIkOyMBCGwIatYUWYGIVRUHq8YUvU3xSFIsYrMwBLhSJrmUrYJ+TsHOa8RSvYs/UIXo3qxnLRFoqJ5hiev853FM5Gl6m4bmyznUl9GHYjbOhd0xsVCa9qGzLeUeTwcaBwYnOEcQMqFInNKDJzZA4x41KaUs+Prx4fqFDEd0RYqkybDfKvpE2ItR8/eNfMJphVLWuMeWI8ih9E/GYlKcrsF9Ln5ghzF9SFgpB6kqBzZudOpGWbfTK7PJHMPeboMK4BBX9BvyOkJKqLE1e3O8i5oWrylVHgBGQSk3ysD1Ie6YXUR3sg4/FutvYrzx1G7kpS31hz4KhCYQoqHhaJrUIavznChUJdDPii3IV3b+NdHuyu7vBpCokppDAeE1vwMeO6BNAs3LHI7YqNa8SoknysD5metwYhba0Ms6rRhYveBzWQWp7thvwFQSU4+mYsBrmL8RyVLB2Ix4hCkdQUwfzX+G48h4XOxpnUB0mbIhql7U+FQnxNNMdA2lqZDVvOdXHn3xhkQ5Axd6gfeGg6ijVjOwoCAcdkSV5agSQrYWzjmFgFrmkNTBCidSjdrUsLPRjo0qF88M6UPjYETtqEPqDWPkFXFvZwppAMqesUvoRaC2D245pWTeGmVjfGixdF0iYcP8w+wWkQcz5pL+IeHEQ+RQSLBdGJ+a64N4D4ijALMgndR8zRYd4c0KqVWJG0YjUc9oBhS5iL5LifQVShMIukMCKkUVtulDHLVbfPz0FCNOroblUcxAmMNdwcZpyC7s7kEWEZjCir4QM+VrSSX6hRDoPlPjcHIJnvHmFtDj0n/UEv081JGyJdXQOOLDeb8hhl7EwK5gUVwPaK5UiaEsQ74t9EH2TWlLIez/O0OlmzGctbGLo4Ha7ICi++8+zmuuqLlC3DLoDGfb7Hig6NVReK2GFsmaNzGJxXLIfkRsUqT7J1gWtmE4uyqBUlCziiZUe3k/Rvjiw3SFPqcb4VzEjTkVEwB+QxIcW5i9FbQs0WLSn18utQvx6XsZV9IW29GK+nP+hFUO/+Icg90QHpj/WwYCvziS5IeaSXgUL9LSGQptRDkcPHUXlmnwypj/ZA+mM9kPhwPztYkQBLf9Cr4Q9YB5SW+0IKBedyiC6JZPrpj/UoXQWBskLKnvBwP2+WiKI9hk9ysxI0TACt+W4/Fb2XAAAgAElEQVRcZVKhMEaE76hQo+Y/uZnfGzXWkihMe5jBKmTmpYUeTVg1JXyRI7gzqQ/iuhTDJTovog/mk0yqHt9K79IKmHzJtf+w6/OfrlCMZ657roPs5gpnB5jO7Zg1eE5zXWdqP38vugDw/HrZEijLH4HM5YgPqIORqVCozW2zl6A5TOwI3gXybwwyE5A2Nvbr0RMhmmBk68HVbOFsNMFNbI0wIGgOYFKYZO1k0La4zIeBP50R9sZQm6NonudVqyF/QRDs1weguMyHNnfbEbCMexATy3JOdGCs4Z1oUEMXhv6gF3S3Bln0RrJ4/c4Q+2LGPzQAppDMfhGGO3EjknysD+IfGoCYo8NgcUc02IDzypVQ5PAheHyuQiEs/ijpnTJP9Ae9zNTUH/JyMpvhTg93GPa5AchcgYY0xOegTA6SzVOqmymInQK5buu3h9i9i4x4TAKnobAkCpjW3RbgrkK6phZKiz0aV60Yj8zy8KyqMKTWK2bNY/JLo474zcJ96yzn6EXJo7gQu/5xMQZV9mhWVRgcE6s0AbDcpYjZsPySxbxVsPUgQcoxsUrTmajDex1ZOBq4zO3aQjKxClLWy+Na55eU4N09rU7mUcMxaxBcM5vAJOZh/vlOhXeQ0IaMwvwblTwLU0DIiilmYGIVOLLcEL85whZzvJJV/4yw4VczHJ2TqrGl9aPjNN0Vc0504DpUSM7Jb4IdqQmNpzv5IbTwTz7Whw5VO0PMw1Bb5BGYSRkc9D6T+5j9+gA+p/UqxzCPKDoiDZ4uSNsDKon6PowkjPHIGkduVrbu94PL0ALF5T4mTJEPiG43vg7bA4OQIDoRYxiLN6W3E9uUvk//xivZ/X7+N0qtix3Gz66sYJTxI6Mc5pWrtU/JFjVsxY6Hzo3zHQXzx56jF22huJAAoPMVivgO5N2TMOechaI3wqKf5Abt94skP6TVigv0LIWi/BKkgY8XxkMXpzR5Df9+YkuEw3nyFob4Z0vto5qsChp3GLQTWAe9tuSNQmvyizoWItl6sMjQ9+mIHcFxwzGxin0vyVE89dEeyDreCRmPdzOFmVajun2Cir1dBAqLuyhjA7uD3DVkHe9kqbl1AHUdZIHH5re3oIFu8kZBnhKFIqE9ws+JPqvSYg9I8d0c/qO/A9PVLPehqCp7CYb+SFPqIacyzOa6RJyiXBTyjqBgYxq39NuwE0l5pBdyT3RA7okOZpxyItkBHyQKe7/iZ1oh63gnpD7agxGDomCRKtSwVbBtr12PvJorlqO8oEPhUrCj2TalUNDrNAUQZzLK44xLfVHnaBTv5qIsFJN/NgUvspQ+BL+iwcPo0WBiFTiT+pi7kLkCo/2yl+AcbYyEmX9wtkJBaHdcN/oROq9cCc6kPpi1Eu/4pYUeyKnEC3XM85lQiWi1eL7q0cala0bOR+4w5C8I8nqQRg41scyRPshybcNhD5uXJLRF2GaPtAZ0AqXVomVdcoNyUqWuQ+8K8kEwhWQG52hLRGOQOSAz4JjySC/zJcjbQX8HelLo9gQYKORNw3bFk5M6h5ijaBAc45XZp8J8zzC7YVGor8WN3pxl+SMIKrqVgywK8xaGoKxgVClQdPe+Zxj0tyCtujx3GErto5DcGAHr/UPsjkXvlX5HiLcnhjuR9BV7r5vdvHS7cEOT+UQXBkSL7QVtPfS3hJhQlnW8k8csEncxr2RvAEwBWbsOv6YWnCl96ALuUURi+jt86GchSHQF85DSHeNV6O4ElqpxFf32EHc8JSVezQ3roi0UauFRWq18TqBSLQqL36wVhaVsUJynOCPjLKMH4yK6ZnCZ2hRxkcjQIEAqOgIgGqNQk7XyFoXG3c+P58uoLhQUAJS5IqyIwkS7b1JtNcx+ZAyqZ9zSYg8H4ZpCMhvQ0qG/w8cgX8yokjXCc7/I1SBT3IzHu5WIQ5VPgppHQdgBB+eo1KPqNj/aZ0FjjEycB5HjYfbJYyIFSUtCr50wDAIzbQ8IIxvyfNiPRjax97oh/qEByH9yM2Qd72QSlm6/n587eX8SQ5UKMiWv0+skFiob8grPUVuPVutBHBdbj2KFl7ZWZlHYuUYMSqVTb684QFpwO34KKf7ZFPQqTOyFlPWyplA4Ll8GeQtDkLUsDFnLwsg/OEehmLVS5jsVmYmkr5GhyIGVn6TW6oN4+pTLYArJ7K1IGgUSXkmJvcjn71Mi6tUdxXiFIqcyjAa8ib3YQk6oZFVjzFHlQosdQQNVLhQHfHgS7wwpdz2BJfBdTZxcSZsUazXScRjv8nAKme7WIAcWx3hktuijxyGrO+v9Q1D4dBvO76JQ0IVD9nccvnPIy5sA4n/o9gj+hbDLI6o0rYstgxGNkQuBlvQcWbsiLPWpu1GvnmO8MscApj7agyOI4E0Y7/LwuELBS2xsvDvItnrGuzzcNel3hLgDtfVE2IGKWJbGuzyQ8HA/diYiFpGIbanrMIU8ZYPgooguIMaDzFJzALu7UvsoFLpwVC5y+DBAOcq1nUYjPnYoAdLEjcmqCkNarQxXXncRrkfV6tGcm0Ls0uScVA0uXTMktCt6CUeWGyRLB6Ssx9aOCoXj8mUgXbseZq1UqjLt4K39mMdw1u3JNbXMvJtVjRcRXbxsmLIryC2g88qVEDuCJ4J07XoM67lsCbimN8KslTJ7TxKAVZ47zECea1oDuIytHHMXe68bNwy7g5DUhEYs5ZdWQGKLaFuF+S09J5qRyZhWPfuSdT2343f4ME+TuADDCrfDFFSxMIVYynBYCSri3AyxKVBTqGPvdTMzk7I/LYPo7ESzPvlr6g960d9SfH6xI7JCrb41qHRTwt2KigW5h9PrS27AMdLaj9iG2S9D+mM9vN7Vbw+B7oAPYu91c5dhFFRyy31u3uLQSELELMPNWJSIY2EZUjQf1P6TY3jMUXQTp1UsvSYOFxLeFTTCEDFMf0sIs0BsXZDcgKOs9Is61Ie0Kp8Hn2tC52KMhLUCPdH5WfsjcIXhIi8UzAO4BFmYcV3C8VpQta39EUirk8F55UpcE4pCISX0QHyH1ptAfZy1UFxaARmrkXXHhYJWdLeqKMFirZi3MMSFwuzHzYZk7QTXjE2aOxBTl0WhkK6pRek5zfJRqd4xXhmJSSp3cdpeqJ+T/pBXo9WI7l74Yt2PP5ur2mqo4/3IXJf4AWzNRkQksf3Q7fezOaxuV5A7BDrYzo3s5sg27hDqJKz3DyFrUnx+bOorOAu6W/EuTypXyyCKttJq0XqfnKgoGJj+t8iBFzoVTdpmUEAReWfSJifuwUHWbej2+bmrMftk5lno9gjzXUH4MmxRskTSH+sB3e1+5X3YG+DXpOZnxD0oAFbRjcZ4xDnyizrk7Vy+TNMtFzl82nO1F4ltRPumfzPK2nFn8qX/5x92ff5zForMIWZcSvHdUOTwQd7CEIuvkpqQxei4bAkUSX6I68J9c9Yy/FCyqsJQXO7jo0jCbQIVCoof5O2K0BOQ1iOnEoHQWSvRO4F0GORDUTgb13rmgMxGt7mL0UovdkSxU+M234uWfdKUegZaiU0Z142is4Q2PDELZyPfobjMpwk9yq3AttMUkrlLYfWkV1YuWCFG0u3GC5q6C7oDknuTrQfp2vpDeHfkmMLtIf59w53YXZiOjLL7N21DSGNDnYbhTqRPU8ZHyiO92MWQZmS7Mo4R7Vy/E1t03V4kLBU58PPKvxG3BLEjWLzNPgTzist9/N4Ul/kgdZ3MXRAVBVr7Ev6Q8HA/r1XVnpwk9tLtDkLMqGLLZ7gTjX7VIjfDYQ+HOOkPernQEymM1qPZS9Cpnda0hsMe0O0OQvLGsc9dHUVJCXfUKcR4ZOZ/2K9Hm8QiB74vtPp3ZF3MxjWi2pIHoWNilaa7IBblrJWyUigcPrYPs/Zjqz7GLUqQeqhQ5C4OaV2ULq2A9BqloyiYhyOAdE0tcyrSa7RuUtI1tQx2cogwgY2qwOC4bnxuziQhCgsoQKtlEMEpx8QqtOvv1XZAUuxm7i4K5gV51UsHdTnUHXBBEOAXtasEpBrlMBaGPQH2siTJNsnU1cxS3f4oB6v9ft5g2HqUjAwahehiojBj2wOD7GCl9oPkNSyFDu/HuZ0+K9eMTWy5b757hPEZ9R2XnitFCtLjkAQ+9VF8HnNONbJfhm4/rkpZECciBmJHENOiMYUiC1Me6VVS5g96IfXRHpaqk3KVgGYS7BWXYXK7+R6kuOtu96MeaVI1roJV5wNly6o7CkpxM0bw/IgOqXKZ2rC7yhy6eAuFM7Ufg3qEoUnKBiwIaWvRNERK6OHvU6GgqHhp6gac/Wc2jXUuPl+huAS9Acg+zXnVanAZWpCP34IFiNZadKJaBvEOFN+BztYZq2XGHEgCbRlEAZI0dQM4JlaB9Is69sGkHbwxjGArofHGiBIOFL9ZqFOFO3RCO/I5+PXqmsGRPsiUYP32kKKR6FcueusAdi0uYysa3ojxSH/Iy3dguphiPCo/yz3KhoNEYFQsuFAIzkH8QwNgvnuENSCW+9yM8WjEVmL+JiMZWjdSocipRPEZdUjRhYIYoLoDKum7KA4EWhJZKuPxbnA82wT2p9oh90QHZD7Rxc+TqOyGw0rmSP6TmyHnRAcWBBUQnPhwPwdK8+vapfBKyPBGuqYWMTVjKyQ3KnYCCe2Ks9islXg+pNfIikeJOstlFLuk/BuDinO8mhZw+TL0AL1i+cVbKNTrUQ2zcjMyG+1zAgw0UaE4K8/i8mVI7rF1gZTQA8kbI+csFLTylGxdqHQUaVksIRYMPMqroA1EXBcqANNqRVQeAU8iqStlvXD9TsFxh0VfewKMeOv2KLgA8QD020OQsh43IFJ8N2RVhZnb4Ugf5OfpmDUIWVXYjtI2gPgSFOycuQLp4Y7MIc7I4AvlTo/mAiDk3xSUeT1J4KU645TEYbrbAtzmk/8ErVwNhz3MbzBsxdUfR/wJYxsSpdl6MXeUzHj0O4Qvxt0jWFi2iQIiQpcZAxF377gHBznhnApXgrjAc050QP6TmyH3RAckH+vjcUodHF34dBvc8MJ6mP38Rih8ug1sD6DALf0xJKZlHe/kYknbEuJrkAN6qX0UOUDx3WiUuxnf++RGJYAq/0YlpFm9wifg3RTEcyO3IoQdZVShcE6qRif2xF645ue6f9j1+aMoFLzBEHc6y9D5CwWx/8YDM89WKM7Ko4g6iBRF8Xlj9uEirEZ/S4i7EPXIEePFu4trxiZwJvVxq09gpeHmMPtRuAwt/JysfRHOhYje1edUKsAiYRBqjUD+guAYMRRZxJFcXHe7X5MuZtiijBaJD/dD+clmbsfjHxpgcJTWkRmPd0P5yWYoP9msOGgdGdXwB/S3hDiDg6jZpH/hjkNFFVf7ZqjHIfPdI+yRkfBwP+Sc6BgTnGy8C7s205FR7jDoyBXFg8aTypdqof30Ymh+6yZY/0YVVL5UCwt+uQ7mnWqAeacaoPRkCxYvUTypYEbfTNTnA302DLj/og7Kc4fHnk/kVi7IbYatIkh709hzVEroYaHZRakeVReK4jIfOFP7+XBkuSGhbfxC4UwbgLxFoTGO2Y7LlyFjMrUfHOmDkLRJKRQuQwsSqCZUgmTrgpybQpBzU0jjak2FwhSKcj8SoJUzbQADf1WGM0lN2PnMqsYdfOywcDyi3AqvjBekwA3iO7FbosclwZZhC55wSZsiGvalrSfCo4GtR3EOT2zBk1W/MwQF84JQlj+CeRHCPo0cuniMoET1e4Y1FzR7e96qMrI94IP4hwYg+Vgf4w+FT7dB7okOSBAjC+lFCp9ug/KTzVD8TCsHGSc83K9QqEUHQxGDZI1vDMvsMkWO3WrzXN0Bn7Km3quyw7sVJeRUzAjUNB0Z1RQLwguIZJV8rA8WvVgPa19fAd3vLAD3e3PB+/5s2P9hDuw4UwQj782B9W9UwapXV0HVKzWw4JfrQHpuExO4ck508LrVJABtungpMyTGg8UvpzKM53MKYhJUKOi1qTsKipCkFTYVCim+G3IqMaOWJPKGm8Mw0fwjKxSnT58GSZKgpKQEVq1aBQAAwWAQcnNzIT8/H955553zPsbkn00BR/ogJG8U8e4TKhFMFOvBpCalUMR1idl/Sj0UzAsqPIrLliAfQnU4r1jOGEXGapE4LdZT0uQ1bGGW2BLRmun2KCE90R1DkcPHj1+WP8IrLCpe0Xb9xkiYV3wxR4f5bkTIP5vJ9gvfROEzYdgS5lBk8oSw9eDjJG1S1nnqFCzy85CuqQXp2vUgxXdjEO72ENvXxd7rZnl26qNojkt3aQIumYx1yAspj/RCyiO93FXMOdUIs5/fCMXPtELuiQ5wPNsEjmeboPRkC5SfbGayVsojvZDxeDdTpTOf6GJTX9qksMrSi4WR8lzVpCPiFOi3h5igRR0RuWtpVr0HfJBzogNyxKhBFG7r/UOs4dj41hLwfyDB0Y/T4ejH6XD/J6lw6jMTHPs0EfZ9mAd9794AzW/dBPVvLIeKl+pg9vMbGSBd8Mt1kEhkNFHY6XNi784wfobWfgS/1Uxctr0TPiDWAfw8o4/0NQh0l9rRM0W3z68oZHcFf1zGNd999x2UlJTAf/3Xf/G/ffjhh2C32+Evf/kLnDlzBgoKCs77OJN/NoWNPcovrQDXzCZIaIuwFb+6UDiy3ODSNUNiS4TvytKUepDiuzmBmw7yr0xdh6tITme6ugaSNikXspTQA5KtS5PrQdbrYzCTTuXxaf+u7nI0AUCiO3FkDrE3BLMSaVYnB+hRBLpKiz2M6rO57Y4QZ4nkVoTAecVySK+JatlFoZASeyGhXQH+iKFoEkYrpNVIVJnjkhqS5OG625E6nfoo3pnpIpGe2wQVL9VB5+mF3KpXvVIDc041ckufqxoDMh7vhuJnWnkksT/VjkI0IlttUbY/ziuWQ1odvmZKJCNzGN0uDCuiDQvhILq9ASjPdoMzpY+dufR3+KD0ZAsXtMKn26D4mVaoea0aOk8vhC2/KoM3P58Jn305Ff7zq+nwp2/08D/fGOF/vzHBH76eAb/7ahq89rkOjn2aCAPvzoeVr64Gx7NNbPNvf6qdQVLTkVFWiZJ3J62eiWdhn6syjRZu47NWyry9KZwdYKWv+iDHbioURhnX6tRN/agKxfPPPw833HAD3HDDDVBYWAgPPfTQmDTz+Pj4H5xm7tI1Q1w32tBR12AdwBY7d3EISos9YL8exU5UKFzTG8E+J4CBvwsxHJaCc0qLPfw918wmDgAim7mC+UFeQc5aiTt9ytCwzwlAUtP4uEnMKIJ+scPYkZQWeyB9jRKRRzN/3qIQFM4OMPhFB3k1xHfgSeOcVA0uUxvY5wSYrUd3HpplU9bjfj2+Q1nFkmmufW4AcirD/LyI/GQU4J8pJDMjk4oFdRPmu0cg5ZFeSD7Wx6Iuy31uSBTiKMezTbDq1VXQ/NZNMPLeHNh2pgT2fZgH3vdnQ+vbFVD5Ui1UvFQHc0414sgh6Nv0+8XPtEL+k5sh4/Fu5jbo7/DxerHUPgpx3RGN3wMRvtSGwGqyme52P6SsR4o+2fyZ7x6BeacaYNGL9XDDC+uh4qU6WPXqKgh94IQjH2fAi58Z4XdfTYM/fD0D/vSNHv73GxP85Xcx8JffxcD/fmOCP36tgy++nAqvfa6DbWdKoOa1asRdRIHKf3Izd1AJD/eznb9+B4549jkB1rPodgUhoQ1drtQpb44sN5+P42V9SPHdUGofhVL7KPtrcrrZdhzN/sXyIyoUd911F8yYMQO+/fZb+Pbbb8Fms8Ho6Cjs3buXfyYvLw+++eabMb974MABKCkpgZKSEvj5z/513EJBbsi2HoWrENeNQBHxKBLakUbNTkATKtG/siMChS7/uMlM0tU1kNg6lsUZ14Xeh8SvKJ9QidyNanlcxqfZJyuW8VQ8vAq4pRb5jHdkrELAK29RCGfSq1bz30xbKzM7kAxq4roUtqfaRYn8G9ScBY7/o0OkeNPf1u3z84VIwCF1AeTepL/DB6mP9kDxM61Q8VIdeN+fDTvOFMG2MyXwxKdx8P4X0+GZ31jg/k9SYceZIhh4dz7Uv7EcEh/uB/0OpG3rD3rB9gBeYJlPdDF+QLgHWf4RH0R/ENmkOcJ9i0YlOthERhWsbDgs8kkOeSHx4X6oeqUGVr66GipeqoP204sh9IETnvmNBT77cqqmMJzt+NM3evjiy6lw5OMMWPv6Cig92cKjGvFEyAFLf8jLQHTyxgiUT6iEjFV4k2CuiOj21OfVGNcqVdeRUxkec66o3bAMN4fhX2ymv/XyveCvv7lQHD9+HBYtWsT/v7KyEvx+v6ajSEhI+Ks7CmsfvkFSfDeUlHrB1hOBsrwR1uZLV9eAy9iqWUMlN0Z41EhsRrp3Wh12DeoPwzVjk8ZRO7VeRrn5pGqkTa9EHn7MqIz5lllujbW9KYhApcUtTGQE4q0uFIabcX5VHwRm0UVLFv+StRODhYXCkwRUVCgS2pEqXjBfxUkQj6PfEeKWVLcXGYYaUZXQTxDYZutRVo26/SIVbGcI4h8a4Ls/tewVL9XBxreWwI4zRfDgJ8nwzG8s8O4X18FXX06Fb7++Dj77cip88tup8NmXU+HYp4mw7UwJLPjlOsg50cGp49b7hyDziS5IPtYHycf6wP5UO/8NjhEQ9vpxDw6C49kmyDreyZoS410exjgMhz3oXH0zkszI25IcqTIe74a1r6+AhjeXwvo3qsD/gQT7P8yBT36Lz/d8RYKOP36tg/e/mA7e92fD0pfXwpxTjQxkGo+MQszRYch/cjOS0cTYYwrguRY7LDAksb3R7fejj4alA9LqsINK2SCP8Yd1JvVx56C+ycR14/qYDZlXynCF8UcEZv7+97+H1NRU+O677+C7776DxMREeOWVV6CoqAi+//57+OijjyA/P/+8j6MuFK4Zm6A8280XfeZyDOeVrJ2QsRovZsfly8BlamNwMrlRudMmNkfYpZsuNsug1o6fP5iUPshYLXPOh8vcjqSmxF7UmAijW/vcAJSUIModvxkfK7EFxUkZq/HObx6nUKizGkilSBeyMayMAdlLMfTFKCsrQuY0hGROiXJeuRJKSjEGj3b5tHYkijKxD00hHH/Yf3JLmNF4LhSUASrA0MSH+3llSG07AX/HPk2E1z7Hi+ffVa37f341Hb79+jr449c6eO1zHdz/SSpsfGsJLHqxHoqfaWUCVNbxTuY52J9qh8Kn26Dw6TbuEPQ7Q2zHV/xMK6Q/1sMjRszRYbA/1Y7U8HuGldyNQ17IeLwb7E+1M7Eq90QHF4qGN5dC6AMnHPwoG774cir84esZF1wo/ucbI3z15VTY9etCWP9GFdzwwnrIJR2J4GGQH4f+DswzIaas2SeznwhpYcqz3VDoQm2JfhviGZKtSznn4ruRvi40ImYfjlTkzUpkQpe5HbKqwj++9eiRI0cgLy8PMjMzYc+ePQAA4Pf7IS8vD/Lz8+Htt98+72OoC0XGalWuY8HouO0ZuQiVlHjHFIrybDdI165nm3e6aBObI2flXYzHoyAb+mh2YGnhWH/KzBWqnAZVoaAMDWL3kdiK2m+i+Y53qLMd1J4H9uuRsUgJ5VQoomd43e7gGDt/tQKRskYJ0DTfPcJFoua1aqh/Yzl3Esc+TYSPfjsV/vSN/pwX139+NR0++u1U2P9hDrSfXgyLXqznglB+spl9NmlNmfF4NyQ83M/sTMPWMPMsSMqe8kgvZB3v5I1KzokOZGWK9WLqoz1Q+HQbry4dzzbByldX83rT/d5c2PdhHnz2AwvF/35jgv/8ajoc+zQRvO/P5rwS6rrIoVu9MdLtDYwZGZjS34ddKKtQ7/BpWJlq+ryaR1FqH+VC4TK38zn6oysUf48vLhSXVqCdnZj509fIkL8gqDlc0xrApWtWbMI2IohYljcCJaVelH1PrAJH5hBkrkDAsGB+EJxpA+csFM6rVoMjy42CtGw3lJR4oUjyI5jagWvJ8txhKHL4EJxS8fAzl4cVBaKgY+sPoaW7muFHxJ/Sky2aOD5iFtJ2wnDYwx2IYUsYLfDE64/fHGG1pDkgQ1neCKTWKwa3uttwranfGWKPCRov4h4c5NTu2HsRqCQsIOHhfnA82wQLfrkOlr68Fprfugm878+G+z9Jhdc+18G3X1933vn+f74xwn9+NR1e/MwIBz/KBvd7c2Ht6yug8qXaMYUi9dEeHk/0B71KoPE+P1vt6w95OeeUVq0Zj3ezhN5wJ44kxO2go/RkC8w71QBrX1/BIOZXX06FP36tu+BC8adv9PCZwCnc781l4hW9X7R6pSP+oQGk5otNDhWAzBVhXJHmDkNWlVCu7g0oilkqFDKOqbEj2N2WFYzCrJUyj9TZS8MokvNj6tzkfzX+w67Pf6pCQZmaZByb2KI1II3vxM2ClNgLUgKCYPqDXtDf4eNwnuijrGAUkprQ2dt51WrlEAi04/JlqNI8C7DkuGwJOK9aDZnL8UMqv7QCist96CmgUnfm3BRSIvz2IQGIWm66GAufboPSky0gPbeJ29jURxGsozuh2syVzVX2Kw5XhKbTxRXjESvZMh/jKUY5zCcimbQYDnsYJKTtA110ai0EjRsEAm47UwLPfhYDn/z2wkBAKhZffDkVTn1mgiMfZzCByfFsExckcozKPdHBZjBqLYhlSIx9+/2sSKWVa8ojvZyrQSON/al2KD3ZArknOrigOJ5tgoY3l8KWX5XB/Z+kwr9/Ne28HdF4GMX+D3Ng4N35UPFSHcw71QCOZ5vYWJgOci8n8RyBz7Ze3Lw5J1WjqHHWILpwe2XlZ1SFwhTEzVapfRQkSwcnvtNjWdx4jtnnBOCa/2faP+z6/OcqFLMG2cQjdZ3MVvP0RmYvQawiaxnKedky7dYg4hpn03xcXcOBK3SkrsO9fXGZD2K88lkjAhzpg1ic4ruZTkuhtNE6EeekapAmr4GM1YhrJB/rgyHIcPYAACAASURBVNwTHXDDC+th6ctrYe3rK8D93lzofmcBNLy5FKpeqYFFL9aD9NwmyHyiCw1m7lHIT6yKFCCZtT/C2Z6kC7H1RljhSsG55bnD7PNgFLwD8shU05jpgpr9/EaQntsE5SebYe3rK5hkVP/Gcuh794Yf3LJT2/7Fl1Ph5c/1sONMEXSeXghzTjXyhZx7ooPNfYmhyYXigE/xkxCkNN0eRVNC1v3qYkOFjl7TvFMNUPNaNYy8NwfkX5XDwY+yf1CRoEJx5rfT4OjH6eB9fzbMfn4jzDnVCAt+uY5jA8hkVy2eMx1BL0xrf4RVoMkbFTUyMWZJCaouFJQwRl0hZasSeM7K293BH9d69O/19W+TTSxusriRRFWWN8I6/Pwbg7jqzB3mRHJKftbfEjproXDNbIKy/BFcKw4pbElrHxJdUusRFCuYF9T4YjouXwalhR7eYY9x4Z5QieIslemuc1I1lJR6ca0rcjil5zbxvN/w5lLwvj8bBt6dD61vVzBN+IYX1oP9qXZIf6xHsYG/08NjB1G6Yzwym9uSP2XssMAvhJlvee4whwXpdmOhIAUkuUhTK0/xf0SIoue69vUVUPFSHTS/dRPIvyr/wXdiOn731TR4+4sZsOvXhdD9zgKYd6oBck508N8mzob+oJft7mhNG/fgIFvjmUII/hHOk/hwP/tYkqCL3LLzn9wMxc+0QuVLtbD29RXQ9+4NEPrACfs/zIE/fD0D/ucb4w8qFO9+cR0c+TgD/B9IcMML62HOqUaYd6qBKdxUrJMbhQEP2QUKINnsR/A4vhNDmtT5MNLUDZxeFteNY3Zyg1D3iq6UFMVE8WY7xNsCP6716N/ra2KsGWPvhIaBQDo1mOlIH9RWVgHSmUKyxjxXfZSUeBkoMgVxE0Kp18RBILt29VZEmryGPRNtPcIbQt1BXLkSkjYhl19dlEwhmZF46blNsPTltdD37g3QfnoxtL5dAe735vL/bz+9GBreXMoUYSLwkOGLWqDFfJJehbuh9obgPbuK66G/JcQOV2wXJ7YiamOX9Md6wP5UO8w71QArX13N/IOR9+bA/Z+kwh+/1l3w2BENbL7/xXTY8+sC6H5nAbM3iVVJalMaH8nZm8YT/SEvy+TJ9i7j8W5IfbSHV64kJZ/9/EYNc3TVq6ug/o3ljLPs+zDvB2MUf/h6Brz5+Uw4/FEm+D+QoPKlWph3qoHFcWT4W5Y/As6rVmMhF76d+h0h7gTUn4/mfJneyCvs+E6045fiuxnUJWo+FQpbj1iXi87roiwUVxhiIHNFGFzmdoV4szOElbYG3adIIKXfFla4/7tx7ZiyQcaO4yyFwjqAjEaXqY3XmZZBBJqkhB5IblAKRWmxB1LrEVgjKbEU382PWST5kRUpxoH0GhlcxlYcc2xdkFaHrk1ZxzthzqlG2PjWEmh9uwJa366Ata+v4AvxhhfWww0vrIdFL9bD7Oc3QvnJZsg50cFai9JiD6+JzT7crTtT+iDnphBH6hHKXjA/CC5TG7hMbcw3sQyJSALhIUlU7dh7kdJN2wQ185K0HOvfqIJ9H+bBi58Z/6ZC8e4X1/FqkbQXhK/oD3qZI0HjEYGW5AlBnh2U3mW+ZxhbcuHwHXuvm7kZlHtKoCyxM0n8RVjL+YoFjU3vfnEdPPZpAoQ+cELDm0vB/lQ75IiRKVGI3bhQTKpGbM0nM4BsvMvD2Sxmn4wdqCo/VJq6Ac9NlYbH1os3yryFGO5MHYetJ8JJZ4atuFr9UfEo/l5fPzfEwKxqvCCt/RGW9Np6kDClDomhxG1uw/fhbjpjFV7o0pR6tN/XNUNJqRfSatHshtSjRQ4fpNWii1bh7AC4DC0YBrtOBsnSgS7eg0rWhCkkQ0kpZiq4dM0wq1ohT5n9KAYqtY9yV5N/I1Kuk4/1QfnJZl4zNry5lMEwIhyVn2xmdSK1z+a7R0B/SwhKSr1QljfCnUJis3BRKvdxxqfuNjTIyb8xyK+5PNuNr7kzwsHDFPVne2AQYu9F+3vyakgQQinHs01Q+HQbSM9tgvo3lsOeXxfAqc9M8O3X1/2glp2Of/9qGrz5+Uyoea0apOc2Qcbj3SxTJ5yFmYvCgIaKGhUT5qIIMhZljhAfhfwyaZVKNnTEnpSe2wQrX10NzW/dBEc/ToeXP8dNxh+/1sGfvtHz/9J//+HrGfDt19fB21/MgCd/Y4U9vy7gz01N6KJAIssgFmkpsRcjHsVqnFSrutswLT2hPQLOtAE+h1y6ZpDiuyG9RmZ5gFFW2Lb2ORglGL9ZEQtyGHMYuTyTpl2EhWJirFkhpwifRVsPXoDOSdUarQVlQPAhaLy2HuRJZC8J88VVJPnBcfkyjcOVmtJdVjCq+D0MKEG2Zp8wuhVp48SUi6ZxU4ixZRABUqKVW/sQp8g63glVr9QwcMnW/MIZKudEh4YfoLbu129TKOBlBaNMQVfnW9L4FDMq82smB/PkRjz5bL0R9tWk7Ydha5j5HMQ/mHOqkZWg8041QOfphbDvwzz43VfTflDLTsdnX06FZ35jge53FsDSl9eyHJ28I0xHRpFWrhqx1L4damdx/c4Q31WjQ4rVBxUgNRV91auroPP0QvC+Pxu2/KoM9n2YB29/MQPe/2I6vPn5TDjz22nw0W9xS0PH4Y8yQf5VOax8dTXnosQ9OKjQzsl0WYyu6gBkdkMX6tiC+ajzsAzhCEWfU8oGVIeSiFBdKCxuZYw0BWSN2tjWgzKDi9Lh6l+sZkVGKz4EWw+yHilty+yTmdWm2xVUDgprCcjMoCxy+CCuC4OE7HMDUFroAWdS31iwc8YmKCsYhbKCUSgt9EChyw+FLj9nebqmNUBZwSgktAkA1ScMboViUE23JvVo3kIEIcnwpfRkCxQ+3QZZxzvZhNZw2MNpVYTYJx/rYwSdnbF3hMDsQ1qwfS6GGKfWq0xwRlEgltygvD+2XgTGyB6P2lnd7X62z1d7O8Q9OAhGOQzpa3BMKT/ZzArRHWeK4OXP9fD+F9Phd19Nu6DO4n++McJnX06FBz9JhpH35kDDm0uh8qVaXhHbn2rnNbBJFTBEylryskxow3xSYquafTJT5clhS3/ICzFHUcCmP+TFUTEkQ8zRYaaKE2ax4JfrWEF6+KNMuP+TVHjwk2Q4+nE6HPk4A/Z/mAO7fl0I8q/KYeDd+bDxrSUw71QDFD7dxhsV2wPo5D1rJZo4c8jRQa/25iUo8zGjMqTW4zlMHBv2HPHLGAAt/ESIpl/o8iMvSJyXGasVMVjsMN40ihw+uPr/vQi3Hv9iM/EdgpyN6S5DEt7odCmmSQvMwnAznlzO1H5wzWzi1VN0UtiFHiz5vXIlehwOqAhV+/wa3UT8ZixK0uQ1MGulzF1O7L0o1U58uP+sAiy6q8fe61Zs70XOhm53EFejIsQ4oQ07H7L6t/WikCyrSrHPV9v16/YE2KKPI/4OeZUc0V1BsD0wiGPNNbWg2xuA4mdaYenLa6Hz9EKQf1UO93+SCk/+xgpvfzHjgtakf/xaBy9+ZoTQB05Y+epqqHmtGipequNxoPiZVs2aUw2wxj0oRqOtGPZUPqESx6e9AQadE9oFwOuXOdmMksKIhEcWf0Qgu+GF9ezAtfTltTDw7nzwfyDBtjMlMPLeHBh4dz6435sL7acXa3Ak+v3Kl2pR13H3CBgjYTSiSR8E3W0BTSASKXV1uxBkT2iPcPYMFWc2QRZRjtSZxHVpwU46SGYe48X81vJL0LHsomRm/kusGXS3+5m6qz/o5TfHKOMJQqYmmrZUWNDHDgszm8lrILciBInNWqLWDy0UzitXQlodzo9JTRH2tyQTGMNhj4Z955g1CJK1U/GHUM3e6raVeBBUKMjvQb8NxxeS0uu3IY03ZYOMBjQioEiavAYK5gU5lNcUlCGxWVmp6fYpuRoUfGO40wOJ4qKh7oUKFzEK9Qe93NbHHB2GeacaoOHNpSwn3/PrAjj8USZ3FuPJs//0jR4++e1UePPzmXDwo2zY8qsyGHh3PlS9UgOzn9/Iq8zCp9u4aJnvGWb/Sk40uw2LW8G8IJRPqORMVGsfrhhdMzZBYuv4hYLWk8nH+iD/yc2w6MV6WPnqaqh8qRYSBfkt5ZFeyDnRAfan2qH8ZDPMO9UAC365Dhb8ch0UP9PKa+TkY328Dp39/Eb8G7uDYO0TBkPic+JEr9v9SuLaVuw4pSn1/LlJ167HLJLt2GnEDmN+iW4X3hil+G6NFF1dKOK6BdHw6pqLu1BMmhaD44U4eXQHfBpxTebyMKSuE+20iFkjy3viVSS0oQozqSnCc6+1H7cbZ+NZjMu9MLRAee4w37lsPRG2smO7tu2YEZpbEYLcCuRxuGY2MY1ao8rchvoFFj8J92faQBgOe/CiF0G1FINo7cf9vCN9UHNkLw3znSjGK0POTSjn5oi+fX7OoiBX7PTHejSO1BmPd7MJLQX96m73czhw6ckWqHqlBja+tQQG3p3P8/0Tn8bBy5/r4aPfToUvvpwKv/tqGvz7V9PgK6EgffI3VjjycQbzRTpPL4SqV2pAem4Tg6ZZxzs12xdajxJtndbA9rkBKJ9QiVuPQ14w+zCc2TmpGtt1USjI6o6SzEisZX+qHeacamTshYqyejuS+UQXcy8czzYxfkJmPQTwZh3v5HhFWuGz6bKw8ktsQetCAsrJQZ14N2X5I5CxCleoscMo9EpqwptBeo3AxMY5H9VaD/73bDdcNeUiHD0m/2wK2K9X+ScIMJPmUmlKPfModHsDnJBVMD8IziuWs6Ft9A6bwlRchpYLLhREWFIfBLQSLpDQHmF7fzWPwhiWuR3VHfCxAItdq6PFX8RIpIzRW0IKZfc8BwGd5JdBhr5qsJe6GfK7JDdqKhTsmK0y1zUHkLNQerIFbnhhPax6dRU0vLkUOk8vhNAHTthxpgiOfpwOxz5NhCc+jYNnP4uBJ39jhQc/SQbv+7PZ9WrVq6ug5rVqqHqlho1f1OHAPHrsVMKB1EI4KhSGLWHuGOzXB7SFQmSNakDNe4bZeTv/yc1s45f/5GZIFIFAFHmo5pOQqU78QwNMt89/cjPEPTjIRZ68UdSFInYEWb90tz9bh2qUFSA2xoPr/miZ+QUXiksu4pDiUvsoxI4gOOdIx1Y+tV5moC11nWJrbuvBO23uYhwzLO6IxlWKxoK/plC4pjWg1b+1k/0qKJ3LMoTjkFm4MqWsR0DKpWtGf8+UPkywEjiGbm+AszspNEa/LczP1RSQxwTlxnhk9oFUk22iD8oQoXldvz3EYTb8+EGZ2ZgxR4chd3EIMpeH2YdStzuIHp2ykihOCWH2p9ph0Yv1UPVKDdS/sZyt78gIho5tZ0rA/4EEnacXwtrXV0DVKzVMTiJuRuHTbQwGkkkt8QyKHD7IX4CvhYxmNa9TULpj73VD/oLgmEJBocFmH262SkqVvBIS5VH3EP/QAFrqiS0WuYeZQjKDuwSEEueDEsXoBmYKiri/flx5Sgk9mrCm8kswn4Q8WJMb0KnNMogYF90QYkYxdMoxa3D84jKpGrKXhjkT5KdCAYoLd1x3RKO7yF4i8hajUrR4w7AI2YnWPgSMUtbLmoPu5uxhIUKCXLpmLAiquwB9X63jcGThelRjTCOEV0Y5zGxStZ1Z/oKg4itxW0A5RExd7Ijy/OI7RbS9CMiJHRHjFXUfwkA2sXXsa+NIwNtwfUhS5oR25WcTWyNK5N4BHzhmDUJJiVdpm4UWwewXLbHI76C7MpGWVr26iglj9W8sB/d7c6Hz9EJofusm6Dy9EDa+tQRWvrqa7eeIG1L4dBt3MeSlSWlc5AxVljeC3eQBH4KRbpV72K2KEjfmKKovXcZWBpd1B3xMvrMMocLWmdTHhYL8LdQUduORUTD7kQNDCeGUGUKYB2FlrOLdFuaoRVLlxnVH0KT56hokUqkc1BJbIux3agrJnJJu9ss8apr9MqRskKG43Ifn5bQGTZfKGqXmyE+Fgr7OVijsc8fq+9WFgmLkbT0RyFoW5ghCOorLcE3qmt4IkqUDSTEehRNhv14xPnUZWzGuTeSeqgvF+Q51oShy+NjPQg28UiivfU6An58ztV+zGlRnbJAFnGFLGApd/jGvLaFtrCWetQ/lyPQzrumNmCQmsidsvYIvEm2ltwfHpeRjfRopOOkpyk82Q81r1bzFcL83FypfqoXCp9sY8Jt3qoHFXuUnm1lEReIvNY9CvR4lqjJtDfQHvUo4b49QTYr0sNjhCMc9FswPsgDL4o4om6J9fpCe28SycPtT7UhkUwnuiJhlOjLKvh3GI6Nge2CQKeTmu0cYC6LPzrAlzJsaixsLhX1OgMlw6kKheY9F4DCpPy1uxJ+cV66E4jIlFjNrWdTWY0IllBZ7fioU9DX5Z1PANbMJhTMq+bZk7YQiyc8OUsawjISibDdG7c0PondFL14g3LYJ5WlyI44qrplNIP2iDkpKvZC0CS+WIsnPIcZFkh9yFwsyS+7wOQtF5vIwe3WOVyhc5nYocvgUAc8+JVbPKIchaRP+7byFIaSKC/cpMi5Rt8KkZ0luwP163qIQA6hx3REljlDEGFoHEBwrkvwYPXflSigt9kByQ4R396aQrAQZ00HBOkJDkf5YD+dv0oVP48QNL6xn4dicU41Q/Ewrs0xzxFYl/8nNkHW8k5mM0cE7GY9343brkJcZh/pDXraNs/YhF6S4zMevkzxIrX14UdqvD3BXYgzLLB7T3Rrk1TNtlhIf7ueNEK+HBXBL4LL57hEcC0T3QjgYu4ALF2zjkVFkhfpQNkDMX/vcADhTkKuTuk7mnA7Dzcj7MfuFvNyD53BZ3giUT6jkkOKYUWRcFkl+cE1vZHVzcbkPSkq8Y7JrLtpCET2jUYirdE0thuMIwU1Z3ginhOUtDHF3kHNTCH/vsiXg0jWj47VIhXaZ2/l38hfghSddXYPW+KoiEL9Z6SgcE6vGtesvLfRghMAmETq7OaJRBdLvxngUFSCTqFSyYdIw6G73jwUwBUmKRhBTUGZjHGbvDeGdlnAFMtelx3Cm9qOBz+XLIG8RjiZjeBZRqVz6OxBUzVHJtskIZs6pRl5vzjnVCIterIfKl2o5s0Ntnsvir3uGOb0r/TE0qqExxHKfm5PNGIAVRdXaF2GgOq5be3c2+1EEaJ87Fvxmd7HDHu4YrPcP4YW/VSFIWdx4A9FvC7PuxXzPMG6MtoY5tIgMdDgpXhgW67cjsSu+I6KRF+RWhMAxsQoyV4R5pW6MhBmbIrtEZ2q/ElIs+fl8MAurRWdKH0jX1EL8ZlwT089yOt6ESph8yf/5h12f/7SFwjW9EVI2oLtP0iZxUYlCYetBMVf5hEoMFJ7WANKUeq64BfOD2DX0iXDeGZtgVjXmeFK34TK0QGq9zNRZo4zZnuSO5bxqNY8pxOMYr1BkVYVxIzMOei1N3cB7cyI46W8JMa5BRrsUdEtYTOxwRMk5HZV5O8KYh2CukuM2pWNFFwoKDkreGOG4A0rVst4/hCPOPmUlyq3/IfTkpBwLtZybcjipYNifamcVaMbj3SwDJyJZyiO9eGcWvpcESsbe6wb9zhBYBhXqsv4WxAvovU5ox/Z8PFq3Rm6/M6SAvhQgLSjU+u2I4+gPepF4tjOE5CixhqcVLYUgqQuFbp8fg5cGcCyQYjdD7mJBVNsTgNgR5LhQJ0o3muQGvNCdKX3cGVKuK2Ftic342pIbkZBFHJ30NTKfT9KUejD7hIub+Fm6GRa6/HDldRchj+JsLtyp63CrQFFrCe1I66bV2XhocUmJF2atlFnrQQFAqfUyOJP6QJq8BpxXroTcCswgNQUUCbczqQ+kxF5wZLnZ3DZlAz6H7KV4SIm94Lh8GeQvCGr8Mx0TqxABFw5cjsuXgRS7GVI2yEoClqAYW9wIbBGpiqTUtNUxbMXXTICefqeq2GxTogCMkbBinbffz0nmtJkxBwT/Y0Tm+D22xtuPd3AC6vR3+NAP455h5oJQ3CCpNNV+l8TBoIg/4imQ/wXRqvmiFVwSMqWJHcZCa/YryVk0RtJrZ2B3V1ABhPcGlNcs7u5mnwxZy/DzyVyhKE4J8NUf9OLr3x1kMpXa24KNclQGOiQjoKJVVjAKs6plZlia/ajmzVwufFSGFKWnZOkAl6kN39u9iJukr5H5HFITAlM2KP9eXOZTbjRT6pFXQ8HTvXjuU1d8URKuzlYoygpGOSkstyJ0wStOCilWFwpmUaYr66iyglG+u5N5rvrIW/gD/ubUDdxuxneIrBHxvdR12k0G+SzMqsYPXp1hSoVCfaht0yi3Qy2KolQqax8WCdrVWwYjigt3lLku2fZR4dFvC7PhLT0ukYx0u5TwYHW7zwxZVao5czO2hLljY0BXdDO6/X7IXIGgq603wibENGKRwxONQ4Y7Pdyx0EijLhS2ngjfOKjbI98O410ezv3Q3Ybp51nHOzV8Eg4aUn026vOA3NQ0oq9dKr5NVGi1ZOkAKXYz/txuXKmqJeZkiGTriUBxuW/88+maWkhoF4xk8Zx+KhRRhcJ5xXK8M0+p50KR1BThynuujkJdKJIbImydp+korloNaWtl3nWTP4WtB2djx6xBSGjHsSd7aZhzRM52FJf5xoQEJW/Eu0XKBgFoCUt6Uwgv4NJCD5TnDkP20jAb6tAKTbcnwPwKw9YwZFWF8Tm1RRg9pzuuOYD7+LL8EfagiPHKYJ8TgLKCUQxBJn6FBzM+pcRe5CgI2jP9Hcon1R9EkNAUkDnxioBV/TZkhGZVhaHUPsocDt2eALMjrfcP4SYlgJ2MxY2H7tYgGO/ClaX+lhDEbxahu4fF75B9wO1+/jeSnueoLmzdngDEd+KNxNqPXWFyA7b0lKDG3JDdCkeFmLO0Ak18uB9ZtKJro25PvY63zw0gqN2rmB6NKRSio0hbi+dYwfwgpNdgJzlrJXIlKCKw/BIlKFtK7NUUkLMWiq04miZtQq2Ha2YTXHOl/h92ff7TForyCZVcJBwTqzhHI3o96rxyJVJfVTtsdaGgn0/ahPJr1/RGxDRsXRjgI/ACKkS09SBSDwODaQPI2xfPKfpDnVUta1d6UXdSAgn120N816FAGOJpULaoOSAr3AtBCCqYHwTXzCZIWyvzvKrGIezXY1SiZSjCr6msYBScSX28EqXnl7kct0OJzRFeyTKr85CX79TEaWDQVZWBau3HNa9k6cBCIboS3R4cMWwPDKIKVBCLLO6IhqtA8QC0baELl/422cpZ7nMzD4LA0oSHcaWcVosYQVxXRNliUEo4Sb9Fp0QEqRivzKQn+puE0xi2YkdANw3iPpSUekGK3cx+E+xbeWsQMYx+LCxJm9Bekc4HOg8KZwfGPUfHKwzqFat0dQ2k1SG4aRmKcHL9T1sP9egxswnnwrwRZQOiWlWqA4ETWyJjePLqQhHfGQGXoQWcaQOYvSms9sh3Iq4bPTElSweSaMYpFBSGHL95/KyR5I0RjS3duIWCUsyFOtZlbB23UKjFb8YwzuxxXXgiEtDlmFiFLfseHDlih7WO5bYexXiYCV3iYtEUitu12w/1NoTWlSTI43lbjDnMOBUXDRUKyv+krQPpOozEWdgWZkxCt9/PYi0yrNXtCfBFrb8F3aKs9w9B/pObIeHhfgRtByOcEK/fHmIhHGFN6hGNVscUgGTti4xRfPJoIuICqHjYehSvSsPNYQbUaY3KnqY+MVqILlddKOK6IqzOPVuRcFy2BNJqZc2Kn8/7iVXgvHIlpK6TNXaNPxUKFUaRVRWGklIvFMwLYgJ0DyK/hbMDUDAfeRKWociY9o0KBTlVuWY2gZTQw1bpFA6cf2MQOQeT14B0TS3usA0tXCiokkdvPaI/6LRaxX7dMognF9uye2UWkrHCcEcIk86m1EOR5Edhm1fZvdPvEV2dilXeohAGKs/HYFzCCUxB8fdVLTOFFBsjYb4IDFtx1i2YH8S1480Cp6CkK9VhFJsUkvgzLf12P48IxoiIR3QjhkRkLv0hL/tuqIlWnBsqiFG6/X6w3j/EKldiStrnBiBlvazRwdgeGGR+A1nExXjEHV64XZEWQ2O+vDPEfBEKe9YfQpo3KWwJwFXntVIKm8UdUT5HNeP2VvwMiPsi/aIOXNMboaTEyx2frQdxqOJy3xjndj7XTW0Yt9CiFPHxjrL8Ec7FleK74d/+7Ufkmfn9999DY2MjZGdnQ2ZmJmzZsgUAAILBIOTm5kJ+fj688847532c8QpFfAdeHHHdeLEyXTqhB1ymNj6BTUF5DIZAhUKt9SBmZlw3jhnjjRCMkaj1BMKFifbl4yaFLY9KCqNgZdWO3ToQYQRctyegGPZOqMSLrE8AYj5tZ0KsvbjuKLanuJsZZcVhST3+8BjQq2RksHHNFly/Wge0wOG4zMWojoO2F9QBGWUcAxyXLUEbwaEIFwHdAR8UP9PKkQWZT3RhHikJ0cRzImt+sw+l/USoYtbq3gBubMSq1TqgBX31O5FZyc8p6n3SbwuPSUxTi8LUqelcKLaHIK5LvPddKqCZSHEBLMyGm7G7ck1rYEc09VFS6uXgaTrUqtIih4/PlTHMzLMcPzow8+2334aioiIAAPjzn/8MMTEx8M4774Ddboe//OUvcObMGSgoKDjv40QXCsdlS5D/Pr0RD10z2OegX2BCG17o1PLZerQbBs3oIe6wrumNqOWY3ghZVeELLhSUXVqe7QZnSh/EdZ29UFj78IKklDMpoQdKSrw466uiAixDONe6ZjYhn2MdzsUEctLFbg4Id+YZm5CCHrsZPRCEZ2iMV+Zwo4zVSmydZQgvXnKOsvXgDE/8AfJ7sPUKf41tCLTaHhjEdSZ5Ut6GYwTL5beHOJxXd8DH6lVrP15MqeuUeVq3T0lKs9yHXIzcEx04WuwOMkOSckfUhYK2CMRqLLWPQpHkZ74IFQqzT4Xl7AqiR4QQuPFoJMRiFneEV8v6bciT88DXTAAAIABJREFUIB8MonbT1oPW0ET9p/c+oV28Z/14PpQWepS1rfAujdYkEWeCdEe2XjykxF6QrqmFtFpFj+RM7T/nePKjLhT/8R//AQ6HA7777jv4/e9/DwkJCbBlyxZNmnl8fPwPTjMf9+JN6oPEZiSlZKzGiyStTsYQ45Q+VnxK1k5wzBqE+E7cPGQuD2swjNzFofMXiiuWQ05lGGatRNTaNb0RXDObIK4rArmLQ/j3bF3899LWypziFdcliFiT14Bk7UQkvlPZrlj78e5RnjsMJaVeiB0Ro8ktIbC4UQA2a6XMXYxk6+JNTYxHmKXsQFFR/GYMJ0qrwxac/DdMQSEa2xlChuieAIKAhz1j1nqkYKWYQsYbBP5AHA7D1rACAO5HhqllKMK7flNQ5v/WHfApTttiE2K5z80WANTtkGeGSeA38R24OaAuQb8TTYYLXX7GeUxHRpmuzSFJtwZZLcsrzF0IiBojyNUghzTyDuXu6jDaE5KwzhTEx0luVIBD6eoaSGxVbhyl9lEoLhMmNIL7YQ4o46d1QBlZYkfwRmESOJR+RwgcWSIft0OQtDaOvdmNGVEMLXy+ZS7/kYUUf//997BhwwaYOXMmXHvttbBjxw7weDywd+9e/pm8vDz45ptvxvzugQMHoKSkBEpKSuDnP/vXC6qk4wJBIqQ4upLbeiLjWvhfSKEY94MShYIyNqK3HFQo8hcEx/xu9pIw7+LVUurYEcVHgzgNmSvQHDd9jSqsOU/JjqCtCa3+CDjlToFGDzH/Uyxf6qM9LJOOfp+IuKX2hqCW39qntPmJIndDtx95FMTFMB4ZxX8X+IvpyCj7d6gPi1t5n4gNSvZ3uttReyNdux6LhCByxY7InGehHhcIjFTT4zXcDhEwTYnoar4IOXoz2LknMKYbII6LulDQ6KF+n8muX02iokJtEroQOl+I41KWN8KFosgxPo9Cc1xawd0HHT+qQnH8+HGYM2cO/PnPf4b//u//hoyMDBgaGtJ0FAkJCX+XjuJcb6KU2Av2Oag0tc8JsBvUeM5WLlMbGu2eg4fhmFgFBfOCkLUsDGlrUcSTuRz5DtaBCLe5mvxIQb9ObsCuI3dxiMeUnMowI/F0sRu2YBdBd06jjGKzQpcf7fxalcCXuC7sniyDyAchTgWNOQTclZR6WXFLIb+6XUH2kFQXAhI7kZBKf9DLa0KiSetvQeyEGKIxR4dZVUrbCrLUs94/xHwEy31u1jeoDXo0NoaqQmE47AGzD9mzmSvCbCyjP+gFYwQxAUqCpwxSXrEKXw0CWXW3BpWw5oNejh+kwhA7IuQAe3G0om1QebYbcm4KMc5k60WA1mVq0xaKrdoQ4rJ8FHc5U/rY9MgUlPl9IOEbeYwYDnvYhdvsQxl53sIQxgwaWyFtLbJM7XMDirbjEgQw6bzOWCX/+ArF8uXLAQC7i/z8fDh9+jQUFRXB999/Dx999BHk5+ef93H+pkJBb6QgEamjAf/agzAKsr5Tk3AS2nHujB2OaLQVZG2W1ITfj+vGEUKavAayqsKczcFpT4KSTDLkmFEMEiqS/LzDt7gjCj4QRn+J/BuD+JjLwhr+h2UQ8QpH+iBiOGI9GuPBi9xyH+or9DtCbJfHK9vblYxTkqQbblbWswTqGu5EzUauiBmYc6oRMp/owov9Tg8XF/M9w3wnJWdx8mdgy719fg7+UUvLrQMRjZKUthaEKVAKO12EBHQbtihyfZaci5GKTGxMQeQisLP3PcNI1toYQRFg3gh+RkOKnWJZwSiu64WxMbmu23pwFCku87EvJjF9yQHdfM8wr3wNWwToepdHUQxH8HOP78QRs7TQw05fSU24zWPPTdVRMD8IV874ERWKv/zlL7BmzRrIy8uDzMxM6OzsBAAAv98PeXl5kJ+fD2+//fZ5H+eftVDwHB9UKN4lpV4OJVaj3KRIdV6xHKSrayC5AYtHQpuKBzF5DVq3RxWK2BFcwbLYaW9A8f3sw+eQ0I4njiPLDQltSnAyOYVL19RC6jr0aiQas8WNHJOcSgXcpPabSWAiYEd3WwBVjemDnBXCnAShtKTuI/6hAbA/1Q6zn9+IpsG3+/l5EuBHcQbM2BTApu2BQd6ocB7HQS8YbhajSZ/iWE2u1qRlIcBXLTl3JvWBc1I1OK9aDSkbZMQehPEwPQfygci5KQTS5DWIZRz2QPpjPWCUw1woHJct4c/WmdSHW6cOxfk7b2EIWb21iiu7ZVBxSNdwWdTvg3hv6H00bA1z5APzXrYqSWCxw3ijIRfv6KM8dxgmX/qTevSvOkh6/NdY848ZPS5fBkUOH2dpxHVHeMxQbz2cqf1g68G1VkmJl9dejsuWsNjLJCjVtt4IlBZ7wD4nAFlVYWSbtiqkKWNYxjuvmLljh7EDoSyP+E4cadLWKtTggvlBKJwdgEKXH+xzAuz0lbs4xHyO0mIPpK6TOeyY81HE6EHkIN0+P6TVoTOWbk+ANxDkumXYGtZYyFnuc0OuMKHRHfApd1pBGkutlyH/RoXvwViB4FiYhNiM6eM+JBTlLsbuiWjjJOrS3RrErZJXZutAUwDbdApIyloW5vHJ1oPvXfJGoSi9Ncj5n/rtIS6UyY3YFXCbf2kFONIH8bMSnz8dzpQ+xo8sgxGloPYoRMDo31Ef+QuCHMZNYyMdxCwl1um5HsdlbL2ICVeU4PVXYBSa428sEuMdpOOI60bEO7pQqI1ruFCsl1kmThhENMDqyHIr0u4DPsXhSnA30mtkNOiZhx4NJDfXMA6jZ38B4nE+ikgKM2wJ80hD7XHsMOaC5C1EajXd8c13j7Ds3RhROBuUvB3XHeFMEMIYDFvCvPo1bEHaOQHN5oCMz0msHymMyPbAIJPK4rpF7MG16zXScmaDqroh7jJUojDH5csQpxLPOa0OwcjM5dip0CqWzHWJ6l2WN6I9dyZUQmq9iKiMPrcurYDyCZWQvkbpKOjuH9d94SJC0veoD2J/GraEEfc4z2NclIVi0rQYtDlfK/8ga/2yvBG2R6cjOnn873FIUzdwZqTaaehshYI6nCIJT2Qy1JUsHRoHr/JsN4OB5rtHwOxT1mnl2W5mnGYvDfNmgwoFsQXJFJYVlTTXE1GJ0qkEJZyO2BEsBGl1IoZAYACGwx5eqxJmQEd57rCSnWntBEfmEG9FmJuhLhQTq5CrsSOkFIrtIdZaUKFIW4u+pgXz0FSIZe4keRdjE0UmkJelxS38RCLCb9Sv0PPHKxScX7ofA5yk2M2QtzDE5w4Bk6n1Moc6jXeQP6tk6QCXsVV5T85iuT/mfLp2Pf8OH+Z2KClFyrxa4fxToVB9/Vwfw3cVtWfm+Q5yB7L14OyWXiNDebYb/QX/L3UX6oMKRWmhB/Uiti6QptQrJ4StizUiqetkrYJwxibcUIhQXvM9w1wkLG4cUyRrJ7hMbZC+RlYKxe4g08otQxG2kVOThgxbBTVbJJ6TI5P6oB1/jBfHEGZL7kMsgN7P9BrkFNBn45hYhReHqQ0kSwdkLg/zz6XX4OhiCir8FvbUIEOcW0LMrTAdGQVzAFWRzrQBSKsVvhm3BcB4F65CydyWlJ3WfmHAE8S/F+OVeZSgQqTfHoKU9Vgo0tcII10RpWgZwm7I2ic4KLUKRb9wNqqSkxsVURiZ10SvlFPWo3OaWsjlvGo1vi/ic+Nz5dIKLAYicd5lahvjgema2QSOLDdmfFg6znneuaY3wjU/1//Drs//XxUKor9mLw1fcGbC36tQEOhouHkcHsV4I9GESkirE2E/5P1wl0qYJNScas4DjR5qQxXrQESJWhSjhcUdYe+H2HvdLAuPPtH123DlaHtgUMkBFVJrW0+EdQXllyzWGB+7dM0Q1yXAtrZx8k2mNyrJ3oIvodszdkRSr0k5IOlWFTdDFAr9QS+H8xJIaLg5zGNZQhs6V/EIJzY4ic1ImIrrijCnI28hAr3MyyAavHDIKpyNK0lacdp6BNszEh6XdRnXrQgXyy9ZDI5ZgzhGCK4LreAdE6u42GpCisU5SqPqubQe6iNjlQwTYy/GAKCrjGhqm+0eYyJ6vkIR34mbiNJiD+TfGITkjSJh6yyFwpE5BPk3BiH/xiA4U/vHfj99kL9/tswFcgBXqwQJ1U7ZIEPBvOBZX4cztR8yVslM3KJRIMaLmSap68QdXvA0zH6Z9/YUkqzWecSOyJyJSus7jXBpVBQkYVFP4BvFDiQ83M+u2LpdKJ0uzx3GDcvEKrBfH4CM1TIXY/ucAJTnDkNqPXY/6na70IVOTsQ3ifHILOoix2taBceOyDwukBcGMUMp+Nd4l4fNZNQXKAG9+TcGFctCFQCq2x2ElA3YUSS2RljunrJBhryFIf6s+BDBQ8kbMZqStCK0dqbvZ6ySsWh2Rfj9LCn18usvyx/hwmL2I87hTO1HnkXaAJ7j4nCm9ivg9+XL0H+zG1+TS9f8U6EY70u99XBOqsY146RqDeFkvINctV0zm8CZNgCJrUiBTlsrn7VQsMdhr1h3TarW3PHVSWHjgVOOy5eB9Is6nmOZW9GqHCQJH+/v2+dq7dYSW5HindiCNF779cg/IF0IXVg0XmnYnMITwXCzwsyM8cg8bnBi2qjM/gzqnBTLUISt6+IeHATd7iDEdyDA6ZxUDa5pDaxxoN9Jq5PBedVqmLVS5swU56RqXCm3Rtivgujk+jt8HNasu93PmpT4Tnyv6K5NVv0sdRcHmdLS+xR9V1c/NxrPDFvDiCEIolR0kFJCm/JZqR8zxiPzZ6O/JaQ8tnj8gvlBKL+0ApI2KV6e9rkBfv1FDh9zUOig0KJzjcKOy5cxnd7WqzBxfyoUUV/qQpHciO1zYktU+zveGzyxCqRf1HHWo/Oq1XySn+13cheHOCGdiC1qAPV8haK43AfJjeJ3cofB1oPzNf9tcZztxLDPDbB6M20tXnQ5lYKQ1YK7eGtfhDUHxIw0+/Ci1LhPk/GuIBjRLG3tj7ALOY8p/SJdTKD9NO+TEYv57hHUaNwSgsQWfC4JbcIE+GaRbTEg/BVaItzJJLRH+OcJG2HWo9BQkCcnibAMW4T/6DW1YOsVz0GoQ9XKVeORUYjxyJBWhxe92siWDlrZUsdFUnrLYIRXs0R1t/UIfxJjK39OtK7kQiE+GyLbqYlnBfNxrHRetRr5JiJhnV4/cUCYoNeLn2dy4/n9KJIbxNh4MxbGuO6zywx+KhSXVkDyxgij/1nLwkhbPQfeQCu4tDoZxTbnU+BluyF7CZqYJLZgupS6fXbMGoTcihDEd6JHoSPLrTkyV4QhvgMBTCoq9jkBpIVHO21NXsO/p25BM1bLkFuhULzJM5Mp3qKtJSfxrCq0w6OcDho9NHmmolDQFsLsw9Egd3EI39MAXjQkKKMtBaVys/HuPj+DnNFUc7NPGYdIoRnjUVp4csMi1ifjDttDiqeF6KSSNyJ/IWZUMddlefp+4duxExPAyLAl5ybkh+TcFOJxKMaDryVvUYiT3TnsWaSB0Qo1rQ65J86rVoM0pR5KSrycjB47IrJBhDu4tV8ZL2JH8EZE2wgpoYcLvlmES1NRz1iNP0srUCo6ZxN90Q0nrivC7y3ZDZQVjOL5kzmk8bMoLfbAv079ETEz/15f6o4iY7XMIB2llGtWiuMVigblDuNM6jt3oRAXcEKbCMId5/vRDlcXcpDrlubvJPQozE3B/hvv7+UtCineBjtDCo9ijTym+Dgyh/gx2ftBVSgIzLS4IwzqZi8NjwuQ8p1UuGqR5FqjHlUDrGKjoPFt2KbNGokdkTUAKXUp6s6GAdhzHGpfDgIuZ1VjAZSuqdU4nqXVyVA+oRKzYqOMbk0BpbNSG9k6Zg0qfBSVG7nudr+Gmm/rEf4ldKFGEa4MW7GQGu/yQGKrojh1zdgEcV0RDg4629qfAoCMcljpjAJaAPWnpDDxpS4U5CUpJfRAVlX4vIWi/NIKcBlaoKTUC7YeXEPmVoTOiW/8LYWiYH4QXOZ2cJnbobgcP+TSYo8WgJpQCbmLQ+z+XVzuw6Dks4wj0tQN4ExBynDGauFNYO0cc3KoC0WpfRQkSwc4U/thVrVyVyMLPqOMgFpCu6AO7wixvwRlYdCqlGzuTILwRfZ9lvvc7EAVe68bWaajYh15EBO1eNQQ2g52gaJkrp0htgmM8So8B41KlVa6ouOgsYisCctzhyGxFccp3a4gMkg3KOOGOYAyf4qLpCIrxW6G1HXK+jO+A3GJ9DV4A+KxbT+Cp8SKJet9UwjZpS5jK4sPM1bJjNuQv6bFjVyR2BEEMDNWYag2icN0tyG7l8BSl7GVP8+CeUFOldNvC3MxJQA7pzKMAVZRN5mLtlA4J1WDa8YmzZhRWujBC+cCNiFS7GZIq8N5lnJIz1cospeElb22sRVBUQLmWgQwWidrjHrtcwRNfEIlSLYuSKuTx6x0icKd0I6/H50kxj83sQoNbGY2gWTthLgu9M8gvsJ4BdF+fQAsQwh4ESGrcHZAuXuKLQqzGIlkJYfZf4Gdp0VbTgQnAhSNYWH5f3SYszos97kxoKdfccyKvdetmNsc8OFosx3HFE7VEhuHtDqZNy00ZlGwEzmCERMzdgRTuNJq0dW6rGBUM7qoGabstr1XCWumccVlaoOU9TK7gJuCMocwGeUw08PJRId4J5QGr9+O1oOu6Y1QfmkFlOWN8IVMJLTx1qbqg6j00S5t0R0FBUFF/759zvg3s4u2UPx/7X1pdFTXlW6AB4HghoYAD2iQVBpLVZpnqUpDjbcAGxuDkJCEhBCS0GAhgcbSiMaabhkbO3bsjvEYOn6djuO0Yxy7SeLul07SSXtIHI/pOPzIWr28Os7qtTptL7fZ78e+e997a5IESMbPddY6y6ZKdc8dv3vO3t/+PmvhWQ40KR+ORRGnVlVhn0/xWAIKEo0habPUQUnNSgKKkoNesK6q4vUw5c7TTiuCUyHK1Qko8ut8kW0FkvqQkyBJrXHwTPQFgYt9QyPODKTKy6RJfJCsq6oYKJSd1v18Iw9L0viSpkPi05NYPXpB5iyQrR5NfzkGIsnEUZpQ6/SzBQGlMlkbQhK6JU5D7HkvZHQgpyCjA5dL9lsa+AHROiXth1VVkN7l5yVN9glcyuU0SaJAtCy5W81pIJBQLV0U/AhKtyrl/Eh1K+c5J5sAMa2b5POkJVbirEQIW1/PQKFMUSdNicwnUS6Hsk5KmbdVVWC/pQEy7pL3WQkU1pWVYF9Xp1o+R4EiTNv41QR291oM4epau7C5maPiidMiT8O1Tpzq2lZXI5dAombnHpOBoqAWufiqN37hWTBXzOD0VDsIpXvdYK6Y4XiJLW+ctRNV+yGpcBcd9mIR0l43lO5zQ+led1BQ1n5LA9+kJECTMobchrTTspcF+YOQahZNz5Vy9iRmwxoSj8+C7pkx5i1Q/INYm6QxmTiNY2pEH/uqMi36Ycnw90m58CvuyRksMHPLM4oEF/JMKqxzYK6YQXu9u9ByQN8rH1/KCM74yKS3dJ8b0rtkHdS0HgwoJ036WWmKlceJ5i6J7BLHQteH5zr28Vm2PmSg+LqHvT5jHvTwbIr8YvOP+rBuZU5Wqop9HNmm8W7kZ+QfxRkBc3AU9SMkn2cumwlKnRPhKrNdBHPZDGS3iFGgCNXW705kAdlrBgoJmckLZD6gID0Jfa+f1a/1vX6w5U8E/X1+nY+XHyrNzFVVYF9fD3kNaEBDFgK6fj84Yrp5GVVYjdoRwqYm3kfrykoGilBjBh6TsKWFNTI4T39O/QZVFp/RA0K6mIEKVvEXp5H5KM0aUr8zzje+dlgW9dX4MeAXf3Gasx5KEZnEp1FzgXxBSOOCKkRJFo9qPWj/Svci/4BiDapgJylRnfOpancMd0jFcQ+5IaMT04f6M35VAZsyyBoYQC2u9IKwpQViHnKzWlfGsyNojXiflyUMYx5xQemLvWC93A26Z8YQDM/jsobOfcwDHtmL5GE3Sxzqe9H+YTH3rm11NQskWVccYgGdcEBhW139xSwz3/y/doDJNHtdQCFoByG9C8lOuY3hCVf0AApbW0HY0oLGK5K5j7C5OeTv7BsaQdANBYnr2vInOIioHcYMAwU4SbnIuuIQZLfg36R14/5ldEqiJPMAhWP3Kci4C3+TfsrPTmSkcZA8IWWHZnHZJKQMsHiKdlh252KKtKIWhLw5KS6Q8K1Jdl7X+H1QtscNjrgeFK2RpP8pjkFO57nfHwLr5W4oktzJuahMAh+q1kz41iQSuh5yM1Doe/GYyO2MZj4keUfxAmXBneEOBDHy6CBH+eQJucqVeCGhgIKCsQRy+u+OQv7zg1BwaYBnFYnTSKvPec4J1svduC/nZYMgOvcEmHQ+aQYkbG6elygY8v6VSIYLAYqyPe7Pl3DNjWqbvrQVhOR+FBbZ1gb29fUY+Z9HcJQfet0QmEunoegw6mGm9eDDd73aFMKWFuQ/FE9C6T43JM6glZ49fQQZmlIwM3EG19G2NTVgzxyBosNeXk5YVxyCnOMimxLTTMZkngWLYQqKDnsxqr26GkVYska5W0rwe+X6NWVE5lvEuzGbkTCHehUWw5TqPPDbWWnW89dunnkkzmARV8qobPcX+wQWTxXUYAl20iQG5NJ6MBWre2YMbD88BRX/cBrKXjoDlT9pgX0vd0LxC/2Q85yT9SkS/maKg6CkMkUxi6Qpkd3bEuakatZJnBnE3ueFpP9zlglgpbe6+XxknxCZ6KURfZzxoKAoPdCUQUia9DMLNKtVnl2RiI7umTH2Hcl/fhBnFhKTVP/dUSh76QxK6EkgQ0uXosNeyG4RmV6e4BLZRFh5/bhnjgS9gGxra9H1nL5fWwvC5mawGKZU+pj5dT78GwWP4nOnwn2jWiST4nmnbRLhilyWCo/Ib5JyIVhcd1FTQik4RTdwzCNYtajvVTPt0rv8DBShtlNUJYnrKgu4xkILuCqn4cSjMN4mMwvZAethmaGp5EbQ9FXJOKSuDOwlzElBunV1YC7FWUjMBRcDhdJ8yHAHUpc1PhFynnNC7U+PQ9VPmqHyJy1w179WQ8cvj8DxnzdA/c8aofInLVD6Yi9U/MNpsF7uZm3N3O8PYQxEolhTCls77FcFImPv97ImZvzFaZUwDNWFsOan5NpFQVmluK6S20Ecl5KDXi5Eo6Bu5veGoeDSAOx7uRP2/PgusF7u5pRw7veHMNgrcRqImWldcQiElAHUo5gK5qUEdl1fCDc7SVxX60QgE7a3I9tTUrhS/j6QRxEFCgKKhF6ejmbchdqT9HYOBxTktGQxTGG5t3ZwYTOShQKFJJOfV4/pTtvqanAk9GL8YgCn0eGmnFRCTMuFlDE/Oz/l1/m4VJtiDeTqrQIKSRI+7pxMEiJNTGUZdFo3noe0Hkl3MW0YBO0g2NNHsA5EIhWRnSJpbsZ7RN5m8gQ+FPbsMdD3yhWP2r8bh30vd8LI67fD2Ov7Yez1/XD/m+Vw/5vlcO+bJrj3TRN437BD2y9q4cg/n4DbXu6A3O8PYcGZxFmIu8eHUgC7usC2uhqn8A/KD3jsfV5IfHoSEp+e5LhGyiiWhGd0+FmOj9K7bEwkKV6ljOALpugwgkLpPjfY8ifYVY4rViUeiNIE2fCDPih9sZcdxAgo6JokzooqYd3kCUkYV7rfSve6mS9CQeWSO718v9D9UGGdg9xG2dQ6dQhnIxmdftYNofs/FFBgmXnMsj2fNy1QCEl9ss28JHVeXBlaPYiAQikmcj3goOz29BHIbJeqIaVCJyVgCbohjFa34ZIkYip0UxNkNyNtPHVQMinWDrKBb9KUKAvTnEOiWdFhL1hXVoLJjDZ1VIhEQUEqH0/rwbJllTPZCH7uiD/DviRJk7LVYLxXpl3TuSYhX63Tj7TzDY0c0Ix7cgbMl3ug/meNIP7GCve/WQ4PvWWEi+/mwtPv5vB/H3+nEMZe3w+tv6iDA/90EvKfH8SA53mZeEXBZtvqapa2Yy1PiRjGhskPI+PUsaMDslpFNjqOedjNdoIxD7u5kpZme7accUgZRdCw5WFdBgVI4z0SBf0xrEfRXJyGrL93Qv7zg1D8Qj+kfgeVu/KfH0SuhbSsifkGckfinsJsTvKEWvFMSBuGzHaMg1CpOd0vwtZWjEttb1dl0cgrhD1eJQMijR+zLJltSN4KdMP7QmY9bgRQMMnqRgrWrKxEG7g1NdxV26fvV1dHBAne19XVYDLPMlDY8ieQ6PPYnEzFloq2BL1T3uaqKhA2NanYooLeCQ7NaUgdlAR/A3L18W55LZ80ieDExVlSkDH28VlmNHI2REoTU91M7HmMGZgv90DHL4/A1K/2wVPv5MMP/i0F/vn9WPjOexncn/1tGnz7vSyeVex7uRMynh1BBucjLjBXzKiWZ7bV1VxIxSxNMimW9ono1JyBueBiBilzIx6U+SK8LFxZyfcGeazGPIi6mw7NadQSGZal9VO/Mw4Zz45A7veHeNlkvdwNOc85Vf4ohh/0Qe73h1BU5xsuNbtXuh+UvBtzxQzY1tZCZruosofk6+QVOfiqpMdr/JiB4fsr4F6KAsUKDCIa7vBA+imcxsV71U7Oqr6qCk1YQmhLLHV37Oxk05p5Zye3NIDhDg8KrdyHhVq6fr8sWkPy9PchkzEwxWZbXc0OVRWWOTTFleoJ6GYkwZjEWXRTK6j1MUckYU5kNazkv5Xcxb/uQe7GXjfrNJBJclYr/j72sTnQf3cUrJe7GSi+/V4W/PB3ifDz92Pgud/q4dvvZcHFd3Ph2+9lwdPv5oD4Gyu0/qIOhB91yQ/aIy6wGKfBvr4eTOZZEJL7OUZBgVVlJWhmmwiGA2giXXInznLizvlk/w4FsCa4RSi3zfG5qbBiL7fNgb7Xz5kbXZ+ft5l/VAFOEt087im0Iyi4NADFL/RDwaUB9jshLobmmzMMUhofyvjReEreDO2LQ3Ma71GjfO0y20U+1+R9QsxMLqw754NasP9vAAAgAElEQVSiKh/qWIS4n6JAoeilt7o5b57W7b8xMwaFYexCZgERH/7MEdD1+8NStFXgt60NH1Ypc0DmuEpjYHqTpA75+UGKtM9KoLCvq+OCsLh7fKhvqTmtYhESKYp8OOLuxnQesVnJZEgZWEz59gTkfn8IbD88BW2/qIWpX+2DZ3+bBi//Lh5+/n4MPP/bVPj2e1nwjbdL4OK7uXDx3VzwvmGH4z9vAOvlbii4NICp0W+4MH60tRV0/RKPYn09l9QHBgCN+z18zJRGjrsbj4HIZEpxXeKmkFUBBxIH5Dc3bTOrFZddsU/M8oMfd49U/HbBBfrvjkLm94bxPBETdFgx85KWL7oBP5tpa50Sk3cB901BjU/WEZH8S8lFTtcvC/HEncOqYZXBcRQoIgOFxofMtetlbpbtcUNmO25LqU50Ld22thaEbW0Lk91bVQWOnZ0oePPMGGT9PdKHlbZ3SZNqrcasVgxm0lsos11UqXhHAgoKiFFshQqNmG0pKXqnd/nZakAJFGQSRKzNA/90koOXz/1WDy//Lh5++f5ueOX3u+Dl38XDxXdz4al38uGBt8rgxL8c5bSp+XIPJD49CcnjfrBnjoBjRweWuY8in4TiBRpR3VPG/HzM+jPyrINA1HCHLLob75YIbwVng4CCRIodu7q4ZkjY0oJxG8mZi9TDqYaFfVMl+wTij8Q84uKsRGa7iDGHbW3giOuRKf8LBAq6xiQNYM8cQUPkbW34X+0gpA5JsTfpPCiX31GgUPbCs5DXIKpKcIPe3isrQUjqm1c+jLpS/ITWl474MyDondilN6yQMoD/1g2pctiL6cLmZpX8mbV4EvS9sqpU8t+exQyG5G7FRKqzOF1OHcSsRV6D7Iie1yCCoHdyEV3qIN6g9uwxVawh5iE313pkdPhZ0yL3mChTkUUf5DWIUC64QEgbZlFZMi6OfUwqWLrXB6Uv9sLAq3fCvW+a4Ol3c+CHv0uEV36/C379+53wf3+nYaB46C0jtP2illOl1svdkPAtFPgR0oZB2N7Oy5vks3J9C5n4hiozJ/BKmkKlK/uGRjCXTkO8G4OXFEw2mWfBnjUKqYN+DhKXCy5kd9JMVLpf7OkjYMsbh+wT+BYn+nXMQ24ulqPAqebiNDJXn5iFuHM+yGpF2ULrClx+2rPHQH9GfW0i3RcVljm+HgW1kohPQIW0/ZYGKKryyU7oTsyM3PRAYTQa4atf/SqMj4+rPvd4PFBcXAwGgwFee+01AEB7wZ6eHjAajWCxWODKlSsRtx3JAMi+ro5TeKGAIpBHsWigWFkJ2Sfki2EtngwqM18sJZd78aS6IEnys+ACrL92y3RrKVdPRrjKNFwoY2QhuZ+Bgj5TPmhKoAhlhFt02BvEo1B2YjkKm5qgdC+CWf3PGmH213vg/jfL4fnfpsLrv/8rePPKDvjn92PhqXfy4eK7ufD4O4XgekOAodcOwF3/Wg3myz3o4UFAsbUVdH0BAVSFDsNCgYJS10qKt1KPIhSPwrpCLtijVGnyWVkrhMRolOnmuHtQhJiB4m51wZ6S46K8NtczU1V25bX5XADFlStX4MKFCyqgePvtt6G0tBQ+/fRTePPNN8FoNAIAwAsvvAA1NTVB/x+u3bIzEZWBqnxcOh0IFMnj+KbLbsG/K6qSGZIZncgHoM/5+xCBIEdcDzLiMkfAZJqFwmofbzvejXwNAoq8BhH/dp43BBUtBcU8CCi+joVGCd+axKClNO2n3D9VsDJQ3IP7lNHhB3vWKGR0+IOAIvcYBvvsWaM4lR32s/sX8RESXGho7NjRgcIu+9yQX+eDrJNSCs+Lb+JywcXnhHpWK7IlC2px26nfGYfbXu6AE/9yFKZ+tQ8ef6cQfvBvKfD8b1Ph6Xdz4NxvLMyp8L5hh45fHoHb/7GNDYvj3ZjmI7Pn/KPIedH1y9oLJQe9PPOy5U/I+yMJ05JvaP5RH7MXc4/J9wMxWJMn/Oy8ljiDjMrCI2gfQECRdRKFcm0542DLn2DadMyjcziDle6H/KM+BMpvuNioKeukyGQ+x+5TvJ8EGsp9KqryQfEhr0oqgVzIAu8Xx+5T/BsyUPrcAQUABAHFgw8+qHIu1+l08NFHH8Hg4CA8/fTTAICzi8TEyCyytUkJkDSFU+LAJYRtbS0rO2v8SG7KuAu7pWSKgYJy0kpkD8vMXFkJwuZmrstQPqyUakzrQeARtrRgV/g3BPaSgyjNJmxr4/oRsqbTiD5WT2IzXykvT+pQ9P9UsUlAQYSrglrMXFClJXUqYy/b4+YycpbGl4BFyVkgbQYl/yBlDFPPwrY2OXi4vR0Kan28fo49j2xJ8+UeOPBPJ6H31UNw7jcWeOqdfLjwdhHc/2Y5TP1qH7jeEMD1hgBnf3Ur1P+sESnQT8zyPikJXuWCC812TqpTicQ14E7nf0sLZHT6OX0ayFykc0L1HwluETTfRJd08n61GKcZKApq5RmosKUFUgdxFqW5OM1gq/H7sNpzSwsGgyWvlKQpScdza6uqAFGpPhaKmUnCzHn1aIwsbG9X6WIKSX2cDaPZnq3gLB9bUZXv8wkUMzMz8PDDD/O/S0pK4A9/+AM0NzfDiy++yJ9rNJqI212blICFXGtrQ2Y1bGtq2BDYno68eNvaWswGSEBBwqRk7hsJKISNxyG9K0DVWYpsK5ceqYN+NvAhObZQ27OtrgbH7lMojtsnKWpvbeXqUq3Tz7UPaVJEnV2u7/GxJgTl+gOBwrjfg/yAbW187La1tRxEDQUUSZNq24JAm8O4p2awkxqWGwPFgnYQa0i+Jus8xH4NSVBp3x2F4hf64fZ/bIMT/3IUBl69E06/Ugnd/3oYOn55BFp/UQfHfnYMhB91QemLvZDznFN1nBbDFDh2dYGuPzRQkEKVslNAT9ensEYMeCFktYpgX1+PweVNTZB+Cqnusffi/ZDZLuKsUMoeBQHF9naMy0hZj5hHkOmpHcaaIWHjcdD3KgyHJTalrk8tAD0fUAhpw6Drk5muuj6/OqC+shJsa2ux2lgCCuuqqqDr/bkDisAZhV6vDzmjSEpKCtrWo48+CiaTCUwmE6zeuo1rFMJ1x64uKNvjVnEWHAm9UGGZQ4l8aemhG/Az/z4sUEjCNXTBiw950exXqpi0ramBCsscf1a2x81GuOH2T9jezsCTOohmMuaKGTBXzKC2pbTOTfvuKGQ8O4IPkOT8RVH1uCeRiRh3Ti7Ksq5Axl+FdS5s+TwDBYnMPIh6Fbo+Rf3JykpWDCPnLjIdSh3Ec1dhnUPqs1SyTqDFfhlSfUny356FnOecUPpiL5gv94D1cjcIP+qCPT++C4QfdUHRC/1yelFiMSbOYhm1yTQLZQ4X6kyYZyGtW5Kd88j08pgHcakW84CHlwHKACibM+9xc2WtyTSLpf2rq8FkmgXjbR4oqkI5fXPZjEobwlw2o6rYtd/SgOK8PbhkyTopsiaELX8CbGtrocKqvh/4flEILVlKpliyQFkDQkDh2NkJZXvcLJqkdap1PHl/ssfAZJqNWIX6uQKKt956C8rLy+Hq1avwzjvvgMFgAACAS5cuwdGjRwEA4KWXXoIjR45E3O5XYhOx8GghAR7JKNa2upqVnVIH5WKozHZZbi3SjCKtR0Z2IsWo1oz074VwLVZWskOWcjpMgcZ4t1wVSXUEMY/OcYAz7skZTpPGPOLCgJluaMGckbI9mEYmqTt6IyaPS6KwCh6GLX+CA3RxTyFQFB7xheRRcGD0AQ+rapHwMQngxF+chsSnsYw883vDkPX3TtA9M4Yam5IxcMxDbmZOZnTiPikVrhKnMS2Z8K1J0P7dOL/VlZYEpCZFwUw6dqJDpw6q6dQRr6H0GfNSpO/NFTMyvZ4kAArORr4HpPvRuqoKzBUzXO5OdHUlUNBvMjr8IQV/F9NvWqCor68HnU4HGo0GLBYLf+5yuaCkpAQMBgO88sorAICziK6uLjAajWA2m+H999+PuO3FAIXhDo9K7ETXjwVDdCHy62TX7rAxilVV4NjRwUCT0YHT16xWKXi5rg7yGkT+bL7Uq3E/OpTFe0XmL9izRsFimGKgSJzBbQvaQRD0Tkg77WeTHxa+JX2Dc1jUVXzIuyCwKD6EZePEWow9L5sMZ50UVRkc4lqQeXLyOKo6hSRcSaK7TKWWHnYGC9LK/IaL/TNIMYsUpmKfwNmS5pszXCil7ASiGgUtO2lK5OMhIWDSpwwFFJntIuud8stAO8jXr/CIXIdjW10NBTU+prund2Gsx7amJiRQpHdJQe0wHhsm0yyPQ0K8FAsiM+hAoMirF/ke/f8OKJay/cX2xOC3QZief9THQiQU0VZKi5Xb5iCvQYS8BvTkiLQte/oI5B7Dbeh78YYwl6GEHS1NtE5Z8VpI7g/pG5Jf51OZ9iTMiUiakeT6E2fwART0TtxGygAHYCmtScHF2Pu8QdWj850TWn5RxD/eg+Pp+v18fLRvJLxLcQmtUxJcSRmAtG5Zul8j4ltRqUpFbt78gJOILgn1KrrWiXGd2PtQ+Ur3zBiCh2SyQwVtGhGXObGPz2Kw8H4v5DQh6zH2fgTA5LN+vqaFR3wqXkvpPjeXwauureQLmzKG19aePYYvFN0Qq5rF3SOzIQW9E0zmWcirF8GePQbmshnQOjG1WlTlC7vssximsBJ0UCZc5TXIlhPxbrwWFsMUKrGvOMRZqqQpycw5fQRV18NI+keBQmqReBSLBYpF95WVkN0scrBS6RQWqquk8BRAoQpe9WPgUenrEamr+AOKt+5CgUL1gEiy/zRTongLzygk/kCg5oHW6WcQYT0KyWskwSXrmZJWCAWANX5ZG4JSwVonBunInDfei2zUuCdlPQolUCiXOYnTGHhkpS5n5EBy2PMgAUW8R6Zd0ywrcEylSbF1VRVktcrXIKxMoXKsWxpQ0SwEULCX6r2YliagSB73y8Hru/GeXqhJcRQoFtCFlAGosMyxrgMBhWP3KSg56A3phTHvNnVDLLnm0JzGAFb+BBcj0RTUVnA2qNzXugJFcuk3tvwJzM2vrQ0LFKlDfg6WElCQzoJybRsJKMwVM1By0AslB70Yz6B92dwMtvwJyG4Rg4AicRZnO6T8pB32s/IWLUtIhStlFM9thXUOxYTzxtmu0ZY3DlmtsosWieZyd0vMxZWVYE8fwaWRpHROLnBEako+i8sJc8UMygUMSIrXElAkzqDGRPEhr4pcNe813dICtvwJsBinoXSfm+8XAgpS1Uqa9HOm7FqBwrqqCuxZo1xeIKQMgK0AxXT5Og/jdSdVcfb8IC+T8ShQzNs2r9oRdg0Y8ibY1gYZd6FIS0anlHrSDkJat1+lsbjgt49kjCxsPK5KQdmzxyCtG8fJqw/h2rW6mn8XipRF0/m0bj/HCXR9CDqOHR3giD8Dad0yG1OpKal1Sp4gm5pC1pIondRJ80B5HHn1MlCYS6chrUcmlaWM4HRcfwaXGtph3EcKwNI+Z50Uw9LX8+vwbcx+pN3ygx97LypYkQcrXZtQPXUQiUTCxuNQWO3Da7i9ncEt3qPWdqDjEzY1od5pmHMf7n4hgeKUseB9IaX0vAaRl562/AkEvA2NPPZiiwlta2qY/Ut8Ha6YlYr2ojOKBbT1uxOZO7+gvrISdTWlTpFnivAvCihWVkJevcju1qo3iLRN+/r6kEBmTx/h3+U0BVsKKn/v2NUFuj6kjQfuc1EVrlnpLa+ceejP+EPGWgKBwramBrJb5ONIHZSXHrbV1SBsalLxTcwVM7hv0izBvqERslpFyGnCqT+f2zDnLadJ5GVEdovIdgJUAk5Se8KWFvV5VHRh43HIbMP1PTmL0zGTTJzSTZycvpQu6KmDGIeJuDQJuF/YTDpgfwiQ7evqQEgbZqCwb2iEjA5p7J5gUuCCXkbr6pBnIR0PnRth43Ekk3VEgWLetnFLApQLLrCUTEGFBXUEqNNad7EXZjHdXDEDxv0edIWKP8NpREvJFDpy0VureBLMFTO8b0p9TpX36MpKDp7xW21LC+j6cGZCx2kyz4KlZArKBRePT50cssnCMHCfLcZp/lshZQD1KPr9XDyWOIP1DGV73Fh7sKoKKiwY6E1wYYCOjs9cNgPlggvl5s+oXcjC9dxjsg2evtfPHALW8fQGx48E7SCP6YjrYcJVehceZygTnMJqX9C5Me73QHYzLmPyj/q4+jXUfgq6IXnMEA+4cp8sJVNIuFtfD8K2NjDu94DJPAsm0yzo+nGGZbzNE6R/udDu2NXF+19hnVNlYkgpjfbDljce8aX3hQSKTV/aCtbiSTn4pPCtSHAjNXrRrmHX0e0bGoOKwhy7T0HqoEJS/h6fStcwVOFRIE1YaU2o8ckiLTyLoWNcVQU5TSiKws5n4Y5f+ty+vh6rTt0YeIw9j8Y9sff6VGlWKl9WPoyU6VAqXFkLz6rHDRi7oEZxjaRgp1KhKd4rclCXfkPAmjqkYGa24sNuXVkJxZVe1X6lDvplz9bAZV+IorBQXRlorrCEKI6r8gWPqcg+lNzp5fOlFNdVXa8A1bPF3m+2NTVB/ibkThbuun/hgcJcOo0l3ikDkNWKoEE1AjlNIqeYlqqbK2Ygu1mtP6kEirhzPja8ibsbH6zk8YUDBcnSk/gJT29vaYD8oz7IacLpf9IUdvo3deXNLmxtRVHWu3DaTilVh+Y06nhIZKXkCZyeC1tawL6uDhya05DR4WeTYhKNTR6X94/SitknpLGPiyr7AzJW1g1gjMGhOY2R/L/GFG/iLIJHdousoVF4RDJCSurjNLNjVxfY8sYhp0lUqZAXVaEHa1GVfE6EtOEgoMhsEzHbEOYBzWwX+TiDHvQVskJ6vEfyB3Wr7zFhaysIeifoe9VA4djRATnHcb/yj/owPqQbwvO/iKWJreAsl7onj8vXJGEOU9E5TahWFjjD+0IDBaXgbGtqwBHXAznHRdXNrHUuTE1qsd2xsxMccT3giOuBwiNIac5ukR9OqjBMGcU3dexjcxhTkByviTEo6IYQVOLPQEGtTxV3ETYeh7wG5AcobwatE8vABb0TzWykB1Yjym93ZacUHMm7pw76uRI0eUIG05RRP0vYJ7hFloSn/clpEtlvlUCRlgHxXnlWR2vqlDFcXijBwra2FgpqfGC8zQOOuB7QOiXug09UpV9JAqBsjxsKq4MNpB1xPUGASPRopR6DtXgSWbC7T0G54GKgiERMS+/yM1MyFFCUCy40opaUqvS9/iA/GAJxZWrcEdfDMw19L177MocLUsYkOvk8LzTb6mpwxHSD4YAHUoeQ8Jd+Sr43KICb1o3p4ShQQDBQOGK61QVbin7DgULSo2BJeqdkQrzxOE/7co+JzN0g/QR6UHm5JNnNJU5La/NQa/yVlWAyzYZMl2qdftkm8Jx6GRAKKMirlb+TtCdp6UEMSSpiCgQK1qNYXw/mMomRGNMNQlIfBwoJKCgrkzKGM4wggeGc8aDljCrOoNQKCTc1D1jmWIzTQdvkgr1u+ZypRGnCAAXTpUMsPUKNHfZvAsBNuX+pQ1KgWLp+Wqc/sir7tjZeiuoGMAsm6IaCzl3pPnd06UFt05e2gmNHBwcOlaQeXb/sqmUpmQrJjFT2CsscvuX2e1DJemUl/z7oYiX1gfE2D5jLZnD7UrcVnFWnSdNHwFw6DeWCi521yEVMGVchE9/UIUk1vHgyePay+5RqLIthCqeefXhTlAsu7sRhUHYSRVFmPaiTC5nW6Wd2JR0bBemUQMFis7Y5sJRMcXrVUjIFJvMsfm6YgoIaJGCljEgO6isrWX/BeJsHcppwdpQwJzKpqaDGJ++zIqgbBJzmWTT4rfNByUEvb7PcNsdgQSZA1yIqRC8Bc+k0LglWVYHhgIep07aCs2C4w4M0bkV2SdjWJu+L4ApKUQcChdaJS7/EaZFTn4Y7PGFfbPZ1dWAtnoSCWh+DuLC5GYOZiusdTvrxCwsUPCVbWwtCcr88rTvjD5IJi9Qz21FbImXEj2tjKbKee0wMSp/SjbiYNSW5bjt2doItbxwrASf9vDSiru+VfDkWsE3jfg9ktoXnLITqBTXo/RHY6S2V4EbQEjY3c/pTmQpUZmzCOWbzNcmfAP0ZPy/JhI3HwXDAwzMZEtshkxxaTnEwLgAcAtOjyeOyRAClR8scLrCurMSlmkcBFOvrWUcz7bTaq9a2piYo1Zlf5+P4kW11NTrZT+CUXtjUhPR7iUVZUOPjfaZaD5r+B14bh+a0KnVLvBSqDE2cxn2cz+2OHN0Xap9J9/AXHigKanyqoNa1AEXcOSS1FB/yMlDoBqQLnjly3UChdfpZTFXYeByJP8n9vFzSDeANvNAH376uTlXotKDfSA9aYCfdDrqBiQhFNy6Ri5RLu3mBYk0NGhidwFkFu5MN+1UGQhbDFAgpA6zjQWQ45bZIgEZJuNI6ZZ0HIlyRNkl2i8jHQjO0cOSnCsscb5eKDJVAYS6bgbTTfla+jnkIs0K0/0mTMhluPqAQdEO4vLsPvV8dMd3yddjczGSw+YSXbWtrmZg23zV3xPVA+imsW/nCA4XJPMvU5JKDXrS2W8Sbtszh4oAYBb/KBRfk1UsZhpzx6wIKe/YY7xvrRST3oxu79MY1HPCoHnwhqY/p3eayGSjdi0uMBdGDA7qwtRVseePBilsSXZrk2KiAKnXIz4VYSmWo3EaRj6PcNsf7R8xW4hcoA49UNKWkapMQbdw9aKbr2NEhA2YAj8KePgJlDpcqo6TsuY0iWgAqNDSymxEokiZlhSp71ijvLzmBWVdgZTEFUbNPiGDLn2DFK9p3FviRKl+pcIuc3SnrEQoohO3tSGW/pYG9R6k+Z74l8Y3ojoRevIcLzkaBYqm6kDKAJzkvACgGr41pp+zz5eoLq+Xv4+72sVO3dti/6LFIRSlQwNW2tlblFCbonWyEmzgjcuERfa80TArSZVxZCbmNuIwIBCRHTDekDkoVr4pCsLhz8wOFUiskVFeCuBIoqPS9wjoXFKNg3seqKig84gvSFuWiMKlyVaUEdg6XOyljUlpXsjEUUgZUy18CCkvJFOuXUIwiYU6MAsVytRsBFI74M1yKXHzIqzLPKbnTy4pFyrJhYVMTvu0DmJ/2dXVQWO3j7c1X/qssM9f1IRVX2NQEDs1pyGtQ60GQ6GvMAyhvF26bFEhTAoFSvj27ReT9y2zDZUWCS9JiTO7H4q3V1chZ0A1xKTOVy6vEXiWgoMwNGSJrfDgzU0oA2NbWgpDUB5ltIuteZLWKYE8fQXXsNTU4ZnI/OBJ6VTOSvHopI6Qbwv3QDqrALQgoVlXxgx37+CzyO6QUNcVEqLo19xie5+QJPzuOxXskPsqkX1U9SjKB9nTUB7EWT6KuxgXUv8hsF9FcWDpXjvgz6PalAAo6D1S6HlaNSrKcUHalKtaCulTVzKpbX1Sg2PzlXYuKQ4TqQlIfC4iQuxLdbFkn8U2SPIEcBV0fxhDCCebab2kAXZ9kzjIqmcgog00rK9FUZvcpcGhOc0Ugl75HKDNPcKHkm8aPuohBY6+vB8fuU1x3QWtX+/p6jjdQ1w34+dg0Pnyws1vCWC9G6La8ccg6iUHgmK97ZAGdexA0QokKld7qZuBVmhJF6qX73EHXprDax9dN0A2xqBDFH5In/GxzEPv4LIvzxN2tmJlIPI+UMYm0JOluaHw4G0kZ8XNVLo1VctALjl1dKH2YN466Gg9g9W7KKC7drCuwGtexqwscmtNQutctK6It8NyW7cHfZLYrhJAWa/+wshKKDnv59xbjNGz+8q5lez5vGqD4SkxiSDLMonso6TMJKBKnRRZG0Yi4dg8XxBM2Hud1Pa3tmU69AmccGZ0SMcqP2gILBQrVmvxYiIe6eJLX8PMBRdZJEWxrajjAqnX659UeDXcj2tbUQFYrLjfIwDjmYZTYC6k+ppCAWzBtmX4T4ZqRTCHxB1IH/bKDuWSUFHuvD3KOKzIZyf0sQRe4xFL2ctscjyWkDTMlP94rqorxKMZjXXGIpQY0PpHZposFCl2flNVYqLRipHMnpXe/EhNZ2f5GtpsHKBajmXktD0HBWSioQe1HYlJqncgJCBJLlcR1ywUMipIeQnaLDBTWVVVgLZ6EvHqRLe1SRpHiWy64wFyKZrzC1lYwV8yolKZD3YzK7th9ikV5lVNxAorsZlH+XiqBJl2LawYKqdvyxqG4UjbLTZyRXMRCcAEEvRNjBgFVtfYNjbI7l6QjGUqUNlw37veAbkA2Z0rvwmUQSe3Ffg3p4UoSlyOuB1PUMyKXzYc638r4kT1rFBJnMWaS4EKjYXPFDJhMKPjLQHHQy1mj5An/ooFCSOrD+2EBMgrC9na8B+dZ6hoOeOArsV9QoCi50xtWrv9GdHvmCAq0TsqBNk4RDsufKUk3trzxiHL9lpIppgenDvnDpsKKD3l5O8qIf+6x8BYFQfu/vh69Rg4Hn6dy2xzzJwpqfCHl3RfaKWBGKWBhS0tIi4DSW5FPImxvV63PHTs6IHVQsvLb1KSKQSg7pVCV0vXKXrbHzaxYUtqitLd2GIVsbGtrsXYloTcok6LaZn8IoMgewyWKH/VA+UGWCvKoToeAQrldIblfZRkR7gVlX1cXUUlbBdJrasCejupktvyJ0NduJcr5Fx/yfnGBgvLu15uBWAhQpPVghWC5TfLWPO9FclKgocva2ogGQLaccUgZwfx+JDk++4ZG3k7JQVz6pIz62czInj4y//5vaGRFpoxO9VvNvr4eHDs70aukXzbDyWsIoZGxCKBIHUJegdJ0qKAGKz1Lb3Xz98olnCOmGx9ASUVKmYFIcImcpTDu94CwvR0y27HgTGn0I2xp4ZS4sPE42LNG2VODKel9uD8pIzIbVZkJyWxTbDNlAHQDaqCwrakBYXs7Bpu7/arrLmxq4usdCBSUBaHzocyiqc7j7lOQMrYw8Vzb6mrUROmRATrnuBgUZHfE9WOI7LwAABQJSURBVLCmyNrEhGV7Pm8qoKAbk4hK9nS1xd31Vo06NKch66QIefWYFbFnj/H6U98ri4YoLeJCyeo5dnby96X7cMq/GFWtsj1uZE0qHiBb/gSutfVO1TErS6jtGxpZESn5bPCYttXVqNPQgt+TxBw9EIGWgcrgsbCtjT+3Fk9CYbWPK1ILan0cbdc6pWxB1iiUCy4orPZBYbWP2YeO+DNgrkB3LjINosKzwmqsAs1uwWWDLWccAWefO3wNBu3f9nYoqvLxeMqeNCWq5AMJkMh+T9ANQbltDpLHEeSEtGHVA2guQy2ScIBqMUyFHJe6oB3EmIduSHV+KyxzEHc3mkILacOqGYJDcxp/R7PCVVVQeqtbtV3DHZ5g2viODky1D/thbVIUKNQCrlJXWr5fbw80AFLOYpTiuiV3Bo+pDBxSXwxQmCtmgvkDkhuVkpEaFMyUgIKEYsPOQoonZYPecXxTKsV1qUfkUazAdXBaj58FewJ/H4qaTI7gWifK4cVfnIaYR+cipoGvt+vP+IOAQuuU6fPpXX4VjyJQI+NG9FCBZqKFswC0gqFaUONj9bFrGS/3mPjFBIrN62PBuB8f0Jzj+DYIvPA3Eihsq6vZX0PQO1WBpqUCCvuGxiAb+6xWEfdhUxPvE52HQKAgAdfiQ15Ingg9ozAc8EBWqzyjSBn1c4yAtDKzm6UxFUupcEChG0AzYRKbJXHeQKBwJPRCQa1PTYRyixx8TJoSoaDGp+rhpuz29fX4kCus+oTt7TgbUByzkDIABbUoCcAmx3d6+ZpajNNYcNXvV52PJQGKDY2QMiYXr1HcK3kCAUvQDalAoaAG9yu/LrSR9ny96LAX1mm+gDGKTV/ayq7dugFp7d6h7qTtQKKqQQ//mhr05rxGlKZebpvjMVX8gFVVIGxrY8WjjLvkfVtIXpyEa/Rn5N8VHwoGIlvOOH9fVOUL9qtIH8ExAyLvtjU1kNcg8m91/TJ/gOMFo342Uw4016Vzn31C5MpJ2lbaaXzIaFvJ4xiXIJd0KrdXvVFHZG2NwHRlyijWyTh2dqqm/PYNjeCIPwP6XnwxOHZ2cvEdKZcL29pA2NYGFZY5SBnFeEH6KRyPRIatK2S5/sB+o4FC2HgchKQ+zIqcla9teheOp9wn6mQ5kTIawaQqQr+psx5GoxG++tWvqiwFL1++DEVFRVBWVgYmkwnee+89AECnsJ6eHjAajWCxWODKlSsRt73pS1s5opvThMo+FGGnTtHlghq0vA+MNgt6Jxu5XNfFl4yPlWNaV6ASk74Xo/Uc7ae/W0DWgoCCahlI9DbobyVOw3zfhzRzXl3Nvw30GlFlA/rVxXEUoc9uEfl7a+FZ3la54GKNjNjzXuQynPdC4jQGDEMBBXml2tbWgj17TAUgcXdj9iLBrVaDKrnTyxmKpEmZREZeJ6mDuG+kDRp3N9LGhZQB0IhqoaDlAorCI8gQTRlBcKNz5ojrQZvDEECR0SHrVoSatX6ugeLKlStB3qNXrlyBP//5zwAA8Nxzz7HH6AsvvAA1NTVB/x+uqcrMC86G1nHY2QkVljnI6AwQsqUHUVJNLjrsRf2FayW2hOkkhUfBz8Vy+wkoco6LYDLPLqhaVNjUBBWWOaiwzKGx7iJEhgtqgrUgSdS1wjoXpOLElZoUN5E0OcxlM5B7DDkVeQ2YoYh5AGslYh70QEGNj/0/iyuxiC91CFWeAq8NTcnJcDhp0q8KGNvTR3j/sk6KXHClNPzVOiVFLzcS4gqr8WFLnJbo5hUzmDLd2cnbMu73sFq3yTy7qCJDIW2Yr4FxvwfyjyIg0WdppzHLYrzNo4ob2Tc0QoVlLqSeBC2LEqdF5IssdF82N0OFZQ6yW8SbFygAgk2Kle2ll16Curo6AIAgN/PExMgHtZBaD+VbKyRQ6J28bMlsE697CRIEFJLcvm5A4hcsknIubG5mSXp9r5+dt22rq8POSFRya2dk6fuFjFdY7VO5q+vPhFbdYvPitbVBQGHf0KgKsArJ/SDohiDubh/EfMOFbujnvSwyLKQMgGNHB+h7/ezGTdWePCMYkLu+F4Ei1Hkoc7hYVSt1SP5N6pCaop0yot5mqGsjbG8H/Rk1eC2k21ZXqwR/NX4M0FLNiNYpk7yEzc0421tgOlrY2gr6MwFFhPT7cPdD/BmW7LupmZnhgOI///M/oaCgAF5//XUAAGhuboYXX3yRv9doNBG3eyOAwra2FlWCtrdfn8VghJuGt0+q4IvZhhTjELa3g2NnJ+skZLapRWPDAUXqUIi4SaQbcVMTCNpB0A3InIWg5drG45B9Avchs11UaVQogSJp0s8eoCT3luASufKSUr1CygAe5/Z2VgPLbMOov0b0gck8K59DOg9HFedBsWxUAkV2i4j1H9vb0Thp9ym5S59HvDbSPs1nFBR47jPbkI2p8fvQ0euCCxL+ZkoFjsyklGjhmW0LFIAOsU+OhF48D2EUwSjVLWxvh81r/mqxj+81txsCFH/+85/BYrHAs88+y58FziiSkpKCtvXoo4+CyWQCk8kEX/nSX6hOiH1dHWYltIPoWSFVQebX+SC/DnPMN3ppsax9ZSVyHk4EyPUHPuzb26GgFo85rwGDkdnNaKK7oKWLVGYejvRjv6UBCqt9LBWfc1zkcyxoB8G+rg61NU9hFoPMnMmdndzYqStvcBK/1TplB3X2KFlZyerWGXfJGQJbwVm81ikDaAcgAQU9PKGWe464nrBycdYVSACjMRdzjRy7ujjOo7RlSB7H4G5mO54rJbiFkwBYaBe0gwg+DldILVD7+np+LjZ/JWaxj+81t+sGio8//hgcDgc8+eSTqr+7dOkSHD16FABwSUKxi3AtcEah5FEsVuHq89RJHGVBRrgL5VEsAiiom0slXY5wvq0Bwsekw6A0+iXhmkhAkXwWCVu2NTUqkWEyTjaXTjPHJXFaFvSlvwsVu8o9JqrrcAK6UuHqWq5RyUFvSIWrUP1GAYXWKfl6BNSHOBJ6+bm4aWMU9fX1oNPpQKPRgMViAQCA8+fPw8aNG6G8vBzKy8uhra0NAHAW0dXVBUajEcxmM7z//vsRt32jgcK+oRFKDnqh6LAXiqp8kH1CXLqis+vo9g2NGLVfgPOUCigkG7+iw96IPa8eeQ9pPZLJb5iyemFbG9izRoMeBvu6OjAcQFcurRMp4bmNqGyldASP94osI5d9QmS+iG4A+RbG2zxsjExA4djRAbaccUwjSgpWNKOwp49AUZVUlzOsBgrb2low3OHhY0zrURfs2dbUgPE2xffdkn5plQ+KDnsjngfrikNcZEe/N1fM4NJwATNYElxerKzhQoHCfksD2LNGIa/hJg9mLlWLCBS96BZFOoQLeTMIW1vVrlwimt8u9sLZ1tZiXGFLyzVf/Ovqq6r4uB27T2EJuFT9qqSAh+spI3jsidPBvh5Bx7m5OehhCAxmaocVkvR3+3jb5KWZ4BLlOpY+nJ4Lm5tB0A5Cehf+TW6jItC8qgry6kX+TjlLIhk7ZbfljAcpXKX1SPR7YrCuq+Oal8Dfp3dJ+xQGmG1ra0HY2gp5DYp9ypx/5najupDUx+PmNAXXelAv2+OG9buiQBFE4aa1sb53YdO6GwUU5tJpNmIhibjlBApHTDcqO/fija/xI4fEvr4+JHs1ZKfK2AhAYSmZQkXrgPLmQKBg/5J7ZGqyY2cnmzin9Uh06bt9cjXwikPM07Cvqwu6+akC1L6uLkhHhD5Xfh8IFIGsRwKKwmpf0O9Dja86D8ZpPA+a06H3aal7hPOkOmerq2HTyv+9bM/nTQsUwuZmKN3rhtJ9cs89hmmokoNepP9GeGjttzRAmcOFv70VxVeyTi5e+clkmuVcfvqpyIYuS9HpPGS14gwi9j4vaIeRpVq61w3Fh5AlSqK0gb3kTi9zPyIBRbgYBQEF0ZNjz3sh3oN07JI7vVAuuFTT46xW2d+jbE8wP0DQO8FcOo0eGxECkJE6AUXWSRFK97qDMlwEFKGsEhya02AxTIWNNwhJfWjqHGlpEuI3dEyLqfm53v6FlMKbNz26shLMpdMohjoROj0atq+qguwWyQh3kRfDZJrlN6jWufxAQZ1k52K+juItFMx07OwEXb9fZXWnuom3taktBHZ2BrtiSedW1x8GKLql5cbdPoh5yI2xBGKGBoB1fp2PLQrZYVyhYEUksNRBSW0qwvUOaf67spIVsMIxGkl9LKg2aFUVlAsuduW6UabXpbe6GYwjWRtGgeIGtEhAYVtbC/l1aG5LFXlJk/5FRbEdOzqujbZbPAkpY3J14mcFFMKmJvSNSO6H0n1u1M6Q0saO3afCxk8cu7og9l4fF2eld2HgL7CXOVxIfAokqa2sZF9WWj9rh+Vt5B4T1bYEW1uZ31BuQwahbgBjJYnTmN5NPzW/XillMrJPIH/CsasLspvxs6xWLFsPS32W9lkZhxC2t4OuH4154j0iZHTKx3CtGQrltRGS+iDtNAbes5sXZ1IcBYpFtEhAYV9XB+mn5DVp7L0oPWfPHAlLrLKtrsabcQHZhIg3gW4IchuRWMTMxM84VStoByH3mBg+lRkAFORbQYVZ+jO4VFH2kHaL29rQcFnRiw95VexNXR8G++h7QTvIRs0FNRjojL0XJQhjHnajSvkAVr4GbtuR0IsCPwESANbCs2AxTrNwrrJSlK/3mhq83mGujWNXF4vmUF0G16RY5uT9v8b7xba2FgqPyHwUi3F6Qdcn7DXe3i7vk3SPO3afUsWQokAxD1CwT8M5X1hBXgpmXktlXlAnOTZpfKV0/c3eiUdRbpsD25oaJgkt5LdsGeiUH1pH/JmQnpt8bdyyiIzGJ8q+Hw+5Ie4eXLrEfN0T8rdaJ2Y1lEDB2Zsx2SCa7ASUQOHYfQp0A+GvjbC9PazptbIvlPUaFjAkHoXWiRIC1zoDLTos08ZL97rZ30QpxhwFihWYjzbc4QHDAQ/qTfbjmyTBhRqHGj8qG4UCArKxT5y9cdwJFVCEiQfcjJ2AgtzLLIYpMJfNgOEAntuyPe6wSzhH/BnkNUjCxAkuVAcLLDbTOv3sm0ECuHHnJMrzIy5c9twv+3CkjPllI+iALmxtxerLvHF+WBJnMOUac8GF4sgekUVwDQc8OPORCvbCXRv7ujqw5U9AQa1P9SDTuOaKGbQ+aBX53FzLdRa2tYG18CxL898QoJDUyLNbZNWuKFDQTRpC4SppUlYqIrepUEU+me0yKelGid183oFCmfWYj9QTqldY51gxK9SbOGFOMXsI6GTWE8jMnG9Mi3Fanpk84EF3tYfckDAnotBPAXqsOhJ65wUK5XHQPpN4rnWFXNmrPKZQCukL7XkNUaBYkhYbGwupqalc+/FZ9Oj40fE/T+PHxsYu2/N50wAFAIDJZIqOHx0/Ov5N2KJAER0/On50/HnbTQUUjz76aHT86PjR8W/CdlMBRbRFW7TdnC0KFNEWbdE2b7spgOKJJ56AoqIiKCoqgpdeemlZxvz1r38NBoMBjEYjGAwG+PnPfw4AAB6PB4qLi8FgMMBrr7225PvxwQcfwF/+5V/ChQsXln38V199FQRBAJPJBMeOHVvW8a9evQqdnZ1QWFgI+fn5cO7cuSUfP5SKfLgxF6sif63j3ygV+6VunzlQfPjhh5Ceng7//d//DR988AGkpaXB//zP/yz5uP/+7/8OH374IQAAvPHGG1BcXAxvv/02lJaWwqeffgpvvvkmGI3GJd+Pzs5OuO222+DChQvLOv7HH38MJpOJzwEALOv4r7zyCpSXlwMAwCeffAKJiYnw2muvLen4oVTkwx3zYlXkr3X8G6Viv9TtMweKS5cuQXt7O/97z5498Pbbby/rPrz33ntgNBrhwQcfBI/Hw5/rdDr46KOPlmzcN954A44dOwbj4+Nw4cKFZR3/xz/+Mdx+++1w++23Q1lZGTzzzDPLOv4HH3wANpsNPv74Y/jTn/4Eer0ezp07t+TjBz6o4Y55sSry1zq+sl2Piv1St88cKJ566ikYHh7mf9fU1MBPfvKTZRv/k08+AUEQ4NKlSzAzMwMPP/wwf1dSUgJ/+MMflmzsO+64A37/+98zUCzn+N/85jdh165d8Mc//hH++Mc/glarhenp6WUb/+rVq9De3g67d++Gbdu2wf33378sxx/4oIYbc7Eq8tc6PrXrVbFf6vaZA0XgjGLv3r3LNqP49NNPobq6Gr72ta8BQPDbRa/XL9kb9fnnn4f+/n4AgLAziqUc/9KlS3Dw4EH+d1VVFbhcrmUdf9++ffDJJ5/Af/3Xf0Fubi5MTEws+fjzzShozIWoyN+I8QGuXcV+OdtnDhQffvghZGRkwEcffQT/8R//sWwxiqtXr0JjYyPMzc3xZ2+99RaUl5fD1atX4Z133gGDwbBk409PT0N5eTkIggAJCQmQlpYGP/rRj5Zt/D/96U+QlZUFH3/8MXz88ceQlpYGP/3pT5dt/EuXLvE0++rVq2AwGODVV19d8vEDH9Rw13yxKvLXOv6NUrFf6vaZAwUAwGOPPcZZjx/84AfLMub3vvc9+PKXv8zq4QcOHAAAAJfLBSUlJWAwGOCVV15Zln2hGcVyj3/x4kUoKSmB/Px8eOihh5Z1/E8//RSampp4/IGBgSUfP5SKfLgxF6sif63j3ygV+6VuNwVQRFu0RdvN3aJAEW3RFm3ztihQRFu0Rdu8LQoU0RZt0TZviwJFtEVbtM3bokARbdEWbfO2KFBEW7RF27wtChTRFm3RNm+LAkW0RVu0zduiQBFt0RZt87YoUERbtEXbvC0KFNEWbdE2b4sCRbRFW7TN26JAEW3RFm3ztihQRFu0Rdu8LQoU0RZt0TZv+3++VfH9LGINPQAAAABJRU5ErkJggg==\" width=\"399\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0d02e080d0>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_patt = np.random.randint(0, len(input_data))\n",
    "plt.figure(figsize = (4,4))\n",
    "plt.imshow(input_data[rand_patt])\n",
    "plt.figure(figsize = (4,4))\n",
    "plt.imshow(input_targets[rand_patt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6a2909",
   "metadata": {},
   "source": [
    "### Set the checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b62fcf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpoint_filepath = str(mp)+'/chk-{epoch:02d}-{val_loss:.5e}.hdf5'\n",
    "chkpoint_model = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = chkpoint_filepath,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"min\",\n",
    "    save_freq=\"epoch\",\n",
    "    options=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2430e279",
   "metadata": {},
   "source": [
    "### Redefine the model parameters if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "88ace2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rebin_factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1ceb00f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name = 'full'\n",
    "hparams= {'KN1':32,'KN2':64,'KN3':128, 'KN4':128, 'KN5':256,'D1':128,'D2':512,'LAT':2,'LR':0.0001, 'B':1}\n",
    "\n",
    "vae_model = create_vae_model(hparams)\n",
    "info[sample_name] = {'rebin': rebin_factor, 'hparams':hparams}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05ca6a1",
   "metadata": {},
   "source": [
    "### Will be helpful to start with a trained model so set one here (otherwise will just take longer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "33c0aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model ='/dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-343-7.92353e+03.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "468f2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model.load_weights(old_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e0450d",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c34e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.3501WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0352s vs `on_test_batch_end` time: 0.1821s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0352s vs `on_test_batch_end` time: 0.1821s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7543.3501 - val_loss: 7534.9858\n",
      "Epoch 2/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.2832\n",
      "Epoch 00002: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7520.2832 - val_loss: 7535.7202\n",
      "Epoch 3/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.7153\n",
      "Epoch 00003: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7526.7153 - val_loss: 7534.4927\n",
      "Epoch 4/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1333\n",
      "Epoch 00004: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7532.1333 - val_loss: 7534.6655\n",
      "Epoch 5/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3818\n",
      "Epoch 00005: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.3818 - val_loss: 7534.7983\n",
      "Epoch 6/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1538\n",
      "Epoch 00006: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.1538 - val_loss: 7534.6201\n",
      "Epoch 7/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.7305\n",
      "Epoch 00007: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7526.7305 - val_loss: 7534.8857\n",
      "Epoch 8/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0898\n",
      "Epoch 00008: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7538.0898 - val_loss: 7534.6606\n",
      "Epoch 9/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.7725\n",
      "Epoch 00009: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7541.7725 - val_loss: 7535.2407\n",
      "Epoch 10/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2163\n",
      "Epoch 00010: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.2163 - val_loss: 7534.9951\n",
      "Epoch 11/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7666\n",
      "Epoch 00011: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.7666 - val_loss: 7535.0674\n",
      "Epoch 12/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9883\n",
      "Epoch 00012: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.9883 - val_loss: 7534.9126\n",
      "Epoch 13/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5747\n",
      "Epoch 00013: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.5747 - val_loss: 7534.8057\n",
      "Epoch 14/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.5996\n",
      "Epoch 00014: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7524.5996 - val_loss: 7534.9448\n",
      "Epoch 15/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.8149\n",
      "Epoch 00015: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.8149 - val_loss: 7535.0386\n",
      "Epoch 16/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.5654\n",
      "Epoch 00016: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7519.5654 - val_loss: 7534.8672\n",
      "Epoch 17/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5137\n",
      "Epoch 00017: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.5137 - val_loss: 7535.1978\n",
      "Epoch 18/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.1055\n",
      "Epoch 00018: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.1055 - val_loss: 7535.1343\n",
      "Epoch 19/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.7427\n",
      "Epoch 00019: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.7427 - val_loss: 7534.8008\n",
      "Epoch 20/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.0317\n",
      "Epoch 00020: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7520.0317 - val_loss: 7535.3071\n",
      "Epoch 21/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.8066\n",
      "Epoch 00021: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.8066 - val_loss: 7534.8145\n",
      "Epoch 22/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.1650\n",
      "Epoch 00022: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7541.1650 - val_loss: 7534.8145\n",
      "Epoch 23/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.4893\n",
      "Epoch 00023: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7524.4893 - val_loss: 7534.7383\n",
      "Epoch 24/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6621\n",
      "Epoch 00024: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.6621 - val_loss: 7534.7310\n",
      "Epoch 25/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.1445\n",
      "Epoch 00025: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7546.1445 - val_loss: 7534.7134\n",
      "Epoch 26/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.3628\n",
      "Epoch 00026: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7519.3628 - val_loss: 7534.5464\n",
      "Epoch 27/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3784\n",
      "Epoch 00027: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7537.3784 - val_loss: 7534.7310\n",
      "Epoch 28/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.8994\n",
      "Epoch 00028: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7524.8994 - val_loss: 7534.8345\n",
      "Epoch 29/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.3857\n",
      "Epoch 00029: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7546.3857 - val_loss: 7534.6890\n",
      "Epoch 30/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0425\n",
      "Epoch 00030: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7531.0425 - val_loss: 7534.6704\n",
      "Epoch 31/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.7925\n",
      "Epoch 00031: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.7925 - val_loss: 7534.5562\n",
      "Epoch 32/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7900\n",
      "Epoch 00032: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.7900 - val_loss: 7534.8496\n",
      "Epoch 33/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.4424\n",
      "Epoch 00033: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.4424 - val_loss: 7534.7944\n",
      "Epoch 34/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.6299\n",
      "Epoch 00034: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7519.6299 - val_loss: 7534.9585\n",
      "Epoch 35/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3599\n",
      "Epoch 00035: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.3599 - val_loss: 7535.0000\n",
      "Epoch 36/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8652\n",
      "Epoch 00036: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.8652 - val_loss: 7534.6079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.4370\n",
      "Epoch 00037: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.4370 - val_loss: 7534.3896\n",
      "Epoch 38/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7666\n",
      "Epoch 00038: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7539.7666 - val_loss: 7534.4951\n",
      "Epoch 39/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0586\n",
      "Epoch 00039: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.0586 - val_loss: 7534.4326\n",
      "Epoch 40/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.2666\n",
      "Epoch 00040: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7536.2666 - val_loss: 7534.4175\n",
      "Epoch 41/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8848\n",
      "Epoch 00041: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.8848 - val_loss: 7534.9697\n",
      "Epoch 42/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.2310\n",
      "Epoch 00042: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7519.2310 - val_loss: 7534.3999\n",
      "Epoch 43/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.2114\n",
      "Epoch 00043: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.2114 - val_loss: 7535.4766\n",
      "Epoch 44/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.0913\n",
      "Epoch 00044: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.0913 - val_loss: 7534.8320\n",
      "Epoch 45/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4009\n",
      "Epoch 00045: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.4009 - val_loss: 7534.5562\n",
      "Epoch 46/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4297\n",
      "Epoch 00046: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.4297 - val_loss: 7534.8784\n",
      "Epoch 47/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2983\n",
      "Epoch 00047: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.2983 - val_loss: 7534.5752\n",
      "Epoch 48/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7495\n",
      "Epoch 00048: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.7495 - val_loss: 7534.5488\n",
      "Epoch 49/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.3984\n",
      "Epoch 00049: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7524.3984 - val_loss: 7534.3120\n",
      "Epoch 50/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1738\n",
      "Epoch 00050: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.1738 - val_loss: 7534.9238\n",
      "Epoch 51/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.9565\n",
      "Epoch 00051: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7545.9565 - val_loss: 7534.5889\n",
      "Epoch 52/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7300\n",
      "Epoch 00052: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.7300 - val_loss: 7534.3184\n",
      "Epoch 53/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6294\n",
      "Epoch 00053: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.6294 - val_loss: 7534.6030\n",
      "Epoch 54/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.5361\n",
      "Epoch 00054: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.5361 - val_loss: 7534.7554\n",
      "Epoch 55/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.5332\n",
      "Epoch 00055: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7546.5332 - val_loss: 7535.1279\n",
      "Epoch 56/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1899\n",
      "Epoch 00056: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.1899 - val_loss: 7534.7695\n",
      "Epoch 57/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8506\n",
      "Epoch 00057: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.8506 - val_loss: 7534.5488\n",
      "Epoch 58/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.2842\n",
      "Epoch 00058: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.2842 - val_loss: 7535.1289\n",
      "Epoch 59/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.5586\n",
      "Epoch 00059: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7546.5586 - val_loss: 7535.2632\n",
      "Epoch 60/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0083\n",
      "Epoch 00060: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.0083 - val_loss: 7535.2754\n",
      "Epoch 61/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.9458\n",
      "Epoch 00061: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7525.9458 - val_loss: 7534.5342\n",
      "Epoch 62/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3262\n",
      "Epoch 00062: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.3262 - val_loss: 7535.2578\n",
      "Epoch 63/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6265\n",
      "Epoch 00063: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7531.6265 - val_loss: 7535.4224\n",
      "Epoch 64/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0283\n",
      "Epoch 00064: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.0283 - val_loss: 7534.9136\n",
      "Epoch 65/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0654\n",
      "Epoch 00065: val_loss did not improve from 7534.25342\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.0654 - val_loss: 7534.4624\n",
      "Epoch 66/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9795\n",
      "Epoch 00066: val_loss improved from 7534.25342 to 7534.20947, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-66-7.53421e+03.hdf5\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7531.9795 - val_loss: 7534.2095\n",
      "Epoch 67/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.4697\n",
      "Epoch 00067: val_loss did not improve from 7534.20947\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.4697 - val_loss: 7534.7222\n",
      "Epoch 68/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4761\n",
      "Epoch 00068: val_loss did not improve from 7534.20947\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.4761 - val_loss: 7535.4663\n",
      "Epoch 69/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.5244\n",
      "Epoch 00069: val_loss did not improve from 7534.20947\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7541.5244 - val_loss: 7535.0122\n",
      "Epoch 70/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.8315\n",
      "Epoch 00070: val_loss did not improve from 7534.20947\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.8315 - val_loss: 7535.1294\n",
      "Epoch 71/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.9438\n",
      "Epoch 00071: val_loss did not improve from 7534.20947\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7537.9438 - val_loss: 7534.4487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0693\n",
      "Epoch 00072: val_loss did not improve from 7534.20947\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7538.0693 - val_loss: 7534.5288\n",
      "Epoch 73/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0483\n",
      "Epoch 00073: val_loss did not improve from 7534.20947\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7533.0483 - val_loss: 7534.4448\n",
      "Epoch 74/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4414\n",
      "Epoch 00074: val_loss did not improve from 7534.20947\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.4414 - val_loss: 7535.0225\n",
      "Epoch 75/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.3418\n",
      "Epoch 00075: val_loss did not improve from 7534.20947\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7546.3418 - val_loss: 7535.0166\n",
      "Epoch 76/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8755\n",
      "Epoch 00076: val_loss did not improve from 7534.20947\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7536.8755 - val_loss: 7534.3120\n",
      "Epoch 77/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6416\n",
      "Epoch 00077: val_loss improved from 7534.20947 to 7534.18262, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-77-7.53418e+03.hdf5\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7536.6416 - val_loss: 7534.1826\n",
      "Epoch 78/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.4858\n",
      "Epoch 00078: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7544.4858 - val_loss: 7534.4336\n",
      "Epoch 79/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6689\n",
      "Epoch 00079: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7536.6689 - val_loss: 7534.4209\n",
      "Epoch 80/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6431\n",
      "Epoch 00080: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7537.6431 - val_loss: 7534.8330\n",
      "Epoch 81/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.8462\n",
      "Epoch 00081: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7541.8462 - val_loss: 7535.3672\n",
      "Epoch 82/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5493\n",
      "Epoch 00082: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7539.5493 - val_loss: 7534.4946\n",
      "Epoch 83/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0967\n",
      "Epoch 00083: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.0967 - val_loss: 7534.4346\n",
      "Epoch 84/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.0488\n",
      "Epoch 00084: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7546.0488 - val_loss: 7534.7056\n",
      "Epoch 85/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4883\n",
      "Epoch 00085: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.4883 - val_loss: 7534.8066\n",
      "Epoch 86/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2334\n",
      "Epoch 00086: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7538.2334 - val_loss: 7535.0977\n",
      "Epoch 87/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.6172\n",
      "Epoch 00087: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.6172 - val_loss: 7534.2393\n",
      "Epoch 88/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.7275\n",
      "Epoch 00088: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.7275 - val_loss: 7534.6450\n",
      "Epoch 89/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.2383\n",
      "Epoch 00089: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.2383 - val_loss: 7534.2520\n",
      "Epoch 90/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8145\n",
      "Epoch 00090: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.8145 - val_loss: 7534.2778\n",
      "Epoch 91/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.4023\n",
      "Epoch 00091: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.4023 - val_loss: 7534.3984\n",
      "Epoch 92/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.9448\n",
      "Epoch 00092: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.9448 - val_loss: 7534.3545\n",
      "Epoch 93/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4800\n",
      "Epoch 00093: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.4800 - val_loss: 7534.4033\n",
      "Epoch 94/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.3457\n",
      "Epoch 00094: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.3457 - val_loss: 7535.0791\n",
      "Epoch 95/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7666\n",
      "Epoch 00095: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.7666 - val_loss: 7536.6929\n",
      "Epoch 96/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9136\n",
      "Epoch 00096: val_loss did not improve from 7534.18262\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.9136 - val_loss: 7534.7480\n",
      "Epoch 97/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.2012\n",
      "Epoch 00097: val_loss improved from 7534.18262 to 7534.15674, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-97-7.53416e+03.hdf5\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7529.2012 - val_loss: 7534.1567\n",
      "Epoch 98/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.1436\n",
      "Epoch 00098: val_loss improved from 7534.15674 to 7534.12305, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-98-7.53412e+03.hdf5\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7544.1436 - val_loss: 7534.1230\n",
      "Epoch 99/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4014\n",
      "Epoch 00099: val_loss did not improve from 7534.12305\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.4014 - val_loss: 7534.3247\n",
      "Epoch 100/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7778\n",
      "Epoch 00100: val_loss did not improve from 7534.12305\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.7778 - val_loss: 7534.6890\n",
      "Epoch 101/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.1626\n",
      "Epoch 00101: val_loss did not improve from 7534.12305\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.1626 - val_loss: 7534.6118\n",
      "Epoch 102/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0625\n",
      "Epoch 00102: val_loss did not improve from 7534.12305\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.0625 - val_loss: 7535.1289\n",
      "Epoch 103/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.0454\n",
      "Epoch 00103: val_loss did not improve from 7534.12305\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.0454 - val_loss: 7534.8042\n",
      "Epoch 104/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3545\n",
      "Epoch 00104: val_loss did not improve from 7534.12305\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.3545 - val_loss: 7535.0361\n",
      "Epoch 105/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.3569\n",
      "Epoch 00105: val_loss did not improve from 7534.12305\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.3569 - val_loss: 7534.3521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0889\n",
      "Epoch 00106: val_loss did not improve from 7534.12305\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.0889 - val_loss: 7534.2017\n",
      "Epoch 107/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.4722\n",
      "Epoch 00107: val_loss did not improve from 7534.12305\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.4722 - val_loss: 7534.2954\n",
      "Epoch 108/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.0771\n",
      "Epoch 00108: val_loss did not improve from 7534.12305\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7519.0771 - val_loss: 7534.8623\n",
      "Epoch 109/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3809\n",
      "Epoch 00109: val_loss did not improve from 7534.12305\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.3809 - val_loss: 7534.2046\n",
      "Epoch 110/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5986\n",
      "Epoch 00110: val_loss did not improve from 7534.12305\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.5986 - val_loss: 7534.6016\n",
      "Epoch 111/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3618\n",
      "Epoch 00111: val_loss did not improve from 7534.12305\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.3618 - val_loss: 7534.3105\n",
      "Epoch 112/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.5454\n",
      "Epoch 00112: val_loss did not improve from 7534.12305\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7530.5454 - val_loss: 7534.1465\n",
      "Epoch 113/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.0796\n",
      "Epoch 00113: val_loss improved from 7534.12305 to 7534.01758, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-113-7.53402e+03.hdf5\n",
      "25/25 [==============================] - 14s 543ms/step - loss: 7525.0796 - val_loss: 7534.0176\n",
      "Epoch 114/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4272\n",
      "Epoch 00114: val_loss did not improve from 7534.01758\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7534.4272 - val_loss: 7535.3262\n",
      "Epoch 115/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8169\n",
      "Epoch 00115: val_loss did not improve from 7534.01758\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.8169 - val_loss: 7534.1719\n",
      "Epoch 116/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5703\n",
      "Epoch 00116: val_loss did not improve from 7534.01758\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.5703 - val_loss: 7534.3198\n",
      "Epoch 117/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4385\n",
      "Epoch 00117: val_loss did not improve from 7534.01758\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.4385 - val_loss: 7534.2119\n",
      "Epoch 118/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.9697\n",
      "Epoch 00118: val_loss did not improve from 7534.01758\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7545.9697 - val_loss: 7534.5073\n",
      "Epoch 119/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7119\n",
      "Epoch 00119: val_loss did not improve from 7534.01758\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.7119 - val_loss: 7534.8657\n",
      "Epoch 120/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4878\n",
      "Epoch 00120: val_loss did not improve from 7534.01758\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.4878 - val_loss: 7534.8174\n",
      "Epoch 121/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.6777\n",
      "Epoch 00121: val_loss did not improve from 7534.01758\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7533.6777 - val_loss: 7534.3921\n",
      "Epoch 122/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1035\n",
      "Epoch 00122: val_loss did not improve from 7534.01758\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.1035 - val_loss: 7534.0576\n",
      "Epoch 123/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.2026\n",
      "Epoch 00123: val_loss did not improve from 7534.01758\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7547.2026 - val_loss: 7535.8257\n",
      "Epoch 124/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.1377\n",
      "Epoch 00124: val_loss did not improve from 7534.01758\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7541.1377 - val_loss: 7534.6494\n",
      "Epoch 125/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.7983\n",
      "Epoch 00125: val_loss improved from 7534.01758 to 7534.00537, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-125-7.53401e+03.hdf5\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7528.7983 - val_loss: 7534.0054\n",
      "Epoch 126/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7427\n",
      "Epoch 00126: val_loss did not improve from 7534.00537\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.7427 - val_loss: 7534.4800\n",
      "Epoch 127/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.8872\n",
      "Epoch 00127: val_loss did not improve from 7534.00537\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.8872 - val_loss: 7535.3071\n",
      "Epoch 128/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.9658\n",
      "Epoch 00128: val_loss did not improve from 7534.00537\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7525.9658 - val_loss: 7534.2881\n",
      "Epoch 129/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.1177\n",
      "Epoch 00129: val_loss did not improve from 7534.00537\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7525.1177 - val_loss: 7534.1094\n",
      "Epoch 130/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.5854\n",
      "Epoch 00130: val_loss improved from 7534.00537 to 7533.91699, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-130-7.53392e+03.hdf5\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7525.5854 - val_loss: 7533.9170\n",
      "Epoch 131/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7568\n",
      "Epoch 00131: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7540.7568 - val_loss: 7534.4121\n",
      "Epoch 132/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.9380\n",
      "Epoch 00132: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7530.9380 - val_loss: 7534.3535\n",
      "Epoch 133/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4355\n",
      "Epoch 00133: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.4355 - val_loss: 7535.1274\n",
      "Epoch 134/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3120\n",
      "Epoch 00134: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.3120 - val_loss: 7534.2646\n",
      "Epoch 135/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3428\n",
      "Epoch 00135: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.3428 - val_loss: 7535.6655\n",
      "Epoch 136/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.3120\n",
      "Epoch 00136: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7524.3120 - val_loss: 7534.1025\n",
      "Epoch 137/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.8374\n",
      "Epoch 00137: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.8374 - val_loss: 7534.4663\n",
      "Epoch 138/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7954\n",
      "Epoch 00138: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.7954 - val_loss: 7534.2642\n",
      "Epoch 139/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7532.3682\n",
      "Epoch 00139: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.3682 - val_loss: 7534.0103\n",
      "Epoch 140/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.8838\n",
      "Epoch 00140: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.8838 - val_loss: 7535.0688\n",
      "Epoch 141/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.2480\n",
      "Epoch 00141: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7536.2480 - val_loss: 7534.4224\n",
      "Epoch 142/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6118\n",
      "Epoch 00142: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7537.6118 - val_loss: 7534.1895\n",
      "Epoch 143/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0308\n",
      "Epoch 00143: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7538.0308 - val_loss: 7534.5767\n",
      "Epoch 144/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.2891\n",
      "Epoch 00144: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7543.2891 - val_loss: 7534.5474\n",
      "Epoch 145/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.6235\n",
      "Epoch 00145: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7542.6235 - val_loss: 7533.9927\n",
      "Epoch 146/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.2539\n",
      "Epoch 00146: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7539.2539 - val_loss: 7534.2710\n",
      "Epoch 147/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6265\n",
      "Epoch 00147: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.6265 - val_loss: 7534.4985\n",
      "Epoch 148/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8169\n",
      "Epoch 00148: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.8169 - val_loss: 7534.6128\n",
      "Epoch 149/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.1294\n",
      "Epoch 00149: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7546.1294 - val_loss: 7534.6479\n",
      "Epoch 150/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.8218\n",
      "Epoch 00150: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.8218 - val_loss: 7534.6694\n",
      "Epoch 151/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8364\n",
      "Epoch 00151: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.8364 - val_loss: 7534.2207\n",
      "Epoch 152/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8721\n",
      "Epoch 00152: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7530.8721 - val_loss: 7534.1206\n",
      "Epoch 153/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7522.3179\n",
      "Epoch 00153: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7522.3179 - val_loss: 7535.2783\n",
      "Epoch 154/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.2788\n",
      "Epoch 00154: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.2788 - val_loss: 7534.2822\n",
      "Epoch 155/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8633\n",
      "Epoch 00155: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.8633 - val_loss: 7534.2490\n",
      "Epoch 156/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3379\n",
      "Epoch 00156: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.3379 - val_loss: 7534.3608\n",
      "Epoch 157/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.3730\n",
      "Epoch 00157: val_loss did not improve from 7533.91699\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.3730 - val_loss: 7534.0752\n",
      "Epoch 158/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.4531\n",
      "Epoch 00158: val_loss improved from 7533.91699 to 7533.90088, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-158-7.53390e+03.hdf5\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7542.4531 - val_loss: 7533.9009\n",
      "Epoch 159/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.0825\n",
      "Epoch 00159: val_loss did not improve from 7533.90088\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7526.0825 - val_loss: 7534.0786\n",
      "Epoch 160/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.1748\n",
      "Epoch 00160: val_loss did not improve from 7533.90088\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.1748 - val_loss: 7533.9746\n",
      "Epoch 161/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1128\n",
      "Epoch 00161: val_loss did not improve from 7533.90088\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.1128 - val_loss: 7534.3970\n",
      "Epoch 162/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1230\n",
      "Epoch 00162: val_loss did not improve from 7533.90088\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.1230 - val_loss: 7533.9390\n",
      "Epoch 163/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.9692\n",
      "Epoch 00163: val_loss did not improve from 7533.90088\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7528.9692 - val_loss: 7534.2231\n",
      "Epoch 164/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0142\n",
      "Epoch 00164: val_loss did not improve from 7533.90088\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.0142 - val_loss: 7534.3174\n",
      "Epoch 165/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.1494\n",
      "Epoch 00165: val_loss did not improve from 7533.90088\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.1494 - val_loss: 7534.2202\n",
      "Epoch 166/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.2061\n",
      "Epoch 00166: val_loss did not improve from 7533.90088\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7530.2061 - val_loss: 7533.9321\n",
      "Epoch 167/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.8594\n",
      "Epoch 00167: val_loss did not improve from 7533.90088\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.8594 - val_loss: 7534.4502\n",
      "Epoch 168/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.3560\n",
      "Epoch 00168: val_loss did not improve from 7533.90088\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.3560 - val_loss: 7534.2710\n",
      "Epoch 169/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5781\n",
      "Epoch 00169: val_loss did not improve from 7533.90088\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.5781 - val_loss: 7534.6958\n",
      "Epoch 170/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5835\n",
      "Epoch 00170: val_loss did not improve from 7533.90088\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.5835 - val_loss: 7534.2778\n",
      "Epoch 171/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.2622\n",
      "Epoch 00171: val_loss improved from 7533.90088 to 7533.84863, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-171-7.53385e+03.hdf5\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7530.2622 - val_loss: 7533.8486\n",
      "Epoch 172/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.1724\n",
      "Epoch 00172: val_loss did not improve from 7533.84863\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.1724 - val_loss: 7534.1177\n",
      "Epoch 173/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7539.3081\n",
      "Epoch 00173: val_loss did not improve from 7533.84863\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7539.3081 - val_loss: 7534.1655\n",
      "Epoch 174/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.5889\n",
      "Epoch 00174: val_loss did not improve from 7533.84863\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7542.5889 - val_loss: 7534.0566\n",
      "Epoch 175/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.5322\n",
      "Epoch 00175: val_loss did not improve from 7533.84863\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7526.5322 - val_loss: 7535.1558\n",
      "Epoch 176/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.1421\n",
      "Epoch 00176: val_loss did not improve from 7533.84863\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7519.1421 - val_loss: 7534.4727\n",
      "Epoch 177/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.6304\n",
      "Epoch 00177: val_loss improved from 7533.84863 to 7533.76562, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-177-7.53377e+03.hdf5\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7535.6304 - val_loss: 7533.7656\n",
      "Epoch 178/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4302\n",
      "Epoch 00178: val_loss did not improve from 7533.76562\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7533.4302 - val_loss: 7534.8696\n",
      "Epoch 179/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7427\n",
      "Epoch 00179: val_loss did not improve from 7533.76562\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7539.7427 - val_loss: 7534.4946\n",
      "Epoch 180/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0322\n",
      "Epoch 00180: val_loss did not improve from 7533.76562\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7537.0322 - val_loss: 7534.4375\n",
      "Epoch 181/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5405\n",
      "Epoch 00181: val_loss did not improve from 7533.76562\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.5405 - val_loss: 7533.8999\n",
      "Epoch 182/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.0156\n",
      "Epoch 00182: val_loss did not improve from 7533.76562\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.0156 - val_loss: 7533.7847\n",
      "Epoch 183/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8823\n",
      "Epoch 00183: val_loss did not improve from 7533.76562\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.8823 - val_loss: 7534.1890\n",
      "Epoch 184/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.1636\n",
      "Epoch 00184: val_loss did not improve from 7533.76562\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.1636 - val_loss: 7533.7871\n",
      "Epoch 185/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.3276\n",
      "Epoch 00185: val_loss did not improve from 7533.76562\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.3276 - val_loss: 7533.9712\n",
      "Epoch 186/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0952\n",
      "Epoch 00186: val_loss improved from 7533.76562 to 7533.73926, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-186-7.53374e+03.hdf5\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.0952 - val_loss: 7533.7393\n",
      "Epoch 187/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6904\n",
      "Epoch 00187: val_loss did not improve from 7533.73926\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.6904 - val_loss: 7534.2080\n",
      "Epoch 188/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2539\n",
      "Epoch 00188: val_loss did not improve from 7533.73926\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.2539 - val_loss: 7533.9561\n",
      "Epoch 189/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7251\n",
      "Epoch 00189: val_loss did not improve from 7533.73926\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.7251 - val_loss: 7533.8745\n",
      "Epoch 190/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.3384\n",
      "Epoch 00190: val_loss improved from 7533.73926 to 7533.60547, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-190-7.53361e+03.hdf5\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7542.3384 - val_loss: 7533.6055\n",
      "Epoch 191/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.9565\n",
      "Epoch 00191: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.9565 - val_loss: 7533.6226\n",
      "Epoch 192/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.6343\n",
      "Epoch 00192: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.6343 - val_loss: 7534.3984\n",
      "Epoch 193/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.8057\n",
      "Epoch 00193: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7543.8057 - val_loss: 7533.7710\n",
      "Epoch 194/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1089\n",
      "Epoch 00194: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.1089 - val_loss: 7533.8687\n",
      "Epoch 195/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5073\n",
      "Epoch 00195: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7531.5073 - val_loss: 7534.4966\n",
      "Epoch 196/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1118\n",
      "Epoch 00196: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.1118 - val_loss: 7534.3296\n",
      "Epoch 197/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.3828\n",
      "Epoch 00197: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.3828 - val_loss: 7533.7544\n",
      "Epoch 198/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.8193\n",
      "Epoch 00198: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.8193 - val_loss: 7534.2271\n",
      "Epoch 199/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8809\n",
      "Epoch 00199: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.8809 - val_loss: 7533.6729\n",
      "Epoch 200/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.9121\n",
      "Epoch 00200: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7534.9121 - val_loss: 7536.9702\n",
      "Epoch 201/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.9546\n",
      "Epoch 00201: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7525.9546 - val_loss: 7534.0703\n",
      "Epoch 202/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.5820\n",
      "Epoch 00202: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7545.5820 - val_loss: 7534.3506\n",
      "Epoch 203/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6953\n",
      "Epoch 00203: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7537.6953 - val_loss: 7534.1514\n",
      "Epoch 204/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.3589\n",
      "Epoch 00204: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7540.3589 - val_loss: 7534.0815\n",
      "Epoch 205/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.9331\n",
      "Epoch 00205: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.9331 - val_loss: 7533.7671\n",
      "Epoch 206/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.5933\n",
      "Epoch 00206: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.5933 - val_loss: 7533.7769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.7280\n",
      "Epoch 00207: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.7280 - val_loss: 7536.3145\n",
      "Epoch 208/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9136\n",
      "Epoch 00208: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.9136 - val_loss: 7533.7026\n",
      "Epoch 209/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8535\n",
      "Epoch 00209: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7538.8535 - val_loss: 7533.9424\n",
      "Epoch 210/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.8823\n",
      "Epoch 00210: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7518.8823 - val_loss: 7534.0527\n",
      "Epoch 211/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.4370\n",
      "Epoch 00211: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7545.4370 - val_loss: 7533.8882\n",
      "Epoch 212/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0591\n",
      "Epoch 00212: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.0591 - val_loss: 7533.6870\n",
      "Epoch 213/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.8218\n",
      "Epoch 00213: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7525.8218 - val_loss: 7534.1274\n",
      "Epoch 214/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.5938\n",
      "Epoch 00214: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7530.5938 - val_loss: 7534.0991\n",
      "Epoch 215/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9663\n",
      "Epoch 00215: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.9663 - val_loss: 7533.6416\n",
      "Epoch 216/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.9438\n",
      "Epoch 00216: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7538.9438 - val_loss: 7533.8105\n",
      "Epoch 217/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2920\n",
      "Epoch 00217: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.2920 - val_loss: 7533.9185\n",
      "Epoch 218/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1274\n",
      "Epoch 00218: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.1274 - val_loss: 7534.4673\n",
      "Epoch 219/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.4434\n",
      "Epoch 00219: val_loss did not improve from 7533.60547\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7518.4434 - val_loss: 7533.7490\n",
      "Epoch 220/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.1694\n",
      "Epoch 00220: val_loss improved from 7533.60547 to 7533.51367, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-220-7.53351e+03.hdf5\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7525.1694 - val_loss: 7533.5137\n",
      "Epoch 221/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.9541\n",
      "Epoch 00221: val_loss did not improve from 7533.51367\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7518.9541 - val_loss: 7533.8174\n",
      "Epoch 222/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.8774\n",
      "Epoch 00222: val_loss did not improve from 7533.51367\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.8774 - val_loss: 7533.6094\n",
      "Epoch 223/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.3706\n",
      "Epoch 00223: val_loss improved from 7533.51367 to 7533.49902, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-223-7.53350e+03.hdf5\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7545.3706 - val_loss: 7533.4990\n",
      "Epoch 224/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7075\n",
      "Epoch 00224: val_loss did not improve from 7533.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.7075 - val_loss: 7534.1138\n",
      "Epoch 225/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.7998\n",
      "Epoch 00225: val_loss did not improve from 7533.49902\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7538.7998 - val_loss: 7533.7090\n",
      "Epoch 226/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1147\n",
      "Epoch 00226: val_loss did not improve from 7533.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.1147 - val_loss: 7533.6870\n",
      "Epoch 227/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2476\n",
      "Epoch 00227: val_loss did not improve from 7533.49902\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.2476 - val_loss: 7533.9111\n",
      "Epoch 228/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4033\n",
      "Epoch 00228: val_loss did not improve from 7533.49902\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.4033 - val_loss: 7534.0815\n",
      "Epoch 229/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.0815\n",
      "Epoch 00229: val_loss did not improve from 7533.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.0815 - val_loss: 7534.1240\n",
      "Epoch 230/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.5688\n",
      "Epoch 00230: val_loss did not improve from 7533.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.5688 - val_loss: 7534.8071\n",
      "Epoch 231/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.9409\n",
      "Epoch 00231: val_loss did not improve from 7533.49902\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.9409 - val_loss: 7534.0327\n",
      "Epoch 232/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.0161\n",
      "Epoch 00232: val_loss improved from 7533.49902 to 7533.48242, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-232-7.53348e+03.hdf5\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7530.0161 - val_loss: 7533.4824\n",
      "Epoch 233/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8057\n",
      "Epoch 00233: val_loss did not improve from 7533.48242\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.8057 - val_loss: 7533.9346\n",
      "Epoch 234/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.4907\n",
      "Epoch 00234: val_loss did not improve from 7533.48242\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7543.4907 - val_loss: 7533.6094\n",
      "Epoch 235/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.9331\n",
      "Epoch 00235: val_loss did not improve from 7533.48242\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7523.9331 - val_loss: 7533.9609\n",
      "Epoch 236/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6196\n",
      "Epoch 00236: val_loss did not improve from 7533.48242\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.6196 - val_loss: 7534.6626\n",
      "Epoch 237/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2324\n",
      "Epoch 00237: val_loss did not improve from 7533.48242\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.2324 - val_loss: 7534.5166\n",
      "Epoch 238/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.2739\n",
      "Epoch 00238: val_loss did not improve from 7533.48242\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.2739 - val_loss: 7533.6943\n",
      "Epoch 239/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0767\n",
      "Epoch 00239: val_loss did not improve from 7533.48242\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.0767 - val_loss: 7534.1216\n",
      "Epoch 240/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7536.9458\n",
      "Epoch 00240: val_loss did not improve from 7533.48242\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.9458 - val_loss: 7533.8271\n",
      "Epoch 241/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.9795\n",
      "Epoch 00241: val_loss improved from 7533.48242 to 7533.44092, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-241-7.53344e+03.hdf5\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7524.9795 - val_loss: 7533.4409\n",
      "Epoch 242/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4600\n",
      "Epoch 00242: val_loss did not improve from 7533.44092\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.4600 - val_loss: 7534.8472\n",
      "Epoch 243/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5718\n",
      "Epoch 00243: val_loss did not improve from 7533.44092\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.5718 - val_loss: 7534.0176\n",
      "Epoch 244/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4224\n",
      "Epoch 00244: val_loss did not improve from 7533.44092\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.4224 - val_loss: 7534.0752\n",
      "Epoch 245/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7212\n",
      "Epoch 00245: val_loss did not improve from 7533.44092\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.7212 - val_loss: 7533.7158\n",
      "Epoch 246/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8760\n",
      "Epoch 00246: val_loss did not improve from 7533.44092\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.8760 - val_loss: 7534.0728\n",
      "Epoch 247/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3047\n",
      "Epoch 00247: val_loss did not improve from 7533.44092\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.3047 - val_loss: 7533.9111\n",
      "Epoch 248/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.7095\n",
      "Epoch 00248: val_loss did not improve from 7533.44092\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7523.7095 - val_loss: 7533.7319\n",
      "Epoch 249/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.5645\n",
      "Epoch 00249: val_loss did not improve from 7533.44092\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7544.5645 - val_loss: 7534.6094\n",
      "Epoch 250/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.5273\n",
      "Epoch 00250: val_loss improved from 7533.44092 to 7533.43604, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-250-7.53344e+03.hdf5\n",
      "25/25 [==============================] - 14s 541ms/step - loss: 7543.5273 - val_loss: 7533.4360\n",
      "Epoch 251/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.8892\n",
      "Epoch 00251: val_loss did not improve from 7533.43604\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7535.8892 - val_loss: 7534.0063\n",
      "Epoch 252/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8794\n",
      "Epoch 00252: val_loss improved from 7533.43604 to 7533.35205, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-252-7.53335e+03.hdf5\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7544.8794 - val_loss: 7533.3521\n",
      "Epoch 253/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.9473\n",
      "Epoch 00253: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.9473 - val_loss: 7533.3960\n",
      "Epoch 254/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1753\n",
      "Epoch 00254: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.1753 - val_loss: 7533.9321\n",
      "Epoch 255/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.9678\n",
      "Epoch 00255: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7545.9678 - val_loss: 7534.1055\n",
      "Epoch 256/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.7046\n",
      "Epoch 00256: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7524.7046 - val_loss: 7533.6377\n",
      "Epoch 257/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.1807\n",
      "Epoch 00257: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.1807 - val_loss: 7533.7041\n",
      "Epoch 258/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2969\n",
      "Epoch 00258: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7532.2969 - val_loss: 7534.9976\n",
      "Epoch 259/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1274\n",
      "Epoch 00259: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.1274 - val_loss: 7534.1289\n",
      "Epoch 260/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.3193\n",
      "Epoch 00260: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7539.3193 - val_loss: 7534.1782\n",
      "Epoch 261/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3506\n",
      "Epoch 00261: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7531.3506 - val_loss: 7533.8896\n",
      "Epoch 262/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6650\n",
      "Epoch 00262: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 14s 542ms/step - loss: 7532.6650 - val_loss: 7533.5200\n",
      "Epoch 263/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3799\n",
      "Epoch 00263: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.3799 - val_loss: 7533.9663\n",
      "Epoch 264/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.3716\n",
      "Epoch 00264: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7535.3716 - val_loss: 7533.6689\n",
      "Epoch 265/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.7563\n",
      "Epoch 00265: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7543.7563 - val_loss: 7533.7266\n",
      "Epoch 266/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.1382\n",
      "Epoch 00266: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7544.1382 - val_loss: 7534.0850\n",
      "Epoch 267/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1162\n",
      "Epoch 00267: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7531.1162 - val_loss: 7534.6191\n",
      "Epoch 268/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.5674\n",
      "Epoch 00268: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7545.5674 - val_loss: 7534.2192\n",
      "Epoch 269/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.7915\n",
      "Epoch 00269: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7535.7915 - val_loss: 7533.9097\n",
      "Epoch 270/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.9717\n",
      "Epoch 00270: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7535.9717 - val_loss: 7534.0103\n",
      "Epoch 271/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.7920\n",
      "Epoch 00271: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 14s 547ms/step - loss: 7543.7920 - val_loss: 7534.8096\n",
      "Epoch 272/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1890\n",
      "Epoch 00272: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7531.1890 - val_loss: 7534.7056\n",
      "Epoch 273/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8979\n",
      "Epoch 00273: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.8979 - val_loss: 7534.3145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.2671\n",
      "Epoch 00274: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7519.2671 - val_loss: 7534.4727\n",
      "Epoch 275/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3364\n",
      "Epoch 00275: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.3364 - val_loss: 7534.1025\n",
      "Epoch 276/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7896\n",
      "Epoch 00276: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.7896 - val_loss: 7533.6626\n",
      "Epoch 277/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7534\n",
      "Epoch 00277: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.7534 - val_loss: 7533.4126\n",
      "Epoch 278/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4458\n",
      "Epoch 00278: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.4458 - val_loss: 7533.7490\n",
      "Epoch 279/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.4219\n",
      "Epoch 00279: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.4219 - val_loss: 7533.5078\n",
      "Epoch 280/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6787\n",
      "Epoch 00280: val_loss did not improve from 7533.35205\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.6787 - val_loss: 7533.4927\n",
      "Epoch 281/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5044\n",
      "Epoch 00281: val_loss improved from 7533.35205 to 7533.22803, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-281-7.53323e+03.hdf5\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7532.5044 - val_loss: 7533.2280\n",
      "Epoch 282/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.1875\n",
      "Epoch 00282: val_loss did not improve from 7533.22803\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.1875 - val_loss: 7533.2642\n",
      "Epoch 283/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.3726\n",
      "Epoch 00283: val_loss did not improve from 7533.22803\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7530.3726 - val_loss: 7533.5034\n",
      "Epoch 284/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.1694\n",
      "Epoch 00284: val_loss did not improve from 7533.22803\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7540.1694 - val_loss: 7533.5903\n",
      "Epoch 285/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.4771\n",
      "Epoch 00285: val_loss did not improve from 7533.22803\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7518.4771 - val_loss: 7533.5239\n",
      "Epoch 286/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.7720\n",
      "Epoch 00286: val_loss did not improve from 7533.22803\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7523.7720 - val_loss: 7533.4897\n",
      "Epoch 287/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7812\n",
      "Epoch 00287: val_loss did not improve from 7533.22803\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7539.7812 - val_loss: 7534.3369\n",
      "Epoch 288/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0679\n",
      "Epoch 00288: val_loss did not improve from 7533.22803\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.0679 - val_loss: 7533.5815\n",
      "Epoch 289/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.2822\n",
      "Epoch 00289: val_loss did not improve from 7533.22803\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.2822 - val_loss: 7533.7793\n",
      "Epoch 290/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.0063\n",
      "Epoch 00290: val_loss did not improve from 7533.22803\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7529.0063 - val_loss: 7534.0342\n",
      "Epoch 291/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8145\n",
      "Epoch 00291: val_loss did not improve from 7533.22803\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.8145 - val_loss: 7533.6865\n",
      "Epoch 292/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8584\n",
      "Epoch 00292: val_loss did not improve from 7533.22803\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.8584 - val_loss: 7534.2007\n",
      "Epoch 293/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8813\n",
      "Epoch 00293: val_loss did not improve from 7533.22803\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.8813 - val_loss: 7534.5776\n",
      "Epoch 294/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.7544\n",
      "Epoch 00294: val_loss did not improve from 7533.22803\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7535.7544 - val_loss: 7533.5024\n",
      "Epoch 295/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.9951\n",
      "Epoch 00295: val_loss did not improve from 7533.22803\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7539.9951 - val_loss: 7533.4990\n",
      "Epoch 296/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.3105\n",
      "Epoch 00296: val_loss did not improve from 7533.22803\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7518.3105 - val_loss: 7533.4375\n",
      "Epoch 297/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.2417\n",
      "Epoch 00297: val_loss improved from 7533.22803 to 7533.13037, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-297-7.53313e+03.hdf5\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7543.2417 - val_loss: 7533.1304\n",
      "Epoch 298/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.1641\n",
      "Epoch 00298: val_loss did not improve from 7533.13037\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.1641 - val_loss: 7533.6865\n",
      "Epoch 299/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5962\n",
      "Epoch 00299: val_loss did not improve from 7533.13037\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.5962 - val_loss: 7533.2529\n",
      "Epoch 300/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.6577\n",
      "Epoch 00300: val_loss did not improve from 7533.13037\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7528.6577 - val_loss: 7533.8193\n",
      "Epoch 301/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3384\n",
      "Epoch 00301: val_loss did not improve from 7533.13037\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.3384 - val_loss: 7533.7129\n",
      "Epoch 302/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5820\n",
      "Epoch 00302: val_loss did not improve from 7533.13037\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.5820 - val_loss: 7533.3145\n",
      "Epoch 303/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.8242\n",
      "Epoch 00303: val_loss did not improve from 7533.13037\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7535.8242 - val_loss: 7533.2754\n",
      "Epoch 304/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6704\n",
      "Epoch 00304: val_loss improved from 7533.13037 to 7533.08496, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-304-7.53308e+03.hdf5\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7531.6704 - val_loss: 7533.0850\n",
      "Epoch 305/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.5723\n",
      "Epoch 00305: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7524.5723 - val_loss: 7533.4546\n",
      "Epoch 306/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.2148\n",
      "Epoch 00306: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7535.2148 - val_loss: 7533.6226\n",
      "Epoch 307/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7530.8359\n",
      "Epoch 00307: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.8359 - val_loss: 7533.6582\n",
      "Epoch 308/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.5757\n",
      "Epoch 00308: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.5757 - val_loss: 7533.7368\n",
      "Epoch 309/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.0405\n",
      "Epoch 00309: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.0405 - val_loss: 7533.9360\n",
      "Epoch 310/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0942\n",
      "Epoch 00310: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.0942 - val_loss: 7533.7134\n",
      "Epoch 311/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.7847\n",
      "Epoch 00311: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.7847 - val_loss: 7533.8442\n",
      "Epoch 312/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1572\n",
      "Epoch 00312: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.1572 - val_loss: 7533.5254\n",
      "Epoch 313/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.4243\n",
      "Epoch 00313: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7538.4243 - val_loss: 7533.2510\n",
      "Epoch 314/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6660\n",
      "Epoch 00314: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.6660 - val_loss: 7533.5088\n",
      "Epoch 315/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.3882\n",
      "Epoch 00315: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7518.3882 - val_loss: 7533.4160\n",
      "Epoch 316/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.5947\n",
      "Epoch 00316: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7523.5947 - val_loss: 7533.5889\n",
      "Epoch 317/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.6948\n",
      "Epoch 00317: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7528.6948 - val_loss: 7533.7905\n",
      "Epoch 318/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6084\n",
      "Epoch 00318: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.6084 - val_loss: 7533.3281\n",
      "Epoch 319/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8496\n",
      "Epoch 00319: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.8496 - val_loss: 7533.7998\n",
      "Epoch 320/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.9976\n",
      "Epoch 00320: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.9976 - val_loss: 7534.0864\n",
      "Epoch 321/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.7778\n",
      "Epoch 00321: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7523.7778 - val_loss: 7533.9502\n",
      "Epoch 322/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7656\n",
      "Epoch 00322: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.7656 - val_loss: 7533.4551\n",
      "Epoch 323/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.2412\n",
      "Epoch 00323: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.2412 - val_loss: 7534.2217\n",
      "Epoch 324/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.4521\n",
      "Epoch 00324: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.4521 - val_loss: 7534.9775\n",
      "Epoch 325/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6909\n",
      "Epoch 00325: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.6909 - val_loss: 7534.6265\n",
      "Epoch 326/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.4590\n",
      "Epoch 00326: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7525.4590 - val_loss: 7534.0879\n",
      "Epoch 327/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4097\n",
      "Epoch 00327: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.4097 - val_loss: 7533.5952\n",
      "Epoch 328/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2759\n",
      "Epoch 00328: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.2759 - val_loss: 7533.9521\n",
      "Epoch 329/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4648\n",
      "Epoch 00329: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.4648 - val_loss: 7534.7544\n",
      "Epoch 330/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4160\n",
      "Epoch 00330: val_loss did not improve from 7533.08496\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.4160 - val_loss: 7533.9473\n",
      "Epoch 331/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4780\n",
      "Epoch 00331: val_loss improved from 7533.08496 to 7533.03369, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-331-7.53303e+03.hdf5\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7531.4780 - val_loss: 7533.0337\n",
      "Epoch 332/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.1245\n",
      "Epoch 00332: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7528.1245 - val_loss: 7533.3623\n",
      "Epoch 333/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.3442\n",
      "Epoch 00333: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.3442 - val_loss: 7533.4023\n",
      "Epoch 334/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.9731\n",
      "Epoch 00334: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.9731 - val_loss: 7533.3198\n",
      "Epoch 335/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.3252\n",
      "Epoch 00335: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.3252 - val_loss: 7533.2847\n",
      "Epoch 336/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8140\n",
      "Epoch 00336: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.8140 - val_loss: 7533.1982\n",
      "Epoch 337/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.9741\n",
      "Epoch 00337: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7535.9741 - val_loss: 7533.4287\n",
      "Epoch 338/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.4980\n",
      "Epoch 00338: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7523.4980 - val_loss: 7533.4702\n",
      "Epoch 339/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.7588\n",
      "Epoch 00339: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.7588 - val_loss: 7534.1426\n",
      "Epoch 340/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4604\n",
      "Epoch 00340: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7537.4604 - val_loss: 7533.7295\n",
      "Epoch 341/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7334\n",
      "Epoch 00341: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.7334 - val_loss: 7533.2417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.6313\n",
      "Epoch 00342: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.6313 - val_loss: 7533.3862\n",
      "Epoch 343/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.5605\n",
      "Epoch 00343: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.5605 - val_loss: 7534.3882\n",
      "Epoch 344/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8423\n",
      "Epoch 00344: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7536.8423 - val_loss: 7534.9048\n",
      "Epoch 345/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7773\n",
      "Epoch 00345: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7536.7773 - val_loss: 7534.3159\n",
      "Epoch 346/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7564.2930\n",
      "Epoch 00346: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7564.2930 - val_loss: 7551.8311\n",
      "Epoch 347/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.7788\n",
      "Epoch 00347: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7526.7788 - val_loss: 7534.6826\n",
      "Epoch 348/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5928\n",
      "Epoch 00348: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.5928 - val_loss: 7533.8086\n",
      "Epoch 349/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1050\n",
      "Epoch 00349: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7537.1050 - val_loss: 7533.3662\n",
      "Epoch 350/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.2666\n",
      "Epoch 00350: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.2666 - val_loss: 7533.4312\n",
      "Epoch 351/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4492\n",
      "Epoch 00351: val_loss did not improve from 7533.03369\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7535.4492 - val_loss: 7533.2271\n",
      "Epoch 352/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.5879\n",
      "Epoch 00352: val_loss improved from 7533.03369 to 7532.98877, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-352-7.53299e+03.hdf5\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7544.5879 - val_loss: 7532.9888\n",
      "Epoch 353/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.5225\n",
      "Epoch 00353: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.5225 - val_loss: 7533.2007\n",
      "Epoch 354/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5181\n",
      "Epoch 00354: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.5181 - val_loss: 7534.0210\n",
      "Epoch 355/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4575\n",
      "Epoch 00355: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.4575 - val_loss: 7533.0151\n",
      "Epoch 356/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1562\n",
      "Epoch 00356: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7537.1562 - val_loss: 7534.8594\n",
      "Epoch 357/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.6211\n",
      "Epoch 00357: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.6211 - val_loss: 7533.8896\n",
      "Epoch 358/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.8916\n",
      "Epoch 00358: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7526.8916 - val_loss: 7536.6050\n",
      "Epoch 359/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.3188\n",
      "Epoch 00359: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7545.3188 - val_loss: 7534.9839\n",
      "Epoch 360/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6455\n",
      "Epoch 00360: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.6455 - val_loss: 7534.0386\n",
      "Epoch 361/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.9946\n",
      "Epoch 00361: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7518.9946 - val_loss: 7533.9600\n",
      "Epoch 362/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.3018\n",
      "Epoch 00362: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7535.3018 - val_loss: 7533.1094\n",
      "Epoch 363/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.0215\n",
      "Epoch 00363: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7545.0215 - val_loss: 7534.9634\n",
      "Epoch 364/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6108\n",
      "Epoch 00364: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.6108 - val_loss: 7534.1216\n",
      "Epoch 365/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1816\n",
      "Epoch 00365: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.1816 - val_loss: 7533.7290\n",
      "Epoch 366/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5923\n",
      "Epoch 00366: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7531.5923 - val_loss: 7533.2959\n",
      "Epoch 367/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.5361\n",
      "Epoch 00367: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7524.5361 - val_loss: 7533.0225\n",
      "Epoch 368/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.3940\n",
      "Epoch 00368: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7543.3940 - val_loss: 7533.4575\n",
      "Epoch 369/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.5830\n",
      "Epoch 00369: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.5830 - val_loss: 7534.3857\n",
      "Epoch 370/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.3789\n",
      "Epoch 00370: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7523.3789 - val_loss: 7533.3110\n",
      "Epoch 371/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.4629\n",
      "Epoch 00371: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7518.4629 - val_loss: 7533.4375\n",
      "Epoch 372/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.7656\n",
      "Epoch 00372: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.7656 - val_loss: 7533.2031\n",
      "Epoch 373/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.6938\n",
      "Epoch 00373: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7535.6938 - val_loss: 7533.3130\n",
      "Epoch 374/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1035\n",
      "Epoch 00374: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.1035 - val_loss: 7533.6138\n",
      "Epoch 375/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8916\n",
      "Epoch 00375: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.8916 - val_loss: 7533.5073\n",
      "Epoch 376/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3350\n",
      "Epoch 00376: val_loss did not improve from 7532.98877\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7536.3350 - val_loss: 7533.7393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.0747\n",
      "Epoch 00377: val_loss improved from 7532.98877 to 7532.86621, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-377-7.53287e+03.hdf5\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7518.0747 - val_loss: 7532.8662\n",
      "Epoch 378/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2700\n",
      "Epoch 00378: val_loss did not improve from 7532.86621\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.2700 - val_loss: 7532.9775\n",
      "Epoch 379/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.2285\n",
      "Epoch 00379: val_loss improved from 7532.86621 to 7532.79688, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-379-7.53280e+03.hdf5\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7524.2285 - val_loss: 7532.7969\n",
      "Epoch 380/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6343\n",
      "Epoch 00380: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.6343 - val_loss: 7534.6138\n",
      "Epoch 381/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0869\n",
      "Epoch 00381: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7536.0869 - val_loss: 7533.9097\n",
      "Epoch 382/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1069\n",
      "Epoch 00382: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7533.1069 - val_loss: 7534.7598\n",
      "Epoch 383/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8496\n",
      "Epoch 00383: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.8496 - val_loss: 7533.4014\n",
      "Epoch 384/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4741\n",
      "Epoch 00384: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7535.4741 - val_loss: 7533.5449\n",
      "Epoch 385/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.4463\n",
      "Epoch 00385: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7538.4463 - val_loss: 7533.2393\n",
      "Epoch 386/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.0312\n",
      "Epoch 00386: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7518.0312 - val_loss: 7532.9062\n",
      "Epoch 387/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.0137\n",
      "Epoch 00387: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7543.0137 - val_loss: 7533.0850\n",
      "Epoch 388/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.1890\n",
      "Epoch 00388: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7546.1890 - val_loss: 7534.2295\n",
      "Epoch 389/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9419\n",
      "Epoch 00389: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.9419 - val_loss: 7533.3774\n",
      "Epoch 390/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.0967\n",
      "Epoch 00390: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7542.0967 - val_loss: 7533.4482\n",
      "Epoch 391/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.2930\n",
      "Epoch 00391: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 540ms/step - loss: 7544.2930 - val_loss: 7535.6758\n",
      "Epoch 392/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.2456\n",
      "Epoch 00392: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7526.2456 - val_loss: 7535.2368\n",
      "Epoch 393/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2471\n",
      "Epoch 00393: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7532.2471 - val_loss: 7534.2466\n",
      "Epoch 394/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.5513\n",
      "Epoch 00394: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7526.5513 - val_loss: 7534.8833\n",
      "Epoch 395/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7495\n",
      "Epoch 00395: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.7495 - val_loss: 7533.5088\n",
      "Epoch 396/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.1284\n",
      "Epoch 00396: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7540.1284 - val_loss: 7533.5918\n",
      "Epoch 397/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9097\n",
      "Epoch 00397: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7531.9097 - val_loss: 7533.5151\n",
      "Epoch 398/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2993\n",
      "Epoch 00398: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.2993 - val_loss: 7533.1362\n",
      "Epoch 399/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.1182\n",
      "Epoch 00399: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.1182 - val_loss: 7533.1704\n",
      "Epoch 400/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.2158\n",
      "Epoch 00400: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7544.2158 - val_loss: 7533.8706\n",
      "Epoch 401/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8447\n",
      "Epoch 00401: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.8447 - val_loss: 7533.4463\n",
      "Epoch 402/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.8633\n",
      "Epoch 00402: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7529.8633 - val_loss: 7533.2007\n",
      "Epoch 403/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.9897\n",
      "Epoch 00403: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7543.9897 - val_loss: 7533.7446\n",
      "Epoch 404/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.1094\n",
      "Epoch 00404: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7524.1094 - val_loss: 7534.0640\n",
      "Epoch 405/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.8716\n",
      "Epoch 00405: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.8716 - val_loss: 7568.1553\n",
      "Epoch 406/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.2061\n",
      "Epoch 00406: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7536.2061 - val_loss: 7537.2256\n",
      "Epoch 407/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3413\n",
      "Epoch 00407: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7531.3413 - val_loss: 7534.6846\n",
      "Epoch 408/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.1519\n",
      "Epoch 00408: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.1519 - val_loss: 7533.8550\n",
      "Epoch 409/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4771\n",
      "Epoch 00409: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.4771 - val_loss: 7533.8794\n",
      "Epoch 410/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5312\n",
      "Epoch 00410: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.5312 - val_loss: 7534.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.6035\n",
      "Epoch 00411: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7543.6035 - val_loss: 7533.7417\n",
      "Epoch 412/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5576\n",
      "Epoch 00412: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7536.5576 - val_loss: 7533.5391\n",
      "Epoch 413/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.1641\n",
      "Epoch 00413: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.1641 - val_loss: 7533.7402\n",
      "Epoch 414/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5649\n",
      "Epoch 00414: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.5649 - val_loss: 7532.8638\n",
      "Epoch 415/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0615\n",
      "Epoch 00415: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.0615 - val_loss: 7532.9761\n",
      "Epoch 416/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.7070\n",
      "Epoch 00416: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.7070 - val_loss: 7533.1050\n",
      "Epoch 417/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.3364\n",
      "Epoch 00417: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7523.3364 - val_loss: 7533.3242\n",
      "Epoch 418/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4888\n",
      "Epoch 00418: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.4888 - val_loss: 7533.7974\n",
      "Epoch 419/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.6611\n",
      "Epoch 00419: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7524.6611 - val_loss: 7533.4438\n",
      "Epoch 420/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.6479\n",
      "Epoch 00420: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7524.6479 - val_loss: 7533.3047\n",
      "Epoch 421/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.7690\n",
      "Epoch 00421: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7518.7690 - val_loss: 7533.6504\n",
      "Epoch 422/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.8394\n",
      "Epoch 00422: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7541.8394 - val_loss: 7533.1855\n",
      "Epoch 423/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1958\n",
      "Epoch 00423: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.1958 - val_loss: 7534.0225\n",
      "Epoch 424/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6655\n",
      "Epoch 00424: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7536.6655 - val_loss: 7534.3838\n",
      "Epoch 425/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.6816\n",
      "Epoch 00425: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7543.6816 - val_loss: 7533.7583\n",
      "Epoch 426/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.5127\n",
      "Epoch 00426: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7540.5127 - val_loss: 7534.4697\n",
      "Epoch 427/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9526\n",
      "Epoch 00427: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.9526 - val_loss: 7533.6670\n",
      "Epoch 428/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7607\n",
      "Epoch 00428: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7530.7607 - val_loss: 7533.6641\n",
      "Epoch 429/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.5542\n",
      "Epoch 00429: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7535.5542 - val_loss: 7533.4839\n",
      "Epoch 430/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.7690\n",
      "Epoch 00430: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.7690 - val_loss: 7536.0063\n",
      "Epoch 431/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3750\n",
      "Epoch 00431: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7536.3750 - val_loss: 7534.2280\n",
      "Epoch 432/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.9458\n",
      "Epoch 00432: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7524.9458 - val_loss: 7533.5903\n",
      "Epoch 433/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.7485\n",
      "Epoch 00433: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7535.7485 - val_loss: 7533.4609\n",
      "Epoch 434/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.4629\n",
      "Epoch 00434: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 14s 542ms/step - loss: 7545.4629 - val_loss: 7534.2896\n",
      "Epoch 435/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6768\n",
      "Epoch 00435: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7532.6768 - val_loss: 7534.4072\n",
      "Epoch 436/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4482\n",
      "Epoch 00436: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7535.4482 - val_loss: 7533.3696\n",
      "Epoch 437/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.3110\n",
      "Epoch 00437: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7523.3110 - val_loss: 7533.2578\n",
      "Epoch 438/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.1401\n",
      "Epoch 00438: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7518.1401 - val_loss: 7533.4673\n",
      "Epoch 439/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.1406\n",
      "Epoch 00439: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.1406 - val_loss: 7533.5112\n",
      "Epoch 440/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5425\n",
      "Epoch 00440: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7539.5425 - val_loss: 7533.2720\n",
      "Epoch 441/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4604\n",
      "Epoch 00441: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.4604 - val_loss: 7533.7583\n",
      "Epoch 442/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8887\n",
      "Epoch 00442: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.8887 - val_loss: 7533.7954\n",
      "Epoch 443/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.9219\n",
      "Epoch 00443: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.9219 - val_loss: 7533.5874\n",
      "Epoch 444/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5210\n",
      "Epoch 00444: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.5210 - val_loss: 7533.4390\n",
      "Epoch 445/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.0361\n",
      "Epoch 00445: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7527.0361 - val_loss: 7534.6602\n",
      "Epoch 446/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7542.9946\n",
      "Epoch 00446: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7542.9946 - val_loss: 7534.0063\n",
      "Epoch 447/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.6279\n",
      "Epoch 00447: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7530.6279 - val_loss: 7533.4346\n",
      "Epoch 448/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8623\n",
      "Epoch 00448: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7544.8623 - val_loss: 7533.4673\n",
      "Epoch 449/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.5869\n",
      "Epoch 00449: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7528.5869 - val_loss: 7533.4561\n",
      "Epoch 450/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.1851\n",
      "Epoch 00450: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7530.1851 - val_loss: 7533.1382\n",
      "Epoch 451/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.2700\n",
      "Epoch 00451: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7543.2700 - val_loss: 7533.4160\n",
      "Epoch 452/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.4731\n",
      "Epoch 00452: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7542.4731 - val_loss: 7533.7495\n",
      "Epoch 453/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.9751\n",
      "Epoch 00453: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.9751 - val_loss: 7533.5601\n",
      "Epoch 454/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.7896\n",
      "Epoch 00454: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7538.7896 - val_loss: 7533.4038\n",
      "Epoch 455/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.4224\n",
      "Epoch 00455: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7543.4224 - val_loss: 7533.4111\n",
      "Epoch 456/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5405\n",
      "Epoch 00456: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7536.5405 - val_loss: 7533.7935\n",
      "Epoch 457/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6309\n",
      "Epoch 00457: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7537.6309 - val_loss: 7534.0386\n",
      "Epoch 458/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8740\n",
      "Epoch 00458: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.8740 - val_loss: 7534.5166\n",
      "Epoch 459/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.3970\n",
      "Epoch 00459: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7542.3970 - val_loss: 7533.9062\n",
      "Epoch 460/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.8667\n",
      "Epoch 00460: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7524.8667 - val_loss: 7533.2598\n",
      "Epoch 461/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.0815\n",
      "Epoch 00461: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7545.0815 - val_loss: 7533.6274\n",
      "Epoch 462/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.6958\n",
      "Epoch 00462: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.6958 - val_loss: 7535.6006\n",
      "Epoch 463/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.6309\n",
      "Epoch 00463: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.6309 - val_loss: 7534.4463\n",
      "Epoch 464/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5786\n",
      "Epoch 00464: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7539.5786 - val_loss: 7533.2153\n",
      "Epoch 465/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.8281\n",
      "Epoch 00465: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.8281 - val_loss: 7533.7471\n",
      "Epoch 466/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9639\n",
      "Epoch 00466: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.9639 - val_loss: 7533.4346\n",
      "Epoch 467/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2007\n",
      "Epoch 00467: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.2007 - val_loss: 7533.1641\n",
      "Epoch 468/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.6865\n",
      "Epoch 00468: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.6865 - val_loss: 7534.0825\n",
      "Epoch 469/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7275\n",
      "Epoch 00469: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.7275 - val_loss: 7534.1519\n",
      "Epoch 470/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.2007\n",
      "Epoch 00470: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7526.2007 - val_loss: 7534.7998\n",
      "Epoch 471/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9087\n",
      "Epoch 00471: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7531.9087 - val_loss: 7533.4600\n",
      "Epoch 472/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0444\n",
      "Epoch 00472: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.0444 - val_loss: 7533.6367\n",
      "Epoch 473/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.1465\n",
      "Epoch 00473: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.1465 - val_loss: 7534.2529\n",
      "Epoch 474/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.6455\n",
      "Epoch 00474: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.6455 - val_loss: 7533.8184\n",
      "Epoch 475/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4824\n",
      "Epoch 00475: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.4824 - val_loss: 7533.0786\n",
      "Epoch 476/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7002\n",
      "Epoch 00476: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.7002 - val_loss: 7533.6313\n",
      "Epoch 477/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.3545\n",
      "Epoch 00477: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.3545 - val_loss: 7533.1440\n",
      "Epoch 478/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7188\n",
      "Epoch 00478: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.7188 - val_loss: 7534.1846\n",
      "Epoch 479/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.2847\n",
      "Epoch 00479: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.2847 - val_loss: 7533.4414\n",
      "Epoch 480/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2026\n",
      "Epoch 00480: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.2026 - val_loss: 7533.6177\n",
      "Epoch 481/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7525.0479\n",
      "Epoch 00481: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7525.0479 - val_loss: 7533.4897\n",
      "Epoch 482/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4697\n",
      "Epoch 00482: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.4697 - val_loss: 7533.1558\n",
      "Epoch 483/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.3452\n",
      "Epoch 00483: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.3452 - val_loss: 7533.2847\n",
      "Epoch 484/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.4531\n",
      "Epoch 00484: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7542.4531 - val_loss: 7534.0303\n",
      "Epoch 485/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5879\n",
      "Epoch 00485: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.5879 - val_loss: 7534.3936\n",
      "Epoch 486/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4185\n",
      "Epoch 00486: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.4185 - val_loss: 7532.9673\n",
      "Epoch 487/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.1221\n",
      "Epoch 00487: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7542.1221 - val_loss: 7533.2783\n",
      "Epoch 488/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4980\n",
      "Epoch 00488: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.4980 - val_loss: 7533.0952\n",
      "Epoch 489/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8853\n",
      "Epoch 00489: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.8853 - val_loss: 7533.3809\n",
      "Epoch 490/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.8159\n",
      "Epoch 00490: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7527.8159 - val_loss: 7533.0854\n",
      "Epoch 491/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.5483\n",
      "Epoch 00491: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.5483 - val_loss: 7535.6006\n",
      "Epoch 492/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.1821\n",
      "Epoch 00492: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7545.1821 - val_loss: 7533.8418\n",
      "Epoch 493/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.7495\n",
      "Epoch 00493: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7524.7495 - val_loss: 7533.4209\n",
      "Epoch 494/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8535\n",
      "Epoch 00494: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.8535 - val_loss: 7533.3286\n",
      "Epoch 495/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.0420\n",
      "Epoch 00495: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.0420 - val_loss: 7533.3306\n",
      "Epoch 496/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.3369\n",
      "Epoch 00496: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.3369 - val_loss: 7532.8950\n",
      "Epoch 497/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.6846\n",
      "Epoch 00497: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.6846 - val_loss: 7533.5112\n",
      "Epoch 498/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.4033\n",
      "Epoch 00498: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7539.4033 - val_loss: 7534.4448\n",
      "Epoch 499/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3823\n",
      "Epoch 00499: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.3823 - val_loss: 7535.8857\n",
      "Epoch 500/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.9829\n",
      "Epoch 00500: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7544.9829 - val_loss: 7533.2905\n",
      "Epoch 501/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8994\n",
      "Epoch 00501: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7536.8994 - val_loss: 7533.6704\n",
      "Epoch 502/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7861\n",
      "Epoch 00502: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7536.7861 - val_loss: 7533.5112\n",
      "Epoch 503/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.9199\n",
      "Epoch 00503: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.9199 - val_loss: 7533.1758\n",
      "Epoch 504/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.6680\n",
      "Epoch 00504: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7528.6680 - val_loss: 7533.9121\n",
      "Epoch 505/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9458\n",
      "Epoch 00505: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.9458 - val_loss: 7533.9727\n",
      "Epoch 506/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.9165\n",
      "Epoch 00506: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7542.9165 - val_loss: 7534.0078\n",
      "Epoch 507/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0923\n",
      "Epoch 00507: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7532.0923 - val_loss: 7533.8799\n",
      "Epoch 508/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4741\n",
      "Epoch 00508: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.4741 - val_loss: 7534.2290\n",
      "Epoch 509/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.9575\n",
      "Epoch 00509: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.9575 - val_loss: 7534.9482\n",
      "Epoch 510/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.1709\n",
      "Epoch 00510: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7525.1709 - val_loss: 7533.7642\n",
      "Epoch 511/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.5454\n",
      "Epoch 00511: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7523.5454 - val_loss: 7533.3594\n",
      "Epoch 512/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1465\n",
      "Epoch 00512: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7537.1465 - val_loss: 7533.4033\n",
      "Epoch 513/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.5908\n",
      "Epoch 00513: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7529.5908 - val_loss: 7532.8872\n",
      "Epoch 514/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4624\n",
      "Epoch 00514: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7535.4624 - val_loss: 7533.2944\n",
      "Epoch 515/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2124\n",
      "Epoch 00515: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.2124 - val_loss: 7534.9136\n",
      "Epoch 516/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7538.9766\n",
      "Epoch 00516: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7538.9766 - val_loss: 7533.6816\n",
      "Epoch 517/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.3804\n",
      "Epoch 00517: val_loss did not improve from 7532.79688\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7518.3804 - val_loss: 7533.5830\n",
      "Epoch 518/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4395\n",
      "Epoch 00518: val_loss improved from 7532.79688 to 7532.70020, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-518-7.53270e+03.hdf5\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7530.4395 - val_loss: 7532.7002\n",
      "Epoch 519/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7522.7612\n",
      "Epoch 00519: val_loss did not improve from 7532.70020\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7522.7612 - val_loss: 7532.8320\n",
      "Epoch 520/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4062\n",
      "Epoch 00520: val_loss did not improve from 7532.70020\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.4062 - val_loss: 7533.2090\n",
      "Epoch 521/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.2871\n",
      "Epoch 00521: val_loss did not improve from 7532.70020\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.2871 - val_loss: 7533.9536\n",
      "Epoch 522/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.9585\n",
      "Epoch 00522: val_loss did not improve from 7532.70020\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7544.9585 - val_loss: 7533.0176\n",
      "Epoch 523/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.2251\n",
      "Epoch 00523: val_loss did not improve from 7532.70020\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7528.2251 - val_loss: 7533.5186\n",
      "Epoch 524/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2393\n",
      "Epoch 00524: val_loss did not improve from 7532.70020\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.2393 - val_loss: 7534.9375\n",
      "Epoch 525/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.1416\n",
      "Epoch 00525: val_loss did not improve from 7532.70020\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.1416 - val_loss: 7533.4648\n",
      "Epoch 526/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0840\n",
      "Epoch 00526: val_loss did not improve from 7532.70020\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7531.0840 - val_loss: 7533.7754\n",
      "Epoch 527/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.2056\n",
      "Epoch 00527: val_loss did not improve from 7532.70020\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.2056 - val_loss: 7533.1865\n",
      "Epoch 528/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2095\n",
      "Epoch 00528: val_loss did not improve from 7532.70020\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.2095 - val_loss: 7533.7402\n",
      "Epoch 529/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.2031\n",
      "Epoch 00529: val_loss did not improve from 7532.70020\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7542.2031 - val_loss: 7533.1689\n",
      "Epoch 530/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.8145\n",
      "Epoch 00530: val_loss did not improve from 7532.70020\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7528.8145 - val_loss: 7533.6030\n",
      "Epoch 531/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.0776\n",
      "Epoch 00531: val_loss improved from 7532.70020 to 7532.66943, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-531-7.53267e+03.hdf5\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7535.0776 - val_loss: 7532.6694\n",
      "Epoch 532/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8853\n",
      "Epoch 00532: val_loss did not improve from 7532.66943\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.8853 - val_loss: 7533.0249\n",
      "Epoch 533/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.2510\n",
      "Epoch 00533: val_loss did not improve from 7532.66943\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.2510 - val_loss: 7534.3242\n",
      "Epoch 534/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.0005\n",
      "Epoch 00534: val_loss did not improve from 7532.66943\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.0005 - val_loss: 7533.1055\n",
      "Epoch 535/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4844\n",
      "Epoch 00535: val_loss did not improve from 7532.66943\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7535.4844 - val_loss: 7533.2178\n",
      "Epoch 536/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0356\n",
      "Epoch 00536: val_loss did not improve from 7532.66943\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.0356 - val_loss: 7533.3130\n",
      "Epoch 537/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8857\n",
      "Epoch 00537: val_loss did not improve from 7532.66943\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7531.8857 - val_loss: 7532.7383\n",
      "Epoch 538/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.5684\n",
      "Epoch 00538: val_loss did not improve from 7532.66943\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.5684 - val_loss: 7532.7407\n",
      "Epoch 539/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.7515\n",
      "Epoch 00539: val_loss did not improve from 7532.66943\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.7515 - val_loss: 7532.9922\n",
      "Epoch 540/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7524\n",
      "Epoch 00540: val_loss did not improve from 7532.66943\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.7524 - val_loss: 7533.7422\n",
      "Epoch 541/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.1514\n",
      "Epoch 00541: val_loss did not improve from 7532.66943\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7528.1514 - val_loss: 7533.2759\n",
      "Epoch 542/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8687\n",
      "Epoch 00542: val_loss did not improve from 7532.66943\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.8687 - val_loss: 7533.2305\n",
      "Epoch 543/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7520\n",
      "Epoch 00543: val_loss did not improve from 7532.66943\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.7520 - val_loss: 7532.9111\n",
      "Epoch 544/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.9526\n",
      "Epoch 00544: val_loss did not improve from 7532.66943\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7535.9526 - val_loss: 7533.2930\n",
      "Epoch 545/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1655\n",
      "Epoch 00545: val_loss did not improve from 7532.66943\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.1655 - val_loss: 7533.0376\n",
      "Epoch 546/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.5312\n",
      "Epoch 00546: val_loss did not improve from 7532.66943\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.5312 - val_loss: 7532.6865\n",
      "Epoch 547/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4233\n",
      "Epoch 00547: val_loss improved from 7532.66943 to 7532.63135, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-547-7.53263e+03.hdf5\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7531.4233 - val_loss: 7532.6313\n",
      "Epoch 548/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.0737\n",
      "Epoch 00548: val_loss improved from 7532.63135 to 7532.62256, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-548-7.53262e+03.hdf5\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7544.0737 - val_loss: 7532.6226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 549/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8647\n",
      "Epoch 00549: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.8647 - val_loss: 7532.7119\n",
      "Epoch 550/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3960\n",
      "Epoch 00550: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.3960 - val_loss: 7534.5312\n",
      "Epoch 551/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8579\n",
      "Epoch 00551: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.8579 - val_loss: 7532.9976\n",
      "Epoch 552/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.4243\n",
      "Epoch 00552: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7539.4243 - val_loss: 7533.0249\n",
      "Epoch 553/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4619\n",
      "Epoch 00553: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.4619 - val_loss: 7533.1904\n",
      "Epoch 554/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.8208\n",
      "Epoch 00554: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7518.8208 - val_loss: 7533.6050\n",
      "Epoch 555/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.9399\n",
      "Epoch 00555: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7524.9399 - val_loss: 7533.7046\n",
      "Epoch 556/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.3467\n",
      "Epoch 00556: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7528.3467 - val_loss: 7533.4336\n",
      "Epoch 557/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.5356\n",
      "Epoch 00557: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.5356 - val_loss: 7532.7905\n",
      "Epoch 558/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.7197\n",
      "Epoch 00558: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7524.7197 - val_loss: 7533.6958\n",
      "Epoch 559/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.8833\n",
      "Epoch 00559: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7529.8833 - val_loss: 7533.1406\n",
      "Epoch 560/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.8135\n",
      "Epoch 00560: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7542.8135 - val_loss: 7533.1138\n",
      "Epoch 561/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.5737\n",
      "Epoch 00561: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7524.5737 - val_loss: 7533.0776\n",
      "Epoch 562/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.9844\n",
      "Epoch 00562: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7518.9844 - val_loss: 7533.6118\n",
      "Epoch 563/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1973\n",
      "Epoch 00563: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.1973 - val_loss: 7533.8174\n",
      "Epoch 564/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.9531\n",
      "Epoch 00564: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7527.9531 - val_loss: 7533.4209\n",
      "Epoch 565/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.1777\n",
      "Epoch 00565: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7543.1777 - val_loss: 7533.5415\n",
      "Epoch 566/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.9321\n",
      "Epoch 00566: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7544.9321 - val_loss: 7533.2959\n",
      "Epoch 567/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.8130\n",
      "Epoch 00567: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7527.8130 - val_loss: 7533.0840\n",
      "Epoch 568/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.2627\n",
      "Epoch 00568: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.2627 - val_loss: 7533.4160\n",
      "Epoch 569/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5366\n",
      "Epoch 00569: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.5366 - val_loss: 7533.7534\n",
      "Epoch 570/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5117\n",
      "Epoch 00570: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.5117 - val_loss: 7534.2490\n",
      "Epoch 571/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.0723\n",
      "Epoch 00571: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.0723 - val_loss: 7533.1943\n",
      "Epoch 572/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.3125\n",
      "Epoch 00572: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.3125 - val_loss: 7533.0527\n",
      "Epoch 573/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.0327\n",
      "Epoch 00573: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.0327 - val_loss: 7535.0249\n",
      "Epoch 574/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0029\n",
      "Epoch 00574: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.0029 - val_loss: 7533.6738\n",
      "Epoch 575/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.9751\n",
      "Epoch 00575: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7530.9751 - val_loss: 7532.9888\n",
      "Epoch 576/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3154\n",
      "Epoch 00576: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.3154 - val_loss: 7532.8975\n",
      "Epoch 577/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.4175\n",
      "Epoch 00577: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7539.4175 - val_loss: 7533.1694\n",
      "Epoch 578/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.9995\n",
      "Epoch 00578: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7523.9995 - val_loss: 7532.7935\n",
      "Epoch 579/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.6787\n",
      "Epoch 00579: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7542.6787 - val_loss: 7532.9888\n",
      "Epoch 580/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.9478\n",
      "Epoch 00580: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7527.9478 - val_loss: 7533.0376\n",
      "Epoch 581/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2539\n",
      "Epoch 00581: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.2539 - val_loss: 7532.7959\n",
      "Epoch 582/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.3218\n",
      "Epoch 00582: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.3218 - val_loss: 7533.8760\n",
      "Epoch 583/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3770\n",
      "Epoch 00583: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.3770 - val_loss: 7532.8711\n",
      "Epoch 584/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7535.0063\n",
      "Epoch 00584: val_loss did not improve from 7532.62256\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7535.0063 - val_loss: 7533.0591\n",
      "Epoch 585/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0664\n",
      "Epoch 00585: val_loss improved from 7532.62256 to 7532.49902, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-585-7.53250e+03.hdf5\n",
      "25/25 [==============================] - 13s 540ms/step - loss: 7531.0664 - val_loss: 7532.4990\n",
      "Epoch 586/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0972\n",
      "Epoch 00586: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.0972 - val_loss: 7532.7578\n",
      "Epoch 587/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2041\n",
      "Epoch 00587: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.2041 - val_loss: 7532.6978\n",
      "Epoch 588/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.9443\n",
      "Epoch 00588: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.9443 - val_loss: 7532.6982\n",
      "Epoch 589/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.2412\n",
      "Epoch 00589: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.2412 - val_loss: 7532.9712\n",
      "Epoch 590/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.1406\n",
      "Epoch 00590: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.1406 - val_loss: 7532.7856\n",
      "Epoch 591/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0942\n",
      "Epoch 00591: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.0942 - val_loss: 7532.6968\n",
      "Epoch 592/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.5229\n",
      "Epoch 00592: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.5229 - val_loss: 7532.5249\n",
      "Epoch 593/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.8516\n",
      "Epoch 00593: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.8516 - val_loss: 7532.6431\n",
      "Epoch 594/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.6274\n",
      "Epoch 00594: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.6274 - val_loss: 7532.9248\n",
      "Epoch 595/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8555\n",
      "Epoch 00595: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.8555 - val_loss: 7533.4194\n",
      "Epoch 596/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.6328\n",
      "Epoch 00596: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.6328 - val_loss: 7533.5190\n",
      "Epoch 597/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.0312\n",
      "Epoch 00597: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7518.0312 - val_loss: 7532.8926\n",
      "Epoch 598/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9980\n",
      "Epoch 00598: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7531.9980 - val_loss: 7532.6992\n",
      "Epoch 599/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.7798\n",
      "Epoch 00599: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7527.7798 - val_loss: 7532.8481\n",
      "Epoch 600/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.2959\n",
      "Epoch 00600: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7535.2959 - val_loss: 7532.5986\n",
      "Epoch 601/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.9390\n",
      "Epoch 00601: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7538.9390 - val_loss: 7532.6846\n",
      "Epoch 602/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.6284\n",
      "Epoch 00602: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7527.6284 - val_loss: 7533.0303\n",
      "Epoch 603/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.9917\n",
      "Epoch 00603: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7542.9917 - val_loss: 7533.2944\n",
      "Epoch 604/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.3774\n",
      "Epoch 00604: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7535.3774 - val_loss: 7533.4048\n",
      "Epoch 605/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8120\n",
      "Epoch 00605: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.8120 - val_loss: 7535.3066\n",
      "Epoch 606/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3604\n",
      "Epoch 00606: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.3604 - val_loss: 7534.4238\n",
      "Epoch 607/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7749\n",
      "Epoch 00607: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7530.7749 - val_loss: 7533.2578\n",
      "Epoch 608/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8379\n",
      "Epoch 00608: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.8379 - val_loss: 7533.3721\n",
      "Epoch 609/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7571.2109\n",
      "Epoch 00609: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7571.2109 - val_loss: 7546.4199\n",
      "Epoch 610/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1304\n",
      "Epoch 00610: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.1304 - val_loss: 7535.9360\n",
      "Epoch 611/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.7158\n",
      "Epoch 00611: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.7158 - val_loss: 7535.9863\n",
      "Epoch 612/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.9839\n",
      "Epoch 00612: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7529.9839 - val_loss: 7535.4785\n",
      "Epoch 613/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6528\n",
      "Epoch 00613: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7536.6528 - val_loss: 7534.0679\n",
      "Epoch 614/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8618\n",
      "Epoch 00614: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7538.8618 - val_loss: 7535.7607\n",
      "Epoch 615/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9897\n",
      "Epoch 00615: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.9897 - val_loss: 7537.4590\n",
      "Epoch 616/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.2783\n",
      "Epoch 00616: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7536.2783 - val_loss: 7537.8042\n",
      "Epoch 617/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2310\n",
      "Epoch 00617: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.2310 - val_loss: 7535.4375\n",
      "Epoch 618/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5200\n",
      "Epoch 00618: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.5200 - val_loss: 7535.0615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 619/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.3545\n",
      "Epoch 00619: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.3545 - val_loss: 7534.1719\n",
      "Epoch 620/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6011\n",
      "Epoch 00620: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7531.6011 - val_loss: 7534.6050\n",
      "Epoch 621/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.0137\n",
      "Epoch 00621: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.0137 - val_loss: 7535.0806\n",
      "Epoch 622/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.0879\n",
      "Epoch 00622: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7539.0879 - val_loss: 7536.4814\n",
      "Epoch 623/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.2344\n",
      "Epoch 00623: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.2344 - val_loss: 7535.7886\n",
      "Epoch 624/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5425\n",
      "Epoch 00624: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.5425 - val_loss: 7534.6768\n",
      "Epoch 625/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0796\n",
      "Epoch 00625: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.0796 - val_loss: 7533.7671\n",
      "Epoch 626/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3125\n",
      "Epoch 00626: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.3125 - val_loss: 7534.2134\n",
      "Epoch 627/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.6807\n",
      "Epoch 00627: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.6807 - val_loss: 7534.0098\n",
      "Epoch 628/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.1313\n",
      "Epoch 00628: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.1313 - val_loss: 7533.7393\n",
      "Epoch 629/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.8984\n",
      "Epoch 00629: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7525.8984 - val_loss: 7534.5713\n",
      "Epoch 630/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.3442\n",
      "Epoch 00630: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7546.3442 - val_loss: 7534.7646\n",
      "Epoch 631/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1016\n",
      "Epoch 00631: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.1016 - val_loss: 7534.4282\n",
      "Epoch 632/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.3428\n",
      "Epoch 00632: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7525.3428 - val_loss: 7533.8442\n",
      "Epoch 633/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.2188\n",
      "Epoch 00633: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.2188 - val_loss: 7533.6655\n",
      "Epoch 634/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.8394\n",
      "Epoch 00634: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7546.8394 - val_loss: 7535.5630\n",
      "Epoch 635/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.6006\n",
      "Epoch 00635: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.6006 - val_loss: 7534.8193\n",
      "Epoch 636/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.9956\n",
      "Epoch 00636: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.9956 - val_loss: 7534.6602\n",
      "Epoch 637/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5425\n",
      "Epoch 00637: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.5425 - val_loss: 7534.2705\n",
      "Epoch 638/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4717\n",
      "Epoch 00638: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.4717 - val_loss: 7534.2832\n",
      "Epoch 639/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.3887\n",
      "Epoch 00639: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7527.3887 - val_loss: 7536.1914\n",
      "Epoch 640/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5576\n",
      "Epoch 00640: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.5576 - val_loss: 7541.1118\n",
      "Epoch 641/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4688\n",
      "Epoch 00641: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.4688 - val_loss: 7539.8223\n",
      "Epoch 642/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.8462\n",
      "Epoch 00642: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7534.8462 - val_loss: 7536.3105\n",
      "Epoch 643/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.6006\n",
      "Epoch 00643: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7547.6006 - val_loss: 7535.8511\n",
      "Epoch 644/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7598\n",
      "Epoch 00644: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.7598 - val_loss: 7536.2954\n",
      "Epoch 645/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1167\n",
      "Epoch 00645: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.1167 - val_loss: 7536.0742\n",
      "Epoch 646/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.8857\n",
      "Epoch 00646: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.8857 - val_loss: 7535.1074\n",
      "Epoch 647/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2070\n",
      "Epoch 00647: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.2070 - val_loss: 7534.3726\n",
      "Epoch 648/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.4976\n",
      "Epoch 00648: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7544.4976 - val_loss: 7534.5000\n",
      "Epoch 649/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.0181\n",
      "Epoch 00649: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7526.0181 - val_loss: 7534.5762\n",
      "Epoch 650/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.9971\n",
      "Epoch 00650: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7537.9971 - val_loss: 7534.5825\n",
      "Epoch 651/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.4985\n",
      "Epoch 00651: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7544.4985 - val_loss: 7534.4937\n",
      "Epoch 652/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2480\n",
      "Epoch 00652: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.2480 - val_loss: 7533.4033\n",
      "Epoch 653/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7114\n",
      "Epoch 00653: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7539.7114 - val_loss: 7533.1079\n",
      "Epoch 654/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7532.6099\n",
      "Epoch 00654: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.6099 - val_loss: 7533.9585\n",
      "Epoch 655/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.1934\n",
      "Epoch 00655: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.1934 - val_loss: 7533.8594\n",
      "Epoch 656/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.0220\n",
      "Epoch 00656: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7528.0220 - val_loss: 7533.2690\n",
      "Epoch 657/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.6621\n",
      "Epoch 00657: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7542.6621 - val_loss: 7532.7754\n",
      "Epoch 658/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.7886\n",
      "Epoch 00658: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.7886 - val_loss: 7532.8169\n",
      "Epoch 659/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.8184\n",
      "Epoch 00659: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7535.8184 - val_loss: 7532.7344\n",
      "Epoch 660/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8740\n",
      "Epoch 00660: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7531.8740 - val_loss: 7532.7319\n",
      "Epoch 661/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.4712\n",
      "Epoch 00661: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.4712 - val_loss: 7532.8506\n",
      "Epoch 662/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1929\n",
      "Epoch 00662: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7537.1929 - val_loss: 7533.6450\n",
      "Epoch 663/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.7607\n",
      "Epoch 00663: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7529.7607 - val_loss: 7534.6655\n",
      "Epoch 664/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5708\n",
      "Epoch 00664: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.5708 - val_loss: 7534.5688\n",
      "Epoch 665/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8887\n",
      "Epoch 00665: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.8887 - val_loss: 7533.2329\n",
      "Epoch 666/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.2271\n",
      "Epoch 00666: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7535.2271 - val_loss: 7532.9185\n",
      "Epoch 667/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.9204\n",
      "Epoch 00667: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.9204 - val_loss: 7533.4272\n",
      "Epoch 668/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3604\n",
      "Epoch 00668: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.3604 - val_loss: 7534.1265\n",
      "Epoch 669/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.9463\n",
      "Epoch 00669: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.9463 - val_loss: 7534.8369\n",
      "Epoch 670/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1641\n",
      "Epoch 00670: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.1641 - val_loss: 7533.3999\n",
      "Epoch 671/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.2686\n",
      "Epoch 00671: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7539.2686 - val_loss: 7533.1074\n",
      "Epoch 672/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4038\n",
      "Epoch 00672: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7534.4038 - val_loss: 7535.5063\n",
      "Epoch 673/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1113\n",
      "Epoch 00673: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.1113 - val_loss: 7533.8208\n",
      "Epoch 674/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.3750\n",
      "Epoch 00674: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.3750 - val_loss: 7533.4658\n",
      "Epoch 675/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.2812\n",
      "Epoch 00675: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.2812 - val_loss: 7533.1753\n",
      "Epoch 676/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.0010\n",
      "Epoch 00676: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.0010 - val_loss: 7534.2783\n",
      "Epoch 677/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.0771\n",
      "Epoch 00677: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7542.0771 - val_loss: 7533.3218\n",
      "Epoch 678/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.1548\n",
      "Epoch 00678: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.1548 - val_loss: 7533.2720\n",
      "Epoch 679/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1060\n",
      "Epoch 00679: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.1060 - val_loss: 7534.1504\n",
      "Epoch 680/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4106\n",
      "Epoch 00680: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.4106 - val_loss: 7532.5889\n",
      "Epoch 681/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.8228\n",
      "Epoch 00681: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.8228 - val_loss: 7533.2754\n",
      "Epoch 682/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.8696\n",
      "Epoch 00682: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7524.8696 - val_loss: 7533.5952\n",
      "Epoch 683/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.8086\n",
      "Epoch 00683: val_loss did not improve from 7532.49902\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.8086 - val_loss: 7532.9937\n",
      "Epoch 684/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7522.6333\n",
      "Epoch 00684: val_loss improved from 7532.49902 to 7532.34229, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-684-7.53234e+03.hdf5\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7522.6333 - val_loss: 7532.3423\n",
      "Epoch 685/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.8301\n",
      "Epoch 00685: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7529.8301 - val_loss: 7532.4946\n",
      "Epoch 686/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4839\n",
      "Epoch 00686: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7534.4839 - val_loss: 7535.4614\n",
      "Epoch 687/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2710\n",
      "Epoch 00687: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.2710 - val_loss: 7532.6050\n",
      "Epoch 688/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.0405\n",
      "Epoch 00688: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.0405 - val_loss: 7533.2031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 689/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.3579\n",
      "Epoch 00689: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.3579 - val_loss: 7535.4102\n",
      "Epoch 690/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3823\n",
      "Epoch 00690: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.3823 - val_loss: 7534.5151\n",
      "Epoch 691/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.7607\n",
      "Epoch 00691: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7543.7607 - val_loss: 7534.5742\n",
      "Epoch 692/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.8359\n",
      "Epoch 00692: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7540.8359 - val_loss: 7534.7495\n",
      "Epoch 693/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9951\n",
      "Epoch 00693: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.9951 - val_loss: 7533.6040\n",
      "Epoch 694/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.5142\n",
      "Epoch 00694: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.5142 - val_loss: 7534.3599\n",
      "Epoch 695/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4053\n",
      "Epoch 00695: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7530.4053 - val_loss: 7533.3071\n",
      "Epoch 696/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.8477\n",
      "Epoch 00696: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7518.8477 - val_loss: 7533.7808\n",
      "Epoch 697/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.8896\n",
      "Epoch 00697: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.8896 - val_loss: 7534.5161\n",
      "Epoch 698/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.9351\n",
      "Epoch 00698: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.9351 - val_loss: 7533.5718\n",
      "Epoch 699/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.3184\n",
      "Epoch 00699: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.3184 - val_loss: 7533.2529\n",
      "Epoch 700/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4189\n",
      "Epoch 00700: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.4189 - val_loss: 7533.3521\n",
      "Epoch 701/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.0522\n",
      "Epoch 00701: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.0522 - val_loss: 7532.9160\n",
      "Epoch 702/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4443\n",
      "Epoch 00702: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7530.4443 - val_loss: 7532.8506\n",
      "Epoch 703/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4019\n",
      "Epoch 00703: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7530.4019 - val_loss: 7533.2593\n",
      "Epoch 704/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.3232\n",
      "Epoch 00704: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7538.3232 - val_loss: 7534.4434\n",
      "Epoch 705/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5742\n",
      "Epoch 00705: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7536.5742 - val_loss: 7534.2642\n",
      "Epoch 706/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.3784\n",
      "Epoch 00706: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7528.3784 - val_loss: 7537.3159\n",
      "Epoch 707/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.4658\n",
      "Epoch 00707: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7544.4658 - val_loss: 7534.5698\n",
      "Epoch 708/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.8379\n",
      "Epoch 00708: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7537.8379 - val_loss: 7535.3506\n",
      "Epoch 709/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.0547\n",
      "Epoch 00709: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.0547 - val_loss: 7533.9058\n",
      "Epoch 710/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.2217\n",
      "Epoch 00710: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7543.2217 - val_loss: 7533.2095\n",
      "Epoch 711/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2349\n",
      "Epoch 00711: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7531.2349 - val_loss: 7533.0166\n",
      "Epoch 712/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9131\n",
      "Epoch 00712: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.9131 - val_loss: 7533.6807\n",
      "Epoch 713/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7603\n",
      "Epoch 00713: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7531.7603 - val_loss: 7534.3174\n",
      "Epoch 714/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8052\n",
      "Epoch 00714: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.8052 - val_loss: 7533.8975\n",
      "Epoch 715/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6958\n",
      "Epoch 00715: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7536.6958 - val_loss: 7534.4248\n",
      "Epoch 716/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6411\n",
      "Epoch 00716: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7536.6411 - val_loss: 7533.4272\n",
      "Epoch 717/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.7656\n",
      "Epoch 00717: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7523.7656 - val_loss: 7534.7153\n",
      "Epoch 718/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.4355\n",
      "Epoch 00718: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7525.4355 - val_loss: 7533.7710\n",
      "Epoch 719/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.3706\n",
      "Epoch 00719: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7542.3706 - val_loss: 7533.5986\n",
      "Epoch 720/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7065\n",
      "Epoch 00720: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.7065 - val_loss: 7533.3130\n",
      "Epoch 721/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.3667\n",
      "Epoch 00721: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7523.3667 - val_loss: 7533.2192\n",
      "Epoch 722/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0894\n",
      "Epoch 00722: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.0894 - val_loss: 7532.5962\n",
      "Epoch 723/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7517.9819\n",
      "Epoch 00723: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7517.9819 - val_loss: 7532.6807\n",
      "Epoch 724/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7531.1689\n",
      "Epoch 00724: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.1689 - val_loss: 7533.1870\n",
      "Epoch 725/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.9902\n",
      "Epoch 00725: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.9902 - val_loss: 7533.0967\n",
      "Epoch 726/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5146\n",
      "Epoch 00726: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7533.5146 - val_loss: 7534.9678\n",
      "Epoch 727/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7407\n",
      "Epoch 00727: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7536.7407 - val_loss: 7533.6602\n",
      "Epoch 728/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.3633\n",
      "Epoch 00728: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7542.3633 - val_loss: 7533.3848\n",
      "Epoch 729/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.2021\n",
      "Epoch 00729: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7530.2021 - val_loss: 7532.4033\n",
      "Epoch 730/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5503\n",
      "Epoch 00730: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7531.5503 - val_loss: 7532.9526\n",
      "Epoch 731/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.8755\n",
      "Epoch 00731: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7534.8755 - val_loss: 7532.4146\n",
      "Epoch 732/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.7476\n",
      "Epoch 00732: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.7476 - val_loss: 7532.4463\n",
      "Epoch 733/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.9219\n",
      "Epoch 00733: val_loss did not improve from 7532.34229\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.9219 - val_loss: 7532.8066\n",
      "Epoch 734/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.6304\n",
      "Epoch 00734: val_loss improved from 7532.34229 to 7532.23340, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-734-7.53223e+03.hdf5\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7530.6304 - val_loss: 7532.2334\n",
      "Epoch 735/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.3823\n",
      "Epoch 00735: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7527.3823 - val_loss: 7532.8022\n",
      "Epoch 736/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.8145\n",
      "Epoch 00736: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7542.8145 - val_loss: 7533.0063\n",
      "Epoch 737/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.2471\n",
      "Epoch 00737: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.2471 - val_loss: 7533.2144\n",
      "Epoch 738/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.6489\n",
      "Epoch 00738: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7542.6489 - val_loss: 7532.5342\n",
      "Epoch 739/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.5718\n",
      "Epoch 00739: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.5718 - val_loss: 7536.7954\n",
      "Epoch 740/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.7373\n",
      "Epoch 00740: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7520.7373 - val_loss: 7535.7568\n",
      "Epoch 741/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.1069\n",
      "Epoch 00741: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7529.1069 - val_loss: 7533.7505\n",
      "Epoch 742/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.8906\n",
      "Epoch 00742: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.8906 - val_loss: 7532.5391\n",
      "Epoch 743/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1382\n",
      "Epoch 00743: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.1382 - val_loss: 7534.7393\n",
      "Epoch 744/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.9443\n",
      "Epoch 00744: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7544.9443 - val_loss: 7533.4546\n",
      "Epoch 745/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.1626\n",
      "Epoch 00745: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7539.1626 - val_loss: 7532.5737\n",
      "Epoch 746/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4829\n",
      "Epoch 00746: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.4829 - val_loss: 7532.7046\n",
      "Epoch 747/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4692\n",
      "Epoch 00747: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.4692 - val_loss: 7532.7256\n",
      "Epoch 748/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.9839\n",
      "Epoch 00748: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7523.9839 - val_loss: 7532.4282\n",
      "Epoch 749/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0479\n",
      "Epoch 00749: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.0479 - val_loss: 7533.2368\n",
      "Epoch 750/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.4668\n",
      "Epoch 00750: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7541.4668 - val_loss: 7532.3394\n",
      "Epoch 751/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.1152\n",
      "Epoch 00751: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.1152 - val_loss: 7532.6670\n",
      "Epoch 752/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3496\n",
      "Epoch 00752: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.3496 - val_loss: 7533.2158\n",
      "Epoch 753/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1987\n",
      "Epoch 00753: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.1987 - val_loss: 7532.5410\n",
      "Epoch 754/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6421\n",
      "Epoch 00754: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.6421 - val_loss: 7533.6855\n",
      "Epoch 755/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6514\n",
      "Epoch 00755: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7537.6514 - val_loss: 7535.3369\n",
      "Epoch 756/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.3770\n",
      "Epoch 00756: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.3770 - val_loss: 7533.6626\n",
      "Epoch 757/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.7690\n",
      "Epoch 00757: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7534.7690 - val_loss: 7532.4897\n",
      "Epoch 758/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1396\n",
      "Epoch 00758: val_loss did not improve from 7532.23340\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7538.1396 - val_loss: 7532.4146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 759/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.6221\n",
      "Epoch 00759: val_loss improved from 7532.23340 to 7532.14551, saving model to /dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/chk-759-7.53215e+03.hdf5\n",
      "25/25 [==============================] - 13s 540ms/step - loss: 7542.6221 - val_loss: 7532.1455\n",
      "Epoch 760/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.4229\n",
      "Epoch 00760: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7518.4229 - val_loss: 7533.1826\n",
      "Epoch 761/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.7295\n",
      "Epoch 00761: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7542.7295 - val_loss: 7532.9272\n",
      "Epoch 762/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.9810\n",
      "Epoch 00762: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7538.9810 - val_loss: 7532.6406\n",
      "Epoch 763/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.1372\n",
      "Epoch 00763: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7530.1372 - val_loss: 7532.8721\n",
      "Epoch 764/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.5737\n",
      "Epoch 00764: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.5737 - val_loss: 7532.7280\n",
      "Epoch 765/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.4136\n",
      "Epoch 00765: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7525.4136 - val_loss: 7533.8193\n",
      "Epoch 766/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0952\n",
      "Epoch 00766: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7532.0952 - val_loss: 7533.0386\n",
      "Epoch 767/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7578.4961\n",
      "Epoch 00767: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7578.4961 - val_loss: 7572.3223\n",
      "Epoch 768/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.7925\n",
      "Epoch 00768: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.7925 - val_loss: 7546.2295\n",
      "Epoch 769/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2515\n",
      "Epoch 00769: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.2515 - val_loss: 7541.3926\n",
      "Epoch 770/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0430\n",
      "Epoch 00770: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.0430 - val_loss: 7539.1440\n",
      "Epoch 771/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.6533\n",
      "Epoch 00771: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7541.6533 - val_loss: 7538.2344\n",
      "Epoch 772/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.6851\n",
      "Epoch 00772: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7540.6851 - val_loss: 7537.7505\n",
      "Epoch 773/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.2065\n",
      "Epoch 00773: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.2065 - val_loss: 7537.4126\n",
      "Epoch 774/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5562\n",
      "Epoch 00774: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.5562 - val_loss: 7537.0239\n",
      "Epoch 775/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.2725\n",
      "Epoch 00775: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7548.2725 - val_loss: 7536.7104\n",
      "Epoch 776/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7521.5034\n",
      "Epoch 00776: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7521.5034 - val_loss: 7536.9736\n",
      "Epoch 777/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.8188\n",
      "Epoch 00777: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7548.8188 - val_loss: 7536.8799\n",
      "Epoch 778/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.9585\n",
      "Epoch 00778: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7539.9585 - val_loss: 7536.2983\n",
      "Epoch 779/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5542\n",
      "Epoch 00779: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.5542 - val_loss: 7535.6479\n",
      "Epoch 780/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4204\n",
      "Epoch 00780: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.4204 - val_loss: 7535.8735\n",
      "Epoch 781/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.5771\n",
      "Epoch 00781: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.5771 - val_loss: 7535.5537\n",
      "Epoch 782/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.6382\n",
      "Epoch 00782: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7519.6382 - val_loss: 7534.9922\n",
      "Epoch 783/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.4971\n",
      "Epoch 00783: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7546.4971 - val_loss: 7534.8096\n",
      "Epoch 784/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9541\n",
      "Epoch 00784: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.9541 - val_loss: 7534.5830\n",
      "Epoch 785/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.4790\n",
      "Epoch 00785: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.4790 - val_loss: 7533.9399\n",
      "Epoch 786/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6357\n",
      "Epoch 00786: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.6357 - val_loss: 7533.9526\n",
      "Epoch 787/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.8696\n",
      "Epoch 00787: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7523.8696 - val_loss: 7533.7510\n",
      "Epoch 788/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.3125\n",
      "Epoch 00788: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7525.3125 - val_loss: 7533.8159\n",
      "Epoch 789/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.2798\n",
      "Epoch 00789: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7549.2798 - val_loss: 7539.2666\n",
      "Epoch 790/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.2798\n",
      "Epoch 00790: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7542.2798 - val_loss: 7544.0161\n",
      "Epoch 791/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.3960\n",
      "Epoch 00791: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7548.3960 - val_loss: 7544.6162\n",
      "Epoch 792/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.5586\n",
      "Epoch 00792: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.5586 - val_loss: 7541.7134\n",
      "Epoch 793/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.8354\n",
      "Epoch 00793: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7549.8354 - val_loss: 7540.4785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 794/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.0508\n",
      "Epoch 00794: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7539.0508 - val_loss: 7539.7920\n",
      "Epoch 795/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.5967\n",
      "Epoch 00795: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7538.5967 - val_loss: 7539.5400\n",
      "Epoch 796/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.4878\n",
      "Epoch 00796: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7541.4878 - val_loss: 7538.9761\n",
      "Epoch 797/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.1177\n",
      "Epoch 00797: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.1177 - val_loss: 7538.8008\n",
      "Epoch 798/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.9097\n",
      "Epoch 00798: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.9097 - val_loss: 7538.5410\n",
      "Epoch 799/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6035\n",
      "Epoch 00799: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7537.6035 - val_loss: 7538.3296\n",
      "Epoch 800/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.1841\n",
      "Epoch 00800: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7542.1841 - val_loss: 7538.0200\n",
      "Epoch 801/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.2520\n",
      "Epoch 00801: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7547.2520 - val_loss: 7537.9087\n",
      "Epoch 802/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.9111\n",
      "Epoch 00802: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.9111 - val_loss: 7537.9951\n",
      "Epoch 803/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.5840\n",
      "Epoch 00803: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7540.5840 - val_loss: 7538.1558\n",
      "Epoch 804/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.8813\n",
      "Epoch 00804: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.8813 - val_loss: 7537.7378\n",
      "Epoch 805/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1079\n",
      "Epoch 00805: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.1079 - val_loss: 7538.2334\n",
      "Epoch 806/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4517\n",
      "Epoch 00806: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.4517 - val_loss: 7537.4648\n",
      "Epoch 807/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.8110\n",
      "Epoch 00807: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7535.8110 - val_loss: 7537.8569\n",
      "Epoch 808/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4468\n",
      "Epoch 00808: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7535.4468 - val_loss: 7537.6577\n",
      "Epoch 809/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1885\n",
      "Epoch 00809: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7536.1885 - val_loss: 7537.0225\n",
      "Epoch 810/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4507\n",
      "Epoch 00810: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7536.4507 - val_loss: 7537.1719\n",
      "Epoch 811/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.2832\n",
      "Epoch 00811: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7535.2832 - val_loss: 7537.4097\n",
      "Epoch 812/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7534\n",
      "Epoch 00812: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.7534 - val_loss: 7536.9561\n",
      "Epoch 813/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3779\n",
      "Epoch 00813: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.3779 - val_loss: 7536.9600\n",
      "Epoch 814/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.2402\n",
      "Epoch 00814: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.2402 - val_loss: 7536.8271\n",
      "Epoch 815/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4268\n",
      "Epoch 00815: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.4268 - val_loss: 7536.9199\n",
      "Epoch 816/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7522.4346\n",
      "Epoch 00816: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7522.4346 - val_loss: 7536.9121\n",
      "Epoch 817/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7446\n",
      "Epoch 00817: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7540.7446 - val_loss: 7536.8486\n",
      "Epoch 818/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.9736\n",
      "Epoch 00818: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.9736 - val_loss: 7536.8911\n",
      "Epoch 819/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.3696\n",
      "Epoch 00819: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7535.3696 - val_loss: 7538.0977\n",
      "Epoch 820/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7522.9302\n",
      "Epoch 00820: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7522.9302 - val_loss: 7536.8423\n",
      "Epoch 821/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.6245\n",
      "Epoch 00821: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7543.6245 - val_loss: 7536.5210\n",
      "Epoch 822/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7522.0513\n",
      "Epoch 00822: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7522.0513 - val_loss: 7536.4814\n",
      "Epoch 823/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.5562\n",
      "Epoch 00823: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.5562 - val_loss: 7536.4370\n",
      "Epoch 824/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.1436\n",
      "Epoch 00824: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7535.1436 - val_loss: 7537.0098\n",
      "Epoch 825/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.5850\n",
      "Epoch 00825: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.5850 - val_loss: 7536.5010\n",
      "Epoch 826/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3525\n",
      "Epoch 00826: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7534.3525 - val_loss: 7536.2734\n",
      "Epoch 827/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.8359\n",
      "Epoch 00827: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7528.8359 - val_loss: 7536.8320\n",
      "Epoch 828/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.1763\n",
      "Epoch 00828: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7542.1763 - val_loss: 7536.3623\n",
      "Epoch 829/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7534.5088\n",
      "Epoch 00829: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7534.5088 - val_loss: 7536.2974\n",
      "Epoch 830/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8486\n",
      "Epoch 00830: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7545.8486 - val_loss: 7536.6841\n",
      "Epoch 831/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.1143\n",
      "Epoch 00831: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7535.1143 - val_loss: 7537.0073\n",
      "Epoch 832/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5625\n",
      "Epoch 00832: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.5625 - val_loss: 7536.5728\n",
      "Epoch 833/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.0942\n",
      "Epoch 00833: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7540.0942 - val_loss: 7536.3442\n",
      "Epoch 834/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5410\n",
      "Epoch 00834: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.5410 - val_loss: 7536.2617\n",
      "Epoch 835/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4277\n",
      "Epoch 00835: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.4277 - val_loss: 7536.2334\n",
      "Epoch 836/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.7891\n",
      "Epoch 00836: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7541.7891 - val_loss: 7537.3770\n",
      "Epoch 837/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.7915\n",
      "Epoch 00837: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7535.7915 - val_loss: 7536.8447\n",
      "Epoch 838/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.5698\n",
      "Epoch 00838: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7546.5698 - val_loss: 7535.9087\n",
      "Epoch 839/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8999\n",
      "Epoch 00839: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.8999 - val_loss: 7536.0151\n",
      "Epoch 840/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2109\n",
      "Epoch 00840: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7533.2109 - val_loss: 7536.0513\n",
      "Epoch 841/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3569\n",
      "Epoch 00841: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7534.3569 - val_loss: 7536.4673\n",
      "Epoch 842/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.9175\n",
      "Epoch 00842: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7538.9175 - val_loss: 7536.4360\n",
      "Epoch 843/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7563.7632\n",
      "Epoch 00843: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7563.7632 - val_loss: 7573.8809\n",
      "Epoch 844/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.2334\n",
      "Epoch 00844: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7540.2334 - val_loss: 7539.6616\n",
      "Epoch 845/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.9863\n",
      "Epoch 00845: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7529.9863 - val_loss: 7536.7759\n",
      "Epoch 846/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.8750\n",
      "Epoch 00846: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.8750 - val_loss: 7536.4360\n",
      "Epoch 847/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.3696\n",
      "Epoch 00847: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.3696 - val_loss: 7536.5430\n",
      "Epoch 848/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.2461\n",
      "Epoch 00848: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.2461 - val_loss: 7536.1338\n",
      "Epoch 849/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.1812\n",
      "Epoch 00849: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.1812 - val_loss: 7536.5791\n",
      "Epoch 850/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.1377\n",
      "Epoch 00850: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7539.1377 - val_loss: 7536.3184\n",
      "Epoch 851/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.0854\n",
      "Epoch 00851: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7529.0854 - val_loss: 7536.0864\n",
      "Epoch 852/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.7271\n",
      "Epoch 00852: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7541.7271 - val_loss: 7535.9126\n",
      "Epoch 853/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7521.6094\n",
      "Epoch 00853: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7521.6094 - val_loss: 7536.1738\n",
      "Epoch 854/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.4443\n",
      "Epoch 00854: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.4443 - val_loss: 7535.9360\n",
      "Epoch 855/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.1123\n",
      "Epoch 00855: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.1123 - val_loss: 7535.9023\n",
      "Epoch 856/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2441\n",
      "Epoch 00856: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7538.2441 - val_loss: 7535.9312\n",
      "Epoch 857/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.4404\n",
      "Epoch 00857: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7538.4404 - val_loss: 7535.9258\n",
      "Epoch 858/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8203\n",
      "Epoch 00858: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.8203 - val_loss: 7536.4482\n",
      "Epoch 859/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.8750\n",
      "Epoch 00859: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.8750 - val_loss: 7541.6768\n",
      "Epoch 860/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0312\n",
      "Epoch 00860: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7537.0312 - val_loss: 7539.0000\n",
      "Epoch 861/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7993\n",
      "Epoch 00861: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.7993 - val_loss: 7538.8745\n",
      "Epoch 862/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.9761\n",
      "Epoch 00862: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.9761 - val_loss: 7537.9233\n",
      "Epoch 863/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.8208\n",
      "Epoch 00863: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7548.8208 - val_loss: 7538.4287\n",
      "Epoch 864/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7544.9888\n",
      "Epoch 00864: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.9888 - val_loss: 7540.1826\n",
      "Epoch 865/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.2002\n",
      "Epoch 00865: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.2002 - val_loss: 7537.6816\n",
      "Epoch 866/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.6167\n",
      "Epoch 00866: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7528.6167 - val_loss: 7538.6001\n",
      "Epoch 867/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.0034\n",
      "Epoch 00867: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7540.0034 - val_loss: 7537.6152\n",
      "Epoch 868/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.6240\n",
      "Epoch 00868: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7533.6240 - val_loss: 7540.0254\n",
      "Epoch 869/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7571.8765\n",
      "Epoch 00869: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7571.8765 - val_loss: 7648.5649\n",
      "Epoch 870/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.5210\n",
      "Epoch 00870: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7549.5210 - val_loss: 7544.8394\n",
      "Epoch 871/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7812\n",
      "Epoch 00871: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.7812 - val_loss: 7540.1328\n",
      "Epoch 872/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.8198\n",
      "Epoch 00872: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7542.8198 - val_loss: 7540.6558\n",
      "Epoch 873/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4766\n",
      "Epoch 00873: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.4766 - val_loss: 7540.0586\n",
      "Epoch 874/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7275\n",
      "Epoch 00874: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7539.7275 - val_loss: 7540.3906\n",
      "Epoch 875/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.6035\n",
      "Epoch 00875: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7523.6035 - val_loss: 7539.2002\n",
      "Epoch 876/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.5557\n",
      "Epoch 00876: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7547.5557 - val_loss: 7538.3057\n",
      "Epoch 877/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4546\n",
      "Epoch 00877: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7537.4546 - val_loss: 7538.2998\n",
      "Epoch 878/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.4521\n",
      "Epoch 00878: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7549.4521 - val_loss: 7539.3223\n",
      "Epoch 879/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7534\n",
      "Epoch 00879: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7540.7534 - val_loss: 7538.5566\n",
      "Epoch 880/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5771\n",
      "Epoch 00880: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7537.5771 - val_loss: 7538.4702\n",
      "Epoch 881/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.7539\n",
      "Epoch 00881: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7541.7539 - val_loss: 7537.6558\n",
      "Epoch 882/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.0913\n",
      "Epoch 00882: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7547.0913 - val_loss: 7537.7759\n",
      "Epoch 883/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.6538\n",
      "Epoch 00883: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7543.6538 - val_loss: 7538.0562\n",
      "Epoch 884/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.7388\n",
      "Epoch 00884: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7547.7388 - val_loss: 7537.6431\n",
      "Epoch 885/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.6797\n",
      "Epoch 00885: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7547.6797 - val_loss: 7537.4390\n",
      "Epoch 886/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7550.1055\n",
      "Epoch 00886: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7550.1055 - val_loss: 7537.5610\n",
      "Epoch 887/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.2261\n",
      "Epoch 00887: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7535.2261 - val_loss: 7537.7378\n",
      "Epoch 888/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5977\n",
      "Epoch 00888: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.5977 - val_loss: 7537.4033\n",
      "Epoch 889/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.0571\n",
      "Epoch 00889: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7523.0571 - val_loss: 7537.8110\n",
      "Epoch 890/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7522.6392\n",
      "Epoch 00890: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7522.6392 - val_loss: 7537.7720\n",
      "Epoch 891/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.0049\n",
      "Epoch 00891: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7540.0049 - val_loss: 7537.8110\n",
      "Epoch 892/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.0400\n",
      "Epoch 00892: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7547.0400 - val_loss: 7538.3110\n",
      "Epoch 893/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0371\n",
      "Epoch 00893: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.0371 - val_loss: 7537.7134\n",
      "Epoch 894/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.4219\n",
      "Epoch 00894: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.4219 - val_loss: 7540.1279\n",
      "Epoch 895/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7550.0205\n",
      "Epoch 00895: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7550.0205 - val_loss: 7537.5215\n",
      "Epoch 896/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4673\n",
      "Epoch 00896: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 541ms/step - loss: 7536.4673 - val_loss: 7537.4199\n",
      "Epoch 897/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.7075\n",
      "Epoch 00897: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7541.7075 - val_loss: 7537.8760\n",
      "Epoch 898/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.4272\n",
      "Epoch 00898: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7546.4272 - val_loss: 7537.2920\n",
      "Epoch 899/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7536.0278\n",
      "Epoch 00899: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7536.0278 - val_loss: 7537.1289\n",
      "Epoch 900/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7256\n",
      "Epoch 00900: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7540.7256 - val_loss: 7537.0889\n",
      "Epoch 901/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.2676\n",
      "Epoch 00901: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7539.2676 - val_loss: 7537.0215\n",
      "Epoch 902/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9775\n",
      "Epoch 00902: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7533.9775 - val_loss: 7537.0273\n",
      "Epoch 903/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3691\n",
      "Epoch 00903: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7537.3691 - val_loss: 7537.7505\n",
      "Epoch 904/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7550.6509\n",
      "Epoch 00904: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7550.6509 - val_loss: 7538.7910\n",
      "Epoch 905/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.2754\n",
      "Epoch 00905: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7545.2754 - val_loss: 7538.6982\n",
      "Epoch 906/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3599\n",
      "Epoch 00906: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7536.3599 - val_loss: 7537.3242\n",
      "Epoch 907/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7550.2505\n",
      "Epoch 00907: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7550.2505 - val_loss: 7537.7378\n",
      "Epoch 908/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.0288\n",
      "Epoch 00908: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7549.0288 - val_loss: 7537.3838\n",
      "Epoch 909/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.7949\n",
      "Epoch 00909: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.7949 - val_loss: 7538.5200\n",
      "Epoch 910/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.4961\n",
      "Epoch 00910: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7549.4961 - val_loss: 7537.3311\n",
      "Epoch 911/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7522.1670\n",
      "Epoch 00911: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7522.1670 - val_loss: 7537.0762\n",
      "Epoch 912/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.3374\n",
      "Epoch 00912: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7528.3374 - val_loss: 7536.8081\n",
      "Epoch 913/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.9854\n",
      "Epoch 00913: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7542.9854 - val_loss: 7536.9014\n",
      "Epoch 914/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.3076\n",
      "Epoch 00914: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7528.3076 - val_loss: 7536.7334\n",
      "Epoch 915/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6123\n",
      "Epoch 00915: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.6123 - val_loss: 7536.8032\n",
      "Epoch 916/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.8525\n",
      "Epoch 00916: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.8525 - val_loss: 7537.1479\n",
      "Epoch 917/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.2705\n",
      "Epoch 00917: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7523.2705 - val_loss: 7538.6377\n",
      "Epoch 918/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3809\n",
      "Epoch 00918: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.3809 - val_loss: 7537.5903\n",
      "Epoch 919/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3687\n",
      "Epoch 00919: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7534.3687 - val_loss: 7536.7778\n",
      "Epoch 920/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.2236\n",
      "Epoch 00920: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7534.2236 - val_loss: 7536.7256\n",
      "Epoch 921/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4087\n",
      "Epoch 00921: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.4087 - val_loss: 7537.2441\n",
      "Epoch 922/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.0869\n",
      "Epoch 00922: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.0869 - val_loss: 7536.7905\n",
      "Epoch 923/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4478\n",
      "Epoch 00923: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.4478 - val_loss: 7536.6528\n",
      "Epoch 924/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6167\n",
      "Epoch 00924: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.6167 - val_loss: 7536.5298\n",
      "Epoch 925/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.4224\n",
      "Epoch 00925: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7549.4224 - val_loss: 7537.1504\n",
      "Epoch 926/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.5312\n",
      "Epoch 00926: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7528.5312 - val_loss: 7536.8784\n",
      "Epoch 927/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.1201\n",
      "Epoch 00927: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7544.1201 - val_loss: 7537.4746\n",
      "Epoch 928/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7551.2075\n",
      "Epoch 00928: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7551.2075 - val_loss: 7546.5889\n",
      "Epoch 929/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.3018\n",
      "Epoch 00929: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7545.3018 - val_loss: 7541.2559\n",
      "Epoch 930/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.9365\n",
      "Epoch 00930: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7539.9365 - val_loss: 7540.5562\n",
      "Epoch 931/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.5542\n",
      "Epoch 00931: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7542.5542 - val_loss: 7540.2368\n",
      "Epoch 932/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.3877\n",
      "Epoch 00932: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7543.3877 - val_loss: 7539.9502\n",
      "Epoch 933/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.0996\n",
      "Epoch 00933: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7535.0996 - val_loss: 7539.8936\n",
      "Epoch 934/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7535.9883\n",
      "Epoch 00934: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7535.9883 - val_loss: 7539.7759\n",
      "Epoch 935/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.7925\n",
      "Epoch 00935: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.7925 - val_loss: 7539.9702\n",
      "Epoch 936/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7550.2300\n",
      "Epoch 00936: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7550.2300 - val_loss: 7539.6553\n",
      "Epoch 937/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.5225\n",
      "Epoch 00937: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.5225 - val_loss: 7539.3335\n",
      "Epoch 938/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4580\n",
      "Epoch 00938: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7535.4580 - val_loss: 7539.3120\n",
      "Epoch 939/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.6440\n",
      "Epoch 00939: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.6440 - val_loss: 7539.7383\n",
      "Epoch 940/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3750\n",
      "Epoch 00940: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.3750 - val_loss: 7539.7710\n",
      "Epoch 941/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6128\n",
      "Epoch 00941: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.6128 - val_loss: 7539.2041\n",
      "Epoch 942/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.1729\n",
      "Epoch 00942: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7535.1729 - val_loss: 7538.9370\n",
      "Epoch 943/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.0757\n",
      "Epoch 00943: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7544.0757 - val_loss: 7538.8882\n",
      "Epoch 944/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5654\n",
      "Epoch 00944: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7536.5654 - val_loss: 7538.7944\n",
      "Epoch 945/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7550.5342\n",
      "Epoch 00945: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7550.5342 - val_loss: 7538.9736\n",
      "Epoch 946/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7550.5742\n",
      "Epoch 00946: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7550.5742 - val_loss: 7539.0303\n",
      "Epoch 947/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.3237\n",
      "Epoch 00947: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7523.3237 - val_loss: 7538.6553\n",
      "Epoch 948/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.2446\n",
      "Epoch 00948: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7536.2446 - val_loss: 7538.6152\n",
      "Epoch 949/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.8203\n",
      "Epoch 00949: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.8203 - val_loss: 7538.5952\n",
      "Epoch 950/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0386\n",
      "Epoch 00950: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.0386 - val_loss: 7538.6128\n",
      "Epoch 951/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.3262\n",
      "Epoch 00951: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7547.3262 - val_loss: 7538.5386\n",
      "Epoch 952/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.8604\n",
      "Epoch 00952: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7548.8604 - val_loss: 7538.5249\n",
      "Epoch 953/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.6123\n",
      "Epoch 00953: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7541.6123 - val_loss: 7538.4961\n",
      "Epoch 954/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.9336\n",
      "Epoch 00954: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7549.9336 - val_loss: 7538.3970\n",
      "Epoch 955/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5552\n",
      "Epoch 00955: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.5552 - val_loss: 7538.5278\n",
      "Epoch 956/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6396\n",
      "Epoch 00956: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.6396 - val_loss: 7538.2383\n",
      "Epoch 957/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7550.1514\n",
      "Epoch 00957: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7550.1514 - val_loss: 7538.4312\n",
      "Epoch 958/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.4097\n",
      "Epoch 00958: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7541.4097 - val_loss: 7538.2993\n",
      "Epoch 959/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5479\n",
      "Epoch 00959: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7536.5479 - val_loss: 7538.1753\n",
      "Epoch 960/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.2490\n",
      "Epoch 00960: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7541.2490 - val_loss: 7538.0879\n",
      "Epoch 961/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7522.7334\n",
      "Epoch 00961: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7522.7334 - val_loss: 7538.0850\n",
      "Epoch 962/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7522.6255\n",
      "Epoch 00962: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7522.6255 - val_loss: 7538.1416\n",
      "Epoch 963/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3179\n",
      "Epoch 00963: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7534.3179 - val_loss: 7538.1440\n",
      "Epoch 964/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.6416\n",
      "Epoch 00964: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7535.6416 - val_loss: 7538.0854\n",
      "Epoch 965/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.1606\n",
      "Epoch 00965: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7543.1606 - val_loss: 7537.9150\n",
      "Epoch 966/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.6978\n",
      "Epoch 00966: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7546.6978 - val_loss: 7537.9102\n",
      "Epoch 967/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0806\n",
      "Epoch 00967: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7537.0806 - val_loss: 7538.3574\n",
      "Epoch 968/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.1147\n",
      "Epoch 00968: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.1147 - val_loss: 7537.9634\n",
      "Epoch 969/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7549.5210\n",
      "Epoch 00969: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7549.5210 - val_loss: 7537.9712\n",
      "Epoch 970/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.9990\n",
      "Epoch 00970: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7542.9990 - val_loss: 7537.7080\n",
      "Epoch 971/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4990\n",
      "Epoch 00971: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.4990 - val_loss: 7537.9458\n",
      "Epoch 972/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.7007\n",
      "Epoch 00972: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.7007 - val_loss: 7538.2070\n",
      "Epoch 973/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3213\n",
      "Epoch 00973: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.3213 - val_loss: 7537.7119\n",
      "Epoch 974/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1553\n",
      "Epoch 00974: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.1553 - val_loss: 7537.7847\n",
      "Epoch 975/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.2964\n",
      "Epoch 00975: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7535.2964 - val_loss: 7537.6426\n",
      "Epoch 976/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6836\n",
      "Epoch 00976: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.6836 - val_loss: 7537.5688\n",
      "Epoch 977/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.1948\n",
      "Epoch 00977: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7549.1948 - val_loss: 7537.6079\n",
      "Epoch 978/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.1323\n",
      "Epoch 00978: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.1323 - val_loss: 7537.5889\n",
      "Epoch 979/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.1831\n",
      "Epoch 00979: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7544.1831 - val_loss: 7537.5010\n",
      "Epoch 980/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0615\n",
      "Epoch 00980: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.0615 - val_loss: 7537.5825\n",
      "Epoch 981/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.3345\n",
      "Epoch 00981: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7549.3345 - val_loss: 7537.5122\n",
      "Epoch 982/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.2144\n",
      "Epoch 00982: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7535.2144 - val_loss: 7537.4863\n",
      "Epoch 983/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.1812\n",
      "Epoch 00983: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7549.1812 - val_loss: 7537.3584\n",
      "Epoch 984/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.9556\n",
      "Epoch 00984: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7529.9556 - val_loss: 7537.3906\n",
      "Epoch 985/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4795\n",
      "Epoch 00985: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.4795 - val_loss: 7537.3569\n",
      "Epoch 986/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.8521\n",
      "Epoch 00986: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7543.8521 - val_loss: 7537.2510\n",
      "Epoch 987/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.3105\n",
      "Epoch 00987: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7527.3105 - val_loss: 7537.3145\n",
      "Epoch 988/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.8945\n",
      "Epoch 00988: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7534.8945 - val_loss: 7537.1904\n",
      "Epoch 989/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7522.0000\n",
      "Epoch 00989: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7522.0000 - val_loss: 7537.2002\n",
      "Epoch 990/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.4844\n",
      "Epoch 00990: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7542.4844 - val_loss: 7537.1655\n",
      "Epoch 991/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.7246\n",
      "Epoch 00991: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7548.7246 - val_loss: 7537.1182\n",
      "Epoch 992/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.3677\n",
      "Epoch 00992: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7527.3677 - val_loss: 7537.1592\n",
      "Epoch 993/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.5708\n",
      "Epoch 00993: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7540.5708 - val_loss: 7537.5537\n",
      "Epoch 994/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3677\n",
      "Epoch 00994: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7536.3677 - val_loss: 7537.2671\n",
      "Epoch 995/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.3491\n",
      "Epoch 00995: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7540.3491 - val_loss: 7537.2441\n",
      "Epoch 996/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.1001\n",
      "Epoch 00996: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7539.1001 - val_loss: 7537.0449\n",
      "Epoch 997/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4409\n",
      "Epoch 00997: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7535.4409 - val_loss: 7537.3574\n",
      "Epoch 998/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.3618\n",
      "Epoch 00998: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7540.3618 - val_loss: 7537.1719\n",
      "Epoch 999/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5425\n",
      "Epoch 00999: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7539.5425 - val_loss: 7537.7598\n",
      "Epoch 1000/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7521.7319\n",
      "Epoch 01000: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7521.7319 - val_loss: 7536.9062\n",
      "Epoch 1001/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.8281\n",
      "Epoch 01001: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7548.8281 - val_loss: 7536.8672\n",
      "Epoch 1002/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5098\n",
      "Epoch 01002: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7534.5098 - val_loss: 7536.9487\n",
      "Epoch 1003/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.3804\n",
      "Epoch 01003: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7535.3804 - val_loss: 7536.8350\n",
      "Epoch 1004/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7536.2295\n",
      "Epoch 01004: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.2295 - val_loss: 7536.9121\n",
      "Epoch 1005/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.6553\n",
      "Epoch 01005: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7548.6553 - val_loss: 7537.1343\n",
      "Epoch 1006/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.7153\n",
      "Epoch 01006: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.7153 - val_loss: 7536.9097\n",
      "Epoch 1007/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1426\n",
      "Epoch 01007: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.1426 - val_loss: 7536.8462\n",
      "Epoch 1008/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.7432\n",
      "Epoch 01008: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7548.7432 - val_loss: 7537.0049\n",
      "Epoch 1009/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.2588\n",
      "Epoch 01009: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7528.2588 - val_loss: 7536.8833\n",
      "Epoch 1010/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7521.5757\n",
      "Epoch 01010: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7521.5757 - val_loss: 7536.7754\n",
      "Epoch 1011/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3403\n",
      "Epoch 01011: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7533.3403 - val_loss: 7536.7681\n",
      "Epoch 1012/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.2524\n",
      "Epoch 01012: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.2524 - val_loss: 7536.7007\n",
      "Epoch 1013/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.4595\n",
      "Epoch 01013: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.4595 - val_loss: 7536.7168\n",
      "Epoch 1014/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.2109\n",
      "Epoch 01014: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.2109 - val_loss: 7536.7983\n",
      "Epoch 1015/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.9932\n",
      "Epoch 01015: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.9932 - val_loss: 7536.7456\n",
      "Epoch 1016/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.2676\n",
      "Epoch 01016: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7548.2676 - val_loss: 7536.5728\n",
      "Epoch 1017/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.9697\n",
      "Epoch 01017: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.9697 - val_loss: 7536.6738\n",
      "Epoch 1018/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.7373\n",
      "Epoch 01018: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.7373 - val_loss: 7536.9087\n",
      "Epoch 1019/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.6938\n",
      "Epoch 01019: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.6938 - val_loss: 7536.4658\n",
      "Epoch 1020/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.7808\n",
      "Epoch 01020: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7535.7808 - val_loss: 7536.6592\n",
      "Epoch 1021/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.8809\n",
      "Epoch 01021: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7541.8809 - val_loss: 7536.6841\n",
      "Epoch 1022/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.4717\n",
      "Epoch 01022: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.4717 - val_loss: 7536.4873\n",
      "Epoch 1023/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.7251\n",
      "Epoch 01023: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7535.7251 - val_loss: 7536.5186\n",
      "Epoch 1024/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9185\n",
      "Epoch 01024: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7532.9185 - val_loss: 7536.5850\n",
      "Epoch 1025/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.6230\n",
      "Epoch 01025: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7538.6230 - val_loss: 7536.7886\n",
      "Epoch 1026/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.7573\n",
      "Epoch 01026: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7527.7573 - val_loss: 7536.4414\n",
      "Epoch 1027/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.1763\n",
      "Epoch 01027: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7539.1763 - val_loss: 7536.8423\n",
      "Epoch 1028/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.6523\n",
      "Epoch 01028: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7548.6523 - val_loss: 7536.7817\n",
      "Epoch 1029/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1685\n",
      "Epoch 01029: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.1685 - val_loss: 7536.4766\n",
      "Epoch 1030/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.8267\n",
      "Epoch 01030: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7542.8267 - val_loss: 7536.2822\n",
      "Epoch 1031/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.1094\n",
      "Epoch 01031: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7545.1094 - val_loss: 7536.2754\n",
      "Epoch 1032/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0420\n",
      "Epoch 01032: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7534.0420 - val_loss: 7536.8838\n",
      "Epoch 1033/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.1587\n",
      "Epoch 01033: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7547.1587 - val_loss: 7536.5649\n",
      "Epoch 1034/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.8857\n",
      "Epoch 01034: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7547.8857 - val_loss: 7536.2754\n",
      "Epoch 1035/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.5415\n",
      "Epoch 01035: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7527.5415 - val_loss: 7536.2783\n",
      "Epoch 1036/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.6152\n",
      "Epoch 01036: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7528.6152 - val_loss: 7536.1943\n",
      "Epoch 1037/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.8223\n",
      "Epoch 01037: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7547.8223 - val_loss: 7536.3706\n",
      "Epoch 1038/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6079\n",
      "Epoch 01038: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.6079 - val_loss: 7536.3330\n",
      "Epoch 1039/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7539.0576\n",
      "Epoch 01039: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7539.0576 - val_loss: 7536.6030\n",
      "Epoch 1040/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.5400\n",
      "Epoch 01040: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7528.5400 - val_loss: 7536.1318\n",
      "Epoch 1041/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3735\n",
      "Epoch 01041: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7533.3735 - val_loss: 7536.5161\n",
      "Epoch 1042/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1221\n",
      "Epoch 01042: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7534.1221 - val_loss: 7536.2983\n",
      "Epoch 1043/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8359\n",
      "Epoch 01043: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.8359 - val_loss: 7536.2080\n",
      "Epoch 1044/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.2144\n",
      "Epoch 01044: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7534.2144 - val_loss: 7536.6641\n",
      "Epoch 1045/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7471\n",
      "Epoch 01045: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7532.7471 - val_loss: 7536.2920\n",
      "Epoch 1046/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2070\n",
      "Epoch 01046: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7538.2070 - val_loss: 7536.1470\n",
      "Epoch 1047/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4634\n",
      "Epoch 01047: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7532.4634 - val_loss: 7536.3242\n",
      "Epoch 1048/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.2959\n",
      "Epoch 01048: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7536.2959 - val_loss: 7538.5366\n",
      "Epoch 1049/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.9297\n",
      "Epoch 01049: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7548.9297 - val_loss: 7537.0527\n",
      "Epoch 1050/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1665\n",
      "Epoch 01050: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7534.1665 - val_loss: 7536.4712\n",
      "Epoch 1051/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.4658\n",
      "Epoch 01051: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.4658 - val_loss: 7537.0830\n",
      "Epoch 1052/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.3120\n",
      "Epoch 01052: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.3120 - val_loss: 7536.5601\n",
      "Epoch 1053/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.9438\n",
      "Epoch 01053: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7542.9438 - val_loss: 7536.4111\n",
      "Epoch 1054/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.3481\n",
      "Epoch 01054: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7539.3481 - val_loss: 7536.5913\n",
      "Epoch 1055/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9893\n",
      "Epoch 01055: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7533.9893 - val_loss: 7536.2969\n",
      "Epoch 1056/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.6499\n",
      "Epoch 01056: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7542.6499 - val_loss: 7536.3433\n",
      "Epoch 1057/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1763\n",
      "Epoch 01057: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.1763 - val_loss: 7536.2622\n",
      "Epoch 1058/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.9868\n",
      "Epoch 01058: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7520.9868 - val_loss: 7536.2158\n",
      "Epoch 1059/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.2817\n",
      "Epoch 01059: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7527.2817 - val_loss: 7536.2090\n",
      "Epoch 1060/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7793\n",
      "Epoch 01060: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.7793 - val_loss: 7536.2417\n",
      "Epoch 1061/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.0293\n",
      "Epoch 01061: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7539.0293 - val_loss: 7535.9863\n",
      "Epoch 1062/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.5278\n",
      "Epoch 01062: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7547.5278 - val_loss: 7536.0918\n",
      "Epoch 1063/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5151\n",
      "Epoch 01063: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.5151 - val_loss: 7536.1450\n",
      "Epoch 1064/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.2437\n",
      "Epoch 01064: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.2437 - val_loss: 7535.9976\n",
      "Epoch 1065/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.9707\n",
      "Epoch 01065: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.9707 - val_loss: 7536.1631\n",
      "Epoch 1066/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.6411\n",
      "Epoch 01066: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7533.6411 - val_loss: 7535.9058\n",
      "Epoch 1067/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.6470\n",
      "Epoch 01067: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7547.6470 - val_loss: 7536.1328\n",
      "Epoch 1068/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7773\n",
      "Epoch 01068: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7539.7773 - val_loss: 7538.8457\n",
      "Epoch 1069/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.9287\n",
      "Epoch 01069: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7529.9287 - val_loss: 7537.9634\n",
      "Epoch 1070/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.1025\n",
      "Epoch 01070: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7539.1025 - val_loss: 7537.0664\n",
      "Epoch 1071/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.7100\n",
      "Epoch 01071: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7538.7100 - val_loss: 7536.5776\n",
      "Epoch 1072/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.4849\n",
      "Epoch 01072: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7549.4849 - val_loss: 7537.6118\n",
      "Epoch 1073/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8521\n",
      "Epoch 01073: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7530.8521 - val_loss: 7538.2256\n",
      "Epoch 1074/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7552.3320\n",
      "Epoch 01074: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7552.3320 - val_loss: 7544.6602\n",
      "Epoch 1075/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.8994\n",
      "Epoch 01075: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7537.8994 - val_loss: 7538.4551\n",
      "Epoch 1076/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.2671\n",
      "Epoch 01076: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.2671 - val_loss: 7537.2222\n",
      "Epoch 1077/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.2129\n",
      "Epoch 01077: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.2129 - val_loss: 7536.5039\n",
      "Epoch 1078/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.4067\n",
      "Epoch 01078: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7539.4067 - val_loss: 7536.3442\n",
      "Epoch 1079/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.9976\n",
      "Epoch 01079: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7527.9976 - val_loss: 7536.5630\n",
      "Epoch 1080/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0190\n",
      "Epoch 01080: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7534.0190 - val_loss: 7536.3374\n",
      "Epoch 1081/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7554.2446\n",
      "Epoch 01081: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7554.2446 - val_loss: 7540.9551\n",
      "Epoch 1082/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.0869\n",
      "Epoch 01082: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7542.0869 - val_loss: 7536.8408\n",
      "Epoch 1083/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.8643\n",
      "Epoch 01083: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7526.8643 - val_loss: 7536.5552\n",
      "Epoch 1084/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6001\n",
      "Epoch 01084: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.6001 - val_loss: 7536.2471\n",
      "Epoch 1085/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.8945\n",
      "Epoch 01085: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7534.8945 - val_loss: 7536.0806\n",
      "Epoch 1086/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.2720\n",
      "Epoch 01086: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7528.2720 - val_loss: 7536.1450\n",
      "Epoch 1087/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6714\n",
      "Epoch 01087: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.6714 - val_loss: 7536.2417\n",
      "Epoch 1088/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.4902\n",
      "Epoch 01088: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7546.4902 - val_loss: 7536.1050\n",
      "Epoch 1089/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.3496\n",
      "Epoch 01089: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7527.3496 - val_loss: 7535.9697\n",
      "Epoch 1090/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8081\n",
      "Epoch 01090: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7530.8081 - val_loss: 7535.6714\n",
      "Epoch 1091/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.8262\n",
      "Epoch 01091: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.8262 - val_loss: 7535.5679\n",
      "Epoch 1092/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.3931\n",
      "Epoch 01092: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7547.3931 - val_loss: 7535.4663\n",
      "Epoch 1093/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.7393\n",
      "Epoch 01093: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.7393 - val_loss: 7535.5737\n",
      "Epoch 1094/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.3696\n",
      "Epoch 01094: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7542.3696 - val_loss: 7535.6255\n",
      "Epoch 1095/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4009\n",
      "Epoch 01095: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.4009 - val_loss: 7535.5679\n",
      "Epoch 1096/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.2983\n",
      "Epoch 01096: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7528.2983 - val_loss: 7536.0337\n",
      "Epoch 1097/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.6152\n",
      "Epoch 01097: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.6152 - val_loss: 7535.8257\n",
      "Epoch 1098/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.1587\n",
      "Epoch 01098: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7547.1587 - val_loss: 7535.5815\n",
      "Epoch 1099/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1221\n",
      "Epoch 01099: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.1221 - val_loss: 7536.0977\n",
      "Epoch 1100/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.7363\n",
      "Epoch 01100: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7547.7363 - val_loss: 7535.8848\n",
      "Epoch 1101/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.2266\n",
      "Epoch 01101: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7528.2266 - val_loss: 7537.0830\n",
      "Epoch 1102/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.6831\n",
      "Epoch 01102: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7535.6831 - val_loss: 7536.7266\n",
      "Epoch 1103/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.3696\n",
      "Epoch 01103: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7535.3696 - val_loss: 7536.7104\n",
      "Epoch 1104/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.3608\n",
      "Epoch 01104: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7542.3608 - val_loss: 7535.9458\n",
      "Epoch 1105/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.3330\n",
      "Epoch 01105: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7547.3330 - val_loss: 7535.5142\n",
      "Epoch 1106/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1265\n",
      "Epoch 01106: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7538.1265 - val_loss: 7535.8975\n",
      "Epoch 1107/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3042\n",
      "Epoch 01107: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.3042 - val_loss: 7535.9600\n",
      "Epoch 1108/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1445\n",
      "Epoch 01108: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7534.1445 - val_loss: 7535.6426\n",
      "Epoch 1109/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7537.7065\n",
      "Epoch 01109: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7537.7065 - val_loss: 7535.8809\n",
      "Epoch 1110/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3657\n",
      "Epoch 01110: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.3657 - val_loss: 7535.6694\n",
      "Epoch 1111/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.8833\n",
      "Epoch 01111: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.8833 - val_loss: 7535.5537\n",
      "Epoch 1112/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9614\n",
      "Epoch 01112: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7533.9614 - val_loss: 7535.6719\n",
      "Epoch 1113/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.1787\n",
      "Epoch 01113: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7547.1787 - val_loss: 7535.6304\n",
      "Epoch 1114/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.3149\n",
      "Epoch 01114: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7538.3149 - val_loss: 7535.4961\n",
      "Epoch 1115/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.3433\n",
      "Epoch 01115: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7545.3433 - val_loss: 7535.3745\n",
      "Epoch 1116/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.0737\n",
      "Epoch 01116: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7539.0737 - val_loss: 7535.7329\n",
      "Epoch 1117/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.1665\n",
      "Epoch 01117: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7526.1665 - val_loss: 7535.8120\n",
      "Epoch 1118/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.7861\n",
      "Epoch 01118: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7526.7861 - val_loss: 7535.4224\n",
      "Epoch 1119/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.3608\n",
      "Epoch 01119: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.3608 - val_loss: 7535.8032\n",
      "Epoch 1120/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.8354\n",
      "Epoch 01120: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.8354 - val_loss: 7535.8945\n",
      "Epoch 1121/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.6675\n",
      "Epoch 01121: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7538.6675 - val_loss: 7535.2998\n",
      "Epoch 1122/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0786\n",
      "Epoch 01122: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7531.0786 - val_loss: 7535.9849\n",
      "Epoch 1123/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0361\n",
      "Epoch 01123: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.0361 - val_loss: 7536.5254\n",
      "Epoch 1124/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.1118\n",
      "Epoch 01124: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7528.1118 - val_loss: 7536.8735\n",
      "Epoch 1125/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5874\n",
      "Epoch 01125: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 541ms/step - loss: 7534.5874 - val_loss: 7536.1162\n",
      "Epoch 1126/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6709\n",
      "Epoch 01126: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7534.6709 - val_loss: 7536.6855\n",
      "Epoch 1127/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2251\n",
      "Epoch 01127: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7532.2251 - val_loss: 7535.9033\n",
      "Epoch 1128/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.3979\n",
      "Epoch 01128: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7544.3979 - val_loss: 7535.8369\n",
      "Epoch 1129/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.2114\n",
      "Epoch 01129: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7539.2114 - val_loss: 7535.7544\n",
      "Epoch 1130/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.9272\n",
      "Epoch 01130: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7534.9272 - val_loss: 7535.8345\n",
      "Epoch 1131/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5054\n",
      "Epoch 01131: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7533.5054 - val_loss: 7535.7622\n",
      "Epoch 1132/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7246\n",
      "Epoch 01132: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.7246 - val_loss: 7535.7178\n",
      "Epoch 1133/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.2417\n",
      "Epoch 01133: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7547.2417 - val_loss: 7535.7256\n",
      "Epoch 1134/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9434\n",
      "Epoch 01134: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.9434 - val_loss: 7535.7881\n",
      "Epoch 1135/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.8779\n",
      "Epoch 01135: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7547.8779 - val_loss: 7537.4878\n",
      "Epoch 1136/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.0659\n",
      "Epoch 01136: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7547.0659 - val_loss: 7536.0312\n",
      "Epoch 1137/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7080\n",
      "Epoch 01137: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7530.7080 - val_loss: 7535.6602\n",
      "Epoch 1138/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.0977\n",
      "Epoch 01138: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7520.0977 - val_loss: 7535.3848\n",
      "Epoch 1139/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.6133\n",
      "Epoch 01139: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7530.6133 - val_loss: 7535.6616\n",
      "Epoch 1140/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.7925\n",
      "Epoch 01140: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.7925 - val_loss: 7535.6704\n",
      "Epoch 1141/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1689\n",
      "Epoch 01141: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.1689 - val_loss: 7535.7393\n",
      "Epoch 1142/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0015\n",
      "Epoch 01142: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.0015 - val_loss: 7535.5024\n",
      "Epoch 1143/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.5674\n",
      "Epoch 01143: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7538.5674 - val_loss: 7535.5376\n",
      "Epoch 1144/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7526.8403\n",
      "Epoch 01144: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7526.8403 - val_loss: 7535.6362\n",
      "Epoch 1145/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.4277\n",
      "Epoch 01145: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7547.4277 - val_loss: 7535.8921\n",
      "Epoch 1146/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4473\n",
      "Epoch 01146: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7533.4473 - val_loss: 7535.7119\n",
      "Epoch 1147/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.8799\n",
      "Epoch 01147: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7541.8799 - val_loss: 7535.5889\n",
      "Epoch 1148/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1890\n",
      "Epoch 01148: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7538.1890 - val_loss: 7535.6904\n",
      "Epoch 1149/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0737\n",
      "Epoch 01149: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.0737 - val_loss: 7535.2974\n",
      "Epoch 1150/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0679\n",
      "Epoch 01150: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.0679 - val_loss: 7535.9849\n",
      "Epoch 1151/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2974\n",
      "Epoch 01151: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.2974 - val_loss: 7535.6895\n",
      "Epoch 1152/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.5166\n",
      "Epoch 01152: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7525.5166 - val_loss: 7535.4121\n",
      "Epoch 1153/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.0425\n",
      "Epoch 01153: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 541ms/step - loss: 7547.0425 - val_loss: 7535.4414\n",
      "Epoch 1154/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.3682\n",
      "Epoch 01154: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 544ms/step - loss: 7544.3682 - val_loss: 7535.8633\n",
      "Epoch 1155/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4683\n",
      "Epoch 01155: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7537.4683 - val_loss: 7535.5918\n",
      "Epoch 1156/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.1245\n",
      "Epoch 01156: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7547.1245 - val_loss: 7535.4126\n",
      "Epoch 1157/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.8711\n",
      "Epoch 01157: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.8711 - val_loss: 7535.5889\n",
      "Epoch 1158/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.2075\n",
      "Epoch 01158: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7520.2075 - val_loss: 7535.4624\n",
      "Epoch 1159/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8691\n",
      "Epoch 01159: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7533.8691 - val_loss: 7535.2607\n",
      "Epoch 1160/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.8525\n",
      "Epoch 01160: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7546.8525 - val_loss: 7535.1616\n",
      "Epoch 1161/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.9722\n",
      "Epoch 01161: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7546.9722 - val_loss: 7535.1665\n",
      "Epoch 1162/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2827\n",
      "Epoch 01162: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7532.2827 - val_loss: 7535.0864\n",
      "Epoch 1163/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.6665\n",
      "Epoch 01163: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7541.6665 - val_loss: 7535.7383\n",
      "Epoch 1164/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.4111\n",
      "Epoch 01164: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7538.4111 - val_loss: 7535.8896\n",
      "Epoch 1165/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.6499\n",
      "Epoch 01165: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.6499 - val_loss: 7535.5103\n",
      "Epoch 1166/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.8916\n",
      "Epoch 01166: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7537.8916 - val_loss: 7535.1406\n",
      "Epoch 1167/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9521\n",
      "Epoch 01167: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7531.9521 - val_loss: 7534.8921\n",
      "Epoch 1168/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4102\n",
      "Epoch 01168: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7533.4102 - val_loss: 7535.3359\n",
      "Epoch 1169/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9507\n",
      "Epoch 01169: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.9507 - val_loss: 7535.0801\n",
      "Epoch 1170/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9219\n",
      "Epoch 01170: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.9219 - val_loss: 7535.3218\n",
      "Epoch 1171/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.4478\n",
      "Epoch 01171: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7526.4478 - val_loss: 7535.4209\n",
      "Epoch 1172/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6763\n",
      "Epoch 01172: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.6763 - val_loss: 7535.1792\n",
      "Epoch 1173/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0513\n",
      "Epoch 01173: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7534.0513 - val_loss: 7535.2798\n",
      "Epoch 1174/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.9048\n",
      "Epoch 01174: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.9048 - val_loss: 7535.2334\n",
      "Epoch 1175/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.9927\n",
      "Epoch 01175: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.9927 - val_loss: 7535.1855\n",
      "Epoch 1176/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.7002\n",
      "Epoch 01176: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.7002 - val_loss: 7535.4272\n",
      "Epoch 1177/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.9741\n",
      "Epoch 01177: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7545.9741 - val_loss: 7535.6758\n",
      "Epoch 1178/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.3306\n",
      "Epoch 01178: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.3306 - val_loss: 7535.3008\n",
      "Epoch 1179/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7520.1450\n",
      "Epoch 01179: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7520.1450 - val_loss: 7535.1240\n",
      "Epoch 1180/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.5186\n",
      "Epoch 01180: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.5186 - val_loss: 7535.3506\n",
      "Epoch 1181/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5630\n",
      "Epoch 01181: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.5630 - val_loss: 7534.9878\n",
      "Epoch 1182/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.5220\n",
      "Epoch 01182: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.5220 - val_loss: 7535.2441\n",
      "Epoch 1183/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.0742\n",
      "Epoch 01183: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7547.0742 - val_loss: 7535.4370\n",
      "Epoch 1184/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2119\n",
      "Epoch 01184: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.2119 - val_loss: 7535.4282\n",
      "Epoch 1185/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.2720\n",
      "Epoch 01185: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7541.2720 - val_loss: 7535.0176\n",
      "Epoch 1186/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.0391\n",
      "Epoch 01186: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7530.0391 - val_loss: 7535.2090\n",
      "Epoch 1187/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.9077\n",
      "Epoch 01187: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7536.9077 - val_loss: 7535.1079\n",
      "Epoch 1188/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5542\n",
      "Epoch 01188: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7537.5542 - val_loss: 7535.3770\n",
      "Epoch 1189/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.6040\n",
      "Epoch 01189: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.6040 - val_loss: 7535.4697\n",
      "Epoch 1190/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.2065\n",
      "Epoch 01190: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.2065 - val_loss: 7534.9966\n",
      "Epoch 1191/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.1890\n",
      "Epoch 01191: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.1890 - val_loss: 7535.1055\n",
      "Epoch 1192/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.9741\n",
      "Epoch 01192: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7519.9741 - val_loss: 7535.2266\n",
      "Epoch 1193/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.7046\n",
      "Epoch 01193: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7519.7046 - val_loss: 7534.9561\n",
      "Epoch 1194/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1616\n",
      "Epoch 01194: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.1616 - val_loss: 7534.9199\n",
      "Epoch 1195/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.5229\n",
      "Epoch 01195: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7520.5229 - val_loss: 7535.6294\n",
      "Epoch 1196/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.2285\n",
      "Epoch 01196: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.2285 - val_loss: 7535.1841\n",
      "Epoch 1197/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1255\n",
      "Epoch 01197: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.1255 - val_loss: 7535.8608\n",
      "Epoch 1198/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.9785\n",
      "Epoch 01198: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.9785 - val_loss: 7534.9663\n",
      "Epoch 1199/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0415\n",
      "Epoch 01199: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.0415 - val_loss: 7534.9375\n",
      "Epoch 1200/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5967\n",
      "Epoch 01200: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.5967 - val_loss: 7534.8696\n",
      "Epoch 1201/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.0601\n",
      "Epoch 01201: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.0601 - val_loss: 7534.8423\n",
      "Epoch 1202/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5015\n",
      "Epoch 01202: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.5015 - val_loss: 7534.9463\n",
      "Epoch 1203/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0171\n",
      "Epoch 01203: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7537.0171 - val_loss: 7534.9663\n",
      "Epoch 1204/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.2324\n",
      "Epoch 01204: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7527.2324 - val_loss: 7534.8784\n",
      "Epoch 1205/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.7476\n",
      "Epoch 01205: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7525.7476 - val_loss: 7536.2217\n",
      "Epoch 1206/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6260\n",
      "Epoch 01206: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.6260 - val_loss: 7535.3374\n",
      "Epoch 1207/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.3320\n",
      "Epoch 01207: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.3320 - val_loss: 7535.5215\n",
      "Epoch 1208/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.3813\n",
      "Epoch 01208: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.3813 - val_loss: 7534.8960\n",
      "Epoch 1209/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5669\n",
      "Epoch 01209: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.5669 - val_loss: 7534.8896\n",
      "Epoch 1210/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.4009\n",
      "Epoch 01210: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7541.4009 - val_loss: 7535.1304\n",
      "Epoch 1211/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.3833\n",
      "Epoch 01211: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.3833 - val_loss: 7535.0830\n",
      "Epoch 1212/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.0942\n",
      "Epoch 01212: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7526.0942 - val_loss: 7534.9609\n",
      "Epoch 1213/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6445\n",
      "Epoch 01213: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7532.6445 - val_loss: 7535.0054\n",
      "Epoch 1214/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7520.0210\n",
      "Epoch 01214: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7520.0210 - val_loss: 7535.1665\n",
      "Epoch 1215/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6470\n",
      "Epoch 01215: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.6470 - val_loss: 7534.9233\n",
      "Epoch 1216/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.1797\n",
      "Epoch 01216: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.1797 - val_loss: 7535.3994\n",
      "Epoch 1217/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6367\n",
      "Epoch 01217: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.6367 - val_loss: 7535.2710\n",
      "Epoch 1218/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.0239\n",
      "Epoch 01218: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7520.0239 - val_loss: 7534.9272\n",
      "Epoch 1219/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5264\n",
      "Epoch 01219: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.5264 - val_loss: 7534.8618\n",
      "Epoch 1220/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.2041\n",
      "Epoch 01220: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7545.2041 - val_loss: 7534.9648\n",
      "Epoch 1221/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.2764\n",
      "Epoch 01221: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7545.2764 - val_loss: 7535.3975\n",
      "Epoch 1222/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.9639\n",
      "Epoch 01222: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7519.9639 - val_loss: 7535.2690\n",
      "Epoch 1223/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.1406\n",
      "Epoch 01223: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.1406 - val_loss: 7534.9609\n",
      "Epoch 1224/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1763\n",
      "Epoch 01224: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7538.1763 - val_loss: 7534.8594\n",
      "Epoch 1225/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5786\n",
      "Epoch 01225: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.5786 - val_loss: 7534.6382\n",
      "Epoch 1226/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.2666\n",
      "Epoch 01226: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.2666 - val_loss: 7535.4951\n",
      "Epoch 1227/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3032\n",
      "Epoch 01227: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 525ms/step - loss: 7532.3032 - val_loss: 7534.7095\n",
      "Epoch 1228/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8560\n",
      "Epoch 01228: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.8560 - val_loss: 7534.6567\n",
      "Epoch 1229/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.5713\n",
      "Epoch 01229: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7529.5713 - val_loss: 7534.7383\n",
      "Epoch 1230/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5225\n",
      "Epoch 01230: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.5225 - val_loss: 7534.7231\n",
      "Epoch 1231/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8335\n",
      "Epoch 01231: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.8335 - val_loss: 7534.5190\n",
      "Epoch 1232/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7812\n",
      "Epoch 01232: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7536.7812 - val_loss: 7534.7383\n",
      "Epoch 1233/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1211\n",
      "Epoch 01233: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.1211 - val_loss: 7534.7114\n",
      "Epoch 1234/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.5547\n",
      "Epoch 01234: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7519.5547 - val_loss: 7534.5254\n",
      "Epoch 1235/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.5439\n",
      "Epoch 01235: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7543.5439 - val_loss: 7534.9966\n",
      "Epoch 1236/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.4277\n",
      "Epoch 01236: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7541.4277 - val_loss: 7535.7832\n",
      "Epoch 1237/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.5137\n",
      "Epoch 01237: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.5137 - val_loss: 7535.2104\n",
      "Epoch 1238/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.0586\n",
      "Epoch 01238: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7543.0586 - val_loss: 7534.8457\n",
      "Epoch 1239/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.6846\n",
      "Epoch 01239: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 543ms/step - loss: 7525.6846 - val_loss: 7534.5498\n",
      "Epoch 1240/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3989\n",
      "Epoch 01240: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7533.3989 - val_loss: 7534.8618\n",
      "Epoch 1241/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7749\n",
      "Epoch 01241: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7532.7749 - val_loss: 7534.4639\n",
      "Epoch 1242/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.9458\n",
      "Epoch 01242: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7524.9458 - val_loss: 7534.8247\n",
      "Epoch 1243/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.4111\n",
      "Epoch 01243: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7519.4111 - val_loss: 7534.8472\n",
      "Epoch 1244/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.4634\n",
      "Epoch 01244: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.4634 - val_loss: 7535.2871\n",
      "Epoch 1245/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.4731\n",
      "Epoch 01245: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7543.4731 - val_loss: 7534.6689\n",
      "Epoch 1246/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.5605\n",
      "Epoch 01246: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7524.5605 - val_loss: 7534.5830\n",
      "Epoch 1247/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6250\n",
      "Epoch 01247: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.6250 - val_loss: 7534.5903\n",
      "Epoch 1248/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5771\n",
      "Epoch 01248: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.5771 - val_loss: 7535.2207\n",
      "Epoch 1249/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7545.9014\n",
      "Epoch 01249: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7545.9014 - val_loss: 7534.5122\n",
      "Epoch 1250/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4141\n",
      "Epoch 01250: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7531.4141 - val_loss: 7534.7720\n",
      "Epoch 1251/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0308\n",
      "Epoch 01251: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.0308 - val_loss: 7534.3984\n",
      "Epoch 1252/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5713\n",
      "Epoch 01252: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.5713 - val_loss: 7534.7271\n",
      "Epoch 1253/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7178\n",
      "Epoch 01253: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.7178 - val_loss: 7534.3687\n",
      "Epoch 1254/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0142\n",
      "Epoch 01254: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7537.0142 - val_loss: 7534.3135\n",
      "Epoch 1255/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8696\n",
      "Epoch 01255: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.8696 - val_loss: 7534.2998\n",
      "Epoch 1256/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.9463\n",
      "Epoch 01256: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7540.9463 - val_loss: 7534.5518\n",
      "Epoch 1257/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.2412\n",
      "Epoch 01257: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7520.2412 - val_loss: 7535.3472\n",
      "Epoch 1258/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0356\n",
      "Epoch 01258: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.0356 - val_loss: 7535.2153\n",
      "Epoch 1259/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1904\n",
      "Epoch 01259: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.1904 - val_loss: 7535.4248\n",
      "Epoch 1260/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.3477\n",
      "Epoch 01260: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.3477 - val_loss: 7534.6895\n",
      "Epoch 1261/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3872\n",
      "Epoch 01261: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.3872 - val_loss: 7535.7129\n",
      "Epoch 1262/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0781\n",
      "Epoch 01262: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7537.0781 - val_loss: 7535.0674\n",
      "Epoch 1263/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3335\n",
      "Epoch 01263: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.3335 - val_loss: 7534.8896\n",
      "Epoch 1264/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7671\n",
      "Epoch 01264: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.7671 - val_loss: 7534.7158\n",
      "Epoch 1265/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8560\n",
      "Epoch 01265: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.8560 - val_loss: 7534.5601\n",
      "Epoch 1266/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.1758\n",
      "Epoch 01266: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7519.1758 - val_loss: 7534.5415\n",
      "Epoch 1267/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0288\n",
      "Epoch 01267: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.0288 - val_loss: 7534.3945\n",
      "Epoch 1268/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.4448\n",
      "Epoch 01268: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7538.4448 - val_loss: 7535.0898\n",
      "Epoch 1269/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8833\n",
      "Epoch 01269: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7532.8833 - val_loss: 7535.0688\n",
      "Epoch 1270/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1460\n",
      "Epoch 01270: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.1460 - val_loss: 7534.8506\n",
      "Epoch 1271/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.9106\n",
      "Epoch 01271: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.9106 - val_loss: 7534.5688\n",
      "Epoch 1272/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2603\n",
      "Epoch 01272: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7532.2603 - val_loss: 7534.6401\n",
      "Epoch 1273/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4189\n",
      "Epoch 01273: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.4189 - val_loss: 7534.9351\n",
      "Epoch 1274/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0469\n",
      "Epoch 01274: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7538.0469 - val_loss: 7535.6553\n",
      "Epoch 1275/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.8647\n",
      "Epoch 01275: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.8647 - val_loss: 7534.8535\n",
      "Epoch 1276/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3452\n",
      "Epoch 01276: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.3452 - val_loss: 7534.9326\n",
      "Epoch 1277/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.5332\n",
      "Epoch 01277: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.5332 - val_loss: 7534.4302\n",
      "Epoch 1278/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6797\n",
      "Epoch 01278: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7536.6797 - val_loss: 7534.4136\n",
      "Epoch 1279/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.2256\n",
      "Epoch 01279: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7546.2256 - val_loss: 7534.8975\n",
      "Epoch 1280/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5234\n",
      "Epoch 01280: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.5234 - val_loss: 7534.1953\n",
      "Epoch 1281/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.5327\n",
      "Epoch 01281: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7524.5327 - val_loss: 7534.4663\n",
      "Epoch 1282/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4873\n",
      "Epoch 01282: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7533.4873 - val_loss: 7534.3130\n",
      "Epoch 1283/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9268\n",
      "Epoch 01283: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.9268 - val_loss: 7534.2017\n",
      "Epoch 1284/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7540.9824\n",
      "Epoch 01284: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.9824 - val_loss: 7534.6177\n",
      "Epoch 1285/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.0835\n",
      "Epoch 01285: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.0835 - val_loss: 7534.8271\n",
      "Epoch 1286/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.1772\n",
      "Epoch 01286: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.1772 - val_loss: 7534.7754\n",
      "Epoch 1287/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7563\n",
      "Epoch 01287: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.7563 - val_loss: 7534.7822\n",
      "Epoch 1288/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5708\n",
      "Epoch 01288: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.5708 - val_loss: 7535.3247\n",
      "Epoch 1289/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1641\n",
      "Epoch 01289: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.1641 - val_loss: 7534.6831\n",
      "Epoch 1290/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.7900\n",
      "Epoch 01290: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.7900 - val_loss: 7534.8618\n",
      "Epoch 1291/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8540\n",
      "Epoch 01291: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.8540 - val_loss: 7534.3687\n",
      "Epoch 1292/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0312\n",
      "Epoch 01292: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.0312 - val_loss: 7535.1592\n",
      "Epoch 1293/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7935\n",
      "Epoch 01293: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.7935 - val_loss: 7534.3750\n",
      "Epoch 1294/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.6611\n",
      "Epoch 01294: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.6611 - val_loss: 7534.5210\n",
      "Epoch 1295/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8091\n",
      "Epoch 01295: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.8091 - val_loss: 7534.5728\n",
      "Epoch 1296/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1733\n",
      "Epoch 01296: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7534.1733 - val_loss: 7534.8862\n",
      "Epoch 1297/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1494\n",
      "Epoch 01297: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7538.1494 - val_loss: 7535.6191\n",
      "Epoch 1298/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.5200\n",
      "Epoch 01298: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.5200 - val_loss: 7535.0566\n",
      "Epoch 1299/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.6094\n",
      "Epoch 01299: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.6094 - val_loss: 7534.5898\n",
      "Epoch 1300/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.1934\n",
      "Epoch 01300: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7529.1934 - val_loss: 7534.2710\n",
      "Epoch 1301/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.2676\n",
      "Epoch 01301: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.2676 - val_loss: 7534.0986\n",
      "Epoch 1302/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8291\n",
      "Epoch 01302: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.8291 - val_loss: 7534.2759\n",
      "Epoch 1303/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.8325\n",
      "Epoch 01303: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7518.8325 - val_loss: 7534.0327\n",
      "Epoch 1304/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2227\n",
      "Epoch 01304: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.2227 - val_loss: 7533.9927\n",
      "Epoch 1305/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7881\n",
      "Epoch 01305: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7530.7881 - val_loss: 7534.1694\n",
      "Epoch 1306/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.6265\n",
      "Epoch 01306: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.6265 - val_loss: 7534.4434\n",
      "Epoch 1307/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7974\n",
      "Epoch 01307: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.7974 - val_loss: 7534.6865\n",
      "Epoch 1308/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.1274\n",
      "Epoch 01308: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7546.1274 - val_loss: 7534.6040\n",
      "Epoch 1309/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8989\n",
      "Epoch 01309: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.8989 - val_loss: 7534.3926\n",
      "Epoch 1310/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.0503\n",
      "Epoch 01310: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7519.0503 - val_loss: 7534.2993\n",
      "Epoch 1311/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.2725\n",
      "Epoch 01311: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7539.2725 - val_loss: 7534.2007\n",
      "Epoch 1312/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0024\n",
      "Epoch 01312: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7531.0024 - val_loss: 7534.0762\n",
      "Epoch 1313/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.0376\n",
      "Epoch 01313: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7519.0376 - val_loss: 7534.2310\n",
      "Epoch 1314/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.6660\n",
      "Epoch 01314: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.6660 - val_loss: 7534.6689\n",
      "Epoch 1315/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.2344\n",
      "Epoch 01315: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7546.2344 - val_loss: 7534.6079\n",
      "Epoch 1316/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.9717\n",
      "Epoch 01316: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.9717 - val_loss: 7534.3496\n",
      "Epoch 1317/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3311\n",
      "Epoch 01317: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.3311 - val_loss: 7534.4209\n",
      "Epoch 1318/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.1650\n",
      "Epoch 01318: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.1650 - val_loss: 7535.4497\n",
      "Epoch 1319/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7545.3779\n",
      "Epoch 01319: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7545.3779 - val_loss: 7534.9927\n",
      "Epoch 1320/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.3877\n",
      "Epoch 01320: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7544.3877 - val_loss: 7534.2280\n",
      "Epoch 1321/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7124\n",
      "Epoch 01321: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.7124 - val_loss: 7533.9775\n",
      "Epoch 1322/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.8755\n",
      "Epoch 01322: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.8755 - val_loss: 7534.4111\n",
      "Epoch 1323/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0029\n",
      "Epoch 01323: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.0029 - val_loss: 7535.0264\n",
      "Epoch 1324/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7559\n",
      "Epoch 01324: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.7559 - val_loss: 7534.4712\n",
      "Epoch 1325/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.3618\n",
      "Epoch 01325: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.3618 - val_loss: 7534.1982\n",
      "Epoch 1326/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4844\n",
      "Epoch 01326: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.4844 - val_loss: 7534.5776\n",
      "Epoch 1327/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.6167\n",
      "Epoch 01327: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.6167 - val_loss: 7534.4673\n",
      "Epoch 1328/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2769\n",
      "Epoch 01328: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.2769 - val_loss: 7533.9263\n",
      "Epoch 1329/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.5884\n",
      "Epoch 01329: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7545.5884 - val_loss: 7534.1919\n",
      "Epoch 1330/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.9487\n",
      "Epoch 01330: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7546.9487 - val_loss: 7535.2886\n",
      "Epoch 1331/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.3350\n",
      "Epoch 01331: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.3350 - val_loss: 7534.4673\n",
      "Epoch 1332/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6943\n",
      "Epoch 01332: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.6943 - val_loss: 7534.8872\n",
      "Epoch 1333/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7173\n",
      "Epoch 01333: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.7173 - val_loss: 7534.3296\n",
      "Epoch 1334/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.3535\n",
      "Epoch 01334: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.3535 - val_loss: 7533.9702\n",
      "Epoch 1335/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6753\n",
      "Epoch 01335: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.6753 - val_loss: 7534.0210\n",
      "Epoch 1336/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4038\n",
      "Epoch 01336: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.4038 - val_loss: 7534.2222\n",
      "Epoch 1337/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2432\n",
      "Epoch 01337: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.2432 - val_loss: 7534.0015\n",
      "Epoch 1338/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.5986\n",
      "Epoch 01338: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7542.5986 - val_loss: 7534.0913\n",
      "Epoch 1339/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7886\n",
      "Epoch 01339: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.7886 - val_loss: 7534.4282\n",
      "Epoch 1340/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1880\n",
      "Epoch 01340: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.1880 - val_loss: 7534.2158\n",
      "Epoch 1341/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0464\n",
      "Epoch 01341: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.0464 - val_loss: 7537.8057\n",
      "Epoch 1342/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.8809\n",
      "Epoch 01342: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7547.8809 - val_loss: 7536.2935\n",
      "Epoch 1343/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4175\n",
      "Epoch 01343: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.4175 - val_loss: 7535.0161\n",
      "Epoch 1344/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.8086\n",
      "Epoch 01344: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7535.8086 - val_loss: 7536.5518\n",
      "Epoch 1345/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4575\n",
      "Epoch 01345: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.4575 - val_loss: 7535.5200\n",
      "Epoch 1346/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5200\n",
      "Epoch 01346: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.5200 - val_loss: 7534.6592\n",
      "Epoch 1347/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0249\n",
      "Epoch 01347: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.0249 - val_loss: 7534.5542\n",
      "Epoch 1348/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5146\n",
      "Epoch 01348: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.5146 - val_loss: 7534.5024\n",
      "Epoch 1349/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4839\n",
      "Epoch 01349: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.4839 - val_loss: 7534.0361\n",
      "Epoch 1350/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1519\n",
      "Epoch 01350: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.1519 - val_loss: 7534.3545\n",
      "Epoch 1351/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.6890\n",
      "Epoch 01351: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.6890 - val_loss: 7534.2183\n",
      "Epoch 1352/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5308\n",
      "Epoch 01352: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.5308 - val_loss: 7533.8262\n",
      "Epoch 1353/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.6235\n",
      "Epoch 01353: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7545.6235 - val_loss: 7534.0640\n",
      "Epoch 1354/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7531.4048\n",
      "Epoch 01354: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.4048 - val_loss: 7533.9238\n",
      "Epoch 1355/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.8633\n",
      "Epoch 01355: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7528.8633 - val_loss: 7533.8320\n",
      "Epoch 1356/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7773\n",
      "Epoch 01356: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7536.7773 - val_loss: 7533.8584\n",
      "Epoch 1357/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.6973\n",
      "Epoch 01357: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.6973 - val_loss: 7534.2056\n",
      "Epoch 1358/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1558\n",
      "Epoch 01358: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.1558 - val_loss: 7534.2559\n",
      "Epoch 1359/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7500\n",
      "Epoch 01359: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.7500 - val_loss: 7534.6094\n",
      "Epoch 1360/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.1362\n",
      "Epoch 01360: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7540.1362 - val_loss: 7535.1719\n",
      "Epoch 1361/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.5425\n",
      "Epoch 01361: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7542.5425 - val_loss: 7534.1230\n",
      "Epoch 1362/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3340\n",
      "Epoch 01362: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7531.3340 - val_loss: 7534.3633\n",
      "Epoch 1363/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3735\n",
      "Epoch 01363: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.3735 - val_loss: 7533.7598\n",
      "Epoch 1364/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.7671\n",
      "Epoch 01364: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.7671 - val_loss: 7533.7642\n",
      "Epoch 1365/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.5376\n",
      "Epoch 01365: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.5376 - val_loss: 7533.8398\n",
      "Epoch 1366/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1284\n",
      "Epoch 01366: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.1284 - val_loss: 7534.0386\n",
      "Epoch 1367/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.6289\n",
      "Epoch 01367: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7544.6289 - val_loss: 7534.4946\n",
      "Epoch 1368/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4604\n",
      "Epoch 01368: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.4604 - val_loss: 7534.1782\n",
      "Epoch 1369/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.9321\n",
      "Epoch 01369: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7546.9321 - val_loss: 7535.2729\n",
      "Epoch 1370/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2983\n",
      "Epoch 01370: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.2983 - val_loss: 7534.0918\n",
      "Epoch 1371/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.8496\n",
      "Epoch 01371: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7518.8496 - val_loss: 7533.8623\n",
      "Epoch 1372/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8604\n",
      "Epoch 01372: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.8604 - val_loss: 7534.2871\n",
      "Epoch 1373/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.8447\n",
      "Epoch 01373: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7535.8447 - val_loss: 7543.9121\n",
      "Epoch 1374/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7036\n",
      "Epoch 01374: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.7036 - val_loss: 7534.8721\n",
      "Epoch 1375/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7241\n",
      "Epoch 01375: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.7241 - val_loss: 7534.1626\n",
      "Epoch 1376/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.4521\n",
      "Epoch 01376: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.4521 - val_loss: 7534.0415\n",
      "Epoch 1377/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0459\n",
      "Epoch 01377: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.0459 - val_loss: 7534.1792\n",
      "Epoch 1378/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.2769\n",
      "Epoch 01378: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.2769 - val_loss: 7534.4790\n",
      "Epoch 1379/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.0874\n",
      "Epoch 01379: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.0874 - val_loss: 7534.1074\n",
      "Epoch 1380/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5142\n",
      "Epoch 01380: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.5142 - val_loss: 7534.6650\n",
      "Epoch 1381/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3765\n",
      "Epoch 01381: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.3765 - val_loss: 7533.8896\n",
      "Epoch 1382/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.5791\n",
      "Epoch 01382: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7519.5791 - val_loss: 7534.6592\n",
      "Epoch 1383/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1538\n",
      "Epoch 01383: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.1538 - val_loss: 7534.0513\n",
      "Epoch 1384/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1807\n",
      "Epoch 01384: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7536.1807 - val_loss: 7534.1958\n",
      "Epoch 1385/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8018\n",
      "Epoch 01385: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7545.8018 - val_loss: 7534.4409\n",
      "Epoch 1386/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1465\n",
      "Epoch 01386: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.1465 - val_loss: 7533.7983\n",
      "Epoch 1387/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6953\n",
      "Epoch 01387: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7537.6953 - val_loss: 7534.0474\n",
      "Epoch 1388/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.0283\n",
      "Epoch 01388: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7539.0283 - val_loss: 7533.8042\n",
      "Epoch 1389/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7545.5620\n",
      "Epoch 01389: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7545.5620 - val_loss: 7534.0938\n",
      "Epoch 1390/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0303\n",
      "Epoch 01390: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.0303 - val_loss: 7534.2192\n",
      "Epoch 1391/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5479\n",
      "Epoch 01391: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.5479 - val_loss: 7533.7607\n",
      "Epoch 1392/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.7661\n",
      "Epoch 01392: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7518.7661 - val_loss: 7533.8936\n",
      "Epoch 1393/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.5596\n",
      "Epoch 01393: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7518.5596 - val_loss: 7533.8398\n",
      "Epoch 1394/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.7612\n",
      "Epoch 01394: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7541.7612 - val_loss: 7535.5518\n",
      "Epoch 1395/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.4521\n",
      "Epoch 01395: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7545.4521 - val_loss: 7535.0513\n",
      "Epoch 1396/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5596\n",
      "Epoch 01396: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.5596 - val_loss: 7534.0762\n",
      "Epoch 1397/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.9780\n",
      "Epoch 01397: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.9780 - val_loss: 7534.2646\n",
      "Epoch 1398/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.6875\n",
      "Epoch 01398: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.6875 - val_loss: 7534.2480\n",
      "Epoch 1399/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4443\n",
      "Epoch 01399: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.4443 - val_loss: 7534.1265\n",
      "Epoch 1400/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2456\n",
      "Epoch 01400: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.2456 - val_loss: 7533.7656\n",
      "Epoch 1401/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4121\n",
      "Epoch 01401: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.4121 - val_loss: 7533.8560\n",
      "Epoch 1402/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.9126\n",
      "Epoch 01402: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.9126 - val_loss: 7534.1890\n",
      "Epoch 1403/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8682\n",
      "Epoch 01403: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7530.8682 - val_loss: 7534.2656\n",
      "Epoch 1404/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.0049\n",
      "Epoch 01404: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7546.0049 - val_loss: 7534.5879\n",
      "Epoch 1405/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.0288\n",
      "Epoch 01405: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7529.0288 - val_loss: 7534.0854\n",
      "Epoch 1406/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9146\n",
      "Epoch 01406: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.9146 - val_loss: 7533.7842\n",
      "Epoch 1407/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.9053\n",
      "Epoch 01407: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.9053 - val_loss: 7534.0049\n",
      "Epoch 1408/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4355\n",
      "Epoch 01408: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.4355 - val_loss: 7533.8921\n",
      "Epoch 1409/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2607\n",
      "Epoch 01409: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.2607 - val_loss: 7533.9746\n",
      "Epoch 1410/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5820\n",
      "Epoch 01410: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.5820 - val_loss: 7534.8271\n",
      "Epoch 1411/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.6782\n",
      "Epoch 01411: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7543.6782 - val_loss: 7535.7632\n",
      "Epoch 1412/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7148\n",
      "Epoch 01412: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.7148 - val_loss: 7535.4585\n",
      "Epoch 1413/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.0537\n",
      "Epoch 01413: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7547.0537 - val_loss: 7535.5640\n",
      "Epoch 1414/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3066\n",
      "Epoch 01414: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.3066 - val_loss: 7535.1670\n",
      "Epoch 1415/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1772\n",
      "Epoch 01415: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.1772 - val_loss: 7535.2886\n",
      "Epoch 1416/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3159\n",
      "Epoch 01416: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7536.3159 - val_loss: 7534.1846\n",
      "Epoch 1417/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7241\n",
      "Epoch 01417: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.7241 - val_loss: 7534.1919\n",
      "Epoch 1418/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4790\n",
      "Epoch 01418: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.4790 - val_loss: 7534.0352\n",
      "Epoch 1419/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.0884\n",
      "Epoch 01419: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.0884 - val_loss: 7534.0640\n",
      "Epoch 1420/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.8921\n",
      "Epoch 01420: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7528.8921 - val_loss: 7533.7681\n",
      "Epoch 1421/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4707\n",
      "Epoch 01421: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.4707 - val_loss: 7535.6943\n",
      "Epoch 1422/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.7632\n",
      "Epoch 01422: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.7632 - val_loss: 7537.0942\n",
      "Epoch 1423/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.1519\n",
      "Epoch 01423: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7546.1519 - val_loss: 7537.6895\n",
      "Epoch 1424/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7529.4829\n",
      "Epoch 01424: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.4829 - val_loss: 7537.7417\n",
      "Epoch 1425/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.6709\n",
      "Epoch 01425: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7543.6709 - val_loss: 7538.3110\n",
      "Epoch 1426/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.3057\n",
      "Epoch 01426: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.3057 - val_loss: 7537.5151\n",
      "Epoch 1427/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4585\n",
      "Epoch 01427: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7530.4585 - val_loss: 7541.2632\n",
      "Epoch 1428/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7522.9126\n",
      "Epoch 01428: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7522.9126 - val_loss: 7537.6953\n",
      "Epoch 1429/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.6821\n",
      "Epoch 01429: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.6821 - val_loss: 7536.9209\n",
      "Epoch 1430/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.2573\n",
      "Epoch 01430: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7549.2573 - val_loss: 7537.0742\n",
      "Epoch 1431/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.9189\n",
      "Epoch 01431: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7541.9189 - val_loss: 7536.3926\n",
      "Epoch 1432/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.8643\n",
      "Epoch 01432: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7534.8643 - val_loss: 7537.4512\n",
      "Epoch 1433/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.4126\n",
      "Epoch 01433: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.4126 - val_loss: 7537.8423\n",
      "Epoch 1434/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.1772\n",
      "Epoch 01434: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7528.1772 - val_loss: 7537.0498\n",
      "Epoch 1435/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.0947\n",
      "Epoch 01435: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7539.0947 - val_loss: 7536.4302\n",
      "Epoch 1436/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6851\n",
      "Epoch 01436: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.6851 - val_loss: 7535.9902\n",
      "Epoch 1437/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.6406\n",
      "Epoch 01437: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7538.6406 - val_loss: 7535.7495\n",
      "Epoch 1438/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.4702\n",
      "Epoch 01438: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7526.4702 - val_loss: 7535.5513\n",
      "Epoch 1439/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.9849\n",
      "Epoch 01439: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7546.9849 - val_loss: 7535.2310\n",
      "Epoch 1440/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.3120\n",
      "Epoch 01440: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7541.3120 - val_loss: 7535.1538\n",
      "Epoch 1441/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.5698\n",
      "Epoch 01441: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.5698 - val_loss: 7535.5674\n",
      "Epoch 1442/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.9727\n",
      "Epoch 01442: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7525.9727 - val_loss: 7535.0010\n",
      "Epoch 1443/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1494\n",
      "Epoch 01443: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7533.1494 - val_loss: 7534.9521\n",
      "Epoch 1444/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0898\n",
      "Epoch 01444: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.0898 - val_loss: 7534.5264\n",
      "Epoch 1445/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8438\n",
      "Epoch 01445: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.8438 - val_loss: 7534.7998\n",
      "Epoch 1446/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2007\n",
      "Epoch 01446: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.2007 - val_loss: 7534.6934\n",
      "Epoch 1447/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3647\n",
      "Epoch 01447: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7532.3647 - val_loss: 7534.4175\n",
      "Epoch 1448/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.3994\n",
      "Epoch 01448: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7519.3994 - val_loss: 7534.6382\n",
      "Epoch 1449/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5654\n",
      "Epoch 01449: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7536.5654 - val_loss: 7534.2720\n",
      "Epoch 1450/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0825\n",
      "Epoch 01450: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7537.0825 - val_loss: 7534.3984\n",
      "Epoch 1451/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7778\n",
      "Epoch 01451: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.7778 - val_loss: 7534.3320\n",
      "Epoch 1452/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0029\n",
      "Epoch 01452: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.0029 - val_loss: 7534.7241\n",
      "Epoch 1453/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.5610\n",
      "Epoch 01453: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7520.5610 - val_loss: 7535.6592\n",
      "Epoch 1454/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.3105\n",
      "Epoch 01454: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7541.3105 - val_loss: 7534.5249\n",
      "Epoch 1455/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4004\n",
      "Epoch 01455: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7532.4004 - val_loss: 7534.2231\n",
      "Epoch 1456/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5312\n",
      "Epoch 01456: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7537.5312 - val_loss: 7534.1890\n",
      "Epoch 1457/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8872\n",
      "Epoch 01457: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7531.8872 - val_loss: 7533.9121\n",
      "Epoch 1458/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4814\n",
      "Epoch 01458: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7530.4814 - val_loss: 7533.9570\n",
      "Epoch 1459/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7532.2344\n",
      "Epoch 01459: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.2344 - val_loss: 7533.9424\n",
      "Epoch 1460/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7471\n",
      "Epoch 01460: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7531.7471 - val_loss: 7534.3950\n",
      "Epoch 1461/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8184\n",
      "Epoch 01461: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.8184 - val_loss: 7534.6343\n",
      "Epoch 1462/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5132\n",
      "Epoch 01462: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.5132 - val_loss: 7534.2559\n",
      "Epoch 1463/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4653\n",
      "Epoch 01463: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.4653 - val_loss: 7533.8511\n",
      "Epoch 1464/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6597\n",
      "Epoch 01464: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7531.6597 - val_loss: 7533.6719\n",
      "Epoch 1465/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3633\n",
      "Epoch 01465: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7532.3633 - val_loss: 7533.9746\n",
      "Epoch 1466/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.5464\n",
      "Epoch 01466: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7542.5464 - val_loss: 7534.0498\n",
      "Epoch 1467/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0020\n",
      "Epoch 01467: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7536.0020 - val_loss: 7533.9438\n",
      "Epoch 1468/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8228\n",
      "Epoch 01468: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7531.8228 - val_loss: 7533.5898\n",
      "Epoch 1469/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8486\n",
      "Epoch 01469: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.8486 - val_loss: 7533.5537\n",
      "Epoch 1470/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.0479\n",
      "Epoch 01470: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.0479 - val_loss: 7533.8374\n",
      "Epoch 1471/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.7075\n",
      "Epoch 01471: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.7075 - val_loss: 7533.6216\n",
      "Epoch 1472/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.8145\n",
      "Epoch 01472: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.8145 - val_loss: 7533.7871\n",
      "Epoch 1473/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0815\n",
      "Epoch 01473: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.0815 - val_loss: 7534.0566\n",
      "Epoch 1474/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.1460\n",
      "Epoch 01474: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.1460 - val_loss: 7537.3960\n",
      "Epoch 1475/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.3862\n",
      "Epoch 01475: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7527.3862 - val_loss: 7535.4688\n",
      "Epoch 1476/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.1558\n",
      "Epoch 01476: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.1558 - val_loss: 7534.5518\n",
      "Epoch 1477/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.4790\n",
      "Epoch 01477: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7529.4790 - val_loss: 7534.4658\n",
      "Epoch 1478/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6182\n",
      "Epoch 01478: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.6182 - val_loss: 7534.3218\n",
      "Epoch 1479/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6753\n",
      "Epoch 01479: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.6753 - val_loss: 7534.5664\n",
      "Epoch 1480/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5303\n",
      "Epoch 01480: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7531.5303 - val_loss: 7533.6406\n",
      "Epoch 1481/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.0234\n",
      "Epoch 01481: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7525.0234 - val_loss: 7533.7446\n",
      "Epoch 1482/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.0156\n",
      "Epoch 01482: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.0156 - val_loss: 7533.5352\n",
      "Epoch 1483/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.7085\n",
      "Epoch 01483: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7535.7085 - val_loss: 7533.6392\n",
      "Epoch 1484/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.6597\n",
      "Epoch 01484: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.6597 - val_loss: 7533.7856\n",
      "Epoch 1485/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8013\n",
      "Epoch 01485: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.8013 - val_loss: 7533.6001\n",
      "Epoch 1486/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.6445\n",
      "Epoch 01486: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7523.6445 - val_loss: 7533.4775\n",
      "Epoch 1487/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2793\n",
      "Epoch 01487: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.2793 - val_loss: 7534.0742\n",
      "Epoch 1488/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.9727\n",
      "Epoch 01488: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7530.9727 - val_loss: 7534.9399\n",
      "Epoch 1489/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6270\n",
      "Epoch 01489: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.6270 - val_loss: 7534.5386\n",
      "Epoch 1490/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5737\n",
      "Epoch 01490: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.5737 - val_loss: 7533.7959\n",
      "Epoch 1491/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8516\n",
      "Epoch 01491: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.8516 - val_loss: 7533.7402\n",
      "Epoch 1492/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.6157\n",
      "Epoch 01492: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7524.6157 - val_loss: 7534.2358\n",
      "Epoch 1493/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7402\n",
      "Epoch 01493: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.7402 - val_loss: 7533.6465\n",
      "Epoch 1494/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7537.1685\n",
      "Epoch 01494: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.1685 - val_loss: 7533.5361\n",
      "Epoch 1495/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.2778\n",
      "Epoch 01495: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7542.2778 - val_loss: 7533.6592\n",
      "Epoch 1496/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9072\n",
      "Epoch 01496: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.9072 - val_loss: 7533.9785\n",
      "Epoch 1497/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.8926\n",
      "Epoch 01497: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7523.8926 - val_loss: 7533.7822\n",
      "Epoch 1498/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.4551\n",
      "Epoch 01498: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7545.4551 - val_loss: 7533.9033\n",
      "Epoch 1499/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8169\n",
      "Epoch 01499: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.8169 - val_loss: 7533.4409\n",
      "Epoch 1500/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.5825\n",
      "Epoch 01500: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.5825 - val_loss: 7533.8457\n",
      "Epoch 1501/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1787\n",
      "Epoch 01501: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.1787 - val_loss: 7534.1426\n",
      "Epoch 1502/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.0591\n",
      "Epoch 01502: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7540.0591 - val_loss: 7534.0288\n",
      "Epoch 1503/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.8203\n",
      "Epoch 01503: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.8203 - val_loss: 7534.9326\n",
      "Epoch 1504/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7090\n",
      "Epoch 01504: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.7090 - val_loss: 7535.3223\n",
      "Epoch 1505/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2847\n",
      "Epoch 01505: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.2847 - val_loss: 7534.4927\n",
      "Epoch 1506/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8276\n",
      "Epoch 01506: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.8276 - val_loss: 7534.1934\n",
      "Epoch 1507/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9482\n",
      "Epoch 01507: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.9482 - val_loss: 7533.6416\n",
      "Epoch 1508/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0088\n",
      "Epoch 01508: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.0088 - val_loss: 7533.9839\n",
      "Epoch 1509/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.3936\n",
      "Epoch 01509: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7525.3936 - val_loss: 7533.9263\n",
      "Epoch 1510/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1860\n",
      "Epoch 01510: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.1860 - val_loss: 7533.7896\n",
      "Epoch 1511/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0283\n",
      "Epoch 01511: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.0283 - val_loss: 7533.7607\n",
      "Epoch 1512/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.7798\n",
      "Epoch 01512: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7518.7798 - val_loss: 7533.4590\n",
      "Epoch 1513/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.5630\n",
      "Epoch 01513: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.5630 - val_loss: 7533.7544\n",
      "Epoch 1514/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.4795\n",
      "Epoch 01514: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7528.4795 - val_loss: 7533.5234\n",
      "Epoch 1515/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.7349\n",
      "Epoch 01515: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7542.7349 - val_loss: 7534.2617\n",
      "Epoch 1516/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1709\n",
      "Epoch 01516: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.1709 - val_loss: 7534.2002\n",
      "Epoch 1517/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.3037\n",
      "Epoch 01517: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.3037 - val_loss: 7533.8560\n",
      "Epoch 1518/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7046\n",
      "Epoch 01518: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.7046 - val_loss: 7534.3081\n",
      "Epoch 1519/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1523\n",
      "Epoch 01519: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7531.1523 - val_loss: 7534.2583\n",
      "Epoch 1520/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2505\n",
      "Epoch 01520: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.2505 - val_loss: 7533.4575\n",
      "Epoch 1521/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.6323\n",
      "Epoch 01521: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7543.6323 - val_loss: 7533.3896\n",
      "Epoch 1522/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1514\n",
      "Epoch 01522: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.1514 - val_loss: 7533.5698\n",
      "Epoch 1523/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0225\n",
      "Epoch 01523: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.0225 - val_loss: 7533.2935\n",
      "Epoch 1524/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.5381\n",
      "Epoch 01524: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7523.5381 - val_loss: 7533.5215\n",
      "Epoch 1525/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.9082\n",
      "Epoch 01525: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.9082 - val_loss: 7534.5239\n",
      "Epoch 1526/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5459\n",
      "Epoch 01526: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.5459 - val_loss: 7534.9312\n",
      "Epoch 1527/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3501\n",
      "Epoch 01527: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.3501 - val_loss: 7535.2471\n",
      "Epoch 1528/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.3589\n",
      "Epoch 01528: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.3589 - val_loss: 7533.6992\n",
      "Epoch 1529/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7543.6602\n",
      "Epoch 01529: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7543.6602 - val_loss: 7533.4561\n",
      "Epoch 1530/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.8813\n",
      "Epoch 01530: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7525.8813 - val_loss: 7533.7910\n",
      "Epoch 1531/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.1138\n",
      "Epoch 01531: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 544ms/step - loss: 7545.1138 - val_loss: 7533.7354\n",
      "Epoch 1532/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8960\n",
      "Epoch 01532: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 540ms/step - loss: 7544.8960 - val_loss: 7533.4546\n",
      "Epoch 1533/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.5176\n",
      "Epoch 01533: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7530.5176 - val_loss: 7533.5215\n",
      "Epoch 1534/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0864\n",
      "Epoch 01534: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.0864 - val_loss: 7534.4712\n",
      "Epoch 1535/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4736\n",
      "Epoch 01535: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.4736 - val_loss: 7533.9526\n",
      "Epoch 1536/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4189\n",
      "Epoch 01536: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.4189 - val_loss: 7533.7734\n",
      "Epoch 1537/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.9829\n",
      "Epoch 01537: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7523.9829 - val_loss: 7533.8784\n",
      "Epoch 1538/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8511\n",
      "Epoch 01538: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.8511 - val_loss: 7533.3247\n",
      "Epoch 1539/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8135\n",
      "Epoch 01539: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.8135 - val_loss: 7533.8110\n",
      "Epoch 1540/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3936\n",
      "Epoch 01540: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.3936 - val_loss: 7533.6504\n",
      "Epoch 1541/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1133\n",
      "Epoch 01541: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.1133 - val_loss: 7533.5410\n",
      "Epoch 1542/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.1626\n",
      "Epoch 01542: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.1626 - val_loss: 7533.4287\n",
      "Epoch 1543/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4146\n",
      "Epoch 01543: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7536.4146 - val_loss: 7533.7266\n",
      "Epoch 1544/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.6680\n",
      "Epoch 01544: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7528.6680 - val_loss: 7533.7632\n",
      "Epoch 1545/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0659\n",
      "Epoch 01545: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.0659 - val_loss: 7533.9170\n",
      "Epoch 1546/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.9702\n",
      "Epoch 01546: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.9702 - val_loss: 7533.6182\n",
      "Epoch 1547/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.5581\n",
      "Epoch 01547: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7530.5581 - val_loss: 7533.8623\n",
      "Epoch 1548/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.6582\n",
      "Epoch 01548: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7524.6582 - val_loss: 7533.4287\n",
      "Epoch 1549/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.1953\n",
      "Epoch 01549: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.1953 - val_loss: 7533.6489\n",
      "Epoch 1550/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.5718\n",
      "Epoch 01550: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.5718 - val_loss: 7533.5200\n",
      "Epoch 1551/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4253\n",
      "Epoch 01551: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7537.4253 - val_loss: 7533.9663\n",
      "Epoch 1552/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1738\n",
      "Epoch 01552: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7537.1738 - val_loss: 7533.7378\n",
      "Epoch 1553/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.1216\n",
      "Epoch 01553: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.1216 - val_loss: 7534.5415\n",
      "Epoch 1554/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.4917\n",
      "Epoch 01554: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7545.4917 - val_loss: 7533.8545\n",
      "Epoch 1555/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.4072\n",
      "Epoch 01555: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7518.4072 - val_loss: 7533.4097\n",
      "Epoch 1556/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.8467\n",
      "Epoch 01556: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.8467 - val_loss: 7533.4346\n",
      "Epoch 1557/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.9692\n",
      "Epoch 01557: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.9692 - val_loss: 7533.3296\n",
      "Epoch 1558/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0625\n",
      "Epoch 01558: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.0625 - val_loss: 7533.2798\n",
      "Epoch 1559/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4502\n",
      "Epoch 01559: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.4502 - val_loss: 7533.8457\n",
      "Epoch 1560/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.3564\n",
      "Epoch 01560: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7518.3564 - val_loss: 7533.3232\n",
      "Epoch 1561/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6035\n",
      "Epoch 01561: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.6035 - val_loss: 7535.1055\n",
      "Epoch 1562/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.0249\n",
      "Epoch 01562: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7528.0249 - val_loss: 7536.9863\n",
      "Epoch 1563/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.8350\n",
      "Epoch 01563: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7542.8350 - val_loss: 7536.1689\n",
      "Epoch 1564/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7541.3657\n",
      "Epoch 01564: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7541.3657 - val_loss: 7534.6958\n",
      "Epoch 1565/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.7183\n",
      "Epoch 01565: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.7183 - val_loss: 7534.8350\n",
      "Epoch 1566/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.0361\n",
      "Epoch 01566: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7543.0361 - val_loss: 7534.6826\n",
      "Epoch 1567/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.6401\n",
      "Epoch 01567: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.6401 - val_loss: 7534.2446\n",
      "Epoch 1568/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6016\n",
      "Epoch 01568: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.6016 - val_loss: 7534.9346\n",
      "Epoch 1569/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5854\n",
      "Epoch 01569: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7539.5854 - val_loss: 7534.5967\n",
      "Epoch 1570/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6851\n",
      "Epoch 01570: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.6851 - val_loss: 7534.3462\n",
      "Epoch 1571/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1689\n",
      "Epoch 01571: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7537.1689 - val_loss: 7534.9678\n",
      "Epoch 1572/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4434\n",
      "Epoch 01572: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.4434 - val_loss: 7534.7207\n",
      "Epoch 1573/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.1641\n",
      "Epoch 01573: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.1641 - val_loss: 7534.8232\n",
      "Epoch 1574/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5957\n",
      "Epoch 01574: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.5957 - val_loss: 7534.4858\n",
      "Epoch 1575/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.7310\n",
      "Epoch 01575: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.7310 - val_loss: 7534.3662\n",
      "Epoch 1576/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6104\n",
      "Epoch 01576: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.6104 - val_loss: 7534.5127\n",
      "Epoch 1577/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.5420\n",
      "Epoch 01577: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.5420 - val_loss: 7533.9536\n",
      "Epoch 1578/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7803\n",
      "Epoch 01578: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.7803 - val_loss: 7534.5024\n",
      "Epoch 1579/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.0771\n",
      "Epoch 01579: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7542.0771 - val_loss: 7533.4097\n",
      "Epoch 1580/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.9341\n",
      "Epoch 01580: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.9341 - val_loss: 7533.4712\n",
      "Epoch 1581/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.8359\n",
      "Epoch 01581: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7523.8359 - val_loss: 7533.4458\n",
      "Epoch 1582/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.6470\n",
      "Epoch 01582: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7528.6470 - val_loss: 7533.7471\n",
      "Epoch 1583/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8301\n",
      "Epoch 01583: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.8301 - val_loss: 7533.6626\n",
      "Epoch 1584/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.9185\n",
      "Epoch 01584: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7530.9185 - val_loss: 7533.3574\n",
      "Epoch 1585/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.7939\n",
      "Epoch 01585: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7541.7939 - val_loss: 7533.2471\n",
      "Epoch 1586/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.3008\n",
      "Epoch 01586: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7535.3008 - val_loss: 7533.1826\n",
      "Epoch 1587/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8594\n",
      "Epoch 01587: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7536.8594 - val_loss: 7533.4199\n",
      "Epoch 1588/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6016\n",
      "Epoch 01588: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.6016 - val_loss: 7533.5327\n",
      "Epoch 1589/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.7251\n",
      "Epoch 01589: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7525.7251 - val_loss: 7533.5640\n",
      "Epoch 1590/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3076\n",
      "Epoch 01590: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.3076 - val_loss: 7533.2817\n",
      "Epoch 1591/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.8730\n",
      "Epoch 01591: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7535.8730 - val_loss: 7533.1895\n",
      "Epoch 1592/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.7534\n",
      "Epoch 01592: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7541.7534 - val_loss: 7533.2793\n",
      "Epoch 1593/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.7905\n",
      "Epoch 01593: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7535.7905 - val_loss: 7533.1289\n",
      "Epoch 1594/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7832\n",
      "Epoch 01594: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7531.7832 - val_loss: 7533.2495\n",
      "Epoch 1595/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9463\n",
      "Epoch 01595: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7531.9463 - val_loss: 7533.7290\n",
      "Epoch 1596/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.3726\n",
      "Epoch 01596: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7539.3726 - val_loss: 7533.8569\n",
      "Epoch 1597/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.7451\n",
      "Epoch 01597: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7544.7451 - val_loss: 7533.4482\n",
      "Epoch 1598/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.3237\n",
      "Epoch 01598: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7545.3237 - val_loss: 7533.7622\n",
      "Epoch 1599/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7544.0415\n",
      "Epoch 01599: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7544.0415 - val_loss: 7534.0850\n",
      "Epoch 1600/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.3818\n",
      "Epoch 01600: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7542.3818 - val_loss: 7533.6416\n",
      "Epoch 1601/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.8369\n",
      "Epoch 01601: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.8369 - val_loss: 7533.3618\n",
      "Epoch 1602/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.4097\n",
      "Epoch 01602: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7529.4097 - val_loss: 7534.3110\n",
      "Epoch 1603/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0044\n",
      "Epoch 01603: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.0044 - val_loss: 7533.7446\n",
      "Epoch 1604/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2729\n",
      "Epoch 01604: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.2729 - val_loss: 7533.5103\n",
      "Epoch 1605/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7236\n",
      "Epoch 01605: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7530.7236 - val_loss: 7533.2070\n",
      "Epoch 1606/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9536\n",
      "Epoch 01606: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.9536 - val_loss: 7532.9937\n",
      "Epoch 1607/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.0562\n",
      "Epoch 01607: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.0562 - val_loss: 7533.2534\n",
      "Epoch 1608/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1064\n",
      "Epoch 01608: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7531.1064 - val_loss: 7533.4102\n",
      "Epoch 1609/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.9492\n",
      "Epoch 01609: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7535.9492 - val_loss: 7533.2534\n",
      "Epoch 1610/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7852\n",
      "Epoch 01610: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.7852 - val_loss: 7533.5376\n",
      "Epoch 1611/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8325\n",
      "Epoch 01611: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7536.8325 - val_loss: 7533.8696\n",
      "Epoch 1612/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7051\n",
      "Epoch 01612: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.7051 - val_loss: 7533.9297\n",
      "Epoch 1613/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.6855\n",
      "Epoch 01613: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7535.6855 - val_loss: 7533.4048\n",
      "Epoch 1614/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1802\n",
      "Epoch 01614: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.1802 - val_loss: 7533.5454\n",
      "Epoch 1615/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.6660\n",
      "Epoch 01615: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7524.6660 - val_loss: 7533.2886\n",
      "Epoch 1616/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3325\n",
      "Epoch 01616: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.3325 - val_loss: 7533.8896\n",
      "Epoch 1617/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.0469\n",
      "Epoch 01617: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.0469 - val_loss: 7533.5088\n",
      "Epoch 1618/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9434\n",
      "Epoch 01618: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.9434 - val_loss: 7534.3130\n",
      "Epoch 1619/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.4521\n",
      "Epoch 01619: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.4521 - val_loss: 7533.2959\n",
      "Epoch 1620/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3574\n",
      "Epoch 01620: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.3574 - val_loss: 7533.8257\n",
      "Epoch 1621/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.5928\n",
      "Epoch 01621: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7518.5928 - val_loss: 7533.7959\n",
      "Epoch 1622/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1372\n",
      "Epoch 01622: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.1372 - val_loss: 7533.7441\n",
      "Epoch 1623/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8164\n",
      "Epoch 01623: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.8164 - val_loss: 7534.0127\n",
      "Epoch 1624/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.5522\n",
      "Epoch 01624: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.5522 - val_loss: 7533.9346\n",
      "Epoch 1625/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0176\n",
      "Epoch 01625: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.0176 - val_loss: 7533.6016\n",
      "Epoch 1626/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8281\n",
      "Epoch 01626: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7544.8281 - val_loss: 7533.7354\n",
      "Epoch 1627/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.7466\n",
      "Epoch 01627: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7529.7466 - val_loss: 7533.2480\n",
      "Epoch 1628/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.2070\n",
      "Epoch 01628: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7545.2070 - val_loss: 7533.4878\n",
      "Epoch 1629/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.3037\n",
      "Epoch 01629: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7543.3037 - val_loss: 7539.0190\n",
      "Epoch 1630/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.1895\n",
      "Epoch 01630: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.1895 - val_loss: 7539.6206\n",
      "Epoch 1631/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.1318\n",
      "Epoch 01631: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7523.1318 - val_loss: 7538.0073\n",
      "Epoch 1632/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7676\n",
      "Epoch 01632: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.7676 - val_loss: 7537.4146\n",
      "Epoch 1633/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.6885\n",
      "Epoch 01633: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7547.6885 - val_loss: 7536.9551\n",
      "Epoch 1634/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7521.9419\n",
      "Epoch 01634: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7521.9419 - val_loss: 7536.7407\n",
      "Epoch 1635/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.1548\n",
      "Epoch 01635: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.1548 - val_loss: 7536.0200\n",
      "Epoch 1636/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.7583\n",
      "Epoch 01636: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7544.7583 - val_loss: 7534.2954\n",
      "Epoch 1637/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1836\n",
      "Epoch 01637: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7531.1836 - val_loss: 7533.7217\n",
      "Epoch 1638/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8276\n",
      "Epoch 01638: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.8276 - val_loss: 7533.6094\n",
      "Epoch 1639/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.5181\n",
      "Epoch 01639: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7528.5181 - val_loss: 7533.4302\n",
      "Epoch 1640/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8838\n",
      "Epoch 01640: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7530.8838 - val_loss: 7533.9463\n",
      "Epoch 1641/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8735\n",
      "Epoch 01641: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.8735 - val_loss: 7533.3926\n",
      "Epoch 1642/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.9375\n",
      "Epoch 01642: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.9375 - val_loss: 7533.3926\n",
      "Epoch 1643/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.4585\n",
      "Epoch 01643: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7538.4585 - val_loss: 7533.3530\n",
      "Epoch 1644/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.6963\n",
      "Epoch 01644: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.6963 - val_loss: 7533.8433\n",
      "Epoch 1645/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.7148\n",
      "Epoch 01645: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7523.7148 - val_loss: 7533.5479\n",
      "Epoch 1646/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.6572\n",
      "Epoch 01646: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7543.6572 - val_loss: 7533.4463\n",
      "Epoch 1647/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8916\n",
      "Epoch 01647: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.8916 - val_loss: 7533.4321\n",
      "Epoch 1648/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8301\n",
      "Epoch 01648: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7544.8301 - val_loss: 7533.5249\n",
      "Epoch 1649/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.9971\n",
      "Epoch 01649: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7544.9971 - val_loss: 7533.4272\n",
      "Epoch 1650/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.3452\n",
      "Epoch 01650: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.3452 - val_loss: 7535.2759\n",
      "Epoch 1651/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7944\n",
      "Epoch 01651: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7531.7944 - val_loss: 7534.2041\n",
      "Epoch 1652/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5508\n",
      "Epoch 01652: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7539.5508 - val_loss: 7533.2778\n",
      "Epoch 1653/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.7979\n",
      "Epoch 01653: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7544.7979 - val_loss: 7533.1431\n",
      "Epoch 1654/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6357\n",
      "Epoch 01654: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7536.6357 - val_loss: 7533.0210\n",
      "Epoch 1655/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.8945\n",
      "Epoch 01655: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7523.8945 - val_loss: 7533.6055\n",
      "Epoch 1656/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.5273\n",
      "Epoch 01656: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7535.5273 - val_loss: 7533.5977\n",
      "Epoch 1657/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.3936\n",
      "Epoch 01657: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7535.3936 - val_loss: 7533.3286\n",
      "Epoch 1658/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.3652\n",
      "Epoch 01658: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7543.3652 - val_loss: 7536.6274\n",
      "Epoch 1659/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5151\n",
      "Epoch 01659: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.5151 - val_loss: 7534.2158\n",
      "Epoch 1660/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.2910\n",
      "Epoch 01660: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7545.2910 - val_loss: 7533.8706\n",
      "Epoch 1661/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4131\n",
      "Epoch 01661: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.4131 - val_loss: 7533.9849\n",
      "Epoch 1662/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1147\n",
      "Epoch 01662: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7531.1147 - val_loss: 7533.6470\n",
      "Epoch 1663/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.9722\n",
      "Epoch 01663: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.9722 - val_loss: 7533.2207\n",
      "Epoch 1664/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8271\n",
      "Epoch 01664: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.8271 - val_loss: 7533.5474\n",
      "Epoch 1665/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.1050\n",
      "Epoch 01665: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7524.1050 - val_loss: 7534.0278\n",
      "Epoch 1666/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.7266\n",
      "Epoch 01666: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7545.7266 - val_loss: 7534.2759\n",
      "Epoch 1667/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2490\n",
      "Epoch 01667: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.2490 - val_loss: 7533.4790\n",
      "Epoch 1668/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.1387\n",
      "Epoch 01668: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.1387 - val_loss: 7533.5576\n",
      "Epoch 1669/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7529.7534\n",
      "Epoch 01669: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7529.7534 - val_loss: 7533.3218\n",
      "Epoch 1670/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.2598\n",
      "Epoch 01670: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.2598 - val_loss: 7533.2334\n",
      "Epoch 1671/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.2837\n",
      "Epoch 01671: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.2837 - val_loss: 7533.1055\n",
      "Epoch 1672/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0098\n",
      "Epoch 01672: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.0098 - val_loss: 7533.6514\n",
      "Epoch 1673/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.3076\n",
      "Epoch 01673: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7538.3076 - val_loss: 7534.8320\n",
      "Epoch 1674/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.2573\n",
      "Epoch 01674: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.2573 - val_loss: 7533.9663\n",
      "Epoch 1675/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.3511\n",
      "Epoch 01675: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.3511 - val_loss: 7533.1328\n",
      "Epoch 1676/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6206\n",
      "Epoch 01676: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.6206 - val_loss: 7533.3262\n",
      "Epoch 1677/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.7368\n",
      "Epoch 01677: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.7368 - val_loss: 7535.9102\n",
      "Epoch 1678/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2422\n",
      "Epoch 01678: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.2422 - val_loss: 7535.2954\n",
      "Epoch 1679/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8262\n",
      "Epoch 01679: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7532.8262 - val_loss: 7535.0210\n",
      "Epoch 1680/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.0464\n",
      "Epoch 01680: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7544.0464 - val_loss: 7535.5898\n",
      "Epoch 1681/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.1147\n",
      "Epoch 01681: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7542.1147 - val_loss: 7536.7256\n",
      "Epoch 1682/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5830\n",
      "Epoch 01682: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.5830 - val_loss: 7534.4438\n",
      "Epoch 1683/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2690\n",
      "Epoch 01683: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.2690 - val_loss: 7534.7954\n",
      "Epoch 1684/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3691\n",
      "Epoch 01684: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.3691 - val_loss: 7534.2642\n",
      "Epoch 1685/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6392\n",
      "Epoch 01685: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.6392 - val_loss: 7533.5112\n",
      "Epoch 1686/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1489\n",
      "Epoch 01686: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7531.1489 - val_loss: 7533.5762\n",
      "Epoch 1687/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7651\n",
      "Epoch 01687: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.7651 - val_loss: 7534.1606\n",
      "Epoch 1688/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1499\n",
      "Epoch 01688: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.1499 - val_loss: 7533.6631\n",
      "Epoch 1689/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.3774\n",
      "Epoch 01689: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.3774 - val_loss: 7533.2832\n",
      "Epoch 1690/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.6499\n",
      "Epoch 01690: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7544.6499 - val_loss: 7533.2729\n",
      "Epoch 1691/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.3022\n",
      "Epoch 01691: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7525.3022 - val_loss: 7533.4736\n",
      "Epoch 1692/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3091\n",
      "Epoch 01692: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7536.3091 - val_loss: 7533.4321\n",
      "Epoch 1693/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.1411\n",
      "Epoch 01693: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.1411 - val_loss: 7533.1138\n",
      "Epoch 1694/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.8071\n",
      "Epoch 01694: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7518.8071 - val_loss: 7533.7153\n",
      "Epoch 1695/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.6274\n",
      "Epoch 01695: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7530.6274 - val_loss: 7533.3442\n",
      "Epoch 1696/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.7666\n",
      "Epoch 01696: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.7666 - val_loss: 7533.0479\n",
      "Epoch 1697/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3623\n",
      "Epoch 01697: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7536.3623 - val_loss: 7532.8042\n",
      "Epoch 1698/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8330\n",
      "Epoch 01698: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7536.8330 - val_loss: 7533.4512\n",
      "Epoch 1699/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.3296\n",
      "Epoch 01699: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7530.3296 - val_loss: 7533.3521\n",
      "Epoch 1700/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.8174\n",
      "Epoch 01700: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.8174 - val_loss: 7533.2202\n",
      "Epoch 1701/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.8174\n",
      "Epoch 01701: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7524.8174 - val_loss: 7533.3130\n",
      "Epoch 1702/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0859\n",
      "Epoch 01702: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.0859 - val_loss: 7533.7305\n",
      "Epoch 1703/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.2637\n",
      "Epoch 01703: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7519.2637 - val_loss: 7534.3047\n",
      "Epoch 1704/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7531.6133\n",
      "Epoch 01704: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.6133 - val_loss: 7534.0542\n",
      "Epoch 1705/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.3101\n",
      "Epoch 01705: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7519.3101 - val_loss: 7534.3770\n",
      "Epoch 1706/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.8301\n",
      "Epoch 01706: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7525.8301 - val_loss: 7534.8535\n",
      "Epoch 1707/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7563\n",
      "Epoch 01707: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.7563 - val_loss: 7533.9937\n",
      "Epoch 1708/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6255\n",
      "Epoch 01708: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.6255 - val_loss: 7533.9448\n",
      "Epoch 1709/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2046\n",
      "Epoch 01709: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7532.2046 - val_loss: 7533.6030\n",
      "Epoch 1710/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.8672\n",
      "Epoch 01710: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7528.8672 - val_loss: 7533.4912\n",
      "Epoch 1711/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9717\n",
      "Epoch 01711: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.9717 - val_loss: 7533.8135\n",
      "Epoch 1712/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4238\n",
      "Epoch 01712: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.4238 - val_loss: 7533.3130\n",
      "Epoch 1713/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8452\n",
      "Epoch 01713: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.8452 - val_loss: 7533.1313\n",
      "Epoch 1714/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6055\n",
      "Epoch 01714: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.6055 - val_loss: 7533.1738\n",
      "Epoch 1715/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3867\n",
      "Epoch 01715: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.3867 - val_loss: 7533.3794\n",
      "Epoch 1716/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7764\n",
      "Epoch 01716: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.7764 - val_loss: 7534.2920\n",
      "Epoch 1717/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.7344\n",
      "Epoch 01717: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7523.7344 - val_loss: 7533.1143\n",
      "Epoch 1718/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.3101\n",
      "Epoch 01718: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7541.3101 - val_loss: 7534.9570\n",
      "Epoch 1719/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.7554\n",
      "Epoch 01719: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7519.7554 - val_loss: 7534.5479\n",
      "Epoch 1720/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.8516\n",
      "Epoch 01720: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.8516 - val_loss: 7533.9922\n",
      "Epoch 1721/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.9248\n",
      "Epoch 01721: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.9248 - val_loss: 7533.5791\n",
      "Epoch 1722/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8965\n",
      "Epoch 01722: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.8965 - val_loss: 7533.3975\n",
      "Epoch 1723/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.8052\n",
      "Epoch 01723: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7524.8052 - val_loss: 7533.5078\n",
      "Epoch 1724/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.5303\n",
      "Epoch 01724: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.5303 - val_loss: 7533.3887\n",
      "Epoch 1725/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.6152\n",
      "Epoch 01725: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7523.6152 - val_loss: 7533.3823\n",
      "Epoch 1726/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.8989\n",
      "Epoch 01726: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7524.8989 - val_loss: 7533.0752\n",
      "Epoch 1727/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.4512\n",
      "Epoch 01727: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.4512 - val_loss: 7532.8550\n",
      "Epoch 1728/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.1558\n",
      "Epoch 01728: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7530.1558 - val_loss: 7532.8008\n",
      "Epoch 1729/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8452\n",
      "Epoch 01729: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.8452 - val_loss: 7533.3311\n",
      "Epoch 1730/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1865\n",
      "Epoch 01730: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.1865 - val_loss: 7532.8809\n",
      "Epoch 1731/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4336\n",
      "Epoch 01731: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7530.4336 - val_loss: 7532.9746\n",
      "Epoch 1732/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.8901\n",
      "Epoch 01732: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7527.8901 - val_loss: 7532.7119\n",
      "Epoch 1733/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6279\n",
      "Epoch 01733: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7531.6279 - val_loss: 7532.8462\n",
      "Epoch 1734/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.1826\n",
      "Epoch 01734: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7543.1826 - val_loss: 7532.8745\n",
      "Epoch 1735/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.3252\n",
      "Epoch 01735: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.3252 - val_loss: 7533.2798\n",
      "Epoch 1736/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.6133\n",
      "Epoch 01736: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7528.6133 - val_loss: 7536.8706\n",
      "Epoch 1737/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4307\n",
      "Epoch 01737: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.4307 - val_loss: 7534.3823\n",
      "Epoch 1738/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7983\n",
      "Epoch 01738: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.7983 - val_loss: 7534.0791\n",
      "Epoch 1739/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7536.4424\n",
      "Epoch 01739: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.4424 - val_loss: 7533.2104\n",
      "Epoch 1740/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.6299\n",
      "Epoch 01740: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.6299 - val_loss: 7533.1470\n",
      "Epoch 1741/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.0293\n",
      "Epoch 01741: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7545.0293 - val_loss: 7533.1855\n",
      "Epoch 1742/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.1411\n",
      "Epoch 01742: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.1411 - val_loss: 7532.9775\n",
      "Epoch 1743/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2358\n",
      "Epoch 01743: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.2358 - val_loss: 7532.8208\n",
      "Epoch 1744/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4292\n",
      "Epoch 01744: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.4292 - val_loss: 7532.7378\n",
      "Epoch 1745/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.5903\n",
      "Epoch 01745: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.5903 - val_loss: 7533.1353\n",
      "Epoch 1746/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.1558\n",
      "Epoch 01746: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7524.1558 - val_loss: 7532.7178\n",
      "Epoch 1747/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.3203\n",
      "Epoch 01747: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7528.3203 - val_loss: 7533.0337\n",
      "Epoch 1748/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8574\n",
      "Epoch 01748: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7544.8574 - val_loss: 7534.4536\n",
      "Epoch 1749/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.6948\n",
      "Epoch 01749: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7528.6948 - val_loss: 7533.1455\n",
      "Epoch 1750/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7031\n",
      "Epoch 01750: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.7031 - val_loss: 7533.0991\n",
      "Epoch 1751/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0161\n",
      "Epoch 01751: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.0161 - val_loss: 7534.5938\n",
      "Epoch 1752/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7554.2905\n",
      "Epoch 01752: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7554.2905 - val_loss: 7542.5264\n",
      "Epoch 1753/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.8418\n",
      "Epoch 01753: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7541.8418 - val_loss: 7539.1602\n",
      "Epoch 1754/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.2510\n",
      "Epoch 01754: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7536.2510 - val_loss: 7537.5986\n",
      "Epoch 1755/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.7690\n",
      "Epoch 01755: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.7690 - val_loss: 7536.9985\n",
      "Epoch 1756/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7555.9028\n",
      "Epoch 01756: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7555.9028 - val_loss: 7551.6001\n",
      "Epoch 1757/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7557.0039\n",
      "Epoch 01757: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7557.0039 - val_loss: 7545.3350\n",
      "Epoch 1758/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.3872\n",
      "Epoch 01758: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7549.3872 - val_loss: 7544.9634\n",
      "Epoch 1759/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.6074\n",
      "Epoch 01759: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7549.6074 - val_loss: 7541.9048\n",
      "Epoch 1760/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6348\n",
      "Epoch 01760: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.6348 - val_loss: 7539.4790\n",
      "Epoch 1761/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.9155\n",
      "Epoch 01761: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7541.9155 - val_loss: 7538.2935\n",
      "Epoch 1762/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.4014\n",
      "Epoch 01762: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.4014 - val_loss: 7537.9561\n",
      "Epoch 1763/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6177\n",
      "Epoch 01763: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.6177 - val_loss: 7537.5903\n",
      "Epoch 1764/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8735\n",
      "Epoch 01764: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7538.8735 - val_loss: 7537.0088\n",
      "Epoch 1765/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.8984\n",
      "Epoch 01765: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7547.8984 - val_loss: 7536.6455\n",
      "Epoch 1766/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.9961\n",
      "Epoch 01766: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7541.9961 - val_loss: 7537.0254\n",
      "Epoch 1767/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.6812\n",
      "Epoch 01767: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7528.6812 - val_loss: 7536.7358\n",
      "Epoch 1768/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.1016\n",
      "Epoch 01768: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7535.1016 - val_loss: 7536.6289\n",
      "Epoch 1769/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.2876\n",
      "Epoch 01769: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7526.2876 - val_loss: 7536.4521\n",
      "Epoch 1770/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.5029\n",
      "Epoch 01770: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7527.5029 - val_loss: 7536.5034\n",
      "Epoch 1771/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.3599\n",
      "Epoch 01771: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7539.3599 - val_loss: 7536.0786\n",
      "Epoch 1772/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9756\n",
      "Epoch 01772: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.9756 - val_loss: 7536.1689\n",
      "Epoch 1773/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.9136\n",
      "Epoch 01773: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.9136 - val_loss: 7536.5850\n",
      "Epoch 1774/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7547.4214\n",
      "Epoch 01774: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7547.4214 - val_loss: 7536.2183\n",
      "Epoch 1775/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7046\n",
      "Epoch 01775: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7532.7046 - val_loss: 7536.1738\n",
      "Epoch 1776/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.6592\n",
      "Epoch 01776: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7520.6592 - val_loss: 7535.8809\n",
      "Epoch 1777/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.1636\n",
      "Epoch 01777: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.1636 - val_loss: 7535.8530\n",
      "Epoch 1778/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9512\n",
      "Epoch 01778: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.9512 - val_loss: 7535.5664\n",
      "Epoch 1779/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3574\n",
      "Epoch 01779: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7537.3574 - val_loss: 7535.5630\n",
      "Epoch 1780/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1519\n",
      "Epoch 01780: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7533.1519 - val_loss: 7535.5610\n",
      "Epoch 1781/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3887\n",
      "Epoch 01781: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7533.3887 - val_loss: 7536.0703\n",
      "Epoch 1782/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3770\n",
      "Epoch 01782: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7537.3770 - val_loss: 7535.7104\n",
      "Epoch 1783/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1353\n",
      "Epoch 01783: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7538.1353 - val_loss: 7535.7632\n",
      "Epoch 1784/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2612\n",
      "Epoch 01784: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.2612 - val_loss: 7535.7480\n",
      "Epoch 1785/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1562\n",
      "Epoch 01785: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7534.1562 - val_loss: 7535.8550\n",
      "Epoch 1786/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7676\n",
      "Epoch 01786: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7533.7676 - val_loss: 7535.8135\n",
      "Epoch 1787/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.4683\n",
      "Epoch 01787: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7540.4683 - val_loss: 7535.5151\n",
      "Epoch 1788/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4980\n",
      "Epoch 01788: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7530.4980 - val_loss: 7535.5854\n",
      "Epoch 1789/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.0396\n",
      "Epoch 01789: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7539.0396 - val_loss: 7535.4346\n",
      "Epoch 1790/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7550.0786\n",
      "Epoch 01790: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7550.0786 - val_loss: 7546.9111\n",
      "Epoch 1791/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.8755\n",
      "Epoch 01791: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7540.8755 - val_loss: 7544.8687\n",
      "Epoch 1792/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.2979\n",
      "Epoch 01792: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7540.2979 - val_loss: 7542.4922\n",
      "Epoch 1793/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.2983\n",
      "Epoch 01793: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7527.2983 - val_loss: 7541.2202\n",
      "Epoch 1794/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.9575\n",
      "Epoch 01794: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7542.9575 - val_loss: 7540.2793\n",
      "Epoch 1795/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8413\n",
      "Epoch 01795: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7536.8413 - val_loss: 7540.1934\n",
      "Epoch 1796/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.3350\n",
      "Epoch 01796: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7542.3350 - val_loss: 7539.8896\n",
      "Epoch 1797/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.8149\n",
      "Epoch 01797: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7537.8149 - val_loss: 7539.5815\n",
      "Epoch 1798/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.4014\n",
      "Epoch 01798: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7546.4014 - val_loss: 7539.1768\n",
      "Epoch 1799/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.9292\n",
      "Epoch 01799: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.9292 - val_loss: 7538.9888\n",
      "Epoch 1800/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8618\n",
      "Epoch 01800: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7530.8618 - val_loss: 7539.0112\n",
      "Epoch 1801/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4971\n",
      "Epoch 01801: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7536.4971 - val_loss: 7538.9590\n",
      "Epoch 1802/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5151\n",
      "Epoch 01802: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7534.5151 - val_loss: 7538.5967\n",
      "Epoch 1803/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4839\n",
      "Epoch 01803: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7535.4839 - val_loss: 7538.3486\n",
      "Epoch 1804/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.4009\n",
      "Epoch 01804: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7547.4009 - val_loss: 7538.3706\n",
      "Epoch 1805/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4268\n",
      "Epoch 01805: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7537.4268 - val_loss: 7538.1694\n",
      "Epoch 1806/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.3472\n",
      "Epoch 01806: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7541.3472 - val_loss: 7538.1182\n",
      "Epoch 1807/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0117\n",
      "Epoch 01807: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.0117 - val_loss: 7538.3154\n",
      "Epoch 1808/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8491\n",
      "Epoch 01808: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.8491 - val_loss: 7538.2354\n",
      "Epoch 1809/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7550.0229\n",
      "Epoch 01809: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7550.0229 - val_loss: 7538.1782\n",
      "Epoch 1810/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.3540\n",
      "Epoch 01810: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.3540 - val_loss: 7537.7129\n",
      "Epoch 1811/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7114\n",
      "Epoch 01811: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.7114 - val_loss: 7537.6138\n",
      "Epoch 1812/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6377\n",
      "Epoch 01812: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.6377 - val_loss: 7537.5474\n",
      "Epoch 1813/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.3472\n",
      "Epoch 01813: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7544.3472 - val_loss: 7537.4448\n",
      "Epoch 1814/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4121\n",
      "Epoch 01814: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.4121 - val_loss: 7537.4609\n",
      "Epoch 1815/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.3306\n",
      "Epoch 01815: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.3306 - val_loss: 7537.3623\n",
      "Epoch 1816/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7522.8726\n",
      "Epoch 01816: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7522.8726 - val_loss: 7537.6465\n",
      "Epoch 1817/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5796\n",
      "Epoch 01817: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.5796 - val_loss: 7537.3726\n",
      "Epoch 1818/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6733\n",
      "Epoch 01818: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.6733 - val_loss: 7537.4648\n",
      "Epoch 1819/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9648\n",
      "Epoch 01819: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.9648 - val_loss: 7537.5327\n",
      "Epoch 1820/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.8159\n",
      "Epoch 01820: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7547.8159 - val_loss: 7537.3657\n",
      "Epoch 1821/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.2588\n",
      "Epoch 01821: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7539.2588 - val_loss: 7537.0718\n",
      "Epoch 1822/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6816\n",
      "Epoch 01822: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7536.6816 - val_loss: 7537.0337\n",
      "Epoch 1823/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.2280\n",
      "Epoch 01823: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.2280 - val_loss: 7536.9136\n",
      "Epoch 1824/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.7612\n",
      "Epoch 01824: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.7612 - val_loss: 7537.2622\n",
      "Epoch 1825/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.6108\n",
      "Epoch 01825: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.6108 - val_loss: 7537.0439\n",
      "Epoch 1826/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8145\n",
      "Epoch 01826: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.8145 - val_loss: 7536.9902\n",
      "Epoch 1827/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.6182\n",
      "Epoch 01827: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7527.6182 - val_loss: 7537.0327\n",
      "Epoch 1828/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.2109\n",
      "Epoch 01828: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7547.2109 - val_loss: 7536.8896\n",
      "Epoch 1829/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.6196\n",
      "Epoch 01829: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7535.6196 - val_loss: 7536.7969\n",
      "Epoch 1830/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.6294\n",
      "Epoch 01830: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7543.6294 - val_loss: 7536.9150\n",
      "Epoch 1831/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.4131\n",
      "Epoch 01831: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7529.4131 - val_loss: 7536.7646\n",
      "Epoch 1832/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.7915\n",
      "Epoch 01832: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7548.7915 - val_loss: 7536.6782\n",
      "Epoch 1833/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.1353\n",
      "Epoch 01833: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.1353 - val_loss: 7537.7568\n",
      "Epoch 1834/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5947\n",
      "Epoch 01834: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.5947 - val_loss: 7536.8999\n",
      "Epoch 1835/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.9478\n",
      "Epoch 01835: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7538.9478 - val_loss: 7536.7344\n",
      "Epoch 1836/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3237\n",
      "Epoch 01836: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7536.3237 - val_loss: 7536.5918\n",
      "Epoch 1837/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.9932\n",
      "Epoch 01837: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.9932 - val_loss: 7536.6255\n",
      "Epoch 1838/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.7070\n",
      "Epoch 01838: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7548.7070 - val_loss: 7536.6714\n",
      "Epoch 1839/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8682\n",
      "Epoch 01839: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.8682 - val_loss: 7536.5400\n",
      "Epoch 1840/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.3975\n",
      "Epoch 01840: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7539.3975 - val_loss: 7536.7998\n",
      "Epoch 1841/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.2124\n",
      "Epoch 01841: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7529.2124 - val_loss: 7536.9937\n",
      "Epoch 1842/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.9829\n",
      "Epoch 01842: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7538.9829 - val_loss: 7536.6890\n",
      "Epoch 1843/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.2856\n",
      "Epoch 01843: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7540.2856 - val_loss: 7536.9761\n",
      "Epoch 1844/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7529.2192\n",
      "Epoch 01844: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.2192 - val_loss: 7536.5518\n",
      "Epoch 1845/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8408\n",
      "Epoch 01845: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.8408 - val_loss: 7536.5337\n",
      "Epoch 1846/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.6406\n",
      "Epoch 01846: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.6406 - val_loss: 7536.3311\n",
      "Epoch 1847/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.8730\n",
      "Epoch 01847: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7539.8730 - val_loss: 7536.8262\n",
      "Epoch 1848/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7521.8325\n",
      "Epoch 01848: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7521.8325 - val_loss: 7536.3711\n",
      "Epoch 1849/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4536\n",
      "Epoch 01849: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.4536 - val_loss: 7536.2295\n",
      "Epoch 1850/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.8657\n",
      "Epoch 01850: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7546.8657 - val_loss: 7536.5552\n",
      "Epoch 1851/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.0596\n",
      "Epoch 01851: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.0596 - val_loss: 7536.3872\n",
      "Epoch 1852/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8984\n",
      "Epoch 01852: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.8984 - val_loss: 7536.2598\n",
      "Epoch 1853/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.1514\n",
      "Epoch 01853: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.1514 - val_loss: 7536.3594\n",
      "Epoch 1854/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1421\n",
      "Epoch 01854: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.1421 - val_loss: 7536.3706\n",
      "Epoch 1855/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.7310\n",
      "Epoch 01855: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7546.7310 - val_loss: 7536.2520\n",
      "Epoch 1856/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.9995\n",
      "Epoch 01856: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7547.9995 - val_loss: 7536.3633\n",
      "Epoch 1857/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.0464\n",
      "Epoch 01857: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.0464 - val_loss: 7536.3506\n",
      "Epoch 1858/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.6553\n",
      "Epoch 01858: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7542.6553 - val_loss: 7537.1162\n",
      "Epoch 1859/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4399\n",
      "Epoch 01859: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7534.4399 - val_loss: 7536.5854\n",
      "Epoch 1860/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1172\n",
      "Epoch 01860: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7534.1172 - val_loss: 7536.4487\n",
      "Epoch 1861/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7344\n",
      "Epoch 01861: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.7344 - val_loss: 7536.5112\n",
      "Epoch 1862/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2080\n",
      "Epoch 01862: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.2080 - val_loss: 7536.2769\n",
      "Epoch 1863/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7521.3110\n",
      "Epoch 01863: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7521.3110 - val_loss: 7536.1665\n",
      "Epoch 1864/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.8931\n",
      "Epoch 01864: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7542.8931 - val_loss: 7536.4385\n",
      "Epoch 1865/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8315\n",
      "Epoch 01865: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7532.8315 - val_loss: 7536.0801\n",
      "Epoch 1866/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.7466\n",
      "Epoch 01866: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7534.7466 - val_loss: 7535.9927\n",
      "Epoch 1867/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.3789\n",
      "Epoch 01867: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7535.3789 - val_loss: 7535.9834\n",
      "Epoch 1868/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0645\n",
      "Epoch 01868: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7534.0645 - val_loss: 7536.3657\n",
      "Epoch 1869/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.8389\n",
      "Epoch 01869: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7546.8389 - val_loss: 7536.1895\n",
      "Epoch 1870/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0181\n",
      "Epoch 01870: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.0181 - val_loss: 7536.1177\n",
      "Epoch 1871/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9004\n",
      "Epoch 01871: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.9004 - val_loss: 7536.2402\n",
      "Epoch 1872/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2329\n",
      "Epoch 01872: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7538.2329 - val_loss: 7536.0366\n",
      "Epoch 1873/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.7446\n",
      "Epoch 01873: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.7446 - val_loss: 7535.9824\n",
      "Epoch 1874/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5654\n",
      "Epoch 01874: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7534.5654 - val_loss: 7535.9614\n",
      "Epoch 1875/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.7280\n",
      "Epoch 01875: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7547.7280 - val_loss: 7544.0073\n",
      "Epoch 1876/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1875\n",
      "Epoch 01876: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7534.1875 - val_loss: 7537.4058\n",
      "Epoch 1877/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3867\n",
      "Epoch 01877: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.3867 - val_loss: 7536.2710\n",
      "Epoch 1878/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.1235\n",
      "Epoch 01878: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.1235 - val_loss: 7536.4302\n",
      "Epoch 1879/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7546.5547\n",
      "Epoch 01879: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7546.5547 - val_loss: 7536.4058\n",
      "Epoch 1880/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.9707\n",
      "Epoch 01880: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7547.9707 - val_loss: 7535.8809\n",
      "Epoch 1881/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5269\n",
      "Epoch 01881: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7532.5269 - val_loss: 7535.8784\n",
      "Epoch 1882/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.8975\n",
      "Epoch 01882: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.8975 - val_loss: 7536.0278\n",
      "Epoch 1883/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.5586\n",
      "Epoch 01883: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7527.5586 - val_loss: 7536.1318\n",
      "Epoch 1884/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2612\n",
      "Epoch 01884: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.2612 - val_loss: 7536.1201\n",
      "Epoch 1885/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7822\n",
      "Epoch 01885: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.7822 - val_loss: 7535.7954\n",
      "Epoch 1886/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5020\n",
      "Epoch 01886: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7534.5020 - val_loss: 7535.7207\n",
      "Epoch 1887/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.3086\n",
      "Epoch 01887: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.3086 - val_loss: 7536.2305\n",
      "Epoch 1888/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7632\n",
      "Epoch 01888: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.7632 - val_loss: 7536.0879\n",
      "Epoch 1889/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0464\n",
      "Epoch 01889: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.0464 - val_loss: 7536.2202\n",
      "Epoch 1890/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.6143\n",
      "Epoch 01890: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7528.6143 - val_loss: 7536.0625\n",
      "Epoch 1891/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.2373\n",
      "Epoch 01891: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7528.2373 - val_loss: 7535.7529\n",
      "Epoch 1892/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.4351\n",
      "Epoch 01892: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7541.4351 - val_loss: 7536.0303\n",
      "Epoch 1893/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.1777\n",
      "Epoch 01893: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7545.1777 - val_loss: 7536.2832\n",
      "Epoch 1894/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.2339\n",
      "Epoch 01894: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7541.2339 - val_loss: 7535.9839\n",
      "Epoch 1895/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0293\n",
      "Epoch 01895: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.0293 - val_loss: 7535.7192\n",
      "Epoch 1896/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.9839\n",
      "Epoch 01896: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7534.9839 - val_loss: 7535.5874\n",
      "Epoch 1897/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6865\n",
      "Epoch 01897: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.6865 - val_loss: 7535.8408\n",
      "Epoch 1898/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.1118\n",
      "Epoch 01898: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7541.1118 - val_loss: 7535.6592\n",
      "Epoch 1899/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.6699\n",
      "Epoch 01899: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.6699 - val_loss: 7536.0337\n",
      "Epoch 1900/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.7842\n",
      "Epoch 01900: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7547.7842 - val_loss: 7535.6064\n",
      "Epoch 1901/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.8882\n",
      "Epoch 01901: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7520.8882 - val_loss: 7535.8672\n",
      "Epoch 1902/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4780\n",
      "Epoch 01902: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.4780 - val_loss: 7535.8447\n",
      "Epoch 1903/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.9355\n",
      "Epoch 01903: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.9355 - val_loss: 7536.5288\n",
      "Epoch 1904/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.6206\n",
      "Epoch 01904: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.6206 - val_loss: 7536.3857\n",
      "Epoch 1905/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.0288\n",
      "Epoch 01905: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7546.0288 - val_loss: 7535.6191\n",
      "Epoch 1906/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0391\n",
      "Epoch 01906: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.0391 - val_loss: 7535.6494\n",
      "Epoch 1907/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7521.0352\n",
      "Epoch 01907: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7521.0352 - val_loss: 7535.6450\n",
      "Epoch 1908/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.2661\n",
      "Epoch 01908: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7547.2661 - val_loss: 7537.0825\n",
      "Epoch 1909/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8374\n",
      "Epoch 01909: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7538.8374 - val_loss: 7535.9521\n",
      "Epoch 1910/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.1406\n",
      "Epoch 01910: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7526.1406 - val_loss: 7535.9873\n",
      "Epoch 1911/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7354\n",
      "Epoch 01911: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.7354 - val_loss: 7535.7310\n",
      "Epoch 1912/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.1094\n",
      "Epoch 01912: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7541.1094 - val_loss: 7535.6846\n",
      "Epoch 1913/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6226\n",
      "Epoch 01913: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.6226 - val_loss: 7536.3423\n",
      "Epoch 1914/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7534.9893\n",
      "Epoch 01914: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.9893 - val_loss: 7535.6758\n",
      "Epoch 1915/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3994\n",
      "Epoch 01915: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.3994 - val_loss: 7535.6006\n",
      "Epoch 1916/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.0669\n",
      "Epoch 01916: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7526.0669 - val_loss: 7535.7266\n",
      "Epoch 1917/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.2046\n",
      "Epoch 01917: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7527.2046 - val_loss: 7535.6104\n",
      "Epoch 1918/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.7729\n",
      "Epoch 01918: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7534.7729 - val_loss: 7536.0889\n",
      "Epoch 1919/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.6367\n",
      "Epoch 01919: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7533.6367 - val_loss: 7535.6592\n",
      "Epoch 1920/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3491\n",
      "Epoch 01920: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7532.3491 - val_loss: 7535.4834\n",
      "Epoch 1921/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.1660\n",
      "Epoch 01921: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7544.1660 - val_loss: 7535.6104\n",
      "Epoch 1922/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0474\n",
      "Epoch 01922: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.0474 - val_loss: 7535.6143\n",
      "Epoch 1923/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.8726\n",
      "Epoch 01923: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.8726 - val_loss: 7535.8486\n",
      "Epoch 1924/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.7485\n",
      "Epoch 01924: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7520.7485 - val_loss: 7535.5967\n",
      "Epoch 1925/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.6909\n",
      "Epoch 01925: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.6909 - val_loss: 7535.5688\n",
      "Epoch 1926/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4121\n",
      "Epoch 01926: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7534.4121 - val_loss: 7535.7056\n",
      "Epoch 1927/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8135\n",
      "Epoch 01927: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.8135 - val_loss: 7535.5898\n",
      "Epoch 1928/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.5786\n",
      "Epoch 01928: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7547.5786 - val_loss: 7536.0352\n",
      "Epoch 1929/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7539\n",
      "Epoch 01929: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.7539 - val_loss: 7535.6689\n",
      "Epoch 1930/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.1533\n",
      "Epoch 01930: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7544.1533 - val_loss: 7535.5127\n",
      "Epoch 1931/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.1865\n",
      "Epoch 01931: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7541.1865 - val_loss: 7535.8271\n",
      "Epoch 1932/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4971\n",
      "Epoch 01932: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.4971 - val_loss: 7535.6919\n",
      "Epoch 1933/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.9253\n",
      "Epoch 01933: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7540.9253 - val_loss: 7535.4966\n",
      "Epoch 1934/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2080\n",
      "Epoch 01934: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.2080 - val_loss: 7535.7598\n",
      "Epoch 1935/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8530\n",
      "Epoch 01935: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7545.8530 - val_loss: 7535.5474\n",
      "Epoch 1936/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5571\n",
      "Epoch 01936: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7537.5571 - val_loss: 7535.8706\n",
      "Epoch 1937/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.8740\n",
      "Epoch 01937: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7526.8740 - val_loss: 7535.3218\n",
      "Epoch 1938/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3247\n",
      "Epoch 01938: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7533.3247 - val_loss: 7535.6553\n",
      "Epoch 1939/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3394\n",
      "Epoch 01939: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.3394 - val_loss: 7535.4824\n",
      "Epoch 1940/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.9438\n",
      "Epoch 01940: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7546.9438 - val_loss: 7535.4839\n",
      "Epoch 1941/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.2578\n",
      "Epoch 01941: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7548.2578 - val_loss: 7536.5918\n",
      "Epoch 1942/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.5059\n",
      "Epoch 01942: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7535.5059 - val_loss: 7536.6318\n",
      "Epoch 1943/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4238\n",
      "Epoch 01943: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7533.4238 - val_loss: 7535.7578\n",
      "Epoch 1944/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.9907\n",
      "Epoch 01944: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.9907 - val_loss: 7539.3423\n",
      "Epoch 1945/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1914\n",
      "Epoch 01945: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.1914 - val_loss: 7535.6826\n",
      "Epoch 1946/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1646\n",
      "Epoch 01946: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7538.1646 - val_loss: 7535.5249\n",
      "Epoch 1947/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.6006\n",
      "Epoch 01947: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.6006 - val_loss: 7535.8687\n",
      "Epoch 1948/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5679\n",
      "Epoch 01948: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7537.5679 - val_loss: 7535.8105\n",
      "Epoch 1949/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7547.2075\n",
      "Epoch 01949: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7547.2075 - val_loss: 7535.4751\n",
      "Epoch 1950/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.9199\n",
      "Epoch 01950: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7540.9199 - val_loss: 7535.5718\n",
      "Epoch 1951/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.5977\n",
      "Epoch 01951: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.5977 - val_loss: 7535.4609\n",
      "Epoch 1952/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.6187\n",
      "Epoch 01952: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7520.6187 - val_loss: 7535.5391\n",
      "Epoch 1953/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.6978\n",
      "Epoch 01953: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.6978 - val_loss: 7535.3623\n",
      "Epoch 1954/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6709\n",
      "Epoch 01954: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.6709 - val_loss: 7535.5137\n",
      "Epoch 1955/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.8838\n",
      "Epoch 01955: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7540.8838 - val_loss: 7535.4673\n",
      "Epoch 1956/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.8496\n",
      "Epoch 01956: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.8496 - val_loss: 7535.8696\n",
      "Epoch 1957/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8018\n",
      "Epoch 01957: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7530.8018 - val_loss: 7535.4722\n",
      "Epoch 1958/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6724\n",
      "Epoch 01958: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7534.6724 - val_loss: 7535.8394\n",
      "Epoch 1959/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.1870\n",
      "Epoch 01959: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7541.1870 - val_loss: 7536.3198\n",
      "Epoch 1960/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8862\n",
      "Epoch 01960: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7545.8862 - val_loss: 7535.6089\n",
      "Epoch 1961/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8999\n",
      "Epoch 01961: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.8999 - val_loss: 7535.2969\n",
      "Epoch 1962/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.3555\n",
      "Epoch 01962: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7547.3555 - val_loss: 7535.5610\n",
      "Epoch 1963/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3208\n",
      "Epoch 01963: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.3208 - val_loss: 7535.3535\n",
      "Epoch 1964/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.0742\n",
      "Epoch 01964: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7541.0742 - val_loss: 7537.8999\n",
      "Epoch 1965/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0127\n",
      "Epoch 01965: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.0127 - val_loss: 7535.5566\n",
      "Epoch 1966/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1069\n",
      "Epoch 01966: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.1069 - val_loss: 7535.5142\n",
      "Epoch 1967/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.1470\n",
      "Epoch 01967: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7547.1470 - val_loss: 7535.3535\n",
      "Epoch 1968/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.3716\n",
      "Epoch 01968: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7538.3716 - val_loss: 7535.4224\n",
      "Epoch 1969/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.5303\n",
      "Epoch 01969: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.5303 - val_loss: 7535.3682\n",
      "Epoch 1970/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0288\n",
      "Epoch 01970: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7534.0288 - val_loss: 7535.3071\n",
      "Epoch 1971/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.7559\n",
      "Epoch 01971: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7547.7559 - val_loss: 7536.0654\n",
      "Epoch 1972/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8931\n",
      "Epoch 01972: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.8931 - val_loss: 7536.6489\n",
      "Epoch 1973/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9077\n",
      "Epoch 01973: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.9077 - val_loss: 7535.3584\n",
      "Epoch 1974/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.6255\n",
      "Epoch 01974: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.6255 - val_loss: 7535.4385\n",
      "Epoch 1975/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5537\n",
      "Epoch 01975: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.5537 - val_loss: 7536.0962\n",
      "Epoch 1976/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.1182\n",
      "Epoch 01976: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7528.1182 - val_loss: 7535.6450\n",
      "Epoch 1977/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0737\n",
      "Epoch 01977: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.0737 - val_loss: 7535.5928\n",
      "Epoch 1978/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8960\n",
      "Epoch 01978: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.8960 - val_loss: 7536.0249\n",
      "Epoch 1979/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.9585\n",
      "Epoch 01979: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7548.9585 - val_loss: 7537.1255\n",
      "Epoch 1980/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4873\n",
      "Epoch 01980: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.4873 - val_loss: 7535.5474\n",
      "Epoch 1981/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0859\n",
      "Epoch 01981: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.0859 - val_loss: 7535.5054\n",
      "Epoch 1982/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.7271\n",
      "Epoch 01982: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.7271 - val_loss: 7535.3569\n",
      "Epoch 1983/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2510\n",
      "Epoch 01983: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.2510 - val_loss: 7535.3857\n",
      "Epoch 1984/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7538.0498\n",
      "Epoch 01984: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.0498 - val_loss: 7535.4146\n",
      "Epoch 1985/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.4810\n",
      "Epoch 01985: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.4810 - val_loss: 7536.0352\n",
      "Epoch 1986/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0742\n",
      "Epoch 01986: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.0742 - val_loss: 7535.5488\n",
      "Epoch 1987/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.5142\n",
      "Epoch 01987: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7542.5142 - val_loss: 7536.2544\n",
      "Epoch 1988/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.4736\n",
      "Epoch 01988: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7545.4736 - val_loss: 7536.6191\n",
      "Epoch 1989/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2969\n",
      "Epoch 01989: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.2969 - val_loss: 7536.4712\n",
      "Epoch 1990/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.8306\n",
      "Epoch 01990: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7520.8306 - val_loss: 7536.2207\n",
      "Epoch 1991/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.7783\n",
      "Epoch 01991: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7545.7783 - val_loss: 7536.0879\n",
      "Epoch 1992/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9004\n",
      "Epoch 01992: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.9004 - val_loss: 7535.2378\n",
      "Epoch 1993/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.8955\n",
      "Epoch 01993: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.8955 - val_loss: 7535.4751\n",
      "Epoch 1994/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8818\n",
      "Epoch 01994: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.8818 - val_loss: 7535.8975\n",
      "Epoch 1995/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0317\n",
      "Epoch 01995: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.0317 - val_loss: 7535.2930\n",
      "Epoch 1996/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.2812\n",
      "Epoch 01996: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7542.2812 - val_loss: 7536.1470\n",
      "Epoch 1997/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7842\n",
      "Epoch 01997: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.7842 - val_loss: 7537.6094\n",
      "Epoch 1998/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8271\n",
      "Epoch 01998: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.8271 - val_loss: 7535.4863\n",
      "Epoch 1999/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.2754\n",
      "Epoch 01999: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7547.2754 - val_loss: 7535.3926\n",
      "Epoch 2000/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5317\n",
      "Epoch 02000: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.5317 - val_loss: 7535.5439\n",
      "Epoch 2001/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.9844\n",
      "Epoch 02001: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7537.9844 - val_loss: 7535.6206\n",
      "Epoch 2002/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7808\n",
      "Epoch 02002: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.7808 - val_loss: 7535.9512\n",
      "Epoch 2003/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7597.4272\n",
      "Epoch 02003: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7597.4272 - val_loss: 7593.4839\n",
      "Epoch 2004/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.1709\n",
      "Epoch 02004: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.1709 - val_loss: 7550.8423\n",
      "Epoch 2005/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7896\n",
      "Epoch 02005: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7539.7896 - val_loss: 7542.5806\n",
      "Epoch 2006/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.2266\n",
      "Epoch 02006: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.2266 - val_loss: 7540.8442\n",
      "Epoch 2007/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.9971\n",
      "Epoch 02007: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.9971 - val_loss: 7539.9424\n",
      "Epoch 2008/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.4170\n",
      "Epoch 02008: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7549.4170 - val_loss: 7539.4609\n",
      "Epoch 2009/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.3706\n",
      "Epoch 02009: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.3706 - val_loss: 7539.1826\n",
      "Epoch 2010/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.5244\n",
      "Epoch 02010: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7528.5244 - val_loss: 7538.9658\n",
      "Epoch 2011/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.7656\n",
      "Epoch 02011: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.7656 - val_loss: 7538.8066\n",
      "Epoch 2012/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.8545\n",
      "Epoch 02012: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.8545 - val_loss: 7538.6831\n",
      "Epoch 2013/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.5601\n",
      "Epoch 02013: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.5601 - val_loss: 7538.5386\n",
      "Epoch 2014/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7550.0234\n",
      "Epoch 02014: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7550.0234 - val_loss: 7538.5103\n",
      "Epoch 2015/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.3037\n",
      "Epoch 02015: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7548.3037 - val_loss: 7538.3584\n",
      "Epoch 2016/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.8462\n",
      "Epoch 02016: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7549.8462 - val_loss: 7538.3174\n",
      "Epoch 2017/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.8633\n",
      "Epoch 02017: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.8633 - val_loss: 7538.2104\n",
      "Epoch 2018/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0376\n",
      "Epoch 02018: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7536.0376 - val_loss: 7538.1377\n",
      "Epoch 2019/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7527.6382\n",
      "Epoch 02019: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7527.6382 - val_loss: 7538.0698\n",
      "Epoch 2020/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0454\n",
      "Epoch 02020: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7536.0454 - val_loss: 7538.0376\n",
      "Epoch 2021/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7522.2871\n",
      "Epoch 02021: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7522.2871 - val_loss: 7537.9775\n",
      "Epoch 2022/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.8560\n",
      "Epoch 02022: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7547.8560 - val_loss: 7537.9482\n",
      "Epoch 2023/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.4487\n",
      "Epoch 02023: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7539.4487 - val_loss: 7537.8711\n",
      "Epoch 2024/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7522.1069\n",
      "Epoch 02024: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7522.1069 - val_loss: 7537.8457\n",
      "Epoch 2025/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.0957\n",
      "Epoch 02025: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7539.0957 - val_loss: 7537.7920\n",
      "Epoch 2026/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.3486\n",
      "Epoch 02026: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7527.3486 - val_loss: 7537.8145\n",
      "Epoch 2027/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.6826\n",
      "Epoch 02027: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7529.6826 - val_loss: 7537.7520\n",
      "Epoch 2028/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.8184\n",
      "Epoch 02028: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.8184 - val_loss: 7537.6831\n",
      "Epoch 2029/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.2285\n",
      "Epoch 02029: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7540.2285 - val_loss: 7537.5962\n",
      "Epoch 2030/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.6289\n",
      "Epoch 02030: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.6289 - val_loss: 7537.5815\n",
      "Epoch 2031/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4429\n",
      "Epoch 02031: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.4429 - val_loss: 7537.5698\n",
      "Epoch 2032/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.3735\n",
      "Epoch 02032: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7547.3735 - val_loss: 7537.5791\n",
      "Epoch 2033/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5928\n",
      "Epoch 02033: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.5928 - val_loss: 7537.4570\n",
      "Epoch 2034/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.2339\n",
      "Epoch 02034: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7540.2339 - val_loss: 7537.4351\n",
      "Epoch 2035/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.1904\n",
      "Epoch 02035: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7540.1904 - val_loss: 7537.4102\n",
      "Epoch 2036/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.5205\n",
      "Epoch 02036: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7548.5205 - val_loss: 7537.3784\n",
      "Epoch 2037/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.3042\n",
      "Epoch 02037: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7529.3042 - val_loss: 7537.3521\n",
      "Epoch 2038/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.9165\n",
      "Epoch 02038: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.9165 - val_loss: 7537.3247\n",
      "Epoch 2039/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.2339\n",
      "Epoch 02039: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.2339 - val_loss: 7537.2578\n",
      "Epoch 2040/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5864\n",
      "Epoch 02040: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7534.5864 - val_loss: 7537.2559\n",
      "Epoch 2041/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.0059\n",
      "Epoch 02041: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.0059 - val_loss: 7537.2168\n",
      "Epoch 2042/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.3418\n",
      "Epoch 02042: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7548.3418 - val_loss: 7537.2856\n",
      "Epoch 2043/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.9346\n",
      "Epoch 02043: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7527.9346 - val_loss: 7537.1602\n",
      "Epoch 2044/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.9360\n",
      "Epoch 02044: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7527.9360 - val_loss: 7537.2305\n",
      "Epoch 2045/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.6338\n",
      "Epoch 02045: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7548.6338 - val_loss: 7537.1426\n",
      "Epoch 2046/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.9409\n",
      "Epoch 02046: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.9409 - val_loss: 7537.1489\n",
      "Epoch 2047/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.7368\n",
      "Epoch 02047: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.7368 - val_loss: 7537.0513\n",
      "Epoch 2048/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.9966\n",
      "Epoch 02048: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7541.9966 - val_loss: 7537.0063\n",
      "Epoch 2049/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.2471\n",
      "Epoch 02049: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7543.2471 - val_loss: 7537.0249\n",
      "Epoch 2050/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4233\n",
      "Epoch 02050: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7534.4233 - val_loss: 7537.0322\n",
      "Epoch 2051/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.8877\n",
      "Epoch 02051: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7527.8877 - val_loss: 7536.9937\n",
      "Epoch 2052/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.3154\n",
      "Epoch 02052: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7535.3154 - val_loss: 7536.9614\n",
      "Epoch 2053/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.0137\n",
      "Epoch 02053: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.0137 - val_loss: 7536.9058\n",
      "Epoch 2054/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7535.0747\n",
      "Epoch 02054: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7535.0747 - val_loss: 7536.9087\n",
      "Epoch 2055/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.4844\n",
      "Epoch 02055: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7548.4844 - val_loss: 7536.9082\n",
      "Epoch 2056/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.0503\n",
      "Epoch 02056: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.0503 - val_loss: 7536.9072\n",
      "Epoch 2057/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.7856\n",
      "Epoch 02057: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.7856 - val_loss: 7536.8823\n",
      "Epoch 2058/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.5586\n",
      "Epoch 02058: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7538.5586 - val_loss: 7536.8457\n",
      "Epoch 2059/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.1812\n",
      "Epoch 02059: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7543.1812 - val_loss: 7536.9775\n",
      "Epoch 2060/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.0610\n",
      "Epoch 02060: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.0610 - val_loss: 7536.7847\n",
      "Epoch 2061/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.4727\n",
      "Epoch 02061: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7548.4727 - val_loss: 7536.8242\n",
      "Epoch 2062/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5767\n",
      "Epoch 02062: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.5767 - val_loss: 7536.8218\n",
      "Epoch 2063/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.7764\n",
      "Epoch 02063: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7528.7764 - val_loss: 7536.7559\n",
      "Epoch 2064/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9482\n",
      "Epoch 02064: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.9482 - val_loss: 7536.7402\n",
      "Epoch 2065/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.9512\n",
      "Epoch 02065: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.9512 - val_loss: 7536.6846\n",
      "Epoch 2066/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.6206\n",
      "Epoch 02066: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7546.6206 - val_loss: 7536.7065\n",
      "Epoch 2067/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.6743\n",
      "Epoch 02067: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7528.6743 - val_loss: 7536.6338\n",
      "Epoch 2068/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.8672\n",
      "Epoch 02068: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 540ms/step - loss: 7539.8672 - val_loss: 7536.7153\n",
      "Epoch 2069/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.5029\n",
      "Epoch 02069: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 542ms/step - loss: 7541.5029 - val_loss: 7536.6382\n",
      "Epoch 2070/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5869\n",
      "Epoch 02070: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7539.5869 - val_loss: 7536.6162\n",
      "Epoch 2071/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.9653\n",
      "Epoch 02071: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7544.9653 - val_loss: 7536.6768\n",
      "Epoch 2072/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9619\n",
      "Epoch 02072: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.9619 - val_loss: 7536.6514\n",
      "Epoch 2073/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0024\n",
      "Epoch 02073: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7534.0024 - val_loss: 7536.6167\n",
      "Epoch 2074/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.0083\n",
      "Epoch 02074: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.0083 - val_loss: 7536.5825\n",
      "Epoch 2075/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.5571\n",
      "Epoch 02075: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7535.5571 - val_loss: 7536.5952\n",
      "Epoch 2076/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9614\n",
      "Epoch 02076: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 543ms/step - loss: 7533.9614 - val_loss: 7536.5225\n",
      "Epoch 2077/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.7207\n",
      "Epoch 02077: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7546.7207 - val_loss: 7536.5210\n",
      "Epoch 2078/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.5762\n",
      "Epoch 02078: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7546.5762 - val_loss: 7536.6450\n",
      "Epoch 2079/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.3105\n",
      "Epoch 02079: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7539.3105 - val_loss: 7537.0376\n",
      "Epoch 2080/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8311\n",
      "Epoch 02080: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7533.8311 - val_loss: 7536.5190\n",
      "Epoch 2081/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.2627\n",
      "Epoch 02081: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7526.2627 - val_loss: 7536.4185\n",
      "Epoch 2082/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2036\n",
      "Epoch 02082: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7531.2036 - val_loss: 7536.4482\n",
      "Epoch 2083/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.6089\n",
      "Epoch 02083: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7528.6089 - val_loss: 7536.4922\n",
      "Epoch 2084/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.9253\n",
      "Epoch 02084: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.9253 - val_loss: 7536.5537\n",
      "Epoch 2085/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.6646\n",
      "Epoch 02085: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.6646 - val_loss: 7536.3330\n",
      "Epoch 2086/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8838\n",
      "Epoch 02086: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.8838 - val_loss: 7536.4136\n",
      "Epoch 2087/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7521.0044\n",
      "Epoch 02087: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7521.0044 - val_loss: 7536.3374\n",
      "Epoch 2088/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.6787\n",
      "Epoch 02088: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.6787 - val_loss: 7536.4990\n",
      "Epoch 2089/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7542.4634\n",
      "Epoch 02089: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7542.4634 - val_loss: 7536.3799\n",
      "Epoch 2090/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7817\n",
      "Epoch 02090: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.7817 - val_loss: 7536.4761\n",
      "Epoch 2091/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0151\n",
      "Epoch 02091: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7538.0151 - val_loss: 7536.3384\n",
      "Epoch 2092/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0342\n",
      "Epoch 02092: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7538.0342 - val_loss: 7536.3008\n",
      "Epoch 2093/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0303\n",
      "Epoch 02093: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7531.0303 - val_loss: 7536.2554\n",
      "Epoch 2094/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.4683\n",
      "Epoch 02094: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7542.4683 - val_loss: 7536.3145\n",
      "Epoch 2095/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.1704\n",
      "Epoch 02095: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7539.1704 - val_loss: 7536.1929\n",
      "Epoch 2096/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6035\n",
      "Epoch 02096: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7534.6035 - val_loss: 7536.2793\n",
      "Epoch 2097/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3560\n",
      "Epoch 02097: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.3560 - val_loss: 7536.1455\n",
      "Epoch 2098/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5542\n",
      "Epoch 02098: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.5542 - val_loss: 7536.3511\n",
      "Epoch 2099/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.4175\n",
      "Epoch 02099: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7543.4175 - val_loss: 7536.7632\n",
      "Epoch 2100/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.6899\n",
      "Epoch 02100: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7547.6899 - val_loss: 7536.1182\n",
      "Epoch 2101/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.3809\n",
      "Epoch 02101: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7547.3809 - val_loss: 7536.1831\n",
      "Epoch 2102/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.0928\n",
      "Epoch 02102: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.0928 - val_loss: 7536.0801\n",
      "Epoch 2103/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.2261\n",
      "Epoch 02103: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7528.2261 - val_loss: 7536.1826\n",
      "Epoch 2104/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.3589\n",
      "Epoch 02104: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7542.3589 - val_loss: 7536.1025\n",
      "Epoch 2105/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6470\n",
      "Epoch 02105: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.6470 - val_loss: 7536.0752\n",
      "Epoch 2106/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.4951\n",
      "Epoch 02106: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.4951 - val_loss: 7536.2754\n",
      "Epoch 2107/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8770\n",
      "Epoch 02107: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.8770 - val_loss: 7536.1504\n",
      "Epoch 2108/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.7070\n",
      "Epoch 02108: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7547.7070 - val_loss: 7536.1470\n",
      "Epoch 2109/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.6963\n",
      "Epoch 02109: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7547.6963 - val_loss: 7536.2954\n",
      "Epoch 2110/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.7466\n",
      "Epoch 02110: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7534.7466 - val_loss: 7536.2354\n",
      "Epoch 2111/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.0073\n",
      "Epoch 02111: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7528.0073 - val_loss: 7536.0337\n",
      "Epoch 2112/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.2002\n",
      "Epoch 02112: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7546.2002 - val_loss: 7536.3066\n",
      "Epoch 2113/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.7495\n",
      "Epoch 02113: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7520.7495 - val_loss: 7536.1362\n",
      "Epoch 2114/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.3516\n",
      "Epoch 02114: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7538.3516 - val_loss: 7536.0151\n",
      "Epoch 2115/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.2280\n",
      "Epoch 02115: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7534.2280 - val_loss: 7536.0566\n",
      "Epoch 2116/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.6133\n",
      "Epoch 02116: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.6133 - val_loss: 7536.3232\n",
      "Epoch 2117/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.9961\n",
      "Epoch 02117: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7525.9961 - val_loss: 7536.0806\n",
      "Epoch 2118/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4399\n",
      "Epoch 02118: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.4399 - val_loss: 7535.8569\n",
      "Epoch 2119/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.7246\n",
      "Epoch 02119: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.7246 - val_loss: 7536.6016\n",
      "Epoch 2120/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.7031\n",
      "Epoch 02120: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7534.7031 - val_loss: 7536.0991\n",
      "Epoch 2121/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.5054\n",
      "Epoch 02121: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7542.5054 - val_loss: 7536.3594\n",
      "Epoch 2122/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.9678\n",
      "Epoch 02122: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.9678 - val_loss: 7535.8545\n",
      "Epoch 2123/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3599\n",
      "Epoch 02123: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.3599 - val_loss: 7536.0415\n",
      "Epoch 2124/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7538.2954\n",
      "Epoch 02124: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7538.2954 - val_loss: 7536.3784\n",
      "Epoch 2125/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6260\n",
      "Epoch 02125: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.6260 - val_loss: 7535.9272\n",
      "Epoch 2126/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4478\n",
      "Epoch 02126: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.4478 - val_loss: 7536.1895\n",
      "Epoch 2127/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5513\n",
      "Epoch 02127: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.5513 - val_loss: 7536.1870\n",
      "Epoch 2128/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.2310\n",
      "Epoch 02128: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.2310 - val_loss: 7535.7407\n",
      "Epoch 2129/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.9106\n",
      "Epoch 02129: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.9106 - val_loss: 7535.8486\n",
      "Epoch 2130/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.6299\n",
      "Epoch 02130: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.6299 - val_loss: 7535.8271\n",
      "Epoch 2131/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6670\n",
      "Epoch 02131: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.6670 - val_loss: 7536.0439\n",
      "Epoch 2132/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.9521\n",
      "Epoch 02132: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.9521 - val_loss: 7535.9736\n",
      "Epoch 2133/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.0684\n",
      "Epoch 02133: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7528.0684 - val_loss: 7535.9233\n",
      "Epoch 2134/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.2456\n",
      "Epoch 02134: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7544.2456 - val_loss: 7535.7695\n",
      "Epoch 2135/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9658\n",
      "Epoch 02135: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.9658 - val_loss: 7535.7729\n",
      "Epoch 2136/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8770\n",
      "Epoch 02136: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7545.8770 - val_loss: 7535.7134\n",
      "Epoch 2137/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2690\n",
      "Epoch 02137: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.2690 - val_loss: 7535.7480\n",
      "Epoch 2138/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8638\n",
      "Epoch 02138: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.8638 - val_loss: 7535.9321\n",
      "Epoch 2139/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.8623\n",
      "Epoch 02139: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.8623 - val_loss: 7535.8662\n",
      "Epoch 2140/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8423\n",
      "Epoch 02140: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.8423 - val_loss: 7536.0625\n",
      "Epoch 2141/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4526\n",
      "Epoch 02141: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.4526 - val_loss: 7535.7920\n",
      "Epoch 2142/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9487\n",
      "Epoch 02142: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.9487 - val_loss: 7535.8623\n",
      "Epoch 2143/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.9121\n",
      "Epoch 02143: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7546.9121 - val_loss: 7535.8184\n",
      "Epoch 2144/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.6333\n",
      "Epoch 02144: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7527.6333 - val_loss: 7535.6182\n",
      "Epoch 2145/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3623\n",
      "Epoch 02145: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7532.3623 - val_loss: 7535.7578\n",
      "Epoch 2146/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4863\n",
      "Epoch 02146: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.4863 - val_loss: 7535.6992\n",
      "Epoch 2147/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.6846\n",
      "Epoch 02147: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.6846 - val_loss: 7535.5239\n",
      "Epoch 2148/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6895\n",
      "Epoch 02148: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.6895 - val_loss: 7535.8682\n",
      "Epoch 2149/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.7568\n",
      "Epoch 02149: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7541.7568 - val_loss: 7535.5688\n",
      "Epoch 2150/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0747\n",
      "Epoch 02150: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7534.0747 - val_loss: 7536.1279\n",
      "Epoch 2151/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.7036\n",
      "Epoch 02151: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.7036 - val_loss: 7535.8745\n",
      "Epoch 2152/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7021\n",
      "Epoch 02152: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.7021 - val_loss: 7535.6978\n",
      "Epoch 2153/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.8452\n",
      "Epoch 02153: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7540.8452 - val_loss: 7536.0879\n",
      "Epoch 2154/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2627\n",
      "Epoch 02154: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.2627 - val_loss: 7536.0977\n",
      "Epoch 2155/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8237\n",
      "Epoch 02155: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.8237 - val_loss: 7535.6689\n",
      "Epoch 2156/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.7637\n",
      "Epoch 02156: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.7637 - val_loss: 7535.4385\n",
      "Epoch 2157/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.8745\n",
      "Epoch 02157: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.8745 - val_loss: 7535.7607\n",
      "Epoch 2158/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.6816\n",
      "Epoch 02158: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7520.6816 - val_loss: 7535.8999\n",
      "Epoch 2159/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7532.3433\n",
      "Epoch 02159: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.3433 - val_loss: 7535.6274\n",
      "Epoch 2160/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5386\n",
      "Epoch 02160: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7534.5386 - val_loss: 7535.5103\n",
      "Epoch 2161/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.2358\n",
      "Epoch 02161: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7537.2358 - val_loss: 7535.7080\n",
      "Epoch 2162/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.9448\n",
      "Epoch 02162: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7545.9448 - val_loss: 7535.4014\n",
      "Epoch 2163/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2651\n",
      "Epoch 02163: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.2651 - val_loss: 7535.7471\n",
      "Epoch 2164/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2749\n",
      "Epoch 02164: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.2749 - val_loss: 7535.8618\n",
      "Epoch 2165/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4341\n",
      "Epoch 02165: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.4341 - val_loss: 7535.7432\n",
      "Epoch 2166/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3115\n",
      "Epoch 02166: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.3115 - val_loss: 7535.9521\n",
      "Epoch 2167/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.5688\n",
      "Epoch 02167: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7525.5688 - val_loss: 7535.5737\n",
      "Epoch 2168/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.4399\n",
      "Epoch 02168: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.4399 - val_loss: 7536.0762\n",
      "Epoch 2169/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3770\n",
      "Epoch 02169: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.3770 - val_loss: 7536.2334\n",
      "Epoch 2170/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5547\n",
      "Epoch 02170: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.5547 - val_loss: 7535.6650\n",
      "Epoch 2171/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.8716\n",
      "Epoch 02171: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7527.8716 - val_loss: 7535.7446\n",
      "Epoch 2172/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.9790\n",
      "Epoch 02172: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.9790 - val_loss: 7536.0254\n",
      "Epoch 2173/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.0127\n",
      "Epoch 02173: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7547.0127 - val_loss: 7536.0151\n",
      "Epoch 2174/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9941\n",
      "Epoch 02174: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.9941 - val_loss: 7535.5161\n",
      "Epoch 2175/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.5342\n",
      "Epoch 02175: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.5342 - val_loss: 7535.3687\n",
      "Epoch 2176/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.8755\n",
      "Epoch 02176: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7527.8755 - val_loss: 7535.9194\n",
      "Epoch 2177/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7144\n",
      "Epoch 02177: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.7144 - val_loss: 7535.4966\n",
      "Epoch 2178/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.7944\n",
      "Epoch 02178: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7543.7944 - val_loss: 7535.5615\n",
      "Epoch 2179/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0859\n",
      "Epoch 02179: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.0859 - val_loss: 7535.3887\n",
      "Epoch 2180/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6001\n",
      "Epoch 02180: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.6001 - val_loss: 7535.7104\n",
      "Epoch 2181/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8555\n",
      "Epoch 02181: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.8555 - val_loss: 7535.6826\n",
      "Epoch 2182/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.2988\n",
      "Epoch 02182: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7547.2988 - val_loss: 7535.7778\n",
      "Epoch 2183/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.6021\n",
      "Epoch 02183: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.6021 - val_loss: 7535.4009\n",
      "Epoch 2184/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8750\n",
      "Epoch 02184: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.8750 - val_loss: 7535.3721\n",
      "Epoch 2185/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.5181\n",
      "Epoch 02185: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7525.5181 - val_loss: 7535.5786\n",
      "Epoch 2186/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.1523\n",
      "Epoch 02186: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.1523 - val_loss: 7535.4414\n",
      "Epoch 2187/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7646\n",
      "Epoch 02187: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.7646 - val_loss: 7535.5142\n",
      "Epoch 2188/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.2104\n",
      "Epoch 02188: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.2104 - val_loss: 7535.2217\n",
      "Epoch 2189/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.4302\n",
      "Epoch 02189: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7525.4302 - val_loss: 7535.8032\n",
      "Epoch 2190/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.4033\n",
      "Epoch 02190: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7525.4033 - val_loss: 7535.4399\n",
      "Epoch 2191/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8184\n",
      "Epoch 02191: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.8184 - val_loss: 7535.9326\n",
      "Epoch 2192/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5176\n",
      "Epoch 02192: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.5176 - val_loss: 7535.5210\n",
      "Epoch 2193/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.6440\n",
      "Epoch 02193: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7545.6440 - val_loss: 7536.0352\n",
      "Epoch 2194/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7545.3789\n",
      "Epoch 02194: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.3789 - val_loss: 7535.3350\n",
      "Epoch 2195/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8545\n",
      "Epoch 02195: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.8545 - val_loss: 7535.7920\n",
      "Epoch 2196/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5879\n",
      "Epoch 02196: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.5879 - val_loss: 7535.6514\n",
      "Epoch 2197/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0107\n",
      "Epoch 02197: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7534.0107 - val_loss: 7535.5674\n",
      "Epoch 2198/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6094\n",
      "Epoch 02198: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7537.6094 - val_loss: 7535.1577\n",
      "Epoch 2199/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9395\n",
      "Epoch 02199: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.9395 - val_loss: 7535.3896\n",
      "Epoch 2200/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6323\n",
      "Epoch 02200: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.6323 - val_loss: 7535.1382\n",
      "Epoch 2201/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6758\n",
      "Epoch 02201: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.6758 - val_loss: 7535.3848\n",
      "Epoch 2202/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.5376\n",
      "Epoch 02202: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7546.5376 - val_loss: 7535.0918\n",
      "Epoch 2203/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.6167\n",
      "Epoch 02203: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7540.6167 - val_loss: 7535.4238\n",
      "Epoch 2204/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4775\n",
      "Epoch 02204: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.4775 - val_loss: 7535.6826\n",
      "Epoch 2205/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.0010\n",
      "Epoch 02205: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7547.0010 - val_loss: 7535.4048\n",
      "Epoch 2206/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.0249\n",
      "Epoch 02206: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7525.0249 - val_loss: 7535.0601\n",
      "Epoch 2207/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.1133\n",
      "Epoch 02207: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7520.1133 - val_loss: 7535.1353\n",
      "Epoch 2208/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.7300\n",
      "Epoch 02208: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.7300 - val_loss: 7535.4062\n",
      "Epoch 2209/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.4868\n",
      "Epoch 02209: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7520.4868 - val_loss: 7535.6553\n",
      "Epoch 2210/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4990\n",
      "Epoch 02210: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.4990 - val_loss: 7535.0801\n",
      "Epoch 2211/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.5361\n",
      "Epoch 02211: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7546.5361 - val_loss: 7535.5273\n",
      "Epoch 2212/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.6216\n",
      "Epoch 02212: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7546.6216 - val_loss: 7535.2710\n",
      "Epoch 2213/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1274\n",
      "Epoch 02213: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.1274 - val_loss: 7535.9121\n",
      "Epoch 2214/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6709\n",
      "Epoch 02214: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.6709 - val_loss: 7536.8921\n",
      "Epoch 2215/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0342\n",
      "Epoch 02215: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.0342 - val_loss: 7535.5264\n",
      "Epoch 2216/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3237\n",
      "Epoch 02216: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.3237 - val_loss: 7535.2642\n",
      "Epoch 2217/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.9800\n",
      "Epoch 02217: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7546.9800 - val_loss: 7535.6162\n",
      "Epoch 2218/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9209\n",
      "Epoch 02218: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.9209 - val_loss: 7535.5767\n",
      "Epoch 2219/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.7744\n",
      "Epoch 02219: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7546.7744 - val_loss: 7535.3481\n",
      "Epoch 2220/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.0430\n",
      "Epoch 02220: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.0430 - val_loss: 7536.6050\n",
      "Epoch 2221/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3721\n",
      "Epoch 02221: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.3721 - val_loss: 7535.7622\n",
      "Epoch 2222/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.6787\n",
      "Epoch 02222: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.6787 - val_loss: 7535.6641\n",
      "Epoch 2223/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6299\n",
      "Epoch 02223: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.6299 - val_loss: 7535.0234\n",
      "Epoch 2224/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5757\n",
      "Epoch 02224: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.5757 - val_loss: 7535.2578\n",
      "Epoch 2225/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4766\n",
      "Epoch 02225: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.4766 - val_loss: 7535.1577\n",
      "Epoch 2226/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.9019\n",
      "Epoch 02226: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7519.9019 - val_loss: 7535.3442\n",
      "Epoch 2227/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2583\n",
      "Epoch 02227: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.2583 - val_loss: 7535.0273\n",
      "Epoch 2228/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.5908\n",
      "Epoch 02228: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7519.5908 - val_loss: 7534.9424\n",
      "Epoch 2229/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7533.7256\n",
      "Epoch 02229: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7533.7256 - val_loss: 7535.1016\n",
      "Epoch 2230/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.2158\n",
      "Epoch 02230: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7540.2158 - val_loss: 7535.2114\n",
      "Epoch 2231/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.0767\n",
      "Epoch 02231: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7520.0767 - val_loss: 7535.2080\n",
      "Epoch 2232/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.0947\n",
      "Epoch 02232: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7547.0947 - val_loss: 7535.6650\n",
      "Epoch 2233/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.2314\n",
      "Epoch 02233: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7528.2314 - val_loss: 7536.5864\n",
      "Epoch 2234/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1953\n",
      "Epoch 02234: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7538.1953 - val_loss: 7535.6274\n",
      "Epoch 2235/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.9395\n",
      "Epoch 02235: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7546.9395 - val_loss: 7535.1992\n",
      "Epoch 2236/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.1582\n",
      "Epoch 02236: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7525.1582 - val_loss: 7535.3936\n",
      "Epoch 2237/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.3696\n",
      "Epoch 02237: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7540.3696 - val_loss: 7535.3506\n",
      "Epoch 2238/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.0122\n",
      "Epoch 02238: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7547.0122 - val_loss: 7535.3784\n",
      "Epoch 2239/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.3867\n",
      "Epoch 02239: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7530.3867 - val_loss: 7535.8105\n",
      "Epoch 2240/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.4888\n",
      "Epoch 02240: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7546.4888 - val_loss: 7535.3848\n",
      "Epoch 2241/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9419\n",
      "Epoch 02241: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 542ms/step - loss: 7533.9419 - val_loss: 7536.0840\n",
      "Epoch 2242/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.9092\n",
      "Epoch 02242: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7529.9092 - val_loss: 7535.2402\n",
      "Epoch 2243/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1572\n",
      "Epoch 02243: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.1572 - val_loss: 7535.0239\n",
      "Epoch 2244/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.9873\n",
      "Epoch 02244: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.9873 - val_loss: 7534.9224\n",
      "Epoch 2245/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.5195\n",
      "Epoch 02245: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7540.5195 - val_loss: 7535.0830\n",
      "Epoch 2246/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.7354\n",
      "Epoch 02246: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7526.7354 - val_loss: 7534.9751\n",
      "Epoch 2247/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8286\n",
      "Epoch 02247: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7536.8286 - val_loss: 7535.0366\n",
      "Epoch 2248/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.2671\n",
      "Epoch 02248: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.2671 - val_loss: 7535.0239\n",
      "Epoch 2249/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4785\n",
      "Epoch 02249: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.4785 - val_loss: 7535.0239\n",
      "Epoch 2250/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.9868\n",
      "Epoch 02250: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.9868 - val_loss: 7534.8809\n",
      "Epoch 2251/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.3599\n",
      "Epoch 02251: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.3599 - val_loss: 7535.0703\n",
      "Epoch 2252/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1953\n",
      "Epoch 02252: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.1953 - val_loss: 7535.0952\n",
      "Epoch 2253/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7451\n",
      "Epoch 02253: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7536.7451 - val_loss: 7534.7520\n",
      "Epoch 2254/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.3350\n",
      "Epoch 02254: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7538.3350 - val_loss: 7535.3799\n",
      "Epoch 2255/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.2686\n",
      "Epoch 02255: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7541.2686 - val_loss: 7534.9414\n",
      "Epoch 2256/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.9829\n",
      "Epoch 02256: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7524.9829 - val_loss: 7534.9473\n",
      "Epoch 2257/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.0640\n",
      "Epoch 02257: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7527.0640 - val_loss: 7535.1304\n",
      "Epoch 2258/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.8569\n",
      "Epoch 02258: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7527.8569 - val_loss: 7535.8833\n",
      "Epoch 2259/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7168\n",
      "Epoch 02259: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.7168 - val_loss: 7535.0527\n",
      "Epoch 2260/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.2280\n",
      "Epoch 02260: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7543.2280 - val_loss: 7534.9326\n",
      "Epoch 2261/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.0005\n",
      "Epoch 02261: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7525.0005 - val_loss: 7534.8638\n",
      "Epoch 2262/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1680\n",
      "Epoch 02262: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.1680 - val_loss: 7534.9062\n",
      "Epoch 2263/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.9058\n",
      "Epoch 02263: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.9058 - val_loss: 7534.7354\n",
      "Epoch 2264/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7536.6162\n",
      "Epoch 02264: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7536.6162 - val_loss: 7534.7871\n",
      "Epoch 2265/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3086\n",
      "Epoch 02265: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.3086 - val_loss: 7534.8506\n",
      "Epoch 2266/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1206\n",
      "Epoch 02266: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7534.1206 - val_loss: 7535.7007\n",
      "Epoch 2267/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4487\n",
      "Epoch 02267: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.4487 - val_loss: 7534.9570\n",
      "Epoch 2268/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.7959\n",
      "Epoch 02268: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7542.7959 - val_loss: 7536.3032\n",
      "Epoch 2269/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9668\n",
      "Epoch 02269: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7531.9668 - val_loss: 7535.5454\n",
      "Epoch 2270/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.7236\n",
      "Epoch 02270: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7526.7236 - val_loss: 7535.9385\n",
      "Epoch 2271/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.3423\n",
      "Epoch 02271: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7546.3423 - val_loss: 7535.6030\n",
      "Epoch 2272/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.2686\n",
      "Epoch 02272: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7525.2686 - val_loss: 7535.1426\n",
      "Epoch 2273/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5928\n",
      "Epoch 02273: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.5928 - val_loss: 7535.2456\n",
      "Epoch 2274/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2773\n",
      "Epoch 02274: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.2773 - val_loss: 7534.9023\n",
      "Epoch 2275/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.0669\n",
      "Epoch 02275: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.0669 - val_loss: 7535.1616\n",
      "Epoch 2276/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.2280\n",
      "Epoch 02276: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7546.2280 - val_loss: 7534.9302\n",
      "Epoch 2277/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.9014\n",
      "Epoch 02277: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.9014 - val_loss: 7535.4800\n",
      "Epoch 2278/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.0625\n",
      "Epoch 02278: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.0625 - val_loss: 7536.4424\n",
      "Epoch 2279/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8906\n",
      "Epoch 02279: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.8906 - val_loss: 7535.3193\n",
      "Epoch 2280/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.3862\n",
      "Epoch 02280: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7527.3862 - val_loss: 7535.3457\n",
      "Epoch 2281/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.6411\n",
      "Epoch 02281: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.6411 - val_loss: 7534.7969\n",
      "Epoch 2282/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.6602\n",
      "Epoch 02282: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.6602 - val_loss: 7534.6719\n",
      "Epoch 2283/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5703\n",
      "Epoch 02283: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.5703 - val_loss: 7535.5034\n",
      "Epoch 2284/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.4004\n",
      "Epoch 02284: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.4004 - val_loss: 7534.6934\n",
      "Epoch 2285/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2334\n",
      "Epoch 02285: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.2334 - val_loss: 7534.4482\n",
      "Epoch 2286/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2261\n",
      "Epoch 02286: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.2261 - val_loss: 7534.7446\n",
      "Epoch 2287/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.4204\n",
      "Epoch 02287: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.4204 - val_loss: 7534.6216\n",
      "Epoch 2288/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.5464\n",
      "Epoch 02288: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.5464 - val_loss: 7534.8345\n",
      "Epoch 2289/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.0957\n",
      "Epoch 02289: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7543.0957 - val_loss: 7534.5801\n",
      "Epoch 2290/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5298\n",
      "Epoch 02290: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.5298 - val_loss: 7534.6016\n",
      "Epoch 2291/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.1094\n",
      "Epoch 02291: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.1094 - val_loss: 7534.7778\n",
      "Epoch 2292/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2510\n",
      "Epoch 02292: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.2510 - val_loss: 7534.6865\n",
      "Epoch 2293/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8379\n",
      "Epoch 02293: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.8379 - val_loss: 7535.3193\n",
      "Epoch 2294/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.0918\n",
      "Epoch 02294: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7543.0918 - val_loss: 7534.5767\n",
      "Epoch 2295/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6338\n",
      "Epoch 02295: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.6338 - val_loss: 7534.5264\n",
      "Epoch 2296/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.1743\n",
      "Epoch 02296: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7541.1743 - val_loss: 7534.8433\n",
      "Epoch 2297/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5059\n",
      "Epoch 02297: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.5059 - val_loss: 7534.6401\n",
      "Epoch 2298/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5562\n",
      "Epoch 02298: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.5562 - val_loss: 7535.0566\n",
      "Epoch 2299/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7532.1519\n",
      "Epoch 02299: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.1519 - val_loss: 7534.9194\n",
      "Epoch 2300/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9956\n",
      "Epoch 02300: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.9956 - val_loss: 7534.6943\n",
      "Epoch 2301/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.6211\n",
      "Epoch 02301: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.6211 - val_loss: 7534.5928\n",
      "Epoch 2302/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.4463\n",
      "Epoch 02302: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7526.4463 - val_loss: 7535.9570\n",
      "Epoch 2303/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8672\n",
      "Epoch 02303: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7536.8672 - val_loss: 7534.9502\n",
      "Epoch 2304/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8779\n",
      "Epoch 02304: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.8779 - val_loss: 7534.8320\n",
      "Epoch 2305/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6006\n",
      "Epoch 02305: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.6006 - val_loss: 7534.7632\n",
      "Epoch 2306/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1587\n",
      "Epoch 02306: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.1587 - val_loss: 7534.4199\n",
      "Epoch 2307/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.9673\n",
      "Epoch 02307: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7545.9673 - val_loss: 7534.5088\n",
      "Epoch 2308/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7305\n",
      "Epoch 02308: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7532.7305 - val_loss: 7534.3936\n",
      "Epoch 2309/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.3022\n",
      "Epoch 02309: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7519.3022 - val_loss: 7534.6519\n",
      "Epoch 2310/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0586\n",
      "Epoch 02310: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.0586 - val_loss: 7534.6479\n",
      "Epoch 2311/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.3711\n",
      "Epoch 02311: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.3711 - val_loss: 7534.4673\n",
      "Epoch 2312/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.3540\n",
      "Epoch 02312: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.3540 - val_loss: 7534.7153\n",
      "Epoch 2313/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7354\n",
      "Epoch 02313: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.7354 - val_loss: 7534.3706\n",
      "Epoch 2314/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.9756\n",
      "Epoch 02314: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7537.9756 - val_loss: 7534.6167\n",
      "Epoch 2315/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7593\n",
      "Epoch 02315: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.7593 - val_loss: 7534.9897\n",
      "Epoch 2316/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2383\n",
      "Epoch 02316: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.2383 - val_loss: 7534.6719\n",
      "Epoch 2317/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.7681\n",
      "Epoch 02317: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.7681 - val_loss: 7535.0425\n",
      "Epoch 2318/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8213\n",
      "Epoch 02318: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.8213 - val_loss: 7534.7778\n",
      "Epoch 2319/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6973\n",
      "Epoch 02319: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.6973 - val_loss: 7534.3457\n",
      "Epoch 2320/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0205\n",
      "Epoch 02320: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.0205 - val_loss: 7534.6855\n",
      "Epoch 2321/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9341\n",
      "Epoch 02321: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.9341 - val_loss: 7534.8569\n",
      "Epoch 2322/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.1113\n",
      "Epoch 02322: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.1113 - val_loss: 7535.1318\n",
      "Epoch 2323/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.1387\n",
      "Epoch 02323: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.1387 - val_loss: 7534.9224\n",
      "Epoch 2324/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.6338\n",
      "Epoch 02324: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7519.6338 - val_loss: 7534.8359\n",
      "Epoch 2325/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.7202\n",
      "Epoch 02325: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.7202 - val_loss: 7535.1553\n",
      "Epoch 2326/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8022\n",
      "Epoch 02326: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.8022 - val_loss: 7534.6191\n",
      "Epoch 2327/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.1484\n",
      "Epoch 02327: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7526.1484 - val_loss: 7535.3159\n",
      "Epoch 2328/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2856\n",
      "Epoch 02328: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.2856 - val_loss: 7534.7305\n",
      "Epoch 2329/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.2827\n",
      "Epoch 02329: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.2827 - val_loss: 7534.3071\n",
      "Epoch 2330/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1768\n",
      "Epoch 02330: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.1768 - val_loss: 7534.4897\n",
      "Epoch 2331/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0483\n",
      "Epoch 02331: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.0483 - val_loss: 7534.4521\n",
      "Epoch 2332/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.9077\n",
      "Epoch 02332: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7537.9077 - val_loss: 7534.6655\n",
      "Epoch 2333/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1577\n",
      "Epoch 02333: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.1577 - val_loss: 7534.8198\n",
      "Epoch 2334/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7533.0757\n",
      "Epoch 02334: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.0757 - val_loss: 7534.3198\n",
      "Epoch 2335/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3354\n",
      "Epoch 02335: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7536.3354 - val_loss: 7534.3145\n",
      "Epoch 2336/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4502\n",
      "Epoch 02336: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.4502 - val_loss: 7534.3423\n",
      "Epoch 2337/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3232\n",
      "Epoch 02337: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.3232 - val_loss: 7534.3662\n",
      "Epoch 2338/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1743\n",
      "Epoch 02338: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.1743 - val_loss: 7534.8086\n",
      "Epoch 2339/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3042\n",
      "Epoch 02339: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.3042 - val_loss: 7534.6128\n",
      "Epoch 2340/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.9062\n",
      "Epoch 02340: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7542.9062 - val_loss: 7534.5186\n",
      "Epoch 2341/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.7036\n",
      "Epoch 02341: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.7036 - val_loss: 7534.8047\n",
      "Epoch 2342/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.8228\n",
      "Epoch 02342: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.8228 - val_loss: 7534.5034\n",
      "Epoch 2343/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0776\n",
      "Epoch 02343: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.0776 - val_loss: 7534.7095\n",
      "Epoch 2344/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2539\n",
      "Epoch 02344: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.2539 - val_loss: 7534.8838\n",
      "Epoch 2345/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4380\n",
      "Epoch 02345: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7536.4380 - val_loss: 7534.7334\n",
      "Epoch 2346/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0903\n",
      "Epoch 02346: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7536.0903 - val_loss: 7534.2632\n",
      "Epoch 2347/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.0791\n",
      "Epoch 02347: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7519.0791 - val_loss: 7534.4194\n",
      "Epoch 2348/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.9351\n",
      "Epoch 02348: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.9351 - val_loss: 7534.4297\n",
      "Epoch 2349/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7378\n",
      "Epoch 02349: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7540.7378 - val_loss: 7534.5352\n",
      "Epoch 2350/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7578\n",
      "Epoch 02350: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7530.7578 - val_loss: 7534.3193\n",
      "Epoch 2351/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.6675\n",
      "Epoch 02351: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.6675 - val_loss: 7534.4014\n",
      "Epoch 2352/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.5259\n",
      "Epoch 02352: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7546.5259 - val_loss: 7535.2026\n",
      "Epoch 2353/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.0435\n",
      "Epoch 02353: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7526.0435 - val_loss: 7534.4194\n",
      "Epoch 2354/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6431\n",
      "Epoch 02354: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7537.6431 - val_loss: 7534.1968\n",
      "Epoch 2355/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.0186\n",
      "Epoch 02355: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7519.0186 - val_loss: 7534.3159\n",
      "Epoch 2356/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.9341\n",
      "Epoch 02356: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7540.9341 - val_loss: 7534.4858\n",
      "Epoch 2357/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.2637\n",
      "Epoch 02357: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7519.2637 - val_loss: 7534.6240\n",
      "Epoch 2358/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8164\n",
      "Epoch 02358: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7530.8164 - val_loss: 7534.4482\n",
      "Epoch 2359/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2646\n",
      "Epoch 02359: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7533.2646 - val_loss: 7535.9072\n",
      "Epoch 2360/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.1880\n",
      "Epoch 02360: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7544.1880 - val_loss: 7535.4346\n",
      "Epoch 2361/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9102\n",
      "Epoch 02361: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7533.9102 - val_loss: 7535.4526\n",
      "Epoch 2362/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3271\n",
      "Epoch 02362: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7533.3271 - val_loss: 7535.9214\n",
      "Epoch 2363/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6177\n",
      "Epoch 02363: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7534.6177 - val_loss: 7535.3198\n",
      "Epoch 2364/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.2324\n",
      "Epoch 02364: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7519.2324 - val_loss: 7534.5654\n",
      "Epoch 2365/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.7886\n",
      "Epoch 02365: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7524.7886 - val_loss: 7534.5151\n",
      "Epoch 2366/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1016\n",
      "Epoch 02366: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7533.1016 - val_loss: 7534.4824\n",
      "Epoch 2367/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.5249\n",
      "Epoch 02367: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7519.5249 - val_loss: 7534.5879\n",
      "Epoch 2368/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.2739\n",
      "Epoch 02368: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.2739 - val_loss: 7534.4351\n",
      "Epoch 2369/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7536.8740\n",
      "Epoch 02369: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.8740 - val_loss: 7534.2480\n",
      "Epoch 2370/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7358\n",
      "Epoch 02370: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7536.7358 - val_loss: 7534.6118\n",
      "Epoch 2371/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9551\n",
      "Epoch 02371: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.9551 - val_loss: 7534.5215\n",
      "Epoch 2372/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.2061\n",
      "Epoch 02372: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.2061 - val_loss: 7534.3130\n",
      "Epoch 2373/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.2812\n",
      "Epoch 02373: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.2812 - val_loss: 7534.4487\n",
      "Epoch 2374/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0645\n",
      "Epoch 02374: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.0645 - val_loss: 7534.4746\n",
      "Epoch 2375/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0879\n",
      "Epoch 02375: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7533.0879 - val_loss: 7534.6426\n",
      "Epoch 2376/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0747\n",
      "Epoch 02376: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 542ms/step - loss: 7531.0747 - val_loss: 7534.6870\n",
      "Epoch 2377/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6216\n",
      "Epoch 02377: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7536.6216 - val_loss: 7534.3799\n",
      "Epoch 2378/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0576\n",
      "Epoch 02378: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7536.0576 - val_loss: 7534.5518\n",
      "Epoch 2379/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5811\n",
      "Epoch 02379: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.5811 - val_loss: 7534.4927\n",
      "Epoch 2380/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1753\n",
      "Epoch 02380: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7536.1753 - val_loss: 7534.1943\n",
      "Epoch 2381/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5850\n",
      "Epoch 02381: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.5850 - val_loss: 7534.0830\n",
      "Epoch 2382/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5801\n",
      "Epoch 02382: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.5801 - val_loss: 7534.2783\n",
      "Epoch 2383/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7510\n",
      "Epoch 02383: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.7510 - val_loss: 7534.2490\n",
      "Epoch 2384/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.7686\n",
      "Epoch 02384: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.7686 - val_loss: 7534.5142\n",
      "Epoch 2385/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6099\n",
      "Epoch 02385: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.6099 - val_loss: 7534.7026\n",
      "Epoch 2386/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.3872\n",
      "Epoch 02386: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.3872 - val_loss: 7534.3071\n",
      "Epoch 2387/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7505\n",
      "Epoch 02387: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.7505 - val_loss: 7534.0449\n",
      "Epoch 2388/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5659\n",
      "Epoch 02388: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.5659 - val_loss: 7534.1582\n",
      "Epoch 2389/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1450\n",
      "Epoch 02389: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.1450 - val_loss: 7534.6050\n",
      "Epoch 2390/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3887\n",
      "Epoch 02390: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.3887 - val_loss: 7534.2056\n",
      "Epoch 2391/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.8511\n",
      "Epoch 02391: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7543.8511 - val_loss: 7533.8872\n",
      "Epoch 2392/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7085\n",
      "Epoch 02392: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.7085 - val_loss: 7534.1870\n",
      "Epoch 2393/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.4316\n",
      "Epoch 02393: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7544.4316 - val_loss: 7534.5874\n",
      "Epoch 2394/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.5571\n",
      "Epoch 02394: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.5571 - val_loss: 7534.2310\n",
      "Epoch 2395/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4429\n",
      "Epoch 02395: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.4429 - val_loss: 7534.7817\n",
      "Epoch 2396/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.7051\n",
      "Epoch 02396: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7529.7051 - val_loss: 7535.1914\n",
      "Epoch 2397/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8550\n",
      "Epoch 02397: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.8550 - val_loss: 7534.4673\n",
      "Epoch 2398/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7729\n",
      "Epoch 02398: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.7729 - val_loss: 7534.2944\n",
      "Epoch 2399/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.4272\n",
      "Epoch 02399: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.4272 - val_loss: 7534.3262\n",
      "Epoch 2400/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7422\n",
      "Epoch 02400: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.7422 - val_loss: 7534.4048\n",
      "Epoch 2401/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4238\n",
      "Epoch 02401: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7537.4238 - val_loss: 7534.3735\n",
      "Epoch 2402/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.4346\n",
      "Epoch 02402: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7524.4346 - val_loss: 7534.1904\n",
      "Epoch 2403/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0845\n",
      "Epoch 02403: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.0845 - val_loss: 7534.1113\n",
      "Epoch 2404/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7532.3120\n",
      "Epoch 02404: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.3120 - val_loss: 7534.8350\n",
      "Epoch 2405/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.8418\n",
      "Epoch 02405: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7525.8418 - val_loss: 7534.2510\n",
      "Epoch 2406/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7842\n",
      "Epoch 02406: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.7842 - val_loss: 7534.4487\n",
      "Epoch 2407/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.2715\n",
      "Epoch 02407: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.2715 - val_loss: 7534.2593\n",
      "Epoch 2408/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.4575\n",
      "Epoch 02408: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7524.4575 - val_loss: 7534.3711\n",
      "Epoch 2409/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4248\n",
      "Epoch 02409: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.4248 - val_loss: 7534.2881\n",
      "Epoch 2410/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.1582\n",
      "Epoch 02410: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.1582 - val_loss: 7534.3345\n",
      "Epoch 2411/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.4634\n",
      "Epoch 02411: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7543.4634 - val_loss: 7534.8081\n",
      "Epoch 2412/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1069\n",
      "Epoch 02412: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.1069 - val_loss: 7534.5591\n",
      "Epoch 2413/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4297\n",
      "Epoch 02413: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.4297 - val_loss: 7534.4863\n",
      "Epoch 2414/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5425\n",
      "Epoch 02414: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.5425 - val_loss: 7534.1001\n",
      "Epoch 2415/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.8613\n",
      "Epoch 02415: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7518.8613 - val_loss: 7534.1934\n",
      "Epoch 2416/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7109\n",
      "Epoch 02416: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.7109 - val_loss: 7534.0967\n",
      "Epoch 2417/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.9219\n",
      "Epoch 02417: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.9219 - val_loss: 7534.4121\n",
      "Epoch 2418/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.9673\n",
      "Epoch 02418: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.9673 - val_loss: 7534.5698\n",
      "Epoch 2419/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.9365\n",
      "Epoch 02419: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.9365 - val_loss: 7536.1182\n",
      "Epoch 2420/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2998\n",
      "Epoch 02420: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.2998 - val_loss: 7534.5967\n",
      "Epoch 2421/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4668\n",
      "Epoch 02421: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.4668 - val_loss: 7534.6929\n",
      "Epoch 2422/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.0122\n",
      "Epoch 02422: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7529.0122 - val_loss: 7534.2017\n",
      "Epoch 2423/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.4580\n",
      "Epoch 02423: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7519.4580 - val_loss: 7534.6328\n",
      "Epoch 2424/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6406\n",
      "Epoch 02424: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.6406 - val_loss: 7534.0098\n",
      "Epoch 2425/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.4697\n",
      "Epoch 02425: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.4697 - val_loss: 7533.9810\n",
      "Epoch 2426/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8774\n",
      "Epoch 02426: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.8774 - val_loss: 7534.7056\n",
      "Epoch 2427/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3745\n",
      "Epoch 02427: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.3745 - val_loss: 7534.3530\n",
      "Epoch 2428/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8125\n",
      "Epoch 02428: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.8125 - val_loss: 7534.5312\n",
      "Epoch 2429/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.9712\n",
      "Epoch 02429: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7536.9712 - val_loss: 7535.4927\n",
      "Epoch 2430/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.8062\n",
      "Epoch 02430: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.8062 - val_loss: 7535.8223\n",
      "Epoch 2431/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.7441\n",
      "Epoch 02431: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7543.7441 - val_loss: 7535.2090\n",
      "Epoch 2432/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5024\n",
      "Epoch 02432: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.5024 - val_loss: 7534.8022\n",
      "Epoch 2433/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8608\n",
      "Epoch 02433: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.8608 - val_loss: 7534.6904\n",
      "Epoch 2434/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.6406\n",
      "Epoch 02434: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7540.6406 - val_loss: 7534.1519\n",
      "Epoch 2435/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5913\n",
      "Epoch 02435: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.5913 - val_loss: 7534.0415\n",
      "Epoch 2436/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.6533\n",
      "Epoch 02436: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7542.6533 - val_loss: 7534.3809\n",
      "Epoch 2437/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.7109\n",
      "Epoch 02437: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7524.7109 - val_loss: 7534.3662\n",
      "Epoch 2438/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6055\n",
      "Epoch 02438: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7532.6055 - val_loss: 7534.2847\n",
      "Epoch 2439/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7532.9497\n",
      "Epoch 02439: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.9497 - val_loss: 7534.2017\n",
      "Epoch 2440/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1460\n",
      "Epoch 02440: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.1460 - val_loss: 7534.3926\n",
      "Epoch 2441/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7119\n",
      "Epoch 02441: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7530.7119 - val_loss: 7534.4072\n",
      "Epoch 2442/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6035\n",
      "Epoch 02442: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.6035 - val_loss: 7534.3320\n",
      "Epoch 2443/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.7104\n",
      "Epoch 02443: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.7104 - val_loss: 7534.1313\n",
      "Epoch 2444/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8101\n",
      "Epoch 02444: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.8101 - val_loss: 7534.2881\n",
      "Epoch 2445/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7393\n",
      "Epoch 02445: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.7393 - val_loss: 7534.0464\n",
      "Epoch 2446/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.7603\n",
      "Epoch 02446: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7542.7603 - val_loss: 7534.1978\n",
      "Epoch 2447/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3682\n",
      "Epoch 02447: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.3682 - val_loss: 7534.0576\n",
      "Epoch 2448/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2520\n",
      "Epoch 02448: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.2520 - val_loss: 7533.8081\n",
      "Epoch 2449/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9131\n",
      "Epoch 02449: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.9131 - val_loss: 7534.4185\n",
      "Epoch 2450/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1616\n",
      "Epoch 02450: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.1616 - val_loss: 7534.3911\n",
      "Epoch 2451/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0444\n",
      "Epoch 02451: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7536.0444 - val_loss: 7534.0962\n",
      "Epoch 2452/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.4897\n",
      "Epoch 02452: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.4897 - val_loss: 7533.9575\n",
      "Epoch 2453/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.3335\n",
      "Epoch 02453: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7539.3335 - val_loss: 7534.2974\n",
      "Epoch 2454/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.9556\n",
      "Epoch 02454: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7542.9556 - val_loss: 7534.6519\n",
      "Epoch 2455/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.8638\n",
      "Epoch 02455: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.8638 - val_loss: 7534.3311\n",
      "Epoch 2456/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.5044\n",
      "Epoch 02456: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7543.5044 - val_loss: 7534.6978\n",
      "Epoch 2457/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.4883\n",
      "Epoch 02457: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7529.4883 - val_loss: 7534.4424\n",
      "Epoch 2458/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.2256\n",
      "Epoch 02458: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.2256 - val_loss: 7534.1890\n",
      "Epoch 2459/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4854\n",
      "Epoch 02459: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7531.4854 - val_loss: 7534.1440\n",
      "Epoch 2460/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.7744\n",
      "Epoch 02460: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7525.7744 - val_loss: 7534.2065\n",
      "Epoch 2461/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7158\n",
      "Epoch 02461: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.7158 - val_loss: 7534.1440\n",
      "Epoch 2462/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4414\n",
      "Epoch 02462: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.4414 - val_loss: 7534.0063\n",
      "Epoch 2463/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4985\n",
      "Epoch 02463: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.4985 - val_loss: 7534.0063\n",
      "Epoch 2464/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0171\n",
      "Epoch 02464: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.0171 - val_loss: 7535.0737\n",
      "Epoch 2465/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.4214\n",
      "Epoch 02465: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7529.4214 - val_loss: 7534.7710\n",
      "Epoch 2466/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.5015\n",
      "Epoch 02466: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.5015 - val_loss: 7533.9512\n",
      "Epoch 2467/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.1763\n",
      "Epoch 02467: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7545.1763 - val_loss: 7534.0815\n",
      "Epoch 2468/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1216\n",
      "Epoch 02468: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.1216 - val_loss: 7533.8535\n",
      "Epoch 2469/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9087\n",
      "Epoch 02469: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.9087 - val_loss: 7534.2578\n",
      "Epoch 2470/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.5957\n",
      "Epoch 02470: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.5957 - val_loss: 7535.2007\n",
      "Epoch 2471/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.0312\n",
      "Epoch 02471: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.0312 - val_loss: 7534.3418\n",
      "Epoch 2472/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.3315\n",
      "Epoch 02472: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.3315 - val_loss: 7534.1870\n",
      "Epoch 2473/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4492\n",
      "Epoch 02473: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.4492 - val_loss: 7534.8574\n",
      "Epoch 2474/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7525.6265\n",
      "Epoch 02474: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7525.6265 - val_loss: 7534.4946\n",
      "Epoch 2475/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7617\n",
      "Epoch 02475: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.7617 - val_loss: 7535.0103\n",
      "Epoch 2476/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.9766\n",
      "Epoch 02476: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7518.9766 - val_loss: 7534.2710\n",
      "Epoch 2477/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0747\n",
      "Epoch 02477: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.0747 - val_loss: 7534.3232\n",
      "Epoch 2478/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5010\n",
      "Epoch 02478: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.5010 - val_loss: 7534.5063\n",
      "Epoch 2479/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4531\n",
      "Epoch 02479: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.4531 - val_loss: 7534.0762\n",
      "Epoch 2480/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.9336\n",
      "Epoch 02480: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.9336 - val_loss: 7534.0449\n",
      "Epoch 2481/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.8662\n",
      "Epoch 02481: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7543.8662 - val_loss: 7534.0918\n",
      "Epoch 2482/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.3335\n",
      "Epoch 02482: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.3335 - val_loss: 7534.0142\n",
      "Epoch 2483/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.4170\n",
      "Epoch 02483: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7542.4170 - val_loss: 7533.6543\n",
      "Epoch 2484/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0146\n",
      "Epoch 02484: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.0146 - val_loss: 7533.8184\n",
      "Epoch 2485/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1772\n",
      "Epoch 02485: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7532.1772 - val_loss: 7534.6377\n",
      "Epoch 2486/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7553.1030\n",
      "Epoch 02486: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7553.1030 - val_loss: 7560.1470\n",
      "Epoch 2487/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.9697\n",
      "Epoch 02487: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7539.9697 - val_loss: 7544.3550\n",
      "Epoch 2488/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.0190\n",
      "Epoch 02488: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7540.0190 - val_loss: 7542.1890\n",
      "Epoch 2489/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.0723\n",
      "Epoch 02489: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7539.0723 - val_loss: 7540.9961\n",
      "Epoch 2490/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.2466\n",
      "Epoch 02490: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7543.2466 - val_loss: 7540.3882\n",
      "Epoch 2491/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.8438\n",
      "Epoch 02491: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7541.8438 - val_loss: 7540.1274\n",
      "Epoch 2492/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.4175\n",
      "Epoch 02492: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 540ms/step - loss: 7544.4175 - val_loss: 7539.7266\n",
      "Epoch 2493/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.2568\n",
      "Epoch 02493: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7546.2568 - val_loss: 7539.7026\n",
      "Epoch 2494/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.7920\n",
      "Epoch 02494: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7549.7920 - val_loss: 7539.4570\n",
      "Epoch 2495/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8545\n",
      "Epoch 02495: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7545.8545 - val_loss: 7539.2222\n",
      "Epoch 2496/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7550.5352\n",
      "Epoch 02496: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7550.5352 - val_loss: 7539.0679\n",
      "Epoch 2497/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.1167\n",
      "Epoch 02497: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7528.1167 - val_loss: 7538.9946\n",
      "Epoch 2498/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6987\n",
      "Epoch 02498: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7537.6987 - val_loss: 7538.8623\n",
      "Epoch 2499/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7686\n",
      "Epoch 02499: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.7686 - val_loss: 7538.7822\n",
      "Epoch 2500/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.0596\n",
      "Epoch 02500: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7542.0596 - val_loss: 7538.8105\n",
      "Epoch 2501/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.8579\n",
      "Epoch 02501: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7541.8579 - val_loss: 7538.7520\n",
      "Epoch 2502/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2881\n",
      "Epoch 02502: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7533.2881 - val_loss: 7538.4287\n",
      "Epoch 2503/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.1968\n",
      "Epoch 02503: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7543.1968 - val_loss: 7538.4062\n",
      "Epoch 2504/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1733\n",
      "Epoch 02504: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7537.1733 - val_loss: 7538.7944\n",
      "Epoch 2505/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9761\n",
      "Epoch 02505: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7532.9761 - val_loss: 7538.2334\n",
      "Epoch 2506/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.9082\n",
      "Epoch 02506: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7549.9082 - val_loss: 7538.4082\n",
      "Epoch 2507/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.9902\n",
      "Epoch 02507: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7542.9902 - val_loss: 7538.2729\n",
      "Epoch 2508/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.2202\n",
      "Epoch 02508: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7549.2202 - val_loss: 7538.0815\n",
      "Epoch 2509/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7544.4614\n",
      "Epoch 02509: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7544.4614 - val_loss: 7537.8794\n",
      "Epoch 2510/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.6997\n",
      "Epoch 02510: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7535.6997 - val_loss: 7537.7144\n",
      "Epoch 2511/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.1230\n",
      "Epoch 02511: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7535.1230 - val_loss: 7537.6206\n",
      "Epoch 2512/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1694\n",
      "Epoch 02512: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7534.1694 - val_loss: 7538.2607\n",
      "Epoch 2513/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.1621\n",
      "Epoch 02513: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 541ms/step - loss: 7543.1621 - val_loss: 7538.3384\n",
      "Epoch 2514/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6396\n",
      "Epoch 02514: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7534.6396 - val_loss: 7537.6958\n",
      "Epoch 2515/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.1411\n",
      "Epoch 02515: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7539.1411 - val_loss: 7537.3950\n",
      "Epoch 2516/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2583\n",
      "Epoch 02516: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7532.2583 - val_loss: 7537.4688\n",
      "Epoch 2517/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.7710\n",
      "Epoch 02517: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7547.7710 - val_loss: 7537.5752\n",
      "Epoch 2518/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.5444\n",
      "Epoch 02518: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7547.5444 - val_loss: 7537.3618\n",
      "Epoch 2519/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.8452\n",
      "Epoch 02519: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 543ms/step - loss: 7534.8452 - val_loss: 7537.3384\n",
      "Epoch 2520/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.9170\n",
      "Epoch 02520: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7539.9170 - val_loss: 7537.2490\n",
      "Epoch 2521/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5889\n",
      "Epoch 02521: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.5889 - val_loss: 7537.1318\n",
      "Epoch 2522/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5654\n",
      "Epoch 02522: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7534.5654 - val_loss: 7537.2446\n",
      "Epoch 2523/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.9653\n",
      "Epoch 02523: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7539.9653 - val_loss: 7537.0049\n",
      "Epoch 2524/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.3691\n",
      "Epoch 02524: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7545.3691 - val_loss: 7536.9209\n",
      "Epoch 2525/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.7563\n",
      "Epoch 02525: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7545.7563 - val_loss: 7537.2480\n",
      "Epoch 2526/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.7539\n",
      "Epoch 02526: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7527.7539 - val_loss: 7536.8286\n",
      "Epoch 2527/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.1006\n",
      "Epoch 02527: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7540.1006 - val_loss: 7536.7393\n",
      "Epoch 2528/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0991\n",
      "Epoch 02528: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7534.0991 - val_loss: 7537.0698\n",
      "Epoch 2529/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.1401\n",
      "Epoch 02529: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7549.1401 - val_loss: 7537.5830\n",
      "Epoch 2530/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.6309\n",
      "Epoch 02530: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7543.6309 - val_loss: 7536.9233\n",
      "Epoch 2531/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.4048\n",
      "Epoch 02531: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7539.4048 - val_loss: 7537.3623\n",
      "Epoch 2532/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.6743\n",
      "Epoch 02532: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7539.6743 - val_loss: 7536.7930\n",
      "Epoch 2533/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.5557\n",
      "Epoch 02533: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.5557 - val_loss: 7536.6104\n",
      "Epoch 2534/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6099\n",
      "Epoch 02534: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.6099 - val_loss: 7537.2305\n",
      "Epoch 2535/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.6660\n",
      "Epoch 02535: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7548.6660 - val_loss: 7537.1714\n",
      "Epoch 2536/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5903\n",
      "Epoch 02536: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7534.5903 - val_loss: 7536.6665\n",
      "Epoch 2537/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.2666\n",
      "Epoch 02537: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.2666 - val_loss: 7536.5137\n",
      "Epoch 2538/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7896\n",
      "Epoch 02538: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.7896 - val_loss: 7536.4321\n",
      "Epoch 2539/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8311\n",
      "Epoch 02539: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.8311 - val_loss: 7536.4424\n",
      "Epoch 2540/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8848\n",
      "Epoch 02540: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.8848 - val_loss: 7536.4800\n",
      "Epoch 2541/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.6191\n",
      "Epoch 02541: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7535.6191 - val_loss: 7536.9536\n",
      "Epoch 2542/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4048\n",
      "Epoch 02542: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 540ms/step - loss: 7533.4048 - val_loss: 7536.5288\n",
      "Epoch 2543/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7651\n",
      "Epoch 02543: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.7651 - val_loss: 7536.4360\n",
      "Epoch 2544/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7534.5645\n",
      "Epoch 02544: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.5645 - val_loss: 7536.7974\n",
      "Epoch 2545/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5171\n",
      "Epoch 02545: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7534.5171 - val_loss: 7536.3022\n",
      "Epoch 2546/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4580\n",
      "Epoch 02546: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.4580 - val_loss: 7536.6479\n",
      "Epoch 2547/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.8306\n",
      "Epoch 02547: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7547.8306 - val_loss: 7536.5615\n",
      "Epoch 2548/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4351\n",
      "Epoch 02548: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.4351 - val_loss: 7536.3154\n",
      "Epoch 2549/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.5151\n",
      "Epoch 02549: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7547.5151 - val_loss: 7536.2905\n",
      "Epoch 2550/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.3936\n",
      "Epoch 02550: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7539.3936 - val_loss: 7536.2002\n",
      "Epoch 2551/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.2446\n",
      "Epoch 02551: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7547.2446 - val_loss: 7537.0073\n",
      "Epoch 2552/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.0479\n",
      "Epoch 02552: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7545.0479 - val_loss: 7538.4526\n",
      "Epoch 2553/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2212\n",
      "Epoch 02553: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.2212 - val_loss: 7538.9814\n",
      "Epoch 2554/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.5366\n",
      "Epoch 02554: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.5366 - val_loss: 7540.9424\n",
      "Epoch 2555/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1846\n",
      "Epoch 02555: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7537.1846 - val_loss: 7538.8311\n",
      "Epoch 2556/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.3374\n",
      "Epoch 02556: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7527.3374 - val_loss: 7537.4370\n",
      "Epoch 2557/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.0063\n",
      "Epoch 02557: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7545.0063 - val_loss: 7536.7681\n",
      "Epoch 2558/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1616\n",
      "Epoch 02558: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7538.1616 - val_loss: 7536.3281\n",
      "Epoch 2559/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.7935\n",
      "Epoch 02559: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7547.7935 - val_loss: 7536.1401\n",
      "Epoch 2560/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.4312\n",
      "Epoch 02560: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.4312 - val_loss: 7536.6416\n",
      "Epoch 2561/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3574\n",
      "Epoch 02561: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7534.3574 - val_loss: 7536.1729\n",
      "Epoch 2562/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6030\n",
      "Epoch 02562: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.6030 - val_loss: 7536.8154\n",
      "Epoch 2563/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.6460\n",
      "Epoch 02563: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7533.6460 - val_loss: 7536.4209\n",
      "Epoch 2564/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0225\n",
      "Epoch 02564: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.0225 - val_loss: 7536.1914\n",
      "Epoch 2565/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.9521\n",
      "Epoch 02565: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7527.9521 - val_loss: 7535.8398\n",
      "Epoch 2566/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6924\n",
      "Epoch 02566: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.6924 - val_loss: 7535.9487\n",
      "Epoch 2567/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0356\n",
      "Epoch 02567: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.0356 - val_loss: 7536.1426\n",
      "Epoch 2568/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.4966\n",
      "Epoch 02568: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7538.4966 - val_loss: 7535.9062\n",
      "Epoch 2569/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1841\n",
      "Epoch 02569: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.1841 - val_loss: 7535.8286\n",
      "Epoch 2570/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.9194\n",
      "Epoch 02570: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7526.9194 - val_loss: 7535.8896\n",
      "Epoch 2571/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.2607\n",
      "Epoch 02571: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7541.2607 - val_loss: 7536.1567\n",
      "Epoch 2572/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.8193\n",
      "Epoch 02572: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7542.8193 - val_loss: 7536.3960\n",
      "Epoch 2573/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.0913\n",
      "Epoch 02573: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7541.0913 - val_loss: 7536.0576\n",
      "Epoch 2574/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.6431\n",
      "Epoch 02574: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7539.6431 - val_loss: 7536.1758\n",
      "Epoch 2575/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.8052\n",
      "Epoch 02575: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7526.8052 - val_loss: 7535.7554\n",
      "Epoch 2576/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.0615\n",
      "Epoch 02576: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7539.0615 - val_loss: 7536.3296\n",
      "Epoch 2577/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.5903\n",
      "Epoch 02577: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7526.5903 - val_loss: 7536.7446\n",
      "Epoch 2578/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.0215\n",
      "Epoch 02578: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 541ms/step - loss: 7526.0215 - val_loss: 7535.9414\n",
      "Epoch 2579/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7532.6445\n",
      "Epoch 02579: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7532.6445 - val_loss: 7535.7969\n",
      "Epoch 2580/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.0112\n",
      "Epoch 02580: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7539.0112 - val_loss: 7536.0063\n",
      "Epoch 2581/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1934\n",
      "Epoch 02581: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.1934 - val_loss: 7535.8711\n",
      "Epoch 2582/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8716\n",
      "Epoch 02582: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.8716 - val_loss: 7535.8057\n",
      "Epoch 2583/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7793\n",
      "Epoch 02583: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7533.7793 - val_loss: 7535.6401\n",
      "Epoch 2584/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.2637\n",
      "Epoch 02584: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7536.2637 - val_loss: 7536.9570\n",
      "Epoch 2585/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.0830\n",
      "Epoch 02585: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7528.0830 - val_loss: 7535.8735\n",
      "Epoch 2586/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3311\n",
      "Epoch 02586: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7534.3311 - val_loss: 7535.9336\n",
      "Epoch 2587/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.4443\n",
      "Epoch 02587: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7542.4443 - val_loss: 7536.0078\n",
      "Epoch 2588/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.1875\n",
      "Epoch 02588: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7539.1875 - val_loss: 7536.5864\n",
      "Epoch 2589/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.7334\n",
      "Epoch 02589: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7547.7334 - val_loss: 7536.2383\n",
      "Epoch 2590/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.6123\n",
      "Epoch 02590: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7539.6123 - val_loss: 7535.9175\n",
      "Epoch 2591/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4214\n",
      "Epoch 02591: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7534.4214 - val_loss: 7535.9521\n",
      "Epoch 2592/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4736\n",
      "Epoch 02592: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.4736 - val_loss: 7536.1226\n",
      "Epoch 2593/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.1006\n",
      "Epoch 02593: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7520.1006 - val_loss: 7535.5376\n",
      "Epoch 2594/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6953\n",
      "Epoch 02594: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.6953 - val_loss: 7535.8130\n",
      "Epoch 2595/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0703\n",
      "Epoch 02595: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7533.0703 - val_loss: 7535.4985\n",
      "Epoch 2596/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3462\n",
      "Epoch 02596: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7533.3462 - val_loss: 7535.6729\n",
      "Epoch 2597/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.7510\n",
      "Epoch 02597: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7525.7510 - val_loss: 7535.6855\n",
      "Epoch 2598/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.1704\n",
      "Epoch 02598: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7544.1704 - val_loss: 7535.7231\n",
      "Epoch 2599/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3252\n",
      "Epoch 02599: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.3252 - val_loss: 7535.5127\n",
      "Epoch 2600/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7344\n",
      "Epoch 02600: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.7344 - val_loss: 7535.3960\n",
      "Epoch 2601/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.7300\n",
      "Epoch 02601: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7537.7300 - val_loss: 7535.9873\n",
      "Epoch 2602/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.8579\n",
      "Epoch 02602: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7547.8579 - val_loss: 7536.7422\n",
      "Epoch 2603/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.5840\n",
      "Epoch 02603: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7540.5840 - val_loss: 7535.5674\n",
      "Epoch 2604/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.9556\n",
      "Epoch 02604: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7543.9556 - val_loss: 7535.4302\n",
      "Epoch 2605/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.2471\n",
      "Epoch 02605: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7539.2471 - val_loss: 7536.9297\n",
      "Epoch 2606/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.4053\n",
      "Epoch 02606: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7547.4053 - val_loss: 7536.0098\n",
      "Epoch 2607/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7090\n",
      "Epoch 02607: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.7090 - val_loss: 7535.4458\n",
      "Epoch 2608/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.7690\n",
      "Epoch 02608: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7527.7690 - val_loss: 7535.7529\n",
      "Epoch 2609/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.9771\n",
      "Epoch 02609: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7527.9771 - val_loss: 7535.9058\n",
      "Epoch 2610/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.5986\n",
      "Epoch 02610: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7530.5986 - val_loss: 7535.8633\n",
      "Epoch 2611/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.9814\n",
      "Epoch 02611: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.9814 - val_loss: 7535.5415\n",
      "Epoch 2612/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6924\n",
      "Epoch 02612: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.6924 - val_loss: 7535.4590\n",
      "Epoch 2613/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5361\n",
      "Epoch 02613: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.5361 - val_loss: 7535.3481\n",
      "Epoch 2614/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7525.6230\n",
      "Epoch 02614: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7525.6230 - val_loss: 7535.5327\n",
      "Epoch 2615/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4790\n",
      "Epoch 02615: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.4790 - val_loss: 7535.5024\n",
      "Epoch 2616/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.6650\n",
      "Epoch 02616: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7546.6650 - val_loss: 7535.5488\n",
      "Epoch 2617/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.5972\n",
      "Epoch 02617: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.5972 - val_loss: 7535.3311\n",
      "Epoch 2618/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6084\n",
      "Epoch 02618: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.6084 - val_loss: 7535.2490\n",
      "Epoch 2619/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.6421\n",
      "Epoch 02619: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.6421 - val_loss: 7538.2920\n",
      "Epoch 2620/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.3071\n",
      "Epoch 02620: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7549.3071 - val_loss: 7538.0479\n",
      "Epoch 2621/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.2573\n",
      "Epoch 02621: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7527.2573 - val_loss: 7536.7319\n",
      "Epoch 2622/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5479\n",
      "Epoch 02622: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.5479 - val_loss: 7536.0952\n",
      "Epoch 2623/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.5352\n",
      "Epoch 02623: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7547.5352 - val_loss: 7535.9521\n",
      "Epoch 2624/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7334\n",
      "Epoch 02624: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7539.7334 - val_loss: 7536.5322\n",
      "Epoch 2625/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5225\n",
      "Epoch 02625: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.5225 - val_loss: 7535.9585\n",
      "Epoch 2626/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.4946\n",
      "Epoch 02626: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7527.4946 - val_loss: 7535.3184\n",
      "Epoch 2627/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5410\n",
      "Epoch 02627: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.5410 - val_loss: 7535.3442\n",
      "Epoch 2628/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.6572\n",
      "Epoch 02628: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7546.6572 - val_loss: 7535.2983\n",
      "Epoch 2629/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.0596\n",
      "Epoch 02629: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.0596 - val_loss: 7536.0376\n",
      "Epoch 2630/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.0337\n",
      "Epoch 02630: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.0337 - val_loss: 7536.7607\n",
      "Epoch 2631/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.2437\n",
      "Epoch 02631: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.2437 - val_loss: 7536.2710\n",
      "Epoch 2632/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.4385\n",
      "Epoch 02632: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7542.4385 - val_loss: 7536.0864\n",
      "Epoch 2633/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.0298\n",
      "Epoch 02633: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7548.0298 - val_loss: 7548.4746\n",
      "Epoch 2634/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.3716\n",
      "Epoch 02634: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7538.3716 - val_loss: 7540.8838\n",
      "Epoch 2635/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.9106\n",
      "Epoch 02635: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7537.9106 - val_loss: 7539.0127\n",
      "Epoch 2636/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4131\n",
      "Epoch 02636: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.4131 - val_loss: 7538.2607\n",
      "Epoch 2637/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.8237\n",
      "Epoch 02637: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7528.8237 - val_loss: 7537.8374\n",
      "Epoch 2638/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.8086\n",
      "Epoch 02638: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7548.8086 - val_loss: 7537.5249\n",
      "Epoch 2639/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.4292\n",
      "Epoch 02639: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7539.4292 - val_loss: 7537.3384\n",
      "Epoch 2640/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.6318\n",
      "Epoch 02640: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7547.6318 - val_loss: 7537.2993\n",
      "Epoch 2641/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0962\n",
      "Epoch 02641: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.0962 - val_loss: 7537.1489\n",
      "Epoch 2642/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5674\n",
      "Epoch 02642: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.5674 - val_loss: 7537.0200\n",
      "Epoch 2643/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7544\n",
      "Epoch 02643: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.7544 - val_loss: 7537.1792\n",
      "Epoch 2644/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4307\n",
      "Epoch 02644: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.4307 - val_loss: 7536.9614\n",
      "Epoch 2645/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.2720\n",
      "Epoch 02645: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.2720 - val_loss: 7536.7466\n",
      "Epoch 2646/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7521.1714\n",
      "Epoch 02646: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7521.1714 - val_loss: 7536.7065\n",
      "Epoch 2647/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.9385\n",
      "Epoch 02647: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.9385 - val_loss: 7536.6895\n",
      "Epoch 2648/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.7251\n",
      "Epoch 02648: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7534.7251 - val_loss: 7536.6953\n",
      "Epoch 2649/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7539.6138\n",
      "Epoch 02649: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.6138 - val_loss: 7536.8506\n",
      "Epoch 2650/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.7139\n",
      "Epoch 02650: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7534.7139 - val_loss: 7537.3320\n",
      "Epoch 2651/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.1011\n",
      "Epoch 02651: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.1011 - val_loss: 7537.7871\n",
      "Epoch 2652/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2324\n",
      "Epoch 02652: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.2324 - val_loss: 7537.4370\n",
      "Epoch 2653/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.2393\n",
      "Epoch 02653: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.2393 - val_loss: 7538.3550\n",
      "Epoch 2654/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.8691\n",
      "Epoch 02654: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.8691 - val_loss: 7537.2998\n",
      "Epoch 2655/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.1226\n",
      "Epoch 02655: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7547.1226 - val_loss: 7536.8975\n",
      "Epoch 2656/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.0864\n",
      "Epoch 02656: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7548.0864 - val_loss: 7536.6353\n",
      "Epoch 2657/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2783\n",
      "Epoch 02657: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.2783 - val_loss: 7536.2769\n",
      "Epoch 2658/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.6284\n",
      "Epoch 02658: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7546.6284 - val_loss: 7536.3896\n",
      "Epoch 2659/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5581\n",
      "Epoch 02659: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.5581 - val_loss: 7536.1870\n",
      "Epoch 2660/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.0151\n",
      "Epoch 02660: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.0151 - val_loss: 7536.7759\n",
      "Epoch 2661/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.3706\n",
      "Epoch 02661: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7547.3706 - val_loss: 7536.2192\n",
      "Epoch 2662/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8872\n",
      "Epoch 02662: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.8872 - val_loss: 7536.1504\n",
      "Epoch 2663/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.1489\n",
      "Epoch 02663: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7540.1489 - val_loss: 7536.7842\n",
      "Epoch 2664/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5415\n",
      "Epoch 02664: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.5415 - val_loss: 7536.1479\n",
      "Epoch 2665/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.5693\n",
      "Epoch 02665: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7520.5693 - val_loss: 7536.0415\n",
      "Epoch 2666/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2686\n",
      "Epoch 02666: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7538.2686 - val_loss: 7536.4360\n",
      "Epoch 2667/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9492\n",
      "Epoch 02667: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7533.9492 - val_loss: 7536.6016\n",
      "Epoch 2668/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3267\n",
      "Epoch 02668: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7534.3267 - val_loss: 7536.2598\n",
      "Epoch 2669/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.0649\n",
      "Epoch 02669: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7535.0649 - val_loss: 7536.1074\n",
      "Epoch 2670/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.6436\n",
      "Epoch 02670: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7542.6436 - val_loss: 7535.8960\n",
      "Epoch 2671/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.8394\n",
      "Epoch 02671: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7520.8394 - val_loss: 7536.0840\n",
      "Epoch 2672/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0308\n",
      "Epoch 02672: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.0308 - val_loss: 7535.8662\n",
      "Epoch 2673/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4751\n",
      "Epoch 02673: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.4751 - val_loss: 7535.6719\n",
      "Epoch 2674/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6479\n",
      "Epoch 02674: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.6479 - val_loss: 7535.6182\n",
      "Epoch 2675/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.4600\n",
      "Epoch 02675: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.4600 - val_loss: 7535.6650\n",
      "Epoch 2676/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7695\n",
      "Epoch 02676: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7533.7695 - val_loss: 7536.0654\n",
      "Epoch 2677/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6636\n",
      "Epoch 02677: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7534.6636 - val_loss: 7536.5752\n",
      "Epoch 2678/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.2222\n",
      "Epoch 02678: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.2222 - val_loss: 7535.5830\n",
      "Epoch 2679/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8062\n",
      "Epoch 02679: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7533.8062 - val_loss: 7535.4902\n",
      "Epoch 2680/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.1836\n",
      "Epoch 02680: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7525.1836 - val_loss: 7535.4839\n",
      "Epoch 2681/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2759\n",
      "Epoch 02681: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7538.2759 - val_loss: 7535.7769\n",
      "Epoch 2682/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.0112\n",
      "Epoch 02682: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7544.0112 - val_loss: 7535.4878\n",
      "Epoch 2683/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7505\n",
      "Epoch 02683: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7533.7505 - val_loss: 7535.6118\n",
      "Epoch 2684/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7526.0015\n",
      "Epoch 02684: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7526.0015 - val_loss: 7536.2817\n",
      "Epoch 2685/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6646\n",
      "Epoch 02685: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 540ms/step - loss: 7532.6646 - val_loss: 7536.6846\n",
      "Epoch 2686/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8276\n",
      "Epoch 02686: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.8276 - val_loss: 7536.3545\n",
      "Epoch 2687/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.5991\n",
      "Epoch 02687: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7538.5991 - val_loss: 7535.8896\n",
      "Epoch 2688/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.1484\n",
      "Epoch 02688: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7520.1484 - val_loss: 7535.8018\n",
      "Epoch 2689/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.3179\n",
      "Epoch 02689: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7520.3179 - val_loss: 7535.7256\n",
      "Epoch 2690/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0200\n",
      "Epoch 02690: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7533.0200 - val_loss: 7535.6738\n",
      "Epoch 2691/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6997\n",
      "Epoch 02691: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7537.6997 - val_loss: 7535.6362\n",
      "Epoch 2692/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.3765\n",
      "Epoch 02692: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7542.3765 - val_loss: 7536.1768\n",
      "Epoch 2693/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.0347\n",
      "Epoch 02693: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.0347 - val_loss: 7535.9585\n",
      "Epoch 2694/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.2178\n",
      "Epoch 02694: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7526.2178 - val_loss: 7536.3359\n",
      "Epoch 2695/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5410\n",
      "Epoch 02695: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.5410 - val_loss: 7536.1694\n",
      "Epoch 2696/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2607\n",
      "Epoch 02696: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.2607 - val_loss: 7536.2554\n",
      "Epoch 2697/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.3198\n",
      "Epoch 02697: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7528.3198 - val_loss: 7536.3057\n",
      "Epoch 2698/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.7778\n",
      "Epoch 02698: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 543ms/step - loss: 7534.7778 - val_loss: 7535.4038\n",
      "Epoch 2699/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.1187\n",
      "Epoch 02699: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7528.1187 - val_loss: 7535.5566\n",
      "Epoch 2700/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0527\n",
      "Epoch 02700: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 542ms/step - loss: 7533.0527 - val_loss: 7535.4990\n",
      "Epoch 2701/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5962\n",
      "Epoch 02701: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 542ms/step - loss: 7537.5962 - val_loss: 7535.1592\n",
      "Epoch 2702/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4863\n",
      "Epoch 02702: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 541ms/step - loss: 7532.4863 - val_loss: 7535.1929\n",
      "Epoch 2703/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.8857\n",
      "Epoch 02703: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7537.8857 - val_loss: 7535.0815\n",
      "Epoch 2704/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1899\n",
      "Epoch 02704: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7534.1899 - val_loss: 7535.1167\n",
      "Epoch 2705/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5762\n",
      "Epoch 02705: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7532.5762 - val_loss: 7535.9536\n",
      "Epoch 2706/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9966\n",
      "Epoch 02706: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.9966 - val_loss: 7535.5630\n",
      "Epoch 2707/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.6025\n",
      "Epoch 02707: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7546.6025 - val_loss: 7535.3535\n",
      "Epoch 2708/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7568\n",
      "Epoch 02708: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7533.7568 - val_loss: 7535.5176\n",
      "Epoch 2709/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1499\n",
      "Epoch 02709: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7532.1499 - val_loss: 7536.0361\n",
      "Epoch 2710/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3706\n",
      "Epoch 02710: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7531.3706 - val_loss: 7535.2031\n",
      "Epoch 2711/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0498\n",
      "Epoch 02711: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7531.0498 - val_loss: 7534.9600\n",
      "Epoch 2712/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.9941\n",
      "Epoch 02712: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7524.9941 - val_loss: 7535.0674\n",
      "Epoch 2713/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.3579\n",
      "Epoch 02713: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7546.3579 - val_loss: 7535.3569\n",
      "Epoch 2714/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.2432\n",
      "Epoch 02714: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7527.2432 - val_loss: 7535.4751\n",
      "Epoch 2715/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.2812\n",
      "Epoch 02715: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7534.2812 - val_loss: 7535.7378\n",
      "Epoch 2716/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4990\n",
      "Epoch 02716: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 540ms/step - loss: 7533.4990 - val_loss: 7535.2954\n",
      "Epoch 2717/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7153\n",
      "Epoch 02717: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 541ms/step - loss: 7533.7153 - val_loss: 7535.4951\n",
      "Epoch 2718/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6348\n",
      "Epoch 02718: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7532.6348 - val_loss: 7535.1953\n",
      "Epoch 2719/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7540.4741\n",
      "Epoch 02719: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7540.4741 - val_loss: 7535.3486\n",
      "Epoch 2720/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9268\n",
      "Epoch 02720: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7533.9268 - val_loss: 7535.2290\n",
      "Epoch 2721/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.9751\n",
      "Epoch 02721: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7534.9751 - val_loss: 7536.3374\n",
      "Epoch 2722/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.6235\n",
      "Epoch 02722: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7527.6235 - val_loss: 7535.4097\n",
      "Epoch 2723/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.2422\n",
      "Epoch 02723: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7542.2422 - val_loss: 7535.3970\n",
      "Epoch 2724/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.7949\n",
      "Epoch 02724: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7546.7949 - val_loss: 7535.1543\n",
      "Epoch 2725/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2593\n",
      "Epoch 02725: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.2593 - val_loss: 7535.9814\n",
      "Epoch 2726/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.8672\n",
      "Epoch 02726: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7540.8672 - val_loss: 7536.0942\n",
      "Epoch 2727/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.2295\n",
      "Epoch 02727: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7534.2295 - val_loss: 7535.5200\n",
      "Epoch 2728/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.3999\n",
      "Epoch 02728: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7538.3999 - val_loss: 7535.4697\n",
      "Epoch 2729/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7622\n",
      "Epoch 02729: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7540.7622 - val_loss: 7536.1440\n",
      "Epoch 2730/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7964\n",
      "Epoch 02730: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.7964 - val_loss: 7535.4336\n",
      "Epoch 2731/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6582\n",
      "Epoch 02731: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7537.6582 - val_loss: 7535.1406\n",
      "Epoch 2732/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.5801\n",
      "Epoch 02732: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7538.5801 - val_loss: 7535.1138\n",
      "Epoch 2733/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7393\n",
      "Epoch 02733: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7536.7393 - val_loss: 7534.7974\n",
      "Epoch 2734/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.3691\n",
      "Epoch 02734: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7546.3691 - val_loss: 7534.9688\n",
      "Epoch 2735/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.5186\n",
      "Epoch 02735: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7529.5186 - val_loss: 7534.6553\n",
      "Epoch 2736/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0220\n",
      "Epoch 02736: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.0220 - val_loss: 7534.8862\n",
      "Epoch 2737/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.8589\n",
      "Epoch 02737: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7541.8589 - val_loss: 7534.9233\n",
      "Epoch 2738/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.5229\n",
      "Epoch 02738: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7543.5229 - val_loss: 7535.2881\n",
      "Epoch 2739/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.2061\n",
      "Epoch 02739: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7534.2061 - val_loss: 7535.0679\n",
      "Epoch 2740/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.8745\n",
      "Epoch 02740: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7529.8745 - val_loss: 7534.8774\n",
      "Epoch 2741/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5625\n",
      "Epoch 02741: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7536.5625 - val_loss: 7534.9185\n",
      "Epoch 2742/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.5283\n",
      "Epoch 02742: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7546.5283 - val_loss: 7534.9463\n",
      "Epoch 2743/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.1675\n",
      "Epoch 02743: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.1675 - val_loss: 7534.9810\n",
      "Epoch 2744/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1338\n",
      "Epoch 02744: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.1338 - val_loss: 7535.2471\n",
      "Epoch 2745/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8452\n",
      "Epoch 02745: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7533.8452 - val_loss: 7535.7383\n",
      "Epoch 2746/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.5229\n",
      "Epoch 02746: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.5229 - val_loss: 7535.6670\n",
      "Epoch 2747/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6377\n",
      "Epoch 02747: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.6377 - val_loss: 7535.1328\n",
      "Epoch 2748/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.2720\n",
      "Epoch 02748: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7543.2720 - val_loss: 7534.8408\n",
      "Epoch 2749/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8325\n",
      "Epoch 02749: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.8325 - val_loss: 7534.9639\n",
      "Epoch 2750/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.6758\n",
      "Epoch 02750: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7519.6758 - val_loss: 7534.8242\n",
      "Epoch 2751/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.3501\n",
      "Epoch 02751: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7543.3501 - val_loss: 7534.9570\n",
      "Epoch 2752/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.9580\n",
      "Epoch 02752: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7545.9580 - val_loss: 7534.7368\n",
      "Epoch 2753/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.0244\n",
      "Epoch 02753: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7548.0244 - val_loss: 7536.3599\n",
      "Epoch 2754/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7539.0034\n",
      "Epoch 02754: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7539.0034 - val_loss: 7536.7783\n",
      "Epoch 2755/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.1948\n",
      "Epoch 02755: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.1948 - val_loss: 7535.1978\n",
      "Epoch 2756/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0903\n",
      "Epoch 02756: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7533.0903 - val_loss: 7535.0254\n",
      "Epoch 2757/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0757\n",
      "Epoch 02757: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.0757 - val_loss: 7534.9810\n",
      "Epoch 2758/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6982\n",
      "Epoch 02758: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.6982 - val_loss: 7534.7471\n",
      "Epoch 2759/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8853\n",
      "Epoch 02759: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.8853 - val_loss: 7534.6431\n",
      "Epoch 2760/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0571\n",
      "Epoch 02760: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7538.0571 - val_loss: 7534.4927\n",
      "Epoch 2761/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7637\n",
      "Epoch 02761: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.7637 - val_loss: 7534.4458\n",
      "Epoch 2762/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.3638\n",
      "Epoch 02762: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7519.3638 - val_loss: 7534.6440\n",
      "Epoch 2763/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0513\n",
      "Epoch 02763: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7534.0513 - val_loss: 7535.1167\n",
      "Epoch 2764/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.4395\n",
      "Epoch 02764: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7519.4395 - val_loss: 7534.7578\n",
      "Epoch 2765/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6323\n",
      "Epoch 02765: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.6323 - val_loss: 7534.6890\n",
      "Epoch 2766/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.4648\n",
      "Epoch 02766: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7519.4648 - val_loss: 7534.4961\n",
      "Epoch 2767/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4170\n",
      "Epoch 02767: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7536.4170 - val_loss: 7534.5088\n",
      "Epoch 2768/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4321\n",
      "Epoch 02768: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.4321 - val_loss: 7534.6831\n",
      "Epoch 2769/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1870\n",
      "Epoch 02769: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.1870 - val_loss: 7534.8633\n",
      "Epoch 2770/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4463\n",
      "Epoch 02770: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.4463 - val_loss: 7534.6367\n",
      "Epoch 2771/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6377\n",
      "Epoch 02771: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.6377 - val_loss: 7534.7344\n",
      "Epoch 2772/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4575\n",
      "Epoch 02772: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.4575 - val_loss: 7535.4551\n",
      "Epoch 2773/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0518\n",
      "Epoch 02773: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.0518 - val_loss: 7535.3281\n",
      "Epoch 2774/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.9761\n",
      "Epoch 02774: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.9761 - val_loss: 7534.8682\n",
      "Epoch 2775/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0977\n",
      "Epoch 02775: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.0977 - val_loss: 7534.8135\n",
      "Epoch 2776/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5718\n",
      "Epoch 02776: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.5718 - val_loss: 7535.0503\n",
      "Epoch 2777/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.8774\n",
      "Epoch 02777: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7529.8774 - val_loss: 7534.9497\n",
      "Epoch 2778/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9209\n",
      "Epoch 02778: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.9209 - val_loss: 7534.8872\n",
      "Epoch 2779/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8989\n",
      "Epoch 02779: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.8989 - val_loss: 7534.8618\n",
      "Epoch 2780/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.6597\n",
      "Epoch 02780: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7524.6597 - val_loss: 7534.6914\n",
      "Epoch 2781/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8901\n",
      "Epoch 02781: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.8901 - val_loss: 7534.7378\n",
      "Epoch 2782/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.4731\n",
      "Epoch 02782: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7546.4731 - val_loss: 7534.7441\n",
      "Epoch 2783/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.8511\n",
      "Epoch 02783: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.8511 - val_loss: 7534.8872\n",
      "Epoch 2784/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4692\n",
      "Epoch 02784: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.4692 - val_loss: 7534.7729\n",
      "Epoch 2785/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9126\n",
      "Epoch 02785: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.9126 - val_loss: 7534.6753\n",
      "Epoch 2786/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1318\n",
      "Epoch 02786: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.1318 - val_loss: 7534.9922\n",
      "Epoch 2787/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6650\n",
      "Epoch 02787: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.6650 - val_loss: 7534.7568\n",
      "Epoch 2788/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.8853\n",
      "Epoch 02788: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7526.8853 - val_loss: 7535.6416\n",
      "Epoch 2789/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7520.3511\n",
      "Epoch 02789: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7520.3511 - val_loss: 7535.8584\n",
      "Epoch 2790/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7017\n",
      "Epoch 02790: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.7017 - val_loss: 7536.2754\n",
      "Epoch 2791/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2495\n",
      "Epoch 02791: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.2495 - val_loss: 7535.3633\n",
      "Epoch 2792/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0908\n",
      "Epoch 02792: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7537.0908 - val_loss: 7534.6689\n",
      "Epoch 2793/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.5972\n",
      "Epoch 02793: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7519.5972 - val_loss: 7534.7632\n",
      "Epoch 2794/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3994\n",
      "Epoch 02794: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.3994 - val_loss: 7534.8657\n",
      "Epoch 2795/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2969\n",
      "Epoch 02795: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.2969 - val_loss: 7534.8442\n",
      "Epoch 2796/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6558\n",
      "Epoch 02796: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.6558 - val_loss: 7534.6455\n",
      "Epoch 2797/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.3159\n",
      "Epoch 02797: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.3159 - val_loss: 7534.5439\n",
      "Epoch 2798/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.7812\n",
      "Epoch 02798: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.7812 - val_loss: 7535.3960\n",
      "Epoch 2799/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0996\n",
      "Epoch 02799: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.0996 - val_loss: 7534.6494\n",
      "Epoch 2800/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.6040\n",
      "Epoch 02800: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.6040 - val_loss: 7534.5054\n",
      "Epoch 2801/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5054\n",
      "Epoch 02801: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7539.5054 - val_loss: 7534.6226\n",
      "Epoch 2802/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2046\n",
      "Epoch 02802: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.2046 - val_loss: 7534.5830\n",
      "Epoch 2803/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.0718\n",
      "Epoch 02803: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7541.0718 - val_loss: 7534.4976\n",
      "Epoch 2804/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.4097\n",
      "Epoch 02804: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.4097 - val_loss: 7534.7017\n",
      "Epoch 2805/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5537\n",
      "Epoch 02805: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.5537 - val_loss: 7534.7954\n",
      "Epoch 2806/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.4873\n",
      "Epoch 02806: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7539.4873 - val_loss: 7534.7969\n",
      "Epoch 2807/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.2729\n",
      "Epoch 02807: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.2729 - val_loss: 7534.5391\n",
      "Epoch 2808/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9917\n",
      "Epoch 02808: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.9917 - val_loss: 7534.5786\n",
      "Epoch 2809/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4434\n",
      "Epoch 02809: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.4434 - val_loss: 7534.8882\n",
      "Epoch 2810/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5620\n",
      "Epoch 02810: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.5620 - val_loss: 7535.2622\n",
      "Epoch 2811/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0024\n",
      "Epoch 02811: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 542ms/step - loss: 7532.0024 - val_loss: 7534.8887\n",
      "Epoch 2812/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9673\n",
      "Epoch 02812: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.9673 - val_loss: 7534.5112\n",
      "Epoch 2813/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.5908\n",
      "Epoch 02813: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7526.5908 - val_loss: 7534.5176\n",
      "Epoch 2814/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.4507\n",
      "Epoch 02814: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7519.4507 - val_loss: 7534.5576\n",
      "Epoch 2815/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0625\n",
      "Epoch 02815: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.0625 - val_loss: 7534.3862\n",
      "Epoch 2816/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8955\n",
      "Epoch 02816: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 540ms/step - loss: 7545.8955 - val_loss: 7534.5776\n",
      "Epoch 2817/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.3125\n",
      "Epoch 02817: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7519.3125 - val_loss: 7534.3545\n",
      "Epoch 2818/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.6450\n",
      "Epoch 02818: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 541ms/step - loss: 7539.6450 - val_loss: 7534.6538\n",
      "Epoch 2819/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4697\n",
      "Epoch 02819: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7536.4697 - val_loss: 7534.5898\n",
      "Epoch 2820/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.5098\n",
      "Epoch 02820: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7524.5098 - val_loss: 7534.7241\n",
      "Epoch 2821/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.1650\n",
      "Epoch 02821: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.1650 - val_loss: 7534.8750\n",
      "Epoch 2822/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.6743\n",
      "Epoch 02822: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7538.6743 - val_loss: 7535.5186\n",
      "Epoch 2823/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0234\n",
      "Epoch 02823: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.0234 - val_loss: 7535.1143\n",
      "Epoch 2824/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7530.3823\n",
      "Epoch 02824: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.3823 - val_loss: 7535.8384\n",
      "Epoch 2825/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8096\n",
      "Epoch 02825: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.8096 - val_loss: 7535.4263\n",
      "Epoch 2826/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7388\n",
      "Epoch 02826: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.7388 - val_loss: 7534.8057\n",
      "Epoch 2827/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3325\n",
      "Epoch 02827: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.3325 - val_loss: 7535.1113\n",
      "Epoch 2828/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.2598\n",
      "Epoch 02828: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7543.2598 - val_loss: 7535.1104\n",
      "Epoch 2829/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8481\n",
      "Epoch 02829: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.8481 - val_loss: 7534.9927\n",
      "Epoch 2830/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0635\n",
      "Epoch 02830: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.0635 - val_loss: 7534.4927\n",
      "Epoch 2831/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.0659\n",
      "Epoch 02831: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7547.0659 - val_loss: 7535.9639\n",
      "Epoch 2832/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7412\n",
      "Epoch 02832: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.7412 - val_loss: 7536.1538\n",
      "Epoch 2833/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5742\n",
      "Epoch 02833: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.5742 - val_loss: 7535.7471\n",
      "Epoch 2834/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3765\n",
      "Epoch 02834: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.3765 - val_loss: 7535.2319\n",
      "Epoch 2835/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6450\n",
      "Epoch 02835: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7537.6450 - val_loss: 7535.2695\n",
      "Epoch 2836/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1709\n",
      "Epoch 02836: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7538.1709 - val_loss: 7535.2344\n",
      "Epoch 2837/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9644\n",
      "Epoch 02837: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.9644 - val_loss: 7536.1382\n",
      "Epoch 2838/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7734\n",
      "Epoch 02838: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7532.7734 - val_loss: 7535.4746\n",
      "Epoch 2839/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8374\n",
      "Epoch 02839: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.8374 - val_loss: 7535.5312\n",
      "Epoch 2840/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.9326\n",
      "Epoch 02840: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7546.9326 - val_loss: 7535.3350\n",
      "Epoch 2841/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.9189\n",
      "Epoch 02841: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7537.9189 - val_loss: 7534.7920\n",
      "Epoch 2842/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.3174\n",
      "Epoch 02842: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7546.3174 - val_loss: 7534.8418\n",
      "Epoch 2843/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9614\n",
      "Epoch 02843: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.9614 - val_loss: 7534.7402\n",
      "Epoch 2844/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.1367\n",
      "Epoch 02844: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7541.1367 - val_loss: 7534.4175\n",
      "Epoch 2845/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.0312\n",
      "Epoch 02845: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7546.0312 - val_loss: 7534.3823\n",
      "Epoch 2846/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5737\n",
      "Epoch 02846: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7536.5737 - val_loss: 7534.3984\n",
      "Epoch 2847/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0640\n",
      "Epoch 02847: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.0640 - val_loss: 7536.2920\n",
      "Epoch 2848/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8701\n",
      "Epoch 02848: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.8701 - val_loss: 7535.1377\n",
      "Epoch 2849/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9277\n",
      "Epoch 02849: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 542ms/step - loss: 7531.9277 - val_loss: 7534.7510\n",
      "Epoch 2850/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7485\n",
      "Epoch 02850: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7532.7485 - val_loss: 7534.7168\n",
      "Epoch 2851/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.0498\n",
      "Epoch 02851: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7547.0498 - val_loss: 7535.8306\n",
      "Epoch 2852/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.3491\n",
      "Epoch 02852: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7538.3491 - val_loss: 7534.5737\n",
      "Epoch 2853/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.3721\n",
      "Epoch 02853: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7539.3721 - val_loss: 7534.4033\n",
      "Epoch 2854/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.9678\n",
      "Epoch 02854: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7535.9678 - val_loss: 7534.1294\n",
      "Epoch 2855/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1230\n",
      "Epoch 02855: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.1230 - val_loss: 7534.2534\n",
      "Epoch 2856/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0732\n",
      "Epoch 02856: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.0732 - val_loss: 7534.4336\n",
      "Epoch 2857/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.7466\n",
      "Epoch 02857: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.7466 - val_loss: 7534.4648\n",
      "Epoch 2858/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.9731\n",
      "Epoch 02858: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.9731 - val_loss: 7534.9009\n",
      "Epoch 2859/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7527.6074\n",
      "Epoch 02859: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7527.6074 - val_loss: 7535.1616\n",
      "Epoch 2860/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.5908\n",
      "Epoch 02860: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.5908 - val_loss: 7535.3706\n",
      "Epoch 2861/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5166\n",
      "Epoch 02861: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.5166 - val_loss: 7535.5576\n",
      "Epoch 2862/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.0166\n",
      "Epoch 02862: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7520.0166 - val_loss: 7535.5752\n",
      "Epoch 2863/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.5869\n",
      "Epoch 02863: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7519.5869 - val_loss: 7534.9502\n",
      "Epoch 2864/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2505\n",
      "Epoch 02864: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.2505 - val_loss: 7534.3042\n",
      "Epoch 2865/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.8379\n",
      "Epoch 02865: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.8379 - val_loss: 7534.0425\n",
      "Epoch 2866/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.1318\n",
      "Epoch 02866: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7541.1318 - val_loss: 7534.3706\n",
      "Epoch 2867/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5996\n",
      "Epoch 02867: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.5996 - val_loss: 7534.6201\n",
      "Epoch 2868/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1294\n",
      "Epoch 02868: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7532.1294 - val_loss: 7534.7334\n",
      "Epoch 2869/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5542\n",
      "Epoch 02869: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.5542 - val_loss: 7534.7759\n",
      "Epoch 2870/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0186\n",
      "Epoch 02870: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.0186 - val_loss: 7534.5513\n",
      "Epoch 2871/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.2090\n",
      "Epoch 02871: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7519.2090 - val_loss: 7534.5400\n",
      "Epoch 2872/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.9951\n",
      "Epoch 02872: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7536.9951 - val_loss: 7534.1953\n",
      "Epoch 2873/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.3252\n",
      "Epoch 02873: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7524.3252 - val_loss: 7534.3359\n",
      "Epoch 2874/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.7256\n",
      "Epoch 02874: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.7256 - val_loss: 7534.7495\n",
      "Epoch 2875/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.9795\n",
      "Epoch 02875: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.9795 - val_loss: 7534.4746\n",
      "Epoch 2876/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.2637\n",
      "Epoch 02876: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.2637 - val_loss: 7534.2881\n",
      "Epoch 2877/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.1836\n",
      "Epoch 02877: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7519.1836 - val_loss: 7534.6714\n",
      "Epoch 2878/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7954\n",
      "Epoch 02878: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.7954 - val_loss: 7534.2495\n",
      "Epoch 2879/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.5542\n",
      "Epoch 02879: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.5542 - val_loss: 7534.5151\n",
      "Epoch 2880/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.3096\n",
      "Epoch 02880: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7519.3096 - val_loss: 7534.4927\n",
      "Epoch 2881/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0933\n",
      "Epoch 02881: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.0933 - val_loss: 7535.0586\n",
      "Epoch 2882/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7437\n",
      "Epoch 02882: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.7437 - val_loss: 7534.5518\n",
      "Epoch 2883/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.3604\n",
      "Epoch 02883: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.3604 - val_loss: 7534.0903\n",
      "Epoch 2884/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7754\n",
      "Epoch 02884: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.7754 - val_loss: 7534.1958\n",
      "Epoch 2885/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1821\n",
      "Epoch 02885: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.1821 - val_loss: 7534.1426\n",
      "Epoch 2886/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8750\n",
      "Epoch 02886: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7530.8750 - val_loss: 7534.5713\n",
      "Epoch 2887/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4932\n",
      "Epoch 02887: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.4932 - val_loss: 7534.5190\n",
      "Epoch 2888/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7378\n",
      "Epoch 02888: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.7378 - val_loss: 7534.8447\n",
      "Epoch 2889/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.6416\n",
      "Epoch 02889: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.6416 - val_loss: 7534.6738\n",
      "Epoch 2890/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9595\n",
      "Epoch 02890: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.9595 - val_loss: 7534.6479\n",
      "Epoch 2891/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8779\n",
      "Epoch 02891: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7544.8779 - val_loss: 7534.7505\n",
      "Epoch 2892/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2749\n",
      "Epoch 02892: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7538.2749 - val_loss: 7534.6455\n",
      "Epoch 2893/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.9380\n",
      "Epoch 02893: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 543ms/step - loss: 7545.9380 - val_loss: 7534.3462\n",
      "Epoch 2894/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7529.5015\n",
      "Epoch 02894: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7529.5015 - val_loss: 7534.6177\n",
      "Epoch 2895/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5889\n",
      "Epoch 02895: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7533.5889 - val_loss: 7534.5200\n",
      "Epoch 2896/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.9639\n",
      "Epoch 02896: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7525.9639 - val_loss: 7534.4346\n",
      "Epoch 2897/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.3872\n",
      "Epoch 02897: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.3872 - val_loss: 7534.8384\n",
      "Epoch 2898/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4067\n",
      "Epoch 02898: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.4067 - val_loss: 7535.4966\n",
      "Epoch 2899/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.4243\n",
      "Epoch 02899: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7543.4243 - val_loss: 7535.1753\n",
      "Epoch 2900/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.2217\n",
      "Epoch 02900: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7548.2217 - val_loss: 7537.3057\n",
      "Epoch 2901/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.7080\n",
      "Epoch 02901: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7525.7080 - val_loss: 7534.7856\n",
      "Epoch 2902/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7700\n",
      "Epoch 02902: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.7700 - val_loss: 7534.2695\n",
      "Epoch 2903/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.9150\n",
      "Epoch 02903: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7542.9150 - val_loss: 7534.6050\n",
      "Epoch 2904/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.0859\n",
      "Epoch 02904: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7548.0859 - val_loss: 7536.9082\n",
      "Epoch 2905/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6597\n",
      "Epoch 02905: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.6597 - val_loss: 7535.1489\n",
      "Epoch 2906/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.5747\n",
      "Epoch 02906: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7519.5747 - val_loss: 7534.8594\n",
      "Epoch 2907/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5210\n",
      "Epoch 02907: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.5210 - val_loss: 7534.6025\n",
      "Epoch 2908/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.8687\n",
      "Epoch 02908: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7542.8687 - val_loss: 7534.5327\n",
      "Epoch 2909/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4209\n",
      "Epoch 02909: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.4209 - val_loss: 7534.5327\n",
      "Epoch 2910/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3071\n",
      "Epoch 02910: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.3071 - val_loss: 7534.2578\n",
      "Epoch 2911/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.1274\n",
      "Epoch 02911: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7546.1274 - val_loss: 7534.6167\n",
      "Epoch 2912/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1709\n",
      "Epoch 02912: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.1709 - val_loss: 7536.2510\n",
      "Epoch 2913/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0854\n",
      "Epoch 02913: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.0854 - val_loss: 7536.1489\n",
      "Epoch 2914/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.0850\n",
      "Epoch 02914: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7547.0850 - val_loss: 7535.9575\n",
      "Epoch 2915/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7393\n",
      "Epoch 02915: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.7393 - val_loss: 7535.5776\n",
      "Epoch 2916/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.6831\n",
      "Epoch 02916: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7539.6831 - val_loss: 7534.8594\n",
      "Epoch 2917/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.4639\n",
      "Epoch 02917: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7519.4639 - val_loss: 7534.7905\n",
      "Epoch 2918/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3286\n",
      "Epoch 02918: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.3286 - val_loss: 7534.6128\n",
      "Epoch 2919/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.6230\n",
      "Epoch 02919: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.6230 - val_loss: 7534.3984\n",
      "Epoch 2920/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7900\n",
      "Epoch 02920: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7530.7900 - val_loss: 7534.8794\n",
      "Epoch 2921/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.1294\n",
      "Epoch 02921: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7539.1294 - val_loss: 7534.4487\n",
      "Epoch 2922/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.8872\n",
      "Epoch 02922: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.8872 - val_loss: 7534.1777\n",
      "Epoch 2923/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.9839\n",
      "Epoch 02923: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.9839 - val_loss: 7534.7646\n",
      "Epoch 2924/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2739\n",
      "Epoch 02924: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.2739 - val_loss: 7534.6792\n",
      "Epoch 2925/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1440\n",
      "Epoch 02925: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7538.1440 - val_loss: 7534.7920\n",
      "Epoch 2926/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.3760\n",
      "Epoch 02926: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7541.3760 - val_loss: 7534.8594\n",
      "Epoch 2927/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.0913\n",
      "Epoch 02927: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7546.0913 - val_loss: 7535.9600\n",
      "Epoch 2928/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.5269\n",
      "Epoch 02928: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7547.5269 - val_loss: 7536.1279\n",
      "Epoch 2929/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7526.0464\n",
      "Epoch 02929: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.0464 - val_loss: 7534.7632\n",
      "Epoch 2930/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.2988\n",
      "Epoch 02930: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7540.2988 - val_loss: 7535.0742\n",
      "Epoch 2931/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.6138\n",
      "Epoch 02931: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7545.6138 - val_loss: 7534.7056\n",
      "Epoch 2932/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.5923\n",
      "Epoch 02932: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.5923 - val_loss: 7534.2930\n",
      "Epoch 2933/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.0176\n",
      "Epoch 02933: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7546.0176 - val_loss: 7534.3633\n",
      "Epoch 2934/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4316\n",
      "Epoch 02934: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.4316 - val_loss: 7534.3369\n",
      "Epoch 2935/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.3076\n",
      "Epoch 02935: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.3076 - val_loss: 7534.0366\n",
      "Epoch 2936/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.1934\n",
      "Epoch 02936: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.1934 - val_loss: 7534.0688\n",
      "Epoch 2937/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7178\n",
      "Epoch 02937: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.7178 - val_loss: 7534.1255\n",
      "Epoch 2938/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6880\n",
      "Epoch 02938: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.6880 - val_loss: 7534.0439\n",
      "Epoch 2939/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.7002\n",
      "Epoch 02939: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.7002 - val_loss: 7533.9824\n",
      "Epoch 2940/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7676\n",
      "Epoch 02940: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.7676 - val_loss: 7534.5474\n",
      "Epoch 2941/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.2964\n",
      "Epoch 02941: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7539.2964 - val_loss: 7534.5298\n",
      "Epoch 2942/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9590\n",
      "Epoch 02942: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.9590 - val_loss: 7534.1431\n",
      "Epoch 2943/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.8716\n",
      "Epoch 02943: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.8716 - val_loss: 7534.1846\n",
      "Epoch 2944/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3843\n",
      "Epoch 02944: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.3843 - val_loss: 7534.1958\n",
      "Epoch 2945/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.4106\n",
      "Epoch 02945: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7525.4106 - val_loss: 7534.1216\n",
      "Epoch 2946/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.8735\n",
      "Epoch 02946: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7537.8735 - val_loss: 7534.2520\n",
      "Epoch 2947/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9448\n",
      "Epoch 02947: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7533.9448 - val_loss: 7534.6904\n",
      "Epoch 2948/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7778\n",
      "Epoch 02948: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.7778 - val_loss: 7534.4673\n",
      "Epoch 2949/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8267\n",
      "Epoch 02949: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.8267 - val_loss: 7534.3398\n",
      "Epoch 2950/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.2280\n",
      "Epoch 02950: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7527.2280 - val_loss: 7537.6128\n",
      "Epoch 2951/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2275\n",
      "Epoch 02951: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.2275 - val_loss: 7535.1655\n",
      "Epoch 2952/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.7017\n",
      "Epoch 02952: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7546.7017 - val_loss: 7535.0400\n",
      "Epoch 2953/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0215\n",
      "Epoch 02953: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7538.0215 - val_loss: 7535.2002\n",
      "Epoch 2954/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.7656\n",
      "Epoch 02954: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7519.7656 - val_loss: 7535.0601\n",
      "Epoch 2955/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5669\n",
      "Epoch 02955: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.5669 - val_loss: 7535.7266\n",
      "Epoch 2956/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.5845\n",
      "Epoch 02956: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.5845 - val_loss: 7535.3662\n",
      "Epoch 2957/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.5986\n",
      "Epoch 02957: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7545.5986 - val_loss: 7535.1782\n",
      "Epoch 2958/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2432\n",
      "Epoch 02958: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.2432 - val_loss: 7534.5752\n",
      "Epoch 2959/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9033\n",
      "Epoch 02959: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.9033 - val_loss: 7534.5503\n",
      "Epoch 2960/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8140\n",
      "Epoch 02960: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.8140 - val_loss: 7534.2671\n",
      "Epoch 2961/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5171\n",
      "Epoch 02961: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.5171 - val_loss: 7534.4360\n",
      "Epoch 2962/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0107\n",
      "Epoch 02962: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.0107 - val_loss: 7534.0200\n",
      "Epoch 2963/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0840\n",
      "Epoch 02963: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.0840 - val_loss: 7533.9521\n",
      "Epoch 2964/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7536.7808\n",
      "Epoch 02964: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.7808 - val_loss: 7534.1030\n",
      "Epoch 2965/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3691\n",
      "Epoch 02965: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.3691 - val_loss: 7533.8545\n",
      "Epoch 2966/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.3115\n",
      "Epoch 02966: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7542.3115 - val_loss: 7533.9336\n",
      "Epoch 2967/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5693\n",
      "Epoch 02967: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.5693 - val_loss: 7533.8926\n",
      "Epoch 2968/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.3545\n",
      "Epoch 02968: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7526.3545 - val_loss: 7534.1831\n",
      "Epoch 2969/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.5532\n",
      "Epoch 02969: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.5532 - val_loss: 7534.0015\n",
      "Epoch 2970/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8657\n",
      "Epoch 02970: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.8657 - val_loss: 7534.5210\n",
      "Epoch 2971/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.5474\n",
      "Epoch 02971: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7518.5474 - val_loss: 7533.9062\n",
      "Epoch 2972/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4707\n",
      "Epoch 02972: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.4707 - val_loss: 7534.2070\n",
      "Epoch 2973/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.1211\n",
      "Epoch 02973: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.1211 - val_loss: 7533.9082\n",
      "Epoch 2974/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8599\n",
      "Epoch 02974: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7538.8599 - val_loss: 7533.9336\n",
      "Epoch 2975/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0156\n",
      "Epoch 02975: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.0156 - val_loss: 7534.0034\n",
      "Epoch 2976/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8818\n",
      "Epoch 02976: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7536.8818 - val_loss: 7534.0322\n",
      "Epoch 2977/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.4688\n",
      "Epoch 02977: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7525.4688 - val_loss: 7535.5615\n",
      "Epoch 2978/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9653\n",
      "Epoch 02978: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.9653 - val_loss: 7535.7705\n",
      "Epoch 2979/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0947\n",
      "Epoch 02979: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.0947 - val_loss: 7536.1904\n",
      "Epoch 2980/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.6284\n",
      "Epoch 02980: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.6284 - val_loss: 7535.5098\n",
      "Epoch 2981/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3159\n",
      "Epoch 02981: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.3159 - val_loss: 7536.9600\n",
      "Epoch 2982/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9688\n",
      "Epoch 02982: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7533.9688 - val_loss: 7535.6968\n",
      "Epoch 2983/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6860\n",
      "Epoch 02983: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.6860 - val_loss: 7535.0791\n",
      "Epoch 2984/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2896\n",
      "Epoch 02984: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.2896 - val_loss: 7534.8032\n",
      "Epoch 2985/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.7437\n",
      "Epoch 02985: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7529.7437 - val_loss: 7534.6318\n",
      "Epoch 2986/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.8574\n",
      "Epoch 02986: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.8574 - val_loss: 7534.8662\n",
      "Epoch 2987/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8896\n",
      "Epoch 02987: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7531.8896 - val_loss: 7534.6030\n",
      "Epoch 2988/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7847\n",
      "Epoch 02988: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7536.7847 - val_loss: 7534.2134\n",
      "Epoch 2989/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.4473\n",
      "Epoch 02989: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7544.4473 - val_loss: 7534.2954\n",
      "Epoch 2990/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1255\n",
      "Epoch 02990: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.1255 - val_loss: 7534.0562\n",
      "Epoch 2991/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.2993\n",
      "Epoch 02991: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7545.2993 - val_loss: 7534.0103\n",
      "Epoch 2992/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.8921\n",
      "Epoch 02992: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7530.8921 - val_loss: 7533.9458\n",
      "Epoch 2993/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.5747\n",
      "Epoch 02993: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7538.5747 - val_loss: 7533.8809\n",
      "Epoch 2994/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.9683\n",
      "Epoch 02994: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7518.9683 - val_loss: 7534.0024\n",
      "Epoch 2995/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.9126\n",
      "Epoch 02995: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7535.9126 - val_loss: 7534.0142\n",
      "Epoch 2996/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9014\n",
      "Epoch 02996: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 540ms/step - loss: 7532.9014 - val_loss: 7533.8257\n",
      "Epoch 2997/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5605\n",
      "Epoch 02997: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 540ms/step - loss: 7536.5605 - val_loss: 7534.1641\n",
      "Epoch 2998/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6587\n",
      "Epoch 02998: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7531.6587 - val_loss: 7534.5815\n",
      "Epoch 2999/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7543.9385\n",
      "Epoch 02999: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7543.9385 - val_loss: 7535.6528\n",
      "Epoch 3000/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0093\n",
      "Epoch 03000: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.0093 - val_loss: 7534.6401\n",
      "Epoch 3001/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.5078\n",
      "Epoch 03001: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.5078 - val_loss: 7536.0625\n",
      "Epoch 3002/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.7173\n",
      "Epoch 03002: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7542.7173 - val_loss: 7534.0518\n",
      "Epoch 3003/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5088\n",
      "Epoch 03003: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.5088 - val_loss: 7534.0449\n",
      "Epoch 3004/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.0249\n",
      "Epoch 03004: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.0249 - val_loss: 7534.0322\n",
      "Epoch 3005/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.7095\n",
      "Epoch 03005: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7541.7095 - val_loss: 7536.6143\n",
      "Epoch 3006/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.8340\n",
      "Epoch 03006: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7542.8340 - val_loss: 7536.4834\n",
      "Epoch 3007/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5986\n",
      "Epoch 03007: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7539.5986 - val_loss: 7536.4150\n",
      "Epoch 3008/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8442\n",
      "Epoch 03008: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7536.8442 - val_loss: 7534.9414\n",
      "Epoch 3009/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.2671\n",
      "Epoch 03009: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7537.2671 - val_loss: 7534.1367\n",
      "Epoch 3010/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.5063\n",
      "Epoch 03010: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7525.5063 - val_loss: 7534.4761\n",
      "Epoch 3011/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.6216\n",
      "Epoch 03011: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 540ms/step - loss: 7526.6216 - val_loss: 7534.9902\n",
      "Epoch 3012/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4829\n",
      "Epoch 03012: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 540ms/step - loss: 7531.4829 - val_loss: 7533.9136\n",
      "Epoch 3013/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7539\n",
      "Epoch 03013: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.7539 - val_loss: 7534.5200\n",
      "Epoch 3014/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6094\n",
      "Epoch 03014: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 546ms/step - loss: 7532.6094 - val_loss: 7534.4912\n",
      "Epoch 3015/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.0859\n",
      "Epoch 03015: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7526.0859 - val_loss: 7534.2622\n",
      "Epoch 3016/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.6753\n",
      "Epoch 03016: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7535.6753 - val_loss: 7533.8066\n",
      "Epoch 3017/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4375\n",
      "Epoch 03017: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7537.4375 - val_loss: 7533.7432\n",
      "Epoch 3018/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5117\n",
      "Epoch 03018: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.5117 - val_loss: 7533.9326\n",
      "Epoch 3019/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3486\n",
      "Epoch 03019: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7531.3486 - val_loss: 7533.8042\n",
      "Epoch 3020/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4619\n",
      "Epoch 03020: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7531.4619 - val_loss: 7533.9482\n",
      "Epoch 3021/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4355\n",
      "Epoch 03021: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.4355 - val_loss: 7534.0024\n",
      "Epoch 3022/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5815\n",
      "Epoch 03022: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.5815 - val_loss: 7534.4097\n",
      "Epoch 3023/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.0195\n",
      "Epoch 03023: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7546.0195 - val_loss: 7534.1382\n",
      "Epoch 3024/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3921\n",
      "Epoch 03024: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.3921 - val_loss: 7534.6753\n",
      "Epoch 3025/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0571\n",
      "Epoch 03025: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.0571 - val_loss: 7533.8135\n",
      "Epoch 3026/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.8940\n",
      "Epoch 03026: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7535.8940 - val_loss: 7534.0190\n",
      "Epoch 3027/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2725\n",
      "Epoch 03027: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.2725 - val_loss: 7534.0464\n",
      "Epoch 3028/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7207\n",
      "Epoch 03028: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.7207 - val_loss: 7534.1328\n",
      "Epoch 3029/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8613\n",
      "Epoch 03029: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.8613 - val_loss: 7534.6431\n",
      "Epoch 3030/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.4883\n",
      "Epoch 03030: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7519.4883 - val_loss: 7534.5200\n",
      "Epoch 3031/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.7705\n",
      "Epoch 03031: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7518.7705 - val_loss: 7534.0264\n",
      "Epoch 3032/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4390\n",
      "Epoch 03032: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.4390 - val_loss: 7534.3608\n",
      "Epoch 3033/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8193\n",
      "Epoch 03033: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.8193 - val_loss: 7534.2041\n",
      "Epoch 3034/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7535.9688\n",
      "Epoch 03034: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7535.9688 - val_loss: 7533.9146\n",
      "Epoch 3035/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.2363\n",
      "Epoch 03035: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7530.2363 - val_loss: 7533.9888\n",
      "Epoch 3036/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0195\n",
      "Epoch 03036: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.0195 - val_loss: 7534.1338\n",
      "Epoch 3037/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7808\n",
      "Epoch 03037: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.7808 - val_loss: 7534.1240\n",
      "Epoch 3038/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4546\n",
      "Epoch 03038: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7530.4546 - val_loss: 7534.1670\n",
      "Epoch 3039/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4551\n",
      "Epoch 03039: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7537.4551 - val_loss: 7535.4609\n",
      "Epoch 3040/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.6069\n",
      "Epoch 03040: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7545.6069 - val_loss: 7534.1362\n",
      "Epoch 3041/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6108\n",
      "Epoch 03041: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.6108 - val_loss: 7533.9785\n",
      "Epoch 3042/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.3789\n",
      "Epoch 03042: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7542.3789 - val_loss: 7534.1006\n",
      "Epoch 3043/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2490\n",
      "Epoch 03043: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7532.2490 - val_loss: 7533.7017\n",
      "Epoch 3044/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.6147\n",
      "Epoch 03044: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7518.6147 - val_loss: 7533.6567\n",
      "Epoch 3045/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.9448\n",
      "Epoch 03045: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7535.9448 - val_loss: 7533.8042\n",
      "Epoch 3046/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2168\n",
      "Epoch 03046: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.2168 - val_loss: 7534.1714\n",
      "Epoch 3047/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.2314\n",
      "Epoch 03047: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7542.2314 - val_loss: 7533.9990\n",
      "Epoch 3048/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5488\n",
      "Epoch 03048: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.5488 - val_loss: 7534.2041\n",
      "Epoch 3049/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3384\n",
      "Epoch 03049: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.3384 - val_loss: 7533.8418\n",
      "Epoch 3050/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2710\n",
      "Epoch 03050: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.2710 - val_loss: 7534.1050\n",
      "Epoch 3051/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7550.7690\n",
      "Epoch 03051: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7550.7690 - val_loss: 7546.0034\n",
      "Epoch 3052/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4268\n",
      "Epoch 03052: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.4268 - val_loss: 7537.0288\n",
      "Epoch 3053/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.9790\n",
      "Epoch 03053: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.9790 - val_loss: 7536.0410\n",
      "Epoch 3054/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.9941\n",
      "Epoch 03054: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.9941 - val_loss: 7536.3032\n",
      "Epoch 3055/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9092\n",
      "Epoch 03055: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.9092 - val_loss: 7535.9502\n",
      "Epoch 3056/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1348\n",
      "Epoch 03056: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7537.1348 - val_loss: 7535.3550\n",
      "Epoch 3057/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.2319\n",
      "Epoch 03057: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.2319 - val_loss: 7534.6377\n",
      "Epoch 3058/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.2510\n",
      "Epoch 03058: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.2510 - val_loss: 7534.3296\n",
      "Epoch 3059/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4341\n",
      "Epoch 03059: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7530.4341 - val_loss: 7534.1865\n",
      "Epoch 3060/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8496\n",
      "Epoch 03060: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.8496 - val_loss: 7534.2793\n",
      "Epoch 3061/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.8564\n",
      "Epoch 03061: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7528.8564 - val_loss: 7534.0591\n",
      "Epoch 3062/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.4653\n",
      "Epoch 03062: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7540.4653 - val_loss: 7533.7266\n",
      "Epoch 3063/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5537\n",
      "Epoch 03063: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.5537 - val_loss: 7533.8911\n",
      "Epoch 3064/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8911\n",
      "Epoch 03064: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.8911 - val_loss: 7533.7993\n",
      "Epoch 3065/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.0186\n",
      "Epoch 03065: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.0186 - val_loss: 7533.8345\n",
      "Epoch 3066/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.9424\n",
      "Epoch 03066: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.9424 - val_loss: 7533.8872\n",
      "Epoch 3067/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9360\n",
      "Epoch 03067: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.9360 - val_loss: 7533.7729\n",
      "Epoch 3068/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5532\n",
      "Epoch 03068: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.5532 - val_loss: 7533.8633\n",
      "Epoch 3069/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7531.1929\n",
      "Epoch 03069: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 540ms/step - loss: 7531.1929 - val_loss: 7533.7305\n",
      "Epoch 3070/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.6499\n",
      "Epoch 03070: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7525.6499 - val_loss: 7533.7266\n",
      "Epoch 3071/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2793\n",
      "Epoch 03071: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7531.2793 - val_loss: 7533.5400\n",
      "Epoch 3072/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.9790\n",
      "Epoch 03072: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7544.9790 - val_loss: 7533.6113\n",
      "Epoch 3073/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0396\n",
      "Epoch 03073: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7536.0396 - val_loss: 7533.7568\n",
      "Epoch 3074/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9370\n",
      "Epoch 03074: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7532.9370 - val_loss: 7533.7734\n",
      "Epoch 3075/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7520\n",
      "Epoch 03075: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7530.7520 - val_loss: 7533.5391\n",
      "Epoch 3076/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.5005\n",
      "Epoch 03076: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7518.5005 - val_loss: 7533.5479\n",
      "Epoch 3077/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1182\n",
      "Epoch 03077: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7536.1182 - val_loss: 7534.0254\n",
      "Epoch 3078/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4702\n",
      "Epoch 03078: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.4702 - val_loss: 7533.9521\n",
      "Epoch 3079/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.7837\n",
      "Epoch 03079: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7524.7837 - val_loss: 7533.7046\n",
      "Epoch 3080/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.8491\n",
      "Epoch 03080: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7525.8491 - val_loss: 7533.8257\n",
      "Epoch 3081/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1606\n",
      "Epoch 03081: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.1606 - val_loss: 7533.5942\n",
      "Epoch 3082/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8687\n",
      "Epoch 03082: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.8687 - val_loss: 7533.7393\n",
      "Epoch 3083/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8779\n",
      "Epoch 03083: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.8779 - val_loss: 7533.6294\n",
      "Epoch 3084/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7319\n",
      "Epoch 03084: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7530.7319 - val_loss: 7533.6177\n",
      "Epoch 3085/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.8354\n",
      "Epoch 03085: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.8354 - val_loss: 7533.6919\n",
      "Epoch 3086/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.4507\n",
      "Epoch 03086: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7518.4507 - val_loss: 7533.4688\n",
      "Epoch 3087/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.7539\n",
      "Epoch 03087: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.7539 - val_loss: 7533.5298\n",
      "Epoch 3088/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.7354\n",
      "Epoch 03088: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7523.7354 - val_loss: 7533.5840\n",
      "Epoch 3089/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.6328\n",
      "Epoch 03089: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7518.6328 - val_loss: 7533.7783\n",
      "Epoch 3090/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6738\n",
      "Epoch 03090: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.6738 - val_loss: 7534.3198\n",
      "Epoch 3091/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.7900\n",
      "Epoch 03091: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.7900 - val_loss: 7533.5352\n",
      "Epoch 3092/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.6875\n",
      "Epoch 03092: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7518.6875 - val_loss: 7533.6294\n",
      "Epoch 3093/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8472\n",
      "Epoch 03093: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.8472 - val_loss: 7538.4976\n",
      "Epoch 3094/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.4082\n",
      "Epoch 03094: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7541.4082 - val_loss: 7535.5674\n",
      "Epoch 3095/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5957\n",
      "Epoch 03095: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.5957 - val_loss: 7534.3198\n",
      "Epoch 3096/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.4614\n",
      "Epoch 03096: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7542.4614 - val_loss: 7534.0127\n",
      "Epoch 3097/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.8462\n",
      "Epoch 03097: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7535.8462 - val_loss: 7533.6494\n",
      "Epoch 3098/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.6157\n",
      "Epoch 03098: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.6157 - val_loss: 7533.5386\n",
      "Epoch 3099/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.6333\n",
      "Epoch 03099: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7528.6333 - val_loss: 7533.7310\n",
      "Epoch 3100/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.5923\n",
      "Epoch 03100: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7525.5923 - val_loss: 7533.6641\n",
      "Epoch 3101/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1938\n",
      "Epoch 03101: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.1938 - val_loss: 7533.3154\n",
      "Epoch 3102/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.5952\n",
      "Epoch 03102: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7529.5952 - val_loss: 7533.3398\n",
      "Epoch 3103/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4165\n",
      "Epoch 03103: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.4165 - val_loss: 7533.3882\n",
      "Epoch 3104/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7544.6270\n",
      "Epoch 03104: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.6270 - val_loss: 7534.7393\n",
      "Epoch 3105/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4868\n",
      "Epoch 03105: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.4868 - val_loss: 7534.4126\n",
      "Epoch 3106/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1777\n",
      "Epoch 03106: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.1777 - val_loss: 7534.5854\n",
      "Epoch 3107/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.1836\n",
      "Epoch 03107: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7547.1836 - val_loss: 7535.5298\n",
      "Epoch 3108/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.2451\n",
      "Epoch 03108: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7520.2451 - val_loss: 7535.5054\n",
      "Epoch 3109/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.2769\n",
      "Epoch 03109: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7530.2769 - val_loss: 7535.5879\n",
      "Epoch 3110/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.4678\n",
      "Epoch 03110: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7527.4678 - val_loss: 7535.6274\n",
      "Epoch 3111/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1724\n",
      "Epoch 03111: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.1724 - val_loss: 7535.9673\n",
      "Epoch 3112/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3521\n",
      "Epoch 03112: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.3521 - val_loss: 7534.7378\n",
      "Epoch 3113/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0151\n",
      "Epoch 03113: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.0151 - val_loss: 7534.0850\n",
      "Epoch 3114/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0547\n",
      "Epoch 03114: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7537.0547 - val_loss: 7534.0679\n",
      "Epoch 3115/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4233\n",
      "Epoch 03115: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.4233 - val_loss: 7533.8047\n",
      "Epoch 3116/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.7036\n",
      "Epoch 03116: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.7036 - val_loss: 7534.1919\n",
      "Epoch 3117/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8940\n",
      "Epoch 03117: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.8940 - val_loss: 7534.4551\n",
      "Epoch 3118/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1982\n",
      "Epoch 03118: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7538.1982 - val_loss: 7536.3696\n",
      "Epoch 3119/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8325\n",
      "Epoch 03119: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.8325 - val_loss: 7536.8032\n",
      "Epoch 3120/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1079\n",
      "Epoch 03120: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.1079 - val_loss: 7535.0449\n",
      "Epoch 3121/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7358\n",
      "Epoch 03121: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.7358 - val_loss: 7534.5200\n",
      "Epoch 3122/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7310\n",
      "Epoch 03122: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.7310 - val_loss: 7534.2017\n",
      "Epoch 3123/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1631\n",
      "Epoch 03123: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.1631 - val_loss: 7534.2319\n",
      "Epoch 3124/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5103\n",
      "Epoch 03124: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.5103 - val_loss: 7533.8945\n",
      "Epoch 3125/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.1777\n",
      "Epoch 03125: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7546.1777 - val_loss: 7534.7617\n",
      "Epoch 3126/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1777\n",
      "Epoch 03126: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.1777 - val_loss: 7534.2568\n",
      "Epoch 3127/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.2705\n",
      "Epoch 03127: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7544.2705 - val_loss: 7534.0073\n",
      "Epoch 3128/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4961\n",
      "Epoch 03128: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.4961 - val_loss: 7535.2393\n",
      "Epoch 3129/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1519\n",
      "Epoch 03129: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.1519 - val_loss: 7533.7417\n",
      "Epoch 3130/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6216\n",
      "Epoch 03130: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.6216 - val_loss: 7534.4561\n",
      "Epoch 3131/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7778\n",
      "Epoch 03131: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.7778 - val_loss: 7534.5762\n",
      "Epoch 3132/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4863\n",
      "Epoch 03132: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.4863 - val_loss: 7534.2319\n",
      "Epoch 3133/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1011\n",
      "Epoch 03133: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.1011 - val_loss: 7533.5625\n",
      "Epoch 3134/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.7705\n",
      "Epoch 03134: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7541.7705 - val_loss: 7533.5938\n",
      "Epoch 3135/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.5918\n",
      "Epoch 03135: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.5918 - val_loss: 7533.7207\n",
      "Epoch 3136/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.0557\n",
      "Epoch 03136: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7530.0557 - val_loss: 7533.6631\n",
      "Epoch 3137/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8066\n",
      "Epoch 03137: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.8066 - val_loss: 7533.6367\n",
      "Epoch 3138/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7979\n",
      "Epoch 03138: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7530.7979 - val_loss: 7533.7695\n",
      "Epoch 3139/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7525.3535\n",
      "Epoch 03139: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7525.3535 - val_loss: 7533.4521\n",
      "Epoch 3140/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4761\n",
      "Epoch 03140: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7535.4761 - val_loss: 7533.3638\n",
      "Epoch 3141/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.2451\n",
      "Epoch 03141: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.2451 - val_loss: 7533.2432\n",
      "Epoch 3142/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1753\n",
      "Epoch 03142: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7536.1753 - val_loss: 7533.3945\n",
      "Epoch 3143/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.3071\n",
      "Epoch 03143: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.3071 - val_loss: 7533.3262\n",
      "Epoch 3144/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.7568\n",
      "Epoch 03144: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.7568 - val_loss: 7533.3193\n",
      "Epoch 3145/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3799\n",
      "Epoch 03145: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7536.3799 - val_loss: 7533.3018\n",
      "Epoch 3146/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4512\n",
      "Epoch 03146: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7535.4512 - val_loss: 7533.4263\n",
      "Epoch 3147/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.4253\n",
      "Epoch 03147: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7525.4253 - val_loss: 7533.3984\n",
      "Epoch 3148/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.5093\n",
      "Epoch 03148: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7540.5093 - val_loss: 7533.6274\n",
      "Epoch 3149/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.5903\n",
      "Epoch 03149: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.5903 - val_loss: 7533.6328\n",
      "Epoch 3150/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.9707\n",
      "Epoch 03150: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.9707 - val_loss: 7533.5254\n",
      "Epoch 3151/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7300\n",
      "Epoch 03151: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.7300 - val_loss: 7533.6606\n",
      "Epoch 3152/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.6216\n",
      "Epoch 03152: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7518.6216 - val_loss: 7533.6279\n",
      "Epoch 3153/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.3838\n",
      "Epoch 03153: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7530.3838 - val_loss: 7534.3486\n",
      "Epoch 3154/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.3149\n",
      "Epoch 03154: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7542.3149 - val_loss: 7534.1367\n",
      "Epoch 3155/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.9653\n",
      "Epoch 03155: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7523.9653 - val_loss: 7533.7646\n",
      "Epoch 3156/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5723\n",
      "Epoch 03156: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7532.5723 - val_loss: 7534.3032\n",
      "Epoch 3157/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0146\n",
      "Epoch 03157: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7532.0146 - val_loss: 7536.6655\n",
      "Epoch 3158/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1509\n",
      "Epoch 03158: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.1509 - val_loss: 7534.7759\n",
      "Epoch 3159/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.0737\n",
      "Epoch 03159: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7519.0737 - val_loss: 7534.0386\n",
      "Epoch 3160/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.3076\n",
      "Epoch 03160: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7526.3076 - val_loss: 7534.3433\n",
      "Epoch 3161/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8325\n",
      "Epoch 03161: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.8325 - val_loss: 7534.8584\n",
      "Epoch 3162/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9331\n",
      "Epoch 03162: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7531.9331 - val_loss: 7534.4521\n",
      "Epoch 3163/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4102\n",
      "Epoch 03163: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7536.4102 - val_loss: 7534.0176\n",
      "Epoch 3164/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.9424\n",
      "Epoch 03164: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7523.9424 - val_loss: 7533.7056\n",
      "Epoch 3165/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.8760\n",
      "Epoch 03165: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7524.8760 - val_loss: 7533.7383\n",
      "Epoch 3166/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.7598\n",
      "Epoch 03166: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 540ms/step - loss: 7528.7598 - val_loss: 7533.7080\n",
      "Epoch 3167/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0278\n",
      "Epoch 03167: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7532.0278 - val_loss: 7533.7974\n",
      "Epoch 3168/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1479\n",
      "Epoch 03168: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.1479 - val_loss: 7533.4736\n",
      "Epoch 3169/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.0146\n",
      "Epoch 03169: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7524.0146 - val_loss: 7533.9194\n",
      "Epoch 3170/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7614.3701\n",
      "Epoch 03170: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7614.3701 - val_loss: 7577.5898\n",
      "Epoch 3171/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.5137\n",
      "Epoch 03171: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.5137 - val_loss: 7539.6016\n",
      "Epoch 3172/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8242\n",
      "Epoch 03172: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.8242 - val_loss: 7536.1489\n",
      "Epoch 3173/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.1479\n",
      "Epoch 03173: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7547.1479 - val_loss: 7535.5264\n",
      "Epoch 3174/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7525.1484\n",
      "Epoch 03174: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.1484 - val_loss: 7534.9458\n",
      "Epoch 3175/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.0981\n",
      "Epoch 03175: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.0981 - val_loss: 7534.8208\n",
      "Epoch 3176/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.5176\n",
      "Epoch 03176: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7544.5176 - val_loss: 7534.4170\n",
      "Epoch 3177/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5879\n",
      "Epoch 03177: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.5879 - val_loss: 7534.3247\n",
      "Epoch 3178/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5625\n",
      "Epoch 03178: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7536.5625 - val_loss: 7534.4033\n",
      "Epoch 3179/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.6665\n",
      "Epoch 03179: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.6665 - val_loss: 7534.3535\n",
      "Epoch 3180/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.1777\n",
      "Epoch 03180: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.1777 - val_loss: 7534.8394\n",
      "Epoch 3181/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.4756\n",
      "Epoch 03181: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7528.4756 - val_loss: 7537.0879\n",
      "Epoch 3182/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.2515\n",
      "Epoch 03182: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.2515 - val_loss: 7537.1567\n",
      "Epoch 3183/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.8027\n",
      "Epoch 03183: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7528.8027 - val_loss: 7536.6367\n",
      "Epoch 3184/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.8223\n",
      "Epoch 03184: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7520.8223 - val_loss: 7536.2769\n",
      "Epoch 3185/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.2598\n",
      "Epoch 03185: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7528.2598 - val_loss: 7536.1519\n",
      "Epoch 3186/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.2524\n",
      "Epoch 03186: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7539.2524 - val_loss: 7536.0078\n",
      "Epoch 3187/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.2466\n",
      "Epoch 03187: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.2466 - val_loss: 7536.1641\n",
      "Epoch 3188/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4126\n",
      "Epoch 03188: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7534.4126 - val_loss: 7536.1831\n",
      "Epoch 3189/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.4902\n",
      "Epoch 03189: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.4902 - val_loss: 7536.1504\n",
      "Epoch 3190/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.1182\n",
      "Epoch 03190: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.1182 - val_loss: 7536.1943\n",
      "Epoch 3191/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.0972\n",
      "Epoch 03191: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7535.0972 - val_loss: 7535.9678\n",
      "Epoch 3192/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.2119\n",
      "Epoch 03192: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7534.2119 - val_loss: 7535.9614\n",
      "Epoch 3193/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.9951\n",
      "Epoch 03193: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.9951 - val_loss: 7535.9746\n",
      "Epoch 3194/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3257\n",
      "Epoch 03194: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7533.3257 - val_loss: 7536.3247\n",
      "Epoch 3195/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.1284\n",
      "Epoch 03195: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7542.1284 - val_loss: 7535.8369\n",
      "Epoch 3196/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.5737\n",
      "Epoch 03196: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7538.5737 - val_loss: 7535.8135\n",
      "Epoch 3197/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.8975\n",
      "Epoch 03197: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7543.8975 - val_loss: 7535.8208\n",
      "Epoch 3198/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4170\n",
      "Epoch 03198: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.4170 - val_loss: 7535.6992\n",
      "Epoch 3199/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4829\n",
      "Epoch 03199: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.4829 - val_loss: 7535.5825\n",
      "Epoch 3200/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2183\n",
      "Epoch 03200: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.2183 - val_loss: 7535.3608\n",
      "Epoch 3201/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.1377\n",
      "Epoch 03201: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.1377 - val_loss: 7535.3799\n",
      "Epoch 3202/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.0708\n",
      "Epoch 03202: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.0708 - val_loss: 7536.1162\n",
      "Epoch 3203/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.4897\n",
      "Epoch 03203: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7548.4897 - val_loss: 7540.6665\n",
      "Epoch 3204/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.6162\n",
      "Epoch 03204: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7547.6162 - val_loss: 7548.4922\n",
      "Epoch 3205/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.1221\n",
      "Epoch 03205: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7542.1221 - val_loss: 7547.1338\n",
      "Epoch 3206/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.7935\n",
      "Epoch 03206: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7545.7935 - val_loss: 7542.8022\n",
      "Epoch 3207/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.3481\n",
      "Epoch 03207: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7541.3481 - val_loss: 7541.3105\n",
      "Epoch 3208/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.0830\n",
      "Epoch 03208: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7549.0830 - val_loss: 7541.1602\n",
      "Epoch 3209/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7538.2207\n",
      "Epoch 03209: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.2207 - val_loss: 7540.6328\n",
      "Epoch 3210/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7363\n",
      "Epoch 03210: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7539.7363 - val_loss: 7540.3120\n",
      "Epoch 3211/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.5869\n",
      "Epoch 03211: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7544.5869 - val_loss: 7539.9697\n",
      "Epoch 3212/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.2144\n",
      "Epoch 03212: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 540ms/step - loss: 7539.2144 - val_loss: 7540.0098\n",
      "Epoch 3213/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7552.6479\n",
      "Epoch 03213: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7552.6479 - val_loss: 7539.6704\n",
      "Epoch 3214/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6582\n",
      "Epoch 03214: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 541ms/step - loss: 7536.6582 - val_loss: 7539.9458\n",
      "Epoch 3215/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.2588\n",
      "Epoch 03215: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7525.2588 - val_loss: 7539.6406\n",
      "Epoch 3216/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.9087\n",
      "Epoch 03216: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.9087 - val_loss: 7539.8594\n",
      "Epoch 3217/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.9058\n",
      "Epoch 03217: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7548.9058 - val_loss: 7539.4897\n",
      "Epoch 3218/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7551.6992\n",
      "Epoch 03218: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7551.6992 - val_loss: 7539.2666\n",
      "Epoch 3219/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7329\n",
      "Epoch 03219: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7532.7329 - val_loss: 7539.0913\n",
      "Epoch 3220/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0249\n",
      "Epoch 03220: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7538.0249 - val_loss: 7539.3994\n",
      "Epoch 3221/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8184\n",
      "Epoch 03221: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.8184 - val_loss: 7539.2158\n",
      "Epoch 3222/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5410\n",
      "Epoch 03222: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7537.5410 - val_loss: 7538.8506\n",
      "Epoch 3223/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.8735\n",
      "Epoch 03223: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7542.8735 - val_loss: 7538.9375\n",
      "Epoch 3224/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.3726\n",
      "Epoch 03224: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7540.3726 - val_loss: 7544.2241\n",
      "Epoch 3225/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.1382\n",
      "Epoch 03225: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.1382 - val_loss: 7541.4888\n",
      "Epoch 3226/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5728\n",
      "Epoch 03226: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7539.5728 - val_loss: 7540.8135\n",
      "Epoch 3227/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8745\n",
      "Epoch 03227: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.8745 - val_loss: 7541.2881\n",
      "Epoch 3228/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7553.4058\n",
      "Epoch 03228: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7553.4058 - val_loss: 7540.6104\n",
      "Epoch 3229/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8521\n",
      "Epoch 03229: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7538.8521 - val_loss: 7540.1519\n",
      "Epoch 3230/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7551.4263\n",
      "Epoch 03230: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7551.4263 - val_loss: 7540.4775\n",
      "Epoch 3231/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7553.2373\n",
      "Epoch 03231: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7553.2373 - val_loss: 7540.4575\n",
      "Epoch 3232/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.6470\n",
      "Epoch 03232: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.6470 - val_loss: 7540.1631\n",
      "Epoch 3233/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2866\n",
      "Epoch 03233: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.2866 - val_loss: 7540.0439\n",
      "Epoch 3234/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.2876\n",
      "Epoch 03234: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7549.2876 - val_loss: 7539.9712\n",
      "Epoch 3235/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7552.0522\n",
      "Epoch 03235: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7552.0522 - val_loss: 7539.9824\n",
      "Epoch 3236/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8311\n",
      "Epoch 03236: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7538.8311 - val_loss: 7539.7759\n",
      "Epoch 3237/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.1914\n",
      "Epoch 03237: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7542.1914 - val_loss: 7539.8711\n",
      "Epoch 3238/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.6089\n",
      "Epoch 03238: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7546.6089 - val_loss: 7539.7417\n",
      "Epoch 3239/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.7964\n",
      "Epoch 03239: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7524.7964 - val_loss: 7539.6016\n",
      "Epoch 3240/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.9312\n",
      "Epoch 03240: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7548.9312 - val_loss: 7539.8408\n",
      "Epoch 3241/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.2256\n",
      "Epoch 03241: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.2256 - val_loss: 7539.4590\n",
      "Epoch 3242/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6992\n",
      "Epoch 03242: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.6992 - val_loss: 7539.6753\n",
      "Epoch 3243/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.8979\n",
      "Epoch 03243: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7542.8979 - val_loss: 7539.3511\n",
      "Epoch 3244/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7538.3208\n",
      "Epoch 03244: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7538.3208 - val_loss: 7539.6040\n",
      "Epoch 3245/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2754\n",
      "Epoch 03245: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.2754 - val_loss: 7539.2910\n",
      "Epoch 3246/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.0322\n",
      "Epoch 03246: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.0322 - val_loss: 7539.2520\n",
      "Epoch 3247/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1919\n",
      "Epoch 03247: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.1919 - val_loss: 7539.2466\n",
      "Epoch 3248/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.2031\n",
      "Epoch 03248: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.2031 - val_loss: 7539.3857\n",
      "Epoch 3249/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.4033\n",
      "Epoch 03249: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7538.4033 - val_loss: 7539.1982\n",
      "Epoch 3250/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.5889\n",
      "Epoch 03250: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7538.5889 - val_loss: 7539.4370\n",
      "Epoch 3251/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2622\n",
      "Epoch 03251: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7538.2622 - val_loss: 7539.2183\n",
      "Epoch 3252/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7551.1064\n",
      "Epoch 03252: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7551.1064 - val_loss: 7539.0688\n",
      "Epoch 3253/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.1626\n",
      "Epoch 03253: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7548.1626 - val_loss: 7539.1104\n",
      "Epoch 3254/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.4351\n",
      "Epoch 03254: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.4351 - val_loss: 7538.9614\n",
      "Epoch 3255/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1450\n",
      "Epoch 03255: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.1450 - val_loss: 7539.0879\n",
      "Epoch 3256/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.1162\n",
      "Epoch 03256: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7541.1162 - val_loss: 7538.8896\n",
      "Epoch 3257/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.7163\n",
      "Epoch 03257: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.7163 - val_loss: 7538.8784\n",
      "Epoch 3258/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9219\n",
      "Epoch 03258: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.9219 - val_loss: 7539.0742\n",
      "Epoch 3259/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6328\n",
      "Epoch 03259: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7537.6328 - val_loss: 7538.7734\n",
      "Epoch 3260/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3081\n",
      "Epoch 03260: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.3081 - val_loss: 7538.7495\n",
      "Epoch 3261/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5723\n",
      "Epoch 03261: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.5723 - val_loss: 7538.7446\n",
      "Epoch 3262/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.3662\n",
      "Epoch 03262: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.3662 - val_loss: 7538.7319\n",
      "Epoch 3263/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.8628\n",
      "Epoch 03263: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.8628 - val_loss: 7538.7158\n",
      "Epoch 3264/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.6289\n",
      "Epoch 03264: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7542.6289 - val_loss: 7538.7378\n",
      "Epoch 3265/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7550.5420\n",
      "Epoch 03265: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7550.5420 - val_loss: 7538.6514\n",
      "Epoch 3266/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.6440\n",
      "Epoch 03266: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7523.6440 - val_loss: 7538.5518\n",
      "Epoch 3267/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7523.5400\n",
      "Epoch 03267: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7523.5400 - val_loss: 7538.6528\n",
      "Epoch 3268/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4746\n",
      "Epoch 03268: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7536.4746 - val_loss: 7538.7734\n",
      "Epoch 3269/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4917\n",
      "Epoch 03269: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7537.4917 - val_loss: 7538.5991\n",
      "Epoch 3270/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.8159\n",
      "Epoch 03270: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7534.8159 - val_loss: 7539.7041\n",
      "Epoch 3271/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0063\n",
      "Epoch 03271: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7534.0063 - val_loss: 7538.5400\n",
      "Epoch 3272/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6646\n",
      "Epoch 03272: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7536.6646 - val_loss: 7538.5640\n",
      "Epoch 3273/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.2197\n",
      "Epoch 03273: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7534.2197 - val_loss: 7538.8638\n",
      "Epoch 3274/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1538\n",
      "Epoch 03274: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7536.1538 - val_loss: 7538.4482\n",
      "Epoch 3275/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.2471\n",
      "Epoch 03275: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 542ms/step - loss: 7535.2471 - val_loss: 7538.6274\n",
      "Epoch 3276/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7100\n",
      "Epoch 03276: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7536.7100 - val_loss: 7539.0864\n",
      "Epoch 3277/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1562\n",
      "Epoch 03277: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.1562 - val_loss: 7538.3696\n",
      "Epoch 3278/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3716\n",
      "Epoch 03278: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.3716 - val_loss: 7538.7471\n",
      "Epoch 3279/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7547.1953\n",
      "Epoch 03279: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7547.1953 - val_loss: 7538.3398\n",
      "Epoch 3280/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.8022\n",
      "Epoch 03280: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.8022 - val_loss: 7538.4575\n",
      "Epoch 3281/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.5815\n",
      "Epoch 03281: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.5815 - val_loss: 7538.3599\n",
      "Epoch 3282/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1938\n",
      "Epoch 03282: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.1938 - val_loss: 7538.2690\n",
      "Epoch 3283/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4785\n",
      "Epoch 03283: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.4785 - val_loss: 7538.1841\n",
      "Epoch 3284/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.8472\n",
      "Epoch 03284: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.8472 - val_loss: 7538.1807\n",
      "Epoch 3285/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3877\n",
      "Epoch 03285: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.3877 - val_loss: 7538.7646\n",
      "Epoch 3286/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.1553\n",
      "Epoch 03286: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7547.1553 - val_loss: 7538.5498\n",
      "Epoch 3287/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0327\n",
      "Epoch 03287: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.0327 - val_loss: 7538.2271\n",
      "Epoch 3288/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.9023\n",
      "Epoch 03288: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.9023 - val_loss: 7538.1553\n",
      "Epoch 3289/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.6973\n",
      "Epoch 03289: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7541.6973 - val_loss: 7538.3608\n",
      "Epoch 3290/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0679\n",
      "Epoch 03290: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.0679 - val_loss: 7538.0337\n",
      "Epoch 3291/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.8970\n",
      "Epoch 03291: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7535.8970 - val_loss: 7538.2090\n",
      "Epoch 3292/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4263\n",
      "Epoch 03292: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.4263 - val_loss: 7538.0698\n",
      "Epoch 3293/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0806\n",
      "Epoch 03293: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.0806 - val_loss: 7538.4209\n",
      "Epoch 3294/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.1660\n",
      "Epoch 03294: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.1660 - val_loss: 7538.3071\n",
      "Epoch 3295/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.0283\n",
      "Epoch 03295: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.0283 - val_loss: 7538.0503\n",
      "Epoch 3296/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.5278\n",
      "Epoch 03296: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.5278 - val_loss: 7538.1094\n",
      "Epoch 3297/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7522.7920\n",
      "Epoch 03297: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7522.7920 - val_loss: 7537.9424\n",
      "Epoch 3298/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.1870\n",
      "Epoch 03298: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.1870 - val_loss: 7538.4121\n",
      "Epoch 3299/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.8145\n",
      "Epoch 03299: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.8145 - val_loss: 7538.2183\n",
      "Epoch 3300/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2017\n",
      "Epoch 03300: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.2017 - val_loss: 7537.8872\n",
      "Epoch 3301/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1753\n",
      "Epoch 03301: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.1753 - val_loss: 7537.9150\n",
      "Epoch 3302/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.6064\n",
      "Epoch 03302: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7546.6064 - val_loss: 7537.9126\n",
      "Epoch 3303/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4312\n",
      "Epoch 03303: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.4312 - val_loss: 7538.5327\n",
      "Epoch 3304/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.7051\n",
      "Epoch 03304: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.7051 - val_loss: 7538.1162\n",
      "Epoch 3305/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.1597\n",
      "Epoch 03305: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7528.1597 - val_loss: 7537.8481\n",
      "Epoch 3306/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.3857\n",
      "Epoch 03306: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7541.3857 - val_loss: 7537.7866\n",
      "Epoch 3307/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7549.9541\n",
      "Epoch 03307: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7549.9541 - val_loss: 7538.3608\n",
      "Epoch 3308/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.1021\n",
      "Epoch 03308: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.1021 - val_loss: 7537.9951\n",
      "Epoch 3309/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.3955\n",
      "Epoch 03309: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7541.3955 - val_loss: 7537.7568\n",
      "Epoch 3310/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3042\n",
      "Epoch 03310: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.3042 - val_loss: 7537.7832\n",
      "Epoch 3311/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.4492\n",
      "Epoch 03311: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7546.4492 - val_loss: 7537.9448\n",
      "Epoch 3312/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5010\n",
      "Epoch 03312: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.5010 - val_loss: 7537.7905\n",
      "Epoch 3313/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0806\n",
      "Epoch 03313: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7536.0806 - val_loss: 7537.9712\n",
      "Epoch 3314/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7540.6606\n",
      "Epoch 03314: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.6606 - val_loss: 7537.7998\n",
      "Epoch 3315/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0811\n",
      "Epoch 03315: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.0811 - val_loss: 7537.7822\n",
      "Epoch 3316/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.2231\n",
      "Epoch 03316: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.2231 - val_loss: 7537.7417\n",
      "Epoch 3317/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.1592\n",
      "Epoch 03317: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7530.1592 - val_loss: 7537.7026\n",
      "Epoch 3318/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.3931\n",
      "Epoch 03318: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.3931 - val_loss: 7537.6216\n",
      "Epoch 3319/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.8379\n",
      "Epoch 03319: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7527.8379 - val_loss: 7537.6543\n",
      "Epoch 3320/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.4668\n",
      "Epoch 03320: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.4668 - val_loss: 7537.8809\n",
      "Epoch 3321/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7900\n",
      "Epoch 03321: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7540.7900 - val_loss: 7537.5825\n",
      "Epoch 3322/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3838\n",
      "Epoch 03322: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.3838 - val_loss: 7537.7266\n",
      "Epoch 3323/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.5605\n",
      "Epoch 03323: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7540.5605 - val_loss: 7537.6040\n",
      "Epoch 3324/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.2725\n",
      "Epoch 03324: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7539.2725 - val_loss: 7537.5010\n",
      "Epoch 3325/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.7642\n",
      "Epoch 03325: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7542.7642 - val_loss: 7537.5400\n",
      "Epoch 3326/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.1787\n",
      "Epoch 03326: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.1787 - val_loss: 7537.6025\n",
      "Epoch 3327/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6240\n",
      "Epoch 03327: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.6240 - val_loss: 7537.6216\n",
      "Epoch 3328/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.0283\n",
      "Epoch 03328: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7548.0283 - val_loss: 7537.5176\n",
      "Epoch 3329/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.4131\n",
      "Epoch 03329: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7540.4131 - val_loss: 7537.5288\n",
      "Epoch 3330/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7522.1709\n",
      "Epoch 03330: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7522.1709 - val_loss: 7537.4575\n",
      "Epoch 3331/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4951\n",
      "Epoch 03331: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.4951 - val_loss: 7537.9414\n",
      "Epoch 3332/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.2593\n",
      "Epoch 03332: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7535.2593 - val_loss: 7537.7241\n",
      "Epoch 3333/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1533\n",
      "Epoch 03333: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7536.1533 - val_loss: 7537.4736\n",
      "Epoch 3334/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.2988\n",
      "Epoch 03334: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.2988 - val_loss: 7537.9058\n",
      "Epoch 3335/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.1216\n",
      "Epoch 03335: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.1216 - val_loss: 7537.4937\n",
      "Epoch 3336/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.4609\n",
      "Epoch 03336: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7527.4609 - val_loss: 7537.3618\n",
      "Epoch 3337/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4932\n",
      "Epoch 03337: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.4932 - val_loss: 7537.3018\n",
      "Epoch 3338/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.9546\n",
      "Epoch 03338: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.9546 - val_loss: 7537.3159\n",
      "Epoch 3339/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.9658\n",
      "Epoch 03339: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7545.9658 - val_loss: 7537.2417\n",
      "Epoch 3340/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.3936\n",
      "Epoch 03340: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7540.3936 - val_loss: 7537.3257\n",
      "Epoch 3341/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.0396\n",
      "Epoch 03341: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.0396 - val_loss: 7537.3550\n",
      "Epoch 3342/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.4292\n",
      "Epoch 03342: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7542.4292 - val_loss: 7537.2295\n",
      "Epoch 3343/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4736\n",
      "Epoch 03343: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.4736 - val_loss: 7537.3472\n",
      "Epoch 3344/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.9287\n",
      "Epoch 03344: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.9287 - val_loss: 7537.2729\n",
      "Epoch 3345/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.0913\n",
      "Epoch 03345: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.0913 - val_loss: 7537.1753\n",
      "Epoch 3346/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4229\n",
      "Epoch 03346: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7535.4229 - val_loss: 7537.2856\n",
      "Epoch 3347/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.2847\n",
      "Epoch 03347: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7528.2847 - val_loss: 7537.0879\n",
      "Epoch 3348/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8706\n",
      "Epoch 03348: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.8706 - val_loss: 7537.1289\n",
      "Epoch 3349/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7547.5137\n",
      "Epoch 03349: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7547.5137 - val_loss: 7537.1016\n",
      "Epoch 3350/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.7549\n",
      "Epoch 03350: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.7549 - val_loss: 7537.1519\n",
      "Epoch 3351/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.7461\n",
      "Epoch 03351: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.7461 - val_loss: 7537.0928\n",
      "Epoch 3352/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.3960\n",
      "Epoch 03352: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7528.3960 - val_loss: 7537.1743\n",
      "Epoch 3353/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4536\n",
      "Epoch 03353: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7535.4536 - val_loss: 7537.0791\n",
      "Epoch 3354/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.7051\n",
      "Epoch 03354: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7535.7051 - val_loss: 7537.5854\n",
      "Epoch 3355/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.3579\n",
      "Epoch 03355: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.3579 - val_loss: 7537.1074\n",
      "Epoch 3356/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9209\n",
      "Epoch 03356: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.9209 - val_loss: 7537.2031\n",
      "Epoch 3357/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.0190\n",
      "Epoch 03357: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7527.0190 - val_loss: 7537.0562\n",
      "Epoch 3358/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.0083\n",
      "Epoch 03358: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.0083 - val_loss: 7536.9976\n",
      "Epoch 3359/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.5625\n",
      "Epoch 03359: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.5625 - val_loss: 7537.2998\n",
      "Epoch 3360/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.1929\n",
      "Epoch 03360: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.1929 - val_loss: 7536.9790\n",
      "Epoch 3361/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.6953\n",
      "Epoch 03361: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.6953 - val_loss: 7536.9463\n",
      "Epoch 3362/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.9331\n",
      "Epoch 03362: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.9331 - val_loss: 7537.0400\n",
      "Epoch 3363/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.3574\n",
      "Epoch 03363: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7535.3574 - val_loss: 7537.0479\n",
      "Epoch 3364/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.0376\n",
      "Epoch 03364: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7527.0376 - val_loss: 7537.1338\n",
      "Epoch 3365/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9473\n",
      "Epoch 03365: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.9473 - val_loss: 7537.2134\n",
      "Epoch 3366/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.0488\n",
      "Epoch 03366: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.0488 - val_loss: 7536.8608\n",
      "Epoch 3367/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.3281\n",
      "Epoch 03367: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7547.3281 - val_loss: 7536.9312\n",
      "Epoch 3368/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.8501\n",
      "Epoch 03368: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.8501 - val_loss: 7536.8647\n",
      "Epoch 3369/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.0068\n",
      "Epoch 03369: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7527.0068 - val_loss: 7536.9824\n",
      "Epoch 3370/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.9897\n",
      "Epoch 03370: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.9897 - val_loss: 7536.8711\n",
      "Epoch 3371/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.0034\n",
      "Epoch 03371: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.0034 - val_loss: 7536.9751\n",
      "Epoch 3372/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3911\n",
      "Epoch 03372: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.3911 - val_loss: 7536.8760\n",
      "Epoch 3373/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.9775\n",
      "Epoch 03373: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.9775 - val_loss: 7536.7329\n",
      "Epoch 3374/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.8843\n",
      "Epoch 03374: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7535.8843 - val_loss: 7536.8232\n",
      "Epoch 3375/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8403\n",
      "Epoch 03375: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7533.8403 - val_loss: 7537.1616\n",
      "Epoch 3376/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.8296\n",
      "Epoch 03376: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7527.8296 - val_loss: 7536.7798\n",
      "Epoch 3377/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.6875\n",
      "Epoch 03377: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7548.6875 - val_loss: 7536.7969\n",
      "Epoch 3378/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.4194\n",
      "Epoch 03378: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7538.4194 - val_loss: 7536.6826\n",
      "Epoch 3379/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.7437\n",
      "Epoch 03379: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7527.7437 - val_loss: 7536.6719\n",
      "Epoch 3380/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.0859\n",
      "Epoch 03380: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7543.0859 - val_loss: 7536.6514\n",
      "Epoch 3381/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.5430\n",
      "Epoch 03381: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7538.5430 - val_loss: 7537.2378\n",
      "Epoch 3382/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.3628\n",
      "Epoch 03382: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7543.3628 - val_loss: 7536.7856\n",
      "Epoch 3383/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.2036\n",
      "Epoch 03383: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7545.2036 - val_loss: 7536.8066\n",
      "Epoch 3384/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7534.2764\n",
      "Epoch 03384: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7534.2764 - val_loss: 7536.5176\n",
      "Epoch 3385/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.5728\n",
      "Epoch 03385: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.5728 - val_loss: 7536.5679\n",
      "Epoch 3386/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.7080\n",
      "Epoch 03386: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7541.7080 - val_loss: 7536.5698\n",
      "Epoch 3387/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.3525\n",
      "Epoch 03387: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7535.3525 - val_loss: 7537.1982\n",
      "Epoch 3388/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.1274\n",
      "Epoch 03388: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.1274 - val_loss: 7536.7002\n",
      "Epoch 3389/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7944\n",
      "Epoch 03389: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.7944 - val_loss: 7536.6074\n",
      "Epoch 3390/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3232\n",
      "Epoch 03390: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.3232 - val_loss: 7536.6816\n",
      "Epoch 3391/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.2871\n",
      "Epoch 03391: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7534.2871 - val_loss: 7536.5010\n",
      "Epoch 3392/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2856\n",
      "Epoch 03392: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.2856 - val_loss: 7536.6650\n",
      "Epoch 3393/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7861\n",
      "Epoch 03393: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.7861 - val_loss: 7536.4438\n",
      "Epoch 3394/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8950\n",
      "Epoch 03394: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.8950 - val_loss: 7536.3872\n",
      "Epoch 3395/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.8506\n",
      "Epoch 03395: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7539.8506 - val_loss: 7536.4575\n",
      "Epoch 3396/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.8589\n",
      "Epoch 03396: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.8589 - val_loss: 7536.4414\n",
      "Epoch 3397/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.0479\n",
      "Epoch 03397: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7548.0479 - val_loss: 7536.5103\n",
      "Epoch 3398/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.1240\n",
      "Epoch 03398: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7542.1240 - val_loss: 7537.0288\n",
      "Epoch 3399/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7548.1465\n",
      "Epoch 03399: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7548.1465 - val_loss: 7536.5410\n",
      "Epoch 3400/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.5347\n",
      "Epoch 03400: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.5347 - val_loss: 7536.3594\n",
      "Epoch 3401/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.8887\n",
      "Epoch 03401: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.8887 - val_loss: 7536.2769\n",
      "Epoch 3402/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1309\n",
      "Epoch 03402: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.1309 - val_loss: 7536.5425\n",
      "Epoch 3403/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.4189\n",
      "Epoch 03403: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7528.4189 - val_loss: 7536.2280\n",
      "Epoch 3404/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.6587\n",
      "Epoch 03404: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7547.6587 - val_loss: 7536.2520\n",
      "Epoch 3405/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.4165\n",
      "Epoch 03405: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7535.4165 - val_loss: 7536.2778\n",
      "Epoch 3406/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.5034\n",
      "Epoch 03406: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7546.5034 - val_loss: 7536.1694\n",
      "Epoch 3407/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7528.4629\n",
      "Epoch 03407: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7528.4629 - val_loss: 7536.4863\n",
      "Epoch 3408/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.1567\n",
      "Epoch 03408: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7539.1567 - val_loss: 7536.2822\n",
      "Epoch 3409/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.4194\n",
      "Epoch 03409: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7543.4194 - val_loss: 7536.6992\n",
      "Epoch 3410/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.1948\n",
      "Epoch 03410: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7540.1948 - val_loss: 7536.3174\n",
      "Epoch 3411/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8979\n",
      "Epoch 03411: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7538.8979 - val_loss: 7536.1543\n",
      "Epoch 3412/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.6289\n",
      "Epoch 03412: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.6289 - val_loss: 7536.1216\n",
      "Epoch 3413/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5352\n",
      "Epoch 03413: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.5352 - val_loss: 7536.1206\n",
      "Epoch 3414/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0732\n",
      "Epoch 03414: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.0732 - val_loss: 7536.0703\n",
      "Epoch 3415/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.6235\n",
      "Epoch 03415: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.6235 - val_loss: 7536.1367\n",
      "Epoch 3416/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.7163\n",
      "Epoch 03416: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7546.7163 - val_loss: 7536.5898\n",
      "Epoch 3417/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.5547\n",
      "Epoch 03417: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7542.5547 - val_loss: 7536.1489\n",
      "Epoch 3418/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5703\n",
      "Epoch 03418: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.5703 - val_loss: 7536.0288\n",
      "Epoch 3419/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7532.4316\n",
      "Epoch 03419: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7532.4316 - val_loss: 7536.0601\n",
      "Epoch 3420/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.6919\n",
      "Epoch 03420: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7547.6919 - val_loss: 7536.2207\n",
      "Epoch 3421/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.2451\n",
      "Epoch 03421: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.2451 - val_loss: 7536.0767\n",
      "Epoch 3422/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.2456\n",
      "Epoch 03422: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.2456 - val_loss: 7535.9570\n",
      "Epoch 3423/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.8970\n",
      "Epoch 03423: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.8970 - val_loss: 7535.9512\n",
      "Epoch 3424/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.0454\n",
      "Epoch 03424: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7527.0454 - val_loss: 7536.1177\n",
      "Epoch 3425/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5967\n",
      "Epoch 03425: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.5967 - val_loss: 7536.1982\n",
      "Epoch 3426/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.0791\n",
      "Epoch 03426: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7535.0791 - val_loss: 7535.9878\n",
      "Epoch 3427/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5161\n",
      "Epoch 03427: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.5161 - val_loss: 7535.9385\n",
      "Epoch 3428/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.6191\n",
      "Epoch 03428: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7527.6191 - val_loss: 7536.1450\n",
      "Epoch 3429/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4785\n",
      "Epoch 03429: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.4785 - val_loss: 7536.1538\n",
      "Epoch 3430/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.0186\n",
      "Epoch 03430: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7527.0186 - val_loss: 7535.8198\n",
      "Epoch 3431/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.6411\n",
      "Epoch 03431: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.6411 - val_loss: 7535.8408\n",
      "Epoch 3432/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3184\n",
      "Epoch 03432: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.3184 - val_loss: 7535.8105\n",
      "Epoch 3433/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.0688\n",
      "Epoch 03433: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7547.0688 - val_loss: 7535.8721\n",
      "Epoch 3434/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.5513\n",
      "Epoch 03434: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7538.5513 - val_loss: 7536.0161\n",
      "Epoch 3435/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6299\n",
      "Epoch 03435: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.6299 - val_loss: 7536.0166\n",
      "Epoch 3436/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.9517\n",
      "Epoch 03436: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7526.9517 - val_loss: 7535.8169\n",
      "Epoch 3437/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.6982\n",
      "Epoch 03437: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.6982 - val_loss: 7535.7856\n",
      "Epoch 3438/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6621\n",
      "Epoch 03438: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.6621 - val_loss: 7535.7729\n",
      "Epoch 3439/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.7339\n",
      "Epoch 03439: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.7339 - val_loss: 7536.0078\n",
      "Epoch 3440/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2539\n",
      "Epoch 03440: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.2539 - val_loss: 7535.7881\n",
      "Epoch 3441/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.2036\n",
      "Epoch 03441: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.2036 - val_loss: 7535.9351\n",
      "Epoch 3442/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.2251\n",
      "Epoch 03442: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.2251 - val_loss: 7535.7466\n",
      "Epoch 3443/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3130\n",
      "Epoch 03443: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.3130 - val_loss: 7536.1665\n",
      "Epoch 3444/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8311\n",
      "Epoch 03444: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.8311 - val_loss: 7535.9297\n",
      "Epoch 3445/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.6211\n",
      "Epoch 03445: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.6211 - val_loss: 7535.6958\n",
      "Epoch 3446/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.9629\n",
      "Epoch 03446: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7520.9629 - val_loss: 7535.9087\n",
      "Epoch 3447/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.2378\n",
      "Epoch 03447: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7542.2378 - val_loss: 7535.7295\n",
      "Epoch 3448/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1196\n",
      "Epoch 03448: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7532.1196 - val_loss: 7535.9312\n",
      "Epoch 3449/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7573\n",
      "Epoch 03449: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7540.7573 - val_loss: 7535.5938\n",
      "Epoch 3450/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5054\n",
      "Epoch 03450: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.5054 - val_loss: 7535.6680\n",
      "Epoch 3451/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.2119\n",
      "Epoch 03451: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7542.2119 - val_loss: 7535.6016\n",
      "Epoch 3452/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.9829\n",
      "Epoch 03452: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7543.9829 - val_loss: 7535.5273\n",
      "Epoch 3453/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.8789\n",
      "Epoch 03453: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7546.8789 - val_loss: 7535.5391\n",
      "Epoch 3454/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7534.2310\n",
      "Epoch 03454: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7534.2310 - val_loss: 7535.5854\n",
      "Epoch 3455/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.7061\n",
      "Epoch 03455: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7540.7061 - val_loss: 7535.7158\n",
      "Epoch 3456/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1133\n",
      "Epoch 03456: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 540ms/step - loss: 7534.1133 - val_loss: 7535.7358\n",
      "Epoch 3457/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6304\n",
      "Epoch 03457: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 540ms/step - loss: 7537.6304 - val_loss: 7535.8042\n",
      "Epoch 3458/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8745\n",
      "Epoch 03458: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.8745 - val_loss: 7535.6304\n",
      "Epoch 3459/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4565\n",
      "Epoch 03459: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.4565 - val_loss: 7535.6143\n",
      "Epoch 3460/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4272\n",
      "Epoch 03460: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7537.4272 - val_loss: 7535.5601\n",
      "Epoch 3461/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0332\n",
      "Epoch 03461: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7533.0332 - val_loss: 7535.6050\n",
      "Epoch 3462/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1064\n",
      "Epoch 03462: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7534.1064 - val_loss: 7535.5806\n",
      "Epoch 3463/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.2402\n",
      "Epoch 03463: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7537.2402 - val_loss: 7535.5088\n",
      "Epoch 3464/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2520\n",
      "Epoch 03464: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.2520 - val_loss: 7535.5137\n",
      "Epoch 3465/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0464\n",
      "Epoch 03465: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7533.0464 - val_loss: 7535.5591\n",
      "Epoch 3466/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4531\n",
      "Epoch 03466: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.4531 - val_loss: 7535.4536\n",
      "Epoch 3467/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3218\n",
      "Epoch 03467: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.3218 - val_loss: 7535.5337\n",
      "Epoch 3468/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1768\n",
      "Epoch 03468: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.1768 - val_loss: 7535.4673\n",
      "Epoch 3469/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3789\n",
      "Epoch 03469: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.3789 - val_loss: 7535.5664\n",
      "Epoch 3470/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.5112\n",
      "Epoch 03470: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7530.5112 - val_loss: 7535.3984\n",
      "Epoch 3471/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8574\n",
      "Epoch 03471: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.8574 - val_loss: 7535.3223\n",
      "Epoch 3472/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.2041\n",
      "Epoch 03472: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7520.2041 - val_loss: 7535.3784\n",
      "Epoch 3473/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1670\n",
      "Epoch 03473: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.1670 - val_loss: 7535.3232\n",
      "Epoch 3474/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4648\n",
      "Epoch 03474: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.4648 - val_loss: 7535.4590\n",
      "Epoch 3475/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.0669\n",
      "Epoch 03475: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.0669 - val_loss: 7535.4736\n",
      "Epoch 3476/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8638\n",
      "Epoch 03476: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.8638 - val_loss: 7535.3086\n",
      "Epoch 3477/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.4580\n",
      "Epoch 03477: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.4580 - val_loss: 7535.2798\n",
      "Epoch 3478/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.9741\n",
      "Epoch 03478: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.9741 - val_loss: 7535.3721\n",
      "Epoch 3479/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7739\n",
      "Epoch 03479: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.7739 - val_loss: 7535.3311\n",
      "Epoch 3480/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.5664\n",
      "Epoch 03480: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.5664 - val_loss: 7535.2354\n",
      "Epoch 3481/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.7271\n",
      "Epoch 03481: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.7271 - val_loss: 7535.3906\n",
      "Epoch 3482/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.7192\n",
      "Epoch 03482: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7547.7192 - val_loss: 7536.0879\n",
      "Epoch 3483/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.2759\n",
      "Epoch 03483: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7527.2759 - val_loss: 7535.3662\n",
      "Epoch 3484/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8813\n",
      "Epoch 03484: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.8813 - val_loss: 7535.2178\n",
      "Epoch 3485/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.7891\n",
      "Epoch 03485: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.7891 - val_loss: 7535.2134\n",
      "Epoch 3486/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.3774\n",
      "Epoch 03486: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.3774 - val_loss: 7535.5425\n",
      "Epoch 3487/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.9585\n",
      "Epoch 03487: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7543.9585 - val_loss: 7535.2217\n",
      "Epoch 3488/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0288\n",
      "Epoch 03488: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.0288 - val_loss: 7535.1416\n",
      "Epoch 3489/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7531.7144\n",
      "Epoch 03489: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.7144 - val_loss: 7535.1865\n",
      "Epoch 3490/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.7153\n",
      "Epoch 03490: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7541.7153 - val_loss: 7535.2441\n",
      "Epoch 3491/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.1875\n",
      "Epoch 03491: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7525.1875 - val_loss: 7535.2178\n",
      "Epoch 3492/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.3887\n",
      "Epoch 03492: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7526.3887 - val_loss: 7535.4536\n",
      "Epoch 3493/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.7227\n",
      "Epoch 03493: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7538.7227 - val_loss: 7535.1377\n",
      "Epoch 3494/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4839\n",
      "Epoch 03494: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.4839 - val_loss: 7535.4072\n",
      "Epoch 3495/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.6680\n",
      "Epoch 03495: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.6680 - val_loss: 7535.4722\n",
      "Epoch 3496/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8052\n",
      "Epoch 03496: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7531.8052 - val_loss: 7535.1538\n",
      "Epoch 3497/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0088\n",
      "Epoch 03497: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7538.0088 - val_loss: 7535.4897\n",
      "Epoch 3498/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4268\n",
      "Epoch 03498: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7533.4268 - val_loss: 7535.3970\n",
      "Epoch 3499/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.4399\n",
      "Epoch 03499: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7526.4399 - val_loss: 7535.2280\n",
      "Epoch 3500/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.0820\n",
      "Epoch 03500: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7525.0820 - val_loss: 7535.1929\n",
      "Epoch 3501/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.1807\n",
      "Epoch 03501: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7540.1807 - val_loss: 7535.0615\n",
      "Epoch 3502/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4800\n",
      "Epoch 03502: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7531.4800 - val_loss: 7535.0825\n",
      "Epoch 3503/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8999\n",
      "Epoch 03503: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.8999 - val_loss: 7535.3218\n",
      "Epoch 3504/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0605\n",
      "Epoch 03504: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.0605 - val_loss: 7535.0991\n",
      "Epoch 3505/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.5332\n",
      "Epoch 03505: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7543.5332 - val_loss: 7535.2544\n",
      "Epoch 3506/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2905\n",
      "Epoch 03506: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7538.2905 - val_loss: 7535.6289\n",
      "Epoch 3507/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1392\n",
      "Epoch 03507: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7537.1392 - val_loss: 7535.0400\n",
      "Epoch 3508/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6792\n",
      "Epoch 03508: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7537.6792 - val_loss: 7535.1001\n",
      "Epoch 3509/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0679\n",
      "Epoch 03509: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.0679 - val_loss: 7535.7358\n",
      "Epoch 3510/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.1875\n",
      "Epoch 03510: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7540.1875 - val_loss: 7535.0703\n",
      "Epoch 3511/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.3789\n",
      "Epoch 03511: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7545.3789 - val_loss: 7535.0142\n",
      "Epoch 3512/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3457\n",
      "Epoch 03512: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.3457 - val_loss: 7535.3242\n",
      "Epoch 3513/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4136\n",
      "Epoch 03513: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.4136 - val_loss: 7535.1802\n",
      "Epoch 3514/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.6533\n",
      "Epoch 03514: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7541.6533 - val_loss: 7534.9624\n",
      "Epoch 3515/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.0015\n",
      "Epoch 03515: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.0015 - val_loss: 7534.9521\n",
      "Epoch 3516/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.7256\n",
      "Epoch 03516: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.7256 - val_loss: 7535.3320\n",
      "Epoch 3517/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.9180\n",
      "Epoch 03517: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.9180 - val_loss: 7535.0718\n",
      "Epoch 3518/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.3633\n",
      "Epoch 03518: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7545.3633 - val_loss: 7535.1538\n",
      "Epoch 3519/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.0366\n",
      "Epoch 03519: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7525.0366 - val_loss: 7534.9990\n",
      "Epoch 3520/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8218\n",
      "Epoch 03520: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.8218 - val_loss: 7534.9775\n",
      "Epoch 3521/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.2114\n",
      "Epoch 03521: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7537.2114 - val_loss: 7535.3247\n",
      "Epoch 3522/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7510\n",
      "Epoch 03522: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.7510 - val_loss: 7535.1167\n",
      "Epoch 3523/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.2676\n",
      "Epoch 03523: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.2676 - val_loss: 7535.2632\n",
      "Epoch 3524/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7539.3306\n",
      "Epoch 03524: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7539.3306 - val_loss: 7535.3872\n",
      "Epoch 3525/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.4658\n",
      "Epoch 03525: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7546.4658 - val_loss: 7535.2095\n",
      "Epoch 3526/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7547.0508\n",
      "Epoch 03526: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7547.0508 - val_loss: 7535.2144\n",
      "Epoch 3527/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1875\n",
      "Epoch 03527: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.1875 - val_loss: 7535.0898\n",
      "Epoch 3528/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.5464\n",
      "Epoch 03528: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.5464 - val_loss: 7535.0303\n",
      "Epoch 3529/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.2266\n",
      "Epoch 03529: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.2266 - val_loss: 7535.1377\n",
      "Epoch 3530/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.7993\n",
      "Epoch 03530: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7519.7993 - val_loss: 7535.1226\n",
      "Epoch 3531/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4038\n",
      "Epoch 03531: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.4038 - val_loss: 7535.6001\n",
      "Epoch 3532/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.5654\n",
      "Epoch 03532: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.5654 - val_loss: 7535.2671\n",
      "Epoch 3533/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1602\n",
      "Epoch 03533: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7534.1602 - val_loss: 7535.2578\n",
      "Epoch 3534/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7236\n",
      "Epoch 03534: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.7236 - val_loss: 7535.0767\n",
      "Epoch 3535/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5811\n",
      "Epoch 03535: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.5811 - val_loss: 7534.9966\n",
      "Epoch 3536/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7373\n",
      "Epoch 03536: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.7373 - val_loss: 7535.0518\n",
      "Epoch 3537/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.7212\n",
      "Epoch 03537: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7519.7212 - val_loss: 7534.8262\n",
      "Epoch 3538/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.7148\n",
      "Epoch 03538: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7537.7148 - val_loss: 7534.9448\n",
      "Epoch 3539/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3101\n",
      "Epoch 03539: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.3101 - val_loss: 7534.8462\n",
      "Epoch 3540/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.7329\n",
      "Epoch 03540: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7543.7329 - val_loss: 7535.9438\n",
      "Epoch 3541/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.8564\n",
      "Epoch 03541: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7529.8564 - val_loss: 7535.1880\n",
      "Epoch 3542/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3701\n",
      "Epoch 03542: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.3701 - val_loss: 7534.7646\n",
      "Epoch 3543/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7915\n",
      "Epoch 03543: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.7915 - val_loss: 7535.3945\n",
      "Epoch 3544/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.7935\n",
      "Epoch 03544: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7537.7935 - val_loss: 7534.7666\n",
      "Epoch 3545/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.5542\n",
      "Epoch 03545: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.5542 - val_loss: 7534.9136\n",
      "Epoch 3546/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8491\n",
      "Epoch 03546: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7536.8491 - val_loss: 7534.9536\n",
      "Epoch 3547/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3857\n",
      "Epoch 03547: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.3857 - val_loss: 7534.9238\n",
      "Epoch 3548/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4331\n",
      "Epoch 03548: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.4331 - val_loss: 7535.0488\n",
      "Epoch 3549/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.7314\n",
      "Epoch 03549: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.7314 - val_loss: 7535.3008\n",
      "Epoch 3550/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1465\n",
      "Epoch 03550: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.1465 - val_loss: 7534.7944\n",
      "Epoch 3551/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5488\n",
      "Epoch 03551: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.5488 - val_loss: 7534.9160\n",
      "Epoch 3552/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8013\n",
      "Epoch 03552: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7533.8013 - val_loss: 7535.0718\n",
      "Epoch 3553/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2490\n",
      "Epoch 03553: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7538.2490 - val_loss: 7535.4048\n",
      "Epoch 3554/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5469\n",
      "Epoch 03554: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.5469 - val_loss: 7534.9014\n",
      "Epoch 3555/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8213\n",
      "Epoch 03555: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.8213 - val_loss: 7535.0049\n",
      "Epoch 3556/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.2212\n",
      "Epoch 03556: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7526.2212 - val_loss: 7535.1318\n",
      "Epoch 3557/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.6372\n",
      "Epoch 03557: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7536.6372 - val_loss: 7534.8823\n",
      "Epoch 3558/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.8359\n",
      "Epoch 03558: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7519.8359 - val_loss: 7535.1055\n",
      "Epoch 3559/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7537.7378\n",
      "Epoch 03559: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.7378 - val_loss: 7534.7695\n",
      "Epoch 3560/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.1660\n",
      "Epoch 03560: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7546.1660 - val_loss: 7534.8218\n",
      "Epoch 3561/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9502\n",
      "Epoch 03561: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.9502 - val_loss: 7534.8838\n",
      "Epoch 3562/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.2397\n",
      "Epoch 03562: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7546.2397 - val_loss: 7534.7295\n",
      "Epoch 3563/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.8960\n",
      "Epoch 03563: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7525.8960 - val_loss: 7534.7520\n",
      "Epoch 3564/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.1699\n",
      "Epoch 03564: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7534.1699 - val_loss: 7535.0161\n",
      "Epoch 3565/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4658\n",
      "Epoch 03565: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.4658 - val_loss: 7534.6865\n",
      "Epoch 3566/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.0903\n",
      "Epoch 03566: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7538.0903 - val_loss: 7534.6367\n",
      "Epoch 3567/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4224\n",
      "Epoch 03567: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7531.4224 - val_loss: 7534.6904\n",
      "Epoch 3568/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.1094\n",
      "Epoch 03568: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7546.1094 - val_loss: 7535.0498\n",
      "Epoch 3569/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.9800\n",
      "Epoch 03569: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.9800 - val_loss: 7534.8584\n",
      "Epoch 3570/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5854\n",
      "Epoch 03570: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7536.5854 - val_loss: 7534.7495\n",
      "Epoch 3571/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.7676\n",
      "Epoch 03571: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.7676 - val_loss: 7534.8433\n",
      "Epoch 3572/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6582\n",
      "Epoch 03572: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.6582 - val_loss: 7534.7690\n",
      "Epoch 3573/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5562\n",
      "Epoch 03573: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.5562 - val_loss: 7534.5703\n",
      "Epoch 3574/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2900\n",
      "Epoch 03574: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.2900 - val_loss: 7535.0352\n",
      "Epoch 3575/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.7778\n",
      "Epoch 03575: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7524.7778 - val_loss: 7534.6694\n",
      "Epoch 3576/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.4458\n",
      "Epoch 03576: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7538.4458 - val_loss: 7534.8550\n",
      "Epoch 3577/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3433\n",
      "Epoch 03577: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.3433 - val_loss: 7534.5928\n",
      "Epoch 3578/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.9775\n",
      "Epoch 03578: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7529.9775 - val_loss: 7534.6958\n",
      "Epoch 3579/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3516\n",
      "Epoch 03579: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7537.3516 - val_loss: 7534.9834\n",
      "Epoch 3580/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.6987\n",
      "Epoch 03580: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7524.6987 - val_loss: 7534.6450\n",
      "Epoch 3581/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.3398\n",
      "Epoch 03581: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7546.3398 - val_loss: 7534.5942\n",
      "Epoch 3582/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4199\n",
      "Epoch 03582: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7533.4199 - val_loss: 7534.5918\n",
      "Epoch 3583/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.8286\n",
      "Epoch 03583: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.8286 - val_loss: 7534.5762\n",
      "Epoch 3584/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.7646\n",
      "Epoch 03584: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7525.7646 - val_loss: 7534.5210\n",
      "Epoch 3585/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.8184\n",
      "Epoch 03585: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7538.8184 - val_loss: 7534.7334\n",
      "Epoch 3586/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.2681\n",
      "Epoch 03586: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7537.2681 - val_loss: 7534.7334\n",
      "Epoch 3587/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8711\n",
      "Epoch 03587: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7545.8711 - val_loss: 7534.6865\n",
      "Epoch 3588/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7543.0669\n",
      "Epoch 03588: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7543.0669 - val_loss: 7534.5654\n",
      "Epoch 3589/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.2642\n",
      "Epoch 03589: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.2642 - val_loss: 7534.5703\n",
      "Epoch 3590/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.8540\n",
      "Epoch 03590: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7525.8540 - val_loss: 7534.6089\n",
      "Epoch 3591/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.1074\n",
      "Epoch 03591: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7546.1074 - val_loss: 7534.5791\n",
      "Epoch 3592/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.1406\n",
      "Epoch 03592: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.1406 - val_loss: 7536.1377\n",
      "Epoch 3593/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.6670\n",
      "Epoch 03593: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.6670 - val_loss: 7534.5889\n",
      "Epoch 3594/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7532.1201\n",
      "Epoch 03594: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.1201 - val_loss: 7534.6602\n",
      "Epoch 3595/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.6021\n",
      "Epoch 03595: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.6021 - val_loss: 7534.9746\n",
      "Epoch 3596/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.4741\n",
      "Epoch 03596: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7533.4741 - val_loss: 7534.6641\n",
      "Epoch 3597/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0850\n",
      "Epoch 03597: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.0850 - val_loss: 7534.4263\n",
      "Epoch 3598/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.1475\n",
      "Epoch 03598: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7546.1475 - val_loss: 7534.5649\n",
      "Epoch 3599/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2178\n",
      "Epoch 03599: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.2178 - val_loss: 7534.5425\n",
      "Epoch 3600/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.9336\n",
      "Epoch 03600: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.9336 - val_loss: 7535.3882\n",
      "Epoch 3601/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.9316\n",
      "Epoch 03601: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.9316 - val_loss: 7534.5078\n",
      "Epoch 3602/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.5581\n",
      "Epoch 03602: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.5581 - val_loss: 7534.4814\n",
      "Epoch 3603/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.6724\n",
      "Epoch 03603: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.6724 - val_loss: 7534.5264\n",
      "Epoch 3604/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.8203\n",
      "Epoch 03604: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7529.8203 - val_loss: 7534.9360\n",
      "Epoch 3605/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5400\n",
      "Epoch 03605: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.5400 - val_loss: 7535.0454\n",
      "Epoch 3606/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.3159\n",
      "Epoch 03606: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.3159 - val_loss: 7534.7295\n",
      "Epoch 3607/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7520.0586\n",
      "Epoch 03607: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7520.0586 - val_loss: 7535.1919\n",
      "Epoch 3608/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.7095\n",
      "Epoch 03608: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.7095 - val_loss: 7534.8906\n",
      "Epoch 3609/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.7231\n",
      "Epoch 03609: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.7231 - val_loss: 7535.1802\n",
      "Epoch 3610/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.3052\n",
      "Epoch 03610: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7534.3052 - val_loss: 7535.3423\n",
      "Epoch 3611/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.8564\n",
      "Epoch 03611: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7526.8564 - val_loss: 7534.8462\n",
      "Epoch 3612/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.8838\n",
      "Epoch 03612: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7524.8838 - val_loss: 7534.7510\n",
      "Epoch 3613/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7456\n",
      "Epoch 03613: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.7456 - val_loss: 7534.6416\n",
      "Epoch 3614/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2803\n",
      "Epoch 03614: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7531.2803 - val_loss: 7535.0503\n",
      "Epoch 3615/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.4214\n",
      "Epoch 03615: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7541.4214 - val_loss: 7534.7666\n",
      "Epoch 3616/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3525\n",
      "Epoch 03616: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.3525 - val_loss: 7534.7310\n",
      "Epoch 3617/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7979\n",
      "Epoch 03617: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.7979 - val_loss: 7534.6152\n",
      "Epoch 3618/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.5820\n",
      "Epoch 03618: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.5820 - val_loss: 7534.7471\n",
      "Epoch 3619/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0957\n",
      "Epoch 03619: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.0957 - val_loss: 7534.6782\n",
      "Epoch 3620/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7881\n",
      "Epoch 03620: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.7881 - val_loss: 7534.5312\n",
      "Epoch 3621/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1992\n",
      "Epoch 03621: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.1992 - val_loss: 7534.7456\n",
      "Epoch 3622/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.3584\n",
      "Epoch 03622: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7519.3584 - val_loss: 7534.5342\n",
      "Epoch 3623/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8066\n",
      "Epoch 03623: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.8066 - val_loss: 7534.6104\n",
      "Epoch 3624/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.9878\n",
      "Epoch 03624: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7537.9878 - val_loss: 7534.7310\n",
      "Epoch 3625/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.4429\n",
      "Epoch 03625: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7541.4429 - val_loss: 7535.0337\n",
      "Epoch 3626/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7539\n",
      "Epoch 03626: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.7539 - val_loss: 7534.5513\n",
      "Epoch 3627/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.5532\n",
      "Epoch 03627: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.5532 - val_loss: 7534.5327\n",
      "Epoch 3628/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.4609\n",
      "Epoch 03628: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.4609 - val_loss: 7536.0215\n",
      "Epoch 3629/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7538.4346\n",
      "Epoch 03629: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7538.4346 - val_loss: 7535.4160\n",
      "Epoch 3630/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.6709\n",
      "Epoch 03630: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.6709 - val_loss: 7534.8521\n",
      "Epoch 3631/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1309\n",
      "Epoch 03631: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.1309 - val_loss: 7534.8384\n",
      "Epoch 3632/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7534.4858\n",
      "Epoch 03632: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7534.4858 - val_loss: 7534.9937\n",
      "Epoch 3633/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.4126\n",
      "Epoch 03633: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7519.4126 - val_loss: 7534.8770\n",
      "Epoch 3634/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.0601\n",
      "Epoch 03634: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7541.0601 - val_loss: 7534.6016\n",
      "Epoch 3635/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8027\n",
      "Epoch 03635: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7532.8027 - val_loss: 7535.2241\n",
      "Epoch 3636/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2241\n",
      "Epoch 03636: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.2241 - val_loss: 7535.6440\n",
      "Epoch 3637/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8359\n",
      "Epoch 03637: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7532.8359 - val_loss: 7534.8594\n",
      "Epoch 3638/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.9990\n",
      "Epoch 03638: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.9990 - val_loss: 7534.6865\n",
      "Epoch 3639/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.3037\n",
      "Epoch 03639: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.3037 - val_loss: 7535.5322\n",
      "Epoch 3640/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.6235\n",
      "Epoch 03640: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7529.6235 - val_loss: 7534.9473\n",
      "Epoch 3641/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5532\n",
      "Epoch 03641: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.5532 - val_loss: 7534.5513\n",
      "Epoch 3642/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3086\n",
      "Epoch 03642: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.3086 - val_loss: 7534.3926\n",
      "Epoch 3643/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.6528\n",
      "Epoch 03643: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.6528 - val_loss: 7534.9814\n",
      "Epoch 3644/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.0991\n",
      "Epoch 03644: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7546.0991 - val_loss: 7535.0874\n",
      "Epoch 3645/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.6035\n",
      "Epoch 03645: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7545.6035 - val_loss: 7534.4126\n",
      "Epoch 3646/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.4297\n",
      "Epoch 03646: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.4297 - val_loss: 7534.4736\n",
      "Epoch 3647/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8091\n",
      "Epoch 03647: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7533.8091 - val_loss: 7534.6631\n",
      "Epoch 3648/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.9854\n",
      "Epoch 03648: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7540.9854 - val_loss: 7534.7134\n",
      "Epoch 3649/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3062\n",
      "Epoch 03649: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.3062 - val_loss: 7534.6440\n",
      "Epoch 3650/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6812\n",
      "Epoch 03650: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7531.6812 - val_loss: 7534.5342\n",
      "Epoch 3651/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.6348\n",
      "Epoch 03651: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.6348 - val_loss: 7534.6182\n",
      "Epoch 3652/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7540.9253\n",
      "Epoch 03652: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7540.9253 - val_loss: 7534.4385\n",
      "Epoch 3653/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.9780\n",
      "Epoch 03653: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7529.9780 - val_loss: 7535.1304\n",
      "Epoch 3654/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.8066\n",
      "Epoch 03654: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.8066 - val_loss: 7534.8726\n",
      "Epoch 3655/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1953\n",
      "Epoch 03655: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7531.1953 - val_loss: 7534.3594\n",
      "Epoch 3656/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7939\n",
      "Epoch 03656: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.7939 - val_loss: 7534.3945\n",
      "Epoch 3657/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.0938\n",
      "Epoch 03657: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.0938 - val_loss: 7534.6255\n",
      "Epoch 3658/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9810\n",
      "Epoch 03658: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.9810 - val_loss: 7534.2959\n",
      "Epoch 3659/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.4902\n",
      "Epoch 03659: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7544.4902 - val_loss: 7534.3262\n",
      "Epoch 3660/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.0327\n",
      "Epoch 03660: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7537.0327 - val_loss: 7534.2993\n",
      "Epoch 3661/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3950\n",
      "Epoch 03661: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7536.3950 - val_loss: 7534.4888\n",
      "Epoch 3662/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.6343\n",
      "Epoch 03662: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7529.6343 - val_loss: 7534.3799\n",
      "Epoch 3663/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.0869\n",
      "Epoch 03663: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7546.0869 - val_loss: 7534.9385\n",
      "Epoch 3664/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7533.3481\n",
      "Epoch 03664: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7533.3481 - val_loss: 7534.2119\n",
      "Epoch 3665/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8057\n",
      "Epoch 03665: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7533.8057 - val_loss: 7534.7393\n",
      "Epoch 3666/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.5347\n",
      "Epoch 03666: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7525.5347 - val_loss: 7534.7441\n",
      "Epoch 3667/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.2305\n",
      "Epoch 03667: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7529.2305 - val_loss: 7534.3818\n",
      "Epoch 3668/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.9326\n",
      "Epoch 03668: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7531.9326 - val_loss: 7534.4370\n",
      "Epoch 3669/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8018\n",
      "Epoch 03669: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7545.8018 - val_loss: 7534.2910\n",
      "Epoch 3670/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.4087\n",
      "Epoch 03670: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7539.4087 - val_loss: 7534.4912\n",
      "Epoch 3671/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.4717\n",
      "Epoch 03671: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 536ms/step - loss: 7526.4717 - val_loss: 7534.5542\n",
      "Epoch 3672/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.1221\n",
      "Epoch 03672: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7532.1221 - val_loss: 7534.4590\n",
      "Epoch 3673/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0293\n",
      "Epoch 03673: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7531.0293 - val_loss: 7534.3374\n",
      "Epoch 3674/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7541.6104\n",
      "Epoch 03674: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 541ms/step - loss: 7541.6104 - val_loss: 7535.2744\n",
      "Epoch 3675/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.8091\n",
      "Epoch 03675: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7526.8091 - val_loss: 7534.8271\n",
      "Epoch 3676/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8081\n",
      "Epoch 03676: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.8081 - val_loss: 7534.4385\n",
      "Epoch 3677/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8374\n",
      "Epoch 03677: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.8374 - val_loss: 7535.0098\n",
      "Epoch 3678/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.2998\n",
      "Epoch 03678: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7544.2998 - val_loss: 7534.1816\n",
      "Epoch 3679/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.8711\n",
      "Epoch 03679: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 541ms/step - loss: 7533.8711 - val_loss: 7534.6465\n",
      "Epoch 3680/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.6396\n",
      "Epoch 03680: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7526.6396 - val_loss: 7534.7358\n",
      "Epoch 3681/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5469\n",
      "Epoch 03681: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.5469 - val_loss: 7534.6577\n",
      "Epoch 3682/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.7412\n",
      "Epoch 03682: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.7412 - val_loss: 7534.5122\n",
      "Epoch 3683/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.4307\n",
      "Epoch 03683: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7536.4307 - val_loss: 7534.3638\n",
      "Epoch 3684/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.2568\n",
      "Epoch 03684: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7519.2568 - val_loss: 7534.4023\n",
      "Epoch 3685/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7734\n",
      "Epoch 03685: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.7734 - val_loss: 7534.4648\n",
      "Epoch 3686/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.9189\n",
      "Epoch 03686: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.9189 - val_loss: 7534.8330\n",
      "Epoch 3687/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7519.6919\n",
      "Epoch 03687: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7519.6919 - val_loss: 7534.8394\n",
      "Epoch 3688/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7578\n",
      "Epoch 03688: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7539.7578 - val_loss: 7534.5566\n",
      "Epoch 3689/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.2544\n",
      "Epoch 03689: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7531.2544 - val_loss: 7534.3638\n",
      "Epoch 3690/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5239\n",
      "Epoch 03690: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.5239 - val_loss: 7534.2729\n",
      "Epoch 3691/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.7002\n",
      "Epoch 03691: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7537.7002 - val_loss: 7535.5151\n",
      "Epoch 3692/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5039\n",
      "Epoch 03692: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.5039 - val_loss: 7535.9761\n",
      "Epoch 3693/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8164\n",
      "Epoch 03693: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7545.8164 - val_loss: 7534.5015\n",
      "Epoch 3694/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.0522\n",
      "Epoch 03694: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 14s 540ms/step - loss: 7531.0522 - val_loss: 7534.3486\n",
      "Epoch 3695/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.9058\n",
      "Epoch 03695: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7539.9058 - val_loss: 7534.7583\n",
      "Epoch 3696/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3325\n",
      "Epoch 03696: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.3325 - val_loss: 7534.3257\n",
      "Epoch 3697/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.2793\n",
      "Epoch 03697: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7529.2793 - val_loss: 7534.5527\n",
      "Epoch 3698/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.2388\n",
      "Epoch 03698: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7535.2388 - val_loss: 7535.6431\n",
      "Epoch 3699/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7544.6089\n",
      "Epoch 03699: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.6089 - val_loss: 7534.4570\n",
      "Epoch 3700/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3320\n",
      "Epoch 03700: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.3320 - val_loss: 7534.2642\n",
      "Epoch 3701/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.6147\n",
      "Epoch 03701: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7539.6147 - val_loss: 7535.1489\n",
      "Epoch 3702/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.7749\n",
      "Epoch 03702: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.7749 - val_loss: 7534.4297\n",
      "Epoch 3703/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.3765\n",
      "Epoch 03703: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 538ms/step - loss: 7525.3765 - val_loss: 7534.8999\n",
      "Epoch 3704/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1538\n",
      "Epoch 03704: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7538.1538 - val_loss: 7534.7114\n",
      "Epoch 3705/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.1328\n",
      "Epoch 03705: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7538.1328 - val_loss: 7534.6880\n",
      "Epoch 3706/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7527.1450\n",
      "Epoch 03706: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7527.1450 - val_loss: 7535.1494\n",
      "Epoch 3707/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.7612\n",
      "Epoch 03707: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7530.7612 - val_loss: 7534.3633\n",
      "Epoch 3708/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2168\n",
      "Epoch 03708: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7532.2168 - val_loss: 7535.5479\n",
      "Epoch 3709/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7651\n",
      "Epoch 03709: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7532.7651 - val_loss: 7535.2070\n",
      "Epoch 3710/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.0698\n",
      "Epoch 03710: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7526.0698 - val_loss: 7535.0625\n",
      "Epoch 3711/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.7065\n",
      "Epoch 03711: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7539.7065 - val_loss: 7534.6030\n",
      "Epoch 3712/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.8623\n",
      "Epoch 03712: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7545.8623 - val_loss: 7534.5073\n",
      "Epoch 3713/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.6831\n",
      "Epoch 03713: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7545.6831 - val_loss: 7534.1831\n",
      "Epoch 3714/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.5239\n",
      "Epoch 03714: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7524.5239 - val_loss: 7535.2065\n",
      "Epoch 3715/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.8403\n",
      "Epoch 03715: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7537.8403 - val_loss: 7534.3926\n",
      "Epoch 3716/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.2852\n",
      "Epoch 03716: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 539ms/step - loss: 7524.2852 - val_loss: 7534.4873\n",
      "Epoch 3717/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.6689\n",
      "Epoch 03717: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 537ms/step - loss: 7524.6689 - val_loss: 7534.8257\n",
      "Epoch 3718/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5034\n",
      "Epoch 03718: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7533.5034 - val_loss: 7534.3154\n",
      "Epoch 3719/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.4585\n",
      "Epoch 03719: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7544.4585 - val_loss: 7534.4058\n",
      "Epoch 3720/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8047\n",
      "Epoch 03720: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.8047 - val_loss: 7534.2930\n",
      "Epoch 3721/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.7871\n",
      "Epoch 03721: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.7871 - val_loss: 7534.4463\n",
      "Epoch 3722/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.1987\n",
      "Epoch 03722: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7537.1987 - val_loss: 7534.1504\n",
      "Epoch 3723/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.4902\n",
      "Epoch 03723: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7530.4902 - val_loss: 7534.1543\n",
      "Epoch 3724/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.6675\n",
      "Epoch 03724: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7546.6675 - val_loss: 7534.9985\n",
      "Epoch 3725/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.2998\n",
      "Epoch 03725: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7539.2998 - val_loss: 7534.1392\n",
      "Epoch 3726/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.2871\n",
      "Epoch 03726: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7538.2871 - val_loss: 7535.0312\n",
      "Epoch 3727/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.3286\n",
      "Epoch 03727: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.3286 - val_loss: 7534.5566\n",
      "Epoch 3728/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7993\n",
      "Epoch 03728: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7536.7993 - val_loss: 7534.1514\n",
      "Epoch 3729/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.1216\n",
      "Epoch 03729: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7536.1216 - val_loss: 7534.1792\n",
      "Epoch 3730/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.8892\n",
      "Epoch 03730: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7536.8892 - val_loss: 7534.3384\n",
      "Epoch 3731/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.6753\n",
      "Epoch 03731: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7531.6753 - val_loss: 7534.2935\n",
      "Epoch 3732/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.2300\n",
      "Epoch 03732: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 7525.2300 - val_loss: 7534.1792\n",
      "Epoch 3733/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7529.2305\n",
      "Epoch 03733: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7529.2305 - val_loss: 7534.3770\n",
      "Epoch 3734/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7532.5591\n",
      "Epoch 03734: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.5591 - val_loss: 7534.0776\n",
      "Epoch 3735/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0220\n",
      "Epoch 03735: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7536.0220 - val_loss: 7534.1792\n",
      "Epoch 3736/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8213\n",
      "Epoch 03736: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.8213 - val_loss: 7534.2769\n",
      "Epoch 3737/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.8955\n",
      "Epoch 03737: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7525.8955 - val_loss: 7534.3862\n",
      "Epoch 3738/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.5552\n",
      "Epoch 03738: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.5552 - val_loss: 7535.2065\n",
      "Epoch 3739/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3711\n",
      "Epoch 03739: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.3711 - val_loss: 7534.1641\n",
      "Epoch 3740/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7349\n",
      "Epoch 03740: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7532.7349 - val_loss: 7534.2783\n",
      "Epoch 3741/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.3267\n",
      "Epoch 03741: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.3267 - val_loss: 7534.2842\n",
      "Epoch 3742/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.3906\n",
      "Epoch 03742: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.3906 - val_loss: 7533.9326\n",
      "Epoch 3743/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.9263\n",
      "Epoch 03743: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.9263 - val_loss: 7533.9502\n",
      "Epoch 3744/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.8818\n",
      "Epoch 03744: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 534ms/step - loss: 7518.8818 - val_loss: 7534.0425\n",
      "Epoch 3745/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.4194\n",
      "Epoch 03745: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7545.4194 - val_loss: 7533.8970\n",
      "Epoch 3746/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.7651\n",
      "Epoch 03746: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7531.7651 - val_loss: 7534.2295\n",
      "Epoch 3747/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7544.4067\n",
      "Epoch 03747: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7544.4067 - val_loss: 7534.3135\n",
      "Epoch 3748/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7539.4717\n",
      "Epoch 03748: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7539.4717 - val_loss: 7534.4976\n",
      "Epoch 3749/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.7026\n",
      "Epoch 03749: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.7026 - val_loss: 7534.6504\n",
      "Epoch 3750/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7803\n",
      "Epoch 03750: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7536.7803 - val_loss: 7534.6406\n",
      "Epoch 3751/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7542.4590\n",
      "Epoch 03751: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7542.4590 - val_loss: 7534.1289\n",
      "Epoch 3752/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.2568\n",
      "Epoch 03752: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7533.2568 - val_loss: 7534.1055\n",
      "Epoch 3753/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.0220\n",
      "Epoch 03753: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7536.0220 - val_loss: 7534.0640\n",
      "Epoch 3754/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.3291\n",
      "Epoch 03754: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 535ms/step - loss: 7526.3291 - val_loss: 7534.1328\n",
      "Epoch 3755/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7536.7329\n",
      "Epoch 03755: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7536.7329 - val_loss: 7534.1826\n",
      "Epoch 3756/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8560\n",
      "Epoch 03756: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.8560 - val_loss: 7534.2031\n",
      "Epoch 3757/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7518.8784\n",
      "Epoch 03757: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7518.8784 - val_loss: 7533.8706\n",
      "Epoch 3758/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.3237\n",
      "Epoch 03758: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7533.3237 - val_loss: 7533.9663\n",
      "Epoch 3759/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7533.1055\n",
      "Epoch 03759: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7533.1055 - val_loss: 7534.3022\n",
      "Epoch 3760/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7530.9048\n",
      "Epoch 03760: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7530.9048 - val_loss: 7534.0879\n",
      "Epoch 3761/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.5669\n",
      "Epoch 03761: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.5669 - val_loss: 7534.0830\n",
      "Epoch 3762/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7525.0166\n",
      "Epoch 03762: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7525.0166 - val_loss: 7533.9434\n",
      "Epoch 3763/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7545.6592\n",
      "Epoch 03763: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7545.6592 - val_loss: 7534.0513\n",
      "Epoch 3764/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.5552\n",
      "Epoch 03764: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7532.5552 - val_loss: 7534.1392\n",
      "Epoch 3765/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8647\n",
      "Epoch 03765: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7531.8647 - val_loss: 7534.3496\n",
      "Epoch 3766/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7546.0049\n",
      "Epoch 03766: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7546.0049 - val_loss: 7534.7583\n",
      "Epoch 3767/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.0034\n",
      "Epoch 03767: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7524.0034 - val_loss: 7533.8945\n",
      "Epoch 3768/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.4170\n",
      "Epoch 03768: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7526.4170 - val_loss: 7534.8096\n",
      "Epoch 3769/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 7532.6401\n",
      "Epoch 03769: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7532.6401 - val_loss: 7534.3296\n",
      "Epoch 3770/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7524.9185\n",
      "Epoch 03770: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7524.9185 - val_loss: 7534.8647\n",
      "Epoch 3771/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7538.9727\n",
      "Epoch 03771: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 529ms/step - loss: 7538.9727 - val_loss: 7533.9678\n",
      "Epoch 3772/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.4824\n",
      "Epoch 03772: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7526.4824 - val_loss: 7534.8042\n",
      "Epoch 3773/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.1597\n",
      "Epoch 03773: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 526ms/step - loss: 7531.1597 - val_loss: 7534.4038\n",
      "Epoch 3774/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.4570\n",
      "Epoch 03774: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7531.4570 - val_loss: 7534.0078\n",
      "Epoch 3775/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7535.8311\n",
      "Epoch 03775: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7535.8311 - val_loss: 7533.9761\n",
      "Epoch 3776/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.2534\n",
      "Epoch 03776: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7532.2534 - val_loss: 7534.1719\n",
      "Epoch 3777/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7526.5830\n",
      "Epoch 03777: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 527ms/step - loss: 7526.5830 - val_loss: 7534.4263\n",
      "Epoch 3778/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7531.8369\n",
      "Epoch 03778: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 533ms/step - loss: 7531.8369 - val_loss: 7534.0698\n",
      "Epoch 3779/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.9385\n",
      "Epoch 03779: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 532ms/step - loss: 7537.9385 - val_loss: 7534.8960\n",
      "Epoch 3780/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7532.8359\n",
      "Epoch 03780: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 530ms/step - loss: 7532.8359 - val_loss: 7534.6377\n",
      "Epoch 3781/10000\n",
      "25/25 [==============================] - ETA: 0s - loss: 7537.8760\n",
      "Epoch 03781: val_loss did not improve from 7532.14551\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 7537.8760 - val_loss: 7534.4160\n",
      "Epoch 3782/10000\n",
      "11/25 [============>.................] - ETA: 6s - loss: 7532.8574"
     ]
    }
   ],
   "source": [
    "history = vae_model.fit(train_gen, validation_data=valid_gen, epochs=10000, callbacks= [chkpoint_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "814a1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model.save_weights('/dls/science/groups/imaging/ePSIC_students/Andy_Bridger/PaperDataRepo/HighMagAlloy/FullModel/ntest.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 - EPSIC [DLS Conda]",
   "language": "python",
   "name": "conda-env-DLS_Conda-epsic3.7-kernel.json"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
