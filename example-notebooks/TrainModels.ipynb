{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9318ec3e",
   "metadata": {},
   "source": [
    "# Train the Models for some/all your datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af03e3",
   "metadata": {},
   "source": [
    "### First just run the cell below, it should hopefully complete without error (expect some Warnings from TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed1e1813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 10:28:55.979830: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/dls_sw/apps/python/anaconda/4.6.14/64/envs/epsic3.7/lib/python3.7/site-packages/pyUSID/viz/__init__.py:18: FutureWarning: Please use sidpy.viz.plot_utils instead of pyUSID.viz.plot_utils. pyUSID.plot_utils will be removed in a future release of pyUSID\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow v2.3.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "#load some packages in\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as python_random\n",
    "from numba import njit\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from stemutils.io import Path\n",
    "import hyperspy.api as hs\n",
    "import concurrent.futures\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import lru_cache\n",
    "\n",
    "#set some variables\n",
    "print('Using TensorFlow v%s' % tf.__version__)\n",
    "plt.style.use('default')\n",
    "python_random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "\n",
    "#define some functions\n",
    "\n",
    "###################################################\n",
    "########### Data Preprocessing ####################\n",
    "###################################################\n",
    "\n",
    "def batch_resize(d, bs=512):\n",
    "    if len(d.shape) == 4:\n",
    "        flat_d = flatten_nav(d)\n",
    "    else:\n",
    "        flat_d = d\n",
    "    n_batches = int(np.ceil(flat_d.shape[0]//bs))\n",
    "    batches = [flat_d[i*bs:(i+1)*bs] for i in range(n_batches+1)]\n",
    "    if len(batches[-1])==0:\n",
    "        batches.pop(-1)\n",
    "    print(len(batches[-1]))\n",
    "    with concurrent.futures.ProcessPoolExecutor() as exe:\n",
    "        res = [exe.submit(resize, batch, (batch.shape[0],128,128)) for batch in batches]\n",
    "    r_batches = [f.result() for f in res]\n",
    "    return np.concatenate(r_batches, axis = 0).reshape((d.shape[0],128,128))\n",
    "\n",
    "def data_manip(d, bs = 512):\n",
    "    if type(d) != np.ndarray:\n",
    "        print('dask to numpy')\n",
    "        d = d.compute()\n",
    "        print('dask to numpy done')\n",
    "    print('started data manipulations')\n",
    "    #d = resize(d,(d.shape[0],128,128))\n",
    "    d = batch_resize(d, bs)\n",
    "    print('resized')\n",
    "    d_maxes = np.max(d,(1,2))[:,None,None]\n",
    "    d /= d_maxes\n",
    "    scaler = np.log(1001)\n",
    "    return np.log((d*1000)+1)/scaler \n",
    "\n",
    "\n",
    "###################################################\n",
    "###################################################\n",
    "###################################################\n",
    "\n",
    "def flatten_nav(sig):\n",
    "    shape = [sig.shape[0]*sig.shape[1]]\n",
    "    for i in sig.shape[2:]:\n",
    "        shape.append(i)\n",
    "    return sig.reshape(shape)\n",
    "\n",
    "\n",
    "class My_Custom_Generator(keras.utils.Sequence) :\n",
    "    def __init__(self, image_filenames,  batch_size) :\n",
    "        self.image_filenames = image_filenames\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n",
    "    \n",
    "    \n",
    "    @lru_cache(None)\n",
    "    def __getitem__(self, idx) :\n",
    "        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        out_img = np.asarray([np.load(file_name)[:,:,None] for file_name in batch_x])\n",
    "        return out_img, out_img\n",
    "        #return batch_x, batch_y\n",
    "        \n",
    "        \n",
    "class Array_Generator(keras.utils.Sequence) :\n",
    "    def __init__(self, images,  batch_size) :\n",
    "        self.images = images\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.images) / float(self.batch_size))).astype(np.int)\n",
    "    \n",
    "    \n",
    "    @lru_cache(None)\n",
    "    def __getitem__(self, idx) :\n",
    "        out_img = self.images[idx * self.batch_size : (idx+1) * self.batch_size, :,:,None]\n",
    "        return out_img, out_img\n",
    "        #return batch_x, batch_y\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        epsilon = tf.keras.backend.random_normal(shape=tf.shape(z_mean))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "def create_vae_model(hparams):\n",
    "    \n",
    "    n_img = 128\n",
    "    latent_dim = hparams['LAT']\n",
    "    beta = hparams['B']\n",
    "\n",
    "    image_input = keras.Input(shape=(n_img, n_img,1), name = 'enc_input')\n",
    "    x = layers.Conv2D(hparams['KN1'],5, strides = 2, activation='relu',padding='same', input_shape=image_input.shape, name = 'enc_conv1')(image_input)\n",
    "    x = layers.Conv2D(hparams['KN2'],5, strides = 2, activation='relu',padding='same', name = 'enc_conv2')(x)\n",
    "    x = layers.Conv2D(hparams['KN3'],5, strides = 2, activation='relu',padding='same', name = 'enc_conv3')(x)\n",
    "    x = layers.Conv2D(hparams['KN4'],5, strides = 2, activation='relu',padding='same', name = 'enc_conv4')(x)\n",
    "    x = layers.Conv2D(hparams['KN5'],5, strides = 2, activation='relu',padding='same', name = 'enc_conv5')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(hparams['D1'], activation='relu', name = 'enc_d1')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d2_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d3_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d4_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d5_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d6_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d7_t')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'enc_d8_t')(x)\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean_t\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var_t\")(x)\n",
    "    z_output = Sampling()([z_mean, z_log_var])\n",
    "    encoder_VAE = keras.Model(image_input, [z_mean, z_log_var, z_output])\n",
    "\n",
    "    z_input = keras.Input(shape=(latent_dim,), name = 'dec_input_t')\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d1_t')(z_input)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d2')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d3')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d4')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d5')(x)\n",
    "    x = layers.Dense(hparams['D2'], activation=\"relu\", name = 'dec_d6')(x)\n",
    "    x = layers.Dense(hparams['D1'], activation=\"relu\", name = 'dec_d7')(x)\n",
    "    x = layers.Dense(4*4*hparams['KN5'], activation=\"relu\", name = 'dec_d8')(x)\n",
    "    x = layers.Reshape((4, 4,hparams['KN5']))(x)\n",
    "    x = layers.Conv2DTranspose(hparams['KN4'],5, strides = 2, activation='relu',padding='same', name = 'dec_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(hparams['KN3'],5, strides = 2, activation='relu',padding='same', name = 'dec_conv2')(x)\n",
    "    x = layers.Conv2DTranspose(hparams['KN2'],5, strides = 2, activation='relu',padding='same', name = 'dec_conv3')(x)\n",
    "    x = layers.Conv2DTranspose(hparams['KN1'],5, strides = 2, activation='relu',padding='same', name = 'dec_conv4')(x)\n",
    "    image_output = layers.Conv2DTranspose(1,5, strides = 2, activation='sigmoid',padding='same', name = 'dec_conv5')(x)\n",
    "    #image_output = layers.Conv2DTranspose(16,3, strides = 2, activation='sigmoid',padding='same')\n",
    "    #image_output = layers.Reshape((n_img, n_img,1))(x)\n",
    "    decoder_VAE = keras.Model(z_input, image_output)\n",
    "\n",
    "    # VAE class\n",
    "    class VAE(keras.Model):\n",
    "        # constructor\n",
    "        def __init__(self, encoder, decoder, **kwargs):\n",
    "            super(VAE, self).__init__(**kwargs)\n",
    "            self.encoder = encoder\n",
    "            self.decoder = decoder\n",
    "\n",
    "        # customise train_step() to implement the loss \n",
    "        def train_step(self, x):\n",
    "            if isinstance(x, tuple):\n",
    "                x = x[0]\n",
    "            with tf.GradientTape() as tape:\n",
    "                # encoding\n",
    "                z_mean, z_log_var, z = self.encoder(x)\n",
    "                # decoding\n",
    "                x_prime = self.decoder(z)\n",
    "                # reconstruction error by binary crossentropy loss\n",
    "                reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(x, x_prime)) * n_img * n_img\n",
    "                # KL divergence\n",
    "                kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "                # loss = reconstruction error + KL divergence\n",
    "                loss = reconstruction_loss + beta* kl_loss\n",
    "            # apply gradient\n",
    "            grads = tape.gradient(loss, self.trainable_weights)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "            # return loss for metrics log\n",
    "            return {\"loss\": loss}\n",
    "\n",
    "\n",
    "        def call(self, x):\n",
    "            if isinstance(x, tuple):\n",
    "                x = x[0]\n",
    "            # encoding\n",
    "            z_mean, z_log_var, z = self.encoder(x)\n",
    "            # decoding\n",
    "            x_prime = self.decoder(z)\n",
    "            return x_prime\n",
    "    # build the VAE\n",
    "    vae_model = VAE(encoder_VAE, decoder_VAE)\n",
    "\n",
    "    # compile the VAE\n",
    "    vae_model.compile(optimizer=keras.optimizers.Adam(learning_rate=hparams['LR']),loss=custom_loss)\n",
    "    vae_model.build((1,128,128,1))\n",
    "    \n",
    "    return vae_model\n",
    "\n",
    "\n",
    "\n",
    "def custom_loss(x,y):\n",
    "    n_img = 128\n",
    "    return tf.reduce_mean(keras.losses.binary_crossentropy(x, y)) * n_img * n_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d8cb2",
   "metadata": {},
   "source": [
    "### Now check that you can find the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "632ca150",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 10:29:16.534909: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 10:29:16.545158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-11-12 10:29:16.545183: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-12 10:29:16.549311: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-12 10:29:16.552300: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-12 10:29:16.553691: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-12 10:29:16.556847: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-12 10:29:16.559326: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-12 10:29:16.565647: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-12 10:29:16.566358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bad647e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_152115')),\n",
       " (1,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_150802')),\n",
       " (2,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_135457')),\n",
       " (3,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_141948')),\n",
       " (4,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_151250')),\n",
       " (5,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_150242')),\n",
       " (6,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_110741')),\n",
       " (7,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_141615')),\n",
       " (8,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_123525')),\n",
       " (9,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_115723')),\n",
       " (10,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_142234')),\n",
       " (11,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_124143')),\n",
       " (12,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_111314')),\n",
       " (13,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_140636')),\n",
       " (14,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_144026')),\n",
       " (15,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_143626')),\n",
       " (16,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_120113')),\n",
       " (17,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_144541')),\n",
       " (18,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_113941')),\n",
       " (19,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_123918')),\n",
       " (20,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_120505')),\n",
       " (21,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_151851')),\n",
       " (22,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_111630')),\n",
       " (23,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_152338')),\n",
       " (24,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_112041')),\n",
       " (25,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_112312')),\n",
       " (26,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_144251')),\n",
       " (27,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_115220')),\n",
       " (28,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_151627')),\n",
       " (29,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_135721')),\n",
       " (30,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_123232')),\n",
       " (31,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_113711')),\n",
       " (32,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_141303')),\n",
       " (33,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_151026')),\n",
       " (34,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_140913')),\n",
       " (35,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_143402')),\n",
       " (36,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_122555')),\n",
       " (37,\n",
       "  Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_150506'))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#set the Path to be the folder containing all your timestamped data\n",
    "fdp = Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated')\n",
    "\n",
    "dl = fdp.ls()\n",
    "[i for i in enumerate(dl)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc9b277",
   "metadata": {},
   "source": [
    "# Training a Single Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f176f5",
   "metadata": {},
   "source": [
    "### Either enter the path directly to the dp variable or use the index from the list above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffe1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Either\n",
    "dp = Path('something/something/file.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77c56a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_141303/20210925_141303_data.hdf5\n"
     ]
    }
   ],
   "source": [
    "#Or\n",
    "#set select as the index of the dataset you want from the list above\n",
    "select = 32\n",
    "#with a cognisant selection of include and exclude phrases should be able to pull out the data\n",
    "dp = dl[select].walk('.hdf5', 'Model')[0]\n",
    "print(dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67044adc",
   "metadata": {},
   "source": [
    "### Create a directory to save our intermediate model checkpoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89b8aabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_141303/CropModel\n"
     ]
    }
   ],
   "source": [
    "mp = dp.redirect('CropModel')\n",
    "if not mp.exists():\n",
    "    mp.mkdir()\n",
    "print(mp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05f914f",
   "metadata": {},
   "source": [
    "### Load in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53835384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:hdf5plugin:blosc filter already loaded, skip it.\n",
      "WARNING:hdf5plugin:bshuf filter already loaded, skip it.\n",
      "WARNING:hdf5plugin:lz4 filter already loaded, skip it.\n",
      "WARNING:hdf5plugin:zfp filter already loaded, skip it.\n",
      "WARNING:hdf5plugin:fcidecomp filter already loaded, skip it.\n"
     ]
    }
   ],
   "source": [
    "ds = hs.load(dp)\n",
    "s = ds.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd976a9c",
   "metadata": {},
   "source": [
    "### Create a dictionary to hold some useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5f57da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f247a3d",
   "metadata": {},
   "source": [
    "### Recommended to first train the model rebinned 3x3 for improved signal to noise and reduced training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "740c5b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "rebin_factor = 3\n",
    "ds = ds.rebin(None, [rebin_factor,rebin_factor,1,1])\n",
    "ds.data = ds.data/(rebin_factor*rebin_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f4e9e8",
   "metadata": {},
   "source": [
    "### Now we want to preprocess the data and factor into batches for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "244c845b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started data manipulations\n",
      "57\n",
      "resized\n",
      "(7225, 128, 128)\n",
      "(7225, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "#Can modify the data preprocessing by changing the Data Preprocessing functions defined in the first cell\n",
    "\n",
    "input_data = data_manip(flatten_nav(ds.data))\n",
    "data_shuffled = [x for x in shuffle(input_data,input_data)]\n",
    "data_shuffled_numpy = np.array(data_shuffled[0])\n",
    "\n",
    "X_train, X_val = data_shuffled_numpy, data_shuffled_numpy\n",
    "print(X_train.shape) # (3800,)   \n",
    "print(X_val.shape)   # (950,)\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "train_gen = Array_Generator(X_train, batch_size)\n",
    "valid_gen = Array_Generator(X_val, batch_size)\n",
    "\n",
    "batch_shape = train_gen[0][0].shape\n",
    "input_shape = (batch_shape[1],batch_shape[2],batch_shape[3])\n",
    "out_dims = int(train_gen[0][1].shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6a2909",
   "metadata": {},
   "source": [
    "### Set the checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b62fcf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpoint_filepath = str(mp)+'/chk-{epoch:02d}-{val_loss:.5e}.hdf5'\n",
    "chkpoint_model = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = chkpoint_filepath,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"min\",\n",
    "    save_freq=\"epoch\",\n",
    "    options=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2430e279",
   "metadata": {},
   "source": [
    "### Redefine the model parameters if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceb00f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name = 'full_3bin'\n",
    "hparams= {'KN1':32,'KN2':64,'KN3':128, 'KN4':128, 'KN5':256,'D1':128,'D2':512,'LAT':2,'LR':0.00001, 'B':1}\n",
    "\n",
    "vae_model = create_vae_model(hparams)\n",
    "info[sample_name] = {'rebin': rebin_factor, 'hparams':hparams}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05ca6a1",
   "metadata": {},
   "source": [
    "### Will be helpful to start with a trained model so set one here (otherwise will just take longer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d2b80f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model = '/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_123232/Final_Models/full_3bin_best_model.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468f2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model.load_weights(old_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e0450d",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c34e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = vae_model.fit(train_gen, validation_data=valid_gen, epochs=2000, callbacks= [chkpoint_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e2a6b8",
   "metadata": {},
   "source": [
    "### If the training has exitted correctly you can delete the intermediate checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cea21a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cps = mp.walk('.hdf5')\n",
    "best_model_ind = np.asarray([float(str(i).split('-')[-1].split('.hd')[0]) for i in cps]).argmin()\n",
    "best_model = cps[best_model_ind]\n",
    "for x, mod in enumerate(cps):\n",
    "    if x != best_model_ind:\n",
    "        mod.unlink()\n",
    "print('cleared')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ce5eae",
   "metadata": {},
   "source": [
    "### You can then resave this model in a different folder along with the model architecture information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5318af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model.load_weights(best_model)\n",
    "\n",
    "final_path = Path('/'.join(str(mp).split('/')[:-1]) + '/Final_Models')\n",
    "\n",
    "if not final_path.exists():\n",
    "    final_path.mkdir()\n",
    "\n",
    "new_name = str(final_path) + f'/{sample_name}_best_model.hdf5'\n",
    "\n",
    "best_model.rename(new_name)\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'{final_path}/{sample_name}_info.json', 'w') as f:\n",
    "    json.dump(info, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98cf3fa",
   "metadata": {},
   "source": [
    "### Done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf52832b",
   "metadata": {},
   "source": [
    "# If you want to train them all sequentially this for loop should work the same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c710acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:hdf5plugin:blosc filter already loaded, skip it.\n",
      "WARNING:hdf5plugin:bshuf filter already loaded, skip it.\n",
      "WARNING:hdf5plugin:lz4 filter already loaded, skip it.\n",
      "WARNING:hdf5plugin:zfp filter already loaded, skip it.\n",
      "WARNING:hdf5plugin:fcidecomp filter already loaded, skip it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow v2.3.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "dp = Path('/dls/e02/data/2021/mg28749-1/processing/Calibrated')\n",
    "\n",
    "dl = dp.ls()\n",
    "dl\n",
    "\n",
    "#set your starting pretrained model here - each subsequent model will retrain off the previous\n",
    "new_name = '/dls/e02/data/2021/mg28749-1/processing/Calibrated/20210925_123232/Final_Models/full_3bin_best_model.hdf5'\n",
    "\n",
    "for select in range(31, len(dl)):\n",
    "    dp = dl[select].walk('.hdf5', 'Model')[0]\n",
    "\n",
    "    mp = Path('/'.join(str(dp).split('/')[:-1])+'/CropModel')\n",
    "    if not mp.exists():\n",
    "        mp.mkdir()\n",
    "\n",
    "    ds = hs.load(dp)\n",
    "    s = ds.data.shape\n",
    "\n",
    "    info = {}\n",
    "\n",
    "    rebin_factor = 3\n",
    "\n",
    "    ds = ds.rebin(None, [rebin_factor,rebin_factor,1,1])\n",
    "\n",
    "    ds.data = ds.data/(rebin_factor*rebin_factor)\n",
    "\n",
    "\n",
    "    input_data = data_manip(flatten_nav(ds.data))\n",
    "    filenames_shuffled = [x for x in shuffle(input_data,input_data)]\n",
    "    filenames_shuffled_numpy = np.array(filenames_shuffled[0])\n",
    "    labels_shuffled_numpy = np.array(filenames_shuffled[1])\n",
    "\n",
    "    X_train, X_val, Y_train, Y_val = filenames_shuffled_numpy, labels_shuffled_numpy, filenames_shuffled_numpy, labels_shuffled_numpy\n",
    "    print(X_train.shape) # (3800,)\n",
    "    print(Y_train.shape)           # (3800, 12)\n",
    "\n",
    "    print(X_val.shape)   # (950,)\n",
    "    print(Y_val.shape)             # (950, 12)\n",
    "\n",
    "    batch_size = 1024\n",
    "\n",
    "    train_gen = Array_Generator(X_train, batch_size)\n",
    "    valid_gen = Array_Generator(X_val, batch_size)\n",
    "\n",
    "    batch_shape = train_gen[0][0].shape\n",
    "    input_shape = (batch_shape[1],batch_shape[2],batch_shape[3])\n",
    "    out_dims = int(train_gen[0][1].shape[1])\n",
    "\n",
    "    chkpoint_filepath = str(mp)+'/chk-{epoch:02d}-{val_loss:.5e}.hdf5'\n",
    "    chkpoint_model = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath = chkpoint_filepath,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        mode=\"min\",\n",
    "        save_freq=\"epoch\",\n",
    "        options=None)\n",
    "\n",
    "\n",
    "    hparams= {'KN1':32,'KN2':64,'KN3':128, 'KN4':128, 'KN5':256,'D1':128,'D2':512,'LAT':2,'LR':0.00001, 'B':1}\n",
    "\n",
    "    vae_model = create_vae_model(hparams)\n",
    "\n",
    "    sample_name = 'full_3bin'\n",
    "    info[sample_name] = {'rebin': rebin_factor, 'hparams':hparams}\n",
    "    #info[sample_name] = {'cxl':cxl, 'cxu':cxu,'cyl':cyl, 'cyu': cyu, 'rebin': rebin_factor, 'hparams':hparams}\n",
    "\n",
    "    vae_model.load_weights(new_name)\n",
    "\n",
    "    history = vae_model.fit(train_gen, validation_data=valid_gen, epochs=2000, callbacks= [chkpoint_model])\n",
    "    print('get cps')\n",
    "    cps = mp.walk('.hdf5')\n",
    "    best_model_ind = np.asarray([float(str(i).split('-')[-1].split('.hd')[0]) for i in cps]).argmin()\n",
    "    best_model = cps[best_model_ind]\n",
    "    for x, mod in enumerate(cps):\n",
    "        if x != best_model_ind:\n",
    "            mod.unlink()\n",
    "    print('cleared')\n",
    "\n",
    "    vae_model.load_weights(best_model)\n",
    "\n",
    "    final_path = Path('/'.join(str(mp).split('/')[:-1]) + '/Final_Models')\n",
    "\n",
    "    if not final_path.exists():\n",
    "        final_path.mkdir()\n",
    "\n",
    "    new_name = str(final_path) + f'/{sample_name}_best_model.hdf5'\n",
    "\n",
    "    best_model.rename(new_name)\n",
    "\n",
    "    import json\n",
    "\n",
    "    with open(f'{final_path}/{sample_name}_info.json', 'w') as f:\n",
    "        json.dump(info, f)\n",
    "        \n",
    "    input_data = None\n",
    "    filenames_shuffled = None\n",
    "    filenames_shuffled_numpy = None\n",
    "    labels_shuffled_numpy = None\n",
    "\n",
    "    X_train, X_val, Y_train, Y_val = None, None, None, None\n",
    "    input_data = None\n",
    "    train_gen = None\n",
    "    valid_gen = None\n",
    "    vae_model = None\n",
    "    history = None\n",
    "    \n",
    "    time.sleep(10)\n",
    "    print('next')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 - EPSIC [DLS Conda]",
   "language": "python",
   "name": "conda-env-DLS_Conda-epsic3.7-kernel.json"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
